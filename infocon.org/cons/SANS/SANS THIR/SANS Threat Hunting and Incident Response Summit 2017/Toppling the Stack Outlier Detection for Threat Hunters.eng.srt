1
00:00:01,601 --> 00:00:04,270
(intense music)

2
00:00:09,642 --> 00:00:11,478
(audience applauds)

3
00:00:11,478 --> 00:00:12,312
- Alright.

4
00:00:13,880 --> 00:00:15,782
Thanks, everybody.

5
00:00:15,782 --> 00:00:18,852
As Rob said, you may not
have heard of me today.

6
00:00:18,852 --> 00:00:22,889
My name is David
Bianco (laughs).

7
00:00:22,889 --> 00:00:25,892
I will tell you a little bit.

8
00:00:25,892 --> 00:00:27,894
I find this a little bit
embarrassing, actually,

9
00:00:27,894 --> 00:00:30,029
so I've decided that I'm
officially announcing

10
00:00:30,030 --> 00:00:33,433
I'm changing my
name to Rob J. Lee.

11
00:00:33,433 --> 00:00:36,269
(audience laughs)

12
00:00:40,974 --> 00:00:43,476
So, anyway, thanks for coming.

13
00:00:45,145 --> 00:00:48,515
I'm gonna give a little
bit different kind of talk

14
00:00:48,515 --> 00:00:50,884
then most of the other
things on the agenda

15
00:00:50,884 --> 00:00:54,320
and it's also a little bit
different than the kind

16
00:00:54,320 --> 00:00:56,756
of talks that I usually give.

17
00:00:59,059 --> 00:01:02,495
I'm gonna do something
super micro-focused

18
00:01:04,864 --> 00:01:07,367
and I apologize if
there are people in here

19
00:01:07,367 --> 00:01:08,735
who may not be
interested in this

20
00:01:08,735 --> 00:01:11,905
but I think it's kind
of an important topic.

21
00:01:11,905 --> 00:01:12,739
I want to,

22
00:01:14,507 --> 00:01:16,876
in my professional career,

23
00:01:16,876 --> 00:01:20,447
help people do better
at finding bad things

24
00:01:21,748 --> 00:01:24,818
on their network and
defending their organizations.

25
00:01:24,818 --> 00:01:28,154
That's my main career
goal at this point

26
00:01:29,055 --> 00:01:31,224
and, as part of that,

27
00:01:31,224 --> 00:01:34,494
I run this side project website

28
00:01:34,494 --> 00:01:36,830
called the
ThreatHunting Project,

29
00:01:36,830 --> 00:01:38,530
threadhunting.net, by the way,

30
00:01:38,531 --> 00:01:41,201
should be pretty
easy to remember

31
00:01:41,201 --> 00:01:43,970
and what I do on the
ThreatHunting Project is

32
00:01:43,970 --> 00:01:46,739
I look online to find
all the different places

33
00:01:46,739 --> 00:01:49,843
people are talking about
how they do threat hunting.

34
00:01:49,843 --> 00:01:52,078
Like what threat hunting things,

35
00:01:52,078 --> 00:01:54,013
procedures they're following.

36
00:01:54,013 --> 00:01:54,981
What's working for them,

37
00:01:54,981 --> 00:01:55,949
what are they trying to find,

38
00:01:55,949 --> 00:01:57,217
how they're trying to find it

39
00:01:57,217 --> 00:01:58,618
and I index them,

40
00:01:59,853 --> 00:02:02,354
such that, any one
of you could go to

41
00:02:02,355 --> 00:02:05,792
threathunting.net and say,
I'm interested in doing

42
00:02:05,792 --> 00:02:08,561
some threat hunting, I'm
not sure where to start,

43
00:02:08,561 --> 00:02:11,998
what kind of hunts are out
there that I can just implement?

44
00:02:11,998 --> 00:02:14,267
I can read about other people
did it and implement it

45
00:02:14,267 --> 00:02:18,471
in my organization or maybe
I'm interested in finding

46
00:02:18,471 --> 00:02:22,041
lateral movement
in my environment,

47
00:02:22,041 --> 00:02:23,877
what hunts do you
have for me that have

48
00:02:23,877 --> 00:02:26,946
to do with lateral
movement, things like that

49
00:02:26,946 --> 00:02:29,048
and as part of my index product,

50
00:02:29,048 --> 00:02:32,418
I go through and I
kind of extract out

51
00:02:32,418 --> 00:02:37,257
the pieces of information
out of the original sources

52
00:02:37,257 --> 00:02:39,025
that you would let
you know, basically,

53
00:02:39,025 --> 00:02:41,494
what this is about and if
it's interesting to you

54
00:02:41,494 --> 00:02:43,663
and then if it is,
you can click through

55
00:02:43,663 --> 00:02:47,767
to go to the original
source for full details

56
00:02:47,767 --> 00:02:50,503
and one of the things I
extract out of this is

57
00:02:50,503 --> 00:02:55,241
the technical mechanisms that
you need to be familiar with

58
00:02:55,241 --> 00:02:57,844
to do the analysis piece

59
00:02:57,844 --> 00:03:00,880
and many of these, most of them,

60
00:03:00,880 --> 00:03:04,716
have something to do
with finding the outliers

61
00:03:06,019 --> 00:03:08,154
inside your data.

62
00:03:08,154 --> 00:03:11,991
The odd data points in
this sea of data points

63
00:03:16,829 --> 00:03:20,500
and I noticed, as I was
going through there,

64
00:03:21,601 --> 00:03:23,369
that we're apparently

65
00:03:24,704 --> 00:03:28,741
not very diverse in our
mechanisms for finding outliers.

66
00:03:31,110 --> 00:03:34,347
In fact, almost every single
thing that I have in there

67
00:03:34,347 --> 00:03:37,584
that needs to find
outliers uses the same

68
00:03:37,584 --> 00:03:40,553
outlier detection mechanism

69
00:03:40,553 --> 00:03:43,890
and it's a good mechanism
for certain things,

70
00:03:43,890 --> 00:03:46,125
it's not good for
certain other things

71
00:03:46,125 --> 00:03:48,127
but we try to use it anyway

72
00:03:48,127 --> 00:03:49,329
and so I thought,

73
00:03:49,329 --> 00:03:50,997
maybe what I would do

74
00:03:50,997 --> 00:03:54,267
was spend my time,
instead of talking about

75
00:03:54,267 --> 00:03:58,704
macro-views of why do
we hunt, how do we hunt,

76
00:03:58,705 --> 00:04:01,407
I want to talk a
little bit about

77
00:04:01,407 --> 00:04:03,843
how we can do a better
job in a specific

78
00:04:03,843 --> 00:04:08,314
piece of the threat
hunting, which is finding

79
00:04:08,314 --> 00:04:12,484
data points that are somewhat
unusual for some reason.

80
00:04:16,422 --> 00:04:19,125
So, I'm gonna talk about

81
00:04:19,125 --> 00:04:20,994
several different techniques,

82
00:04:20,994 --> 00:04:23,696
some which are not new to you,

83
00:04:23,696 --> 00:04:25,898
some of which might
be new to you,

84
00:04:25,898 --> 00:04:30,036
one of which is almost
certainly new to you

85
00:04:30,036 --> 00:04:34,474
and some of these things
that you may have seen.

86
00:04:34,474 --> 00:04:37,310
You may have learned some of
these in high school science,

87
00:04:37,310 --> 00:04:41,481
for example, but maybe just
a reminder of the technique,

88
00:04:44,617 --> 00:04:48,021
some points about when
you could consider

89
00:04:48,021 --> 00:04:50,356
using this technique and
when maybe you should

90
00:04:50,356 --> 00:04:52,392
consider doing something else

91
00:04:52,392 --> 00:04:54,894
and even in all of these cases,

92
00:04:54,894 --> 00:04:57,964
I will show you a little
bit of implementation

93
00:04:57,964 --> 00:05:00,833
of that mechanism
in usually Python

94
00:05:02,101 --> 00:05:05,238
but don't worry, it's
not a coding challenge.

95
00:05:05,238 --> 00:05:07,373
It's mostly there
for later on when you

96
00:05:07,373 --> 00:05:09,242
want to come through
and read the slides

97
00:05:09,242 --> 00:05:13,413
after the conference, you
will have a tiny, tiny

98
00:05:13,413 --> 00:05:14,614
bit of source code.

99
00:05:14,614 --> 00:05:16,616
Right now, today, I
just want you to kind of

100
00:05:16,616 --> 00:05:19,952
look at the size, like none
of these really require

101
00:05:19,952 --> 00:05:21,821
very much coding at all

102
00:05:21,821 --> 00:05:24,457
but they can be
really useful for you.

103
00:05:24,457 --> 00:05:27,159
So the first one, the first
technique that we've seen

104
00:05:27,160 --> 00:05:31,197
already today, so Michelle
and Maxine mentioned

105
00:05:31,197 --> 00:05:34,300
some things about it in
their presentation earlier.

106
00:05:34,300 --> 00:05:38,705
It's called Least Frequency
of Occurrence analysis.

107
00:05:38,705 --> 00:05:41,873
We also, it's probably
much more well known

108
00:05:41,874 --> 00:05:46,813
in this industry, in this
room, by it's other name,

109
00:05:46,813 --> 00:05:49,048
stack counting or stacking.

110
00:05:50,316 --> 00:05:52,919
Who does stack counting?

111
00:05:52,919 --> 00:05:55,121
Everybody probably
should raise their hand.

112
00:05:55,121 --> 00:05:57,022
The trick is, the lights
are shining in my eyes

113
00:05:57,023 --> 00:06:00,893
so I have no idea who
raised their hand or not

114
00:06:00,893 --> 00:06:03,462
but the basic idea
is really simple,

115
00:06:03,463 --> 00:06:06,866
you just take a data column
that you're interested in

116
00:06:06,866 --> 00:06:11,537
and you find all the unique
values in that column

117
00:06:11,537 --> 00:06:15,274
and you count how
many times that that,

118
00:06:15,274 --> 00:06:18,611
each unique value occurs
and you sort by that count

119
00:06:18,611 --> 00:06:22,081
and so, here's an
example that we have,

120
00:06:22,081 --> 00:06:25,651
a synthetic data set from
CERT/CC Insider Threat

121
00:06:25,651 --> 00:06:29,122
Dataset that basically just
says here's some counts

122
00:06:29,122 --> 00:06:32,759
of the files that
people have read.

123
00:06:32,759 --> 00:06:36,195
Show me the ones that people
don't read very often,

124
00:06:36,195 --> 00:06:38,865
like maybe that's a suspicious,

125
00:06:38,865 --> 00:06:42,869
somebody going out and
just gathering lots of data

126
00:06:42,869 --> 00:06:44,737
that no one has ever
accessed but they're just

127
00:06:44,737 --> 00:06:46,205
sucking it all up, right,

128
00:06:46,205 --> 00:06:47,907
and you can see, we start
with a bunch of ones

129
00:06:47,907 --> 00:06:50,743
that only one person's
read and then we get

130
00:06:50,743 --> 00:06:53,980
up to a few that a
couple people have read

131
00:06:53,980 --> 00:06:55,915
and it's really simple.

132
00:06:57,250 --> 00:06:59,519
So here's the first
of our code fragments.

133
00:06:59,519 --> 00:07:02,989
This one is so super
simple that it is basically

134
00:07:02,989 --> 00:07:06,525
in almost every kind
of database system

135
00:07:06,526 --> 00:07:10,930
or threat hunting product,
can do stack counting.

136
00:07:10,930 --> 00:07:15,101
So the first you see, just
regular relational database SQL.

137
00:07:17,136 --> 00:07:20,006
It's basically group
by and then order by

138
00:07:20,006 --> 00:07:21,573
but you can do this in Splunk,

139
00:07:21,574 --> 00:07:24,310
they have an easy
way of doing it

140
00:07:24,310 --> 00:07:27,980
and Python has an
easy way of doing it.

141
00:07:27,980 --> 00:07:30,650
It's not really complicated,

142
00:07:30,650 --> 00:07:32,051
it's really easy to understand

143
00:07:32,051 --> 00:07:33,719
and it's really
easy to implement,

144
00:07:33,719 --> 00:07:37,390
which I think is really
why it's so popular.

145
00:07:38,658 --> 00:07:41,928
So, but let's look at
some of the use cases,

146
00:07:41,928 --> 00:07:43,896
why you would want to
use this and maybe some

147
00:07:43,896 --> 00:07:46,966
where maybe you should try
to do something different.

148
00:07:46,966 --> 00:07:49,802
So, first of all,
yeah, obviously

149
00:07:49,802 --> 00:07:51,003
we're stack counting things,

150
00:07:51,003 --> 00:07:52,438
we're looking for unique values,

151
00:07:52,438 --> 00:07:55,241
so this kind of implies that

152
00:07:55,241 --> 00:07:57,210
the things that
you're looking at

153
00:07:57,210 --> 00:08:00,179
need to be something
where you can actually

154
00:08:00,179 --> 00:08:03,950
look at enumerated types
or categorical values

155
00:08:05,685 --> 00:08:07,854
or strings or
something where there's

156
00:08:07,854 --> 00:08:12,024
not like an infinite number
of different values in there.

157
00:08:13,392 --> 00:08:16,162
In our case, we were looking
at file name strings,

158
00:08:16,162 --> 00:08:19,397
so it's pretty easy
to say, in this set,

159
00:08:19,398 --> 00:08:21,634
how many different
strings do you have

160
00:08:21,634 --> 00:08:24,637
and then count them all, right?

161
00:08:24,637 --> 00:08:28,407
It also works best when
rarity is suspicious,

162
00:08:29,575 --> 00:08:31,377
which is not always the case.

163
00:08:31,377 --> 00:08:34,714
Sometimes, many times rare
values are just normal

164
00:08:34,714 --> 00:08:38,518
things hanging out but
when you do something,

165
00:08:38,518 --> 00:08:42,154
I think Michelle
was talking about

166
00:08:42,154 --> 00:08:46,125
rare HTTP user agents,
which is actually, I think,

167
00:08:46,125 --> 00:08:49,929
one of the classics
of threat hunting,

168
00:08:49,929 --> 00:08:52,698
rarest HTTP user
agents check those out

169
00:08:52,698 --> 00:08:55,668
because they might be
somebody who has installed

170
00:08:55,668 --> 00:08:57,336
a program that
they shouldn't have

171
00:08:57,336 --> 00:08:59,472
or it might be a malware
author who has made a mistake

172
00:08:59,472 --> 00:09:02,475
in emulating an
actual user agent and

173
00:09:03,910 --> 00:09:08,046
rarity, in that case, may
very well be suspicious.

174
00:09:09,282 --> 00:09:13,019
We also saw, by the way,
kind of the opposite

175
00:09:14,020 --> 00:09:17,323
of this analysis technique when,

176
00:09:17,323 --> 00:09:21,861
I'm sorry, I forget if
it was Maxine or Michelle

177
00:09:21,861 --> 00:09:23,896
were talking about
building the baselines

178
00:09:23,896 --> 00:09:25,464
where they actually
did the opposite

179
00:09:25,464 --> 00:09:28,301
and they looked for the
most frequent appearance,

180
00:09:28,301 --> 00:09:31,170
so high frequency
occurrence analysis.

181
00:09:31,170 --> 00:09:33,606
They said the most common things

182
00:09:33,606 --> 00:09:36,242
are the least suspicious, right?

183
00:09:36,242 --> 00:09:40,212
It's basically, it's exact
same analysis technique

184
00:09:40,212 --> 00:09:44,383
with just like the greater
than sign flipped for the sort.

185
00:09:46,619 --> 00:09:49,822
Now, this has some
substantial weaknesses though.

186
00:09:49,822 --> 00:09:51,824
First of all, I think
it's kind of obvious,

187
00:09:51,824 --> 00:09:55,493
when you're working with
non-categorical data,

188
00:09:55,494 --> 00:09:59,665
like numbers, numbers don't
tend to stack count very well.

189
00:10:02,168 --> 00:10:04,003
Some things that
look like numbers,

190
00:10:04,003 --> 00:10:06,138
like TCP port numbers may

191
00:10:06,138 --> 00:10:08,708
but they're not really numbers.

192
00:10:11,477 --> 00:10:13,545
It's also a little
bit more difficult

193
00:10:13,546 --> 00:10:17,717
when you get into more than
one data field per data point.

194
00:10:18,884 --> 00:10:21,520
So, it's possible
to say, for example,

195
00:10:21,520 --> 00:10:24,890
stack count on multiple
columns of the same row,

196
00:10:24,890 --> 00:10:26,826
but the more columns
that you add to that,

197
00:10:26,826 --> 00:10:30,963
the harder it is, basically,
to do that stack counting

198
00:10:30,963 --> 00:10:33,632
but the last two things
here on this slide

199
00:10:33,633 --> 00:10:36,602
are the ones that I think
are the most critical

200
00:10:36,602 --> 00:10:38,437
weaknesses of this approach.

201
00:10:38,437 --> 00:10:42,608
First of all, it's hard to
take that stack counted thing

202
00:10:43,843 --> 00:10:46,512
and turn it into an
automated detection.

203
00:10:46,512 --> 00:10:49,949
One of the things that I like
to see out of threat hunting

204
00:10:49,949 --> 00:10:54,219
is the drive toward automation
of successful hunts,

205
00:10:54,220 --> 00:10:56,622
maybe we won't always get there

206
00:10:56,622 --> 00:10:58,424
and this is an example
of where it's gonna

207
00:10:58,424 --> 00:11:00,126
be hard to get fully automated,

208
00:11:00,126 --> 00:11:03,062
mostly what people end up
doing with stack counting

209
00:11:03,062 --> 00:11:05,731
is they put them into dashboards

210
00:11:07,433 --> 00:11:10,403
and that long tail of results

211
00:11:10,403 --> 00:11:14,573
in a big data set, you're
going to get a lot of rarities.

212
00:11:15,708 --> 00:11:19,011
I say use this when
rarity equals suspicion

213
00:11:20,513 --> 00:11:25,051
but, in fact, rarity usually
does not equal suspicion.

214
00:11:25,051 --> 00:11:28,421
Rarity might be one small
indicator of suspicion,

215
00:11:28,421 --> 00:11:32,625
but in a typical enterprise,
there are maybe hundreds

216
00:11:33,726 --> 00:11:36,929
of unique, for example,
HTTP user agents,

217
00:11:40,599 --> 00:11:44,837
but most of those hundreds
are actually legitimate

218
00:11:44,837 --> 00:11:47,907
or at least benign, not
things that you care about

219
00:11:47,907 --> 00:11:51,077
so you potentially have
a long tail of results

220
00:11:51,077 --> 00:11:53,212
to go through here
and it's gonna be hard

221
00:11:53,212 --> 00:11:56,082
for the automation to kind
of help you weed those out

222
00:11:56,082 --> 00:11:57,550
just with stack counting.

223
00:11:57,550 --> 00:11:59,017
Now, having said that,

224
00:11:59,018 --> 00:12:00,886
there are certain
circumstances, I think,

225
00:12:00,886 --> 00:12:02,420
which are great
for stack counting,

226
00:12:02,421 --> 00:12:03,823
so here at the
bottom of the slide,

227
00:12:03,823 --> 00:12:06,826
I have probably one
of the ones that

228
00:12:08,060 --> 00:12:09,962
is an almost perfect
fit for stack counting.

229
00:12:09,962 --> 00:12:14,400
I've never seen this
service on any of my devices

230
00:12:14,400 --> 00:12:17,502
across my large network
and so therefore,

231
00:12:17,503 --> 00:12:19,905
if one or two or three of them

232
00:12:19,905 --> 00:12:21,473
come up with a new
service one day,

233
00:12:21,474 --> 00:12:23,876
that's kind of suspicious
and I wanna know about it.

234
00:12:23,876 --> 00:12:25,578
So think about this when
you're thinking about

235
00:12:25,578 --> 00:12:27,913
whether you should
use stack counting.

236
00:12:27,913 --> 00:12:32,618
How close does that sound to
a problem statement like this?

237
00:12:32,618 --> 00:12:36,489
If it's really close, it
might be a really good way

238
00:12:36,489 --> 00:12:38,023
to do your analysis.

239
00:12:38,023 --> 00:12:41,761
The farther it gets away from
that kind of statement though,

240
00:12:41,761 --> 00:12:45,430
the least likely it
is that stack counting

241
00:12:45,431 --> 00:12:48,100
or least frequency of
occurrence is the thing

242
00:12:48,100 --> 00:12:50,202
that you should be doing.

243
00:12:53,739 --> 00:12:57,209
Now, the next couple
I wanna talk about

244
00:12:57,209 --> 00:12:58,911
are visualizations.

245
00:12:58,911 --> 00:13:03,649
So, maybe not intended
entirely or really directly for

246
00:13:03,649 --> 00:13:06,619
automation but they're part
of the analysis process

247
00:13:06,619 --> 00:13:08,921
that will get you to be able to

248
00:13:08,921 --> 00:13:10,923
figure out how to automate this.

249
00:13:10,923 --> 00:13:14,093
The human brain is
really, really good

250
00:13:17,062 --> 00:13:20,266
at taking in a lot
of data visually

251
00:13:20,266 --> 00:13:23,435
and making a quick
decision about that.

252
00:13:23,435 --> 00:13:25,537
Chris Sanders is
somewhere in here,

253
00:13:25,538 --> 00:13:28,874
he's our industry's expert
in this now, I think and

254
00:13:28,874 --> 00:13:32,211
he'd probably tell
you a lot about this.

255
00:13:35,414 --> 00:13:39,585
I'm not pursuing my PhD
in cognitive psychology so

256
00:13:41,020 --> 00:13:43,289
I will defer to him but
I think he would probably

257
00:13:43,289 --> 00:13:46,391
agree with me that
one way to kind of

258
00:13:47,827 --> 00:13:51,363
get the full brain engaged
in making some of these

259
00:13:51,363 --> 00:13:54,066
outlier decisions is to
show things visually.

260
00:13:54,066 --> 00:13:55,835
We're very good at it.

261
00:13:55,835 --> 00:14:00,372
Look at that piece of toast
and tell me what you see.

262
00:14:00,372 --> 00:14:01,507
No, I mean it.

263
00:14:02,875 --> 00:14:05,678
Tell me what's on that toast.

264
00:14:05,678 --> 00:14:06,879
(audience member mumbles)

265
00:14:06,879 --> 00:14:08,113
Yeah, I hear Elvis.

266
00:14:08,113 --> 00:14:09,615
Yeah and if you
didn't see Elvis,

267
00:14:09,615 --> 00:14:14,520
you probably cannot unsee
Elvis now on that toast.

268
00:14:14,520 --> 00:14:17,256
Our brains are so
hardwired to find patterns

269
00:14:17,256 --> 00:14:21,427
that we can literally see
Elvis on what is actually

270
00:14:22,728 --> 00:14:24,396
random toast, right?

271
00:14:25,297 --> 00:14:27,333
And the best thing about that is

272
00:14:27,333 --> 00:14:29,235
when we're so good at
finding the patterns,

273
00:14:29,235 --> 00:14:31,303
it kind of implies that
we have some ability

274
00:14:31,303 --> 00:14:35,474
to find the pieces that don't
fall into the pattern as well.

275
00:14:36,876 --> 00:14:40,379
So, let me talk a little
bit first about just

276
00:14:40,379 --> 00:14:42,648
the basic scatter plot.

277
00:14:42,648 --> 00:14:44,950
I think the basic scatter
plot does not get enough love

278
00:14:44,950 --> 00:14:48,454
in the threat hunting community.

279
00:14:48,454 --> 00:14:50,589
Alex Pinto talked about

280
00:14:50,589 --> 00:14:53,559
this particular plot earlier
during this presentation.

281
00:14:53,559 --> 00:14:55,060
He mentioned it briefly.

282
00:14:55,060 --> 00:14:58,964
He said he really liked this
example of threat hunting.

283
00:14:58,964 --> 00:15:01,000
This is, I won't go
into the whole thing,

284
00:15:01,000 --> 00:15:02,735
I tweeted the link
to the blog post that

285
00:15:02,735 --> 00:15:04,770
this was taken from earlier,
if you wanna read it,

286
00:15:04,770 --> 00:15:07,106
but I'm basically looking to see

287
00:15:07,106 --> 00:15:09,475
who might have changed,

288
00:15:09,475 --> 00:15:12,077
which hosts on the
network might have changed

289
00:15:12,077 --> 00:15:15,981
their ratio of bytes that
they send to the internet

290
00:15:15,981 --> 00:15:19,785
versus bytes they download
from the internet,

291
00:15:19,785 --> 00:15:22,820
as a way of looking
for who's acting oddly

292
00:15:22,821 --> 00:15:26,058
and maybe starting
some data exfiltration.

293
00:15:26,058 --> 00:15:29,295
So, what I've done is
I've basically computed,

294
00:15:29,295 --> 00:15:33,464
they call it the
producer/consumer ratio metric

295
00:15:34,833 --> 00:15:37,969
for each host in the
data set and then

296
00:15:37,970 --> 00:15:40,739
on one axis I have
last week's value

297
00:15:40,739 --> 00:15:43,008
and the other axis I
have this week's value

298
00:15:43,008 --> 00:15:46,345
and if there's no change,
they fall along this

299
00:15:46,345 --> 00:15:48,013
diagonal line,
right in the middle

300
00:15:48,013 --> 00:15:49,415
and you can see, there's
a number of hosts

301
00:15:49,415 --> 00:15:50,882
that fall very
close to that line,

302
00:15:50,883 --> 00:15:53,953
most of them fall kind of close,

303
00:15:53,953 --> 00:15:57,423
but visually, you can
kind of see some outliers

304
00:15:57,423 --> 00:15:59,191
and I have highlighted
them a little bit

305
00:15:59,191 --> 00:16:02,962
by color coding so the
more positive they are,

306
00:16:02,962 --> 00:16:05,597
the more data they've been
sending to the internet,

307
00:16:05,597 --> 00:16:07,566
the more red they
are and the more data

308
00:16:07,566 --> 00:16:10,669
that they changed receiving
data from the internet,

309
00:16:10,669 --> 00:16:13,172
the more blue they are.

310
00:16:13,172 --> 00:16:14,974
I'm, in this particular
case, not concerned

311
00:16:14,974 --> 00:16:16,542
with the blue data.

312
00:16:16,542 --> 00:16:18,477
I'm more concerned
with the red data,

313
00:16:18,477 --> 00:16:20,411
so it happens that the most

314
00:16:20,412 --> 00:16:23,649
red host jumps out
at you pretty easily

315
00:16:25,084 --> 00:16:26,718
just by looking at this thing

316
00:16:26,719 --> 00:16:31,423
and it would not really
be an easy thing to do,

317
00:16:31,423 --> 00:16:33,592
just looking at a
column of numbers.

318
00:16:33,592 --> 00:16:35,060
Yeah, you could sort of
the column of numbers

319
00:16:35,060 --> 00:16:38,030
but it doesn't really give
you as much of an idea

320
00:16:38,030 --> 00:16:41,033
of how different it is and
whether you should really care

321
00:16:41,033 --> 00:16:43,635
because there are a number
of ones that are over

322
00:16:43,635 --> 00:16:46,071
or above, over the
line or below the line

323
00:16:46,071 --> 00:16:48,707
but you really need to
know the magnitude as well

324
00:16:48,707 --> 00:16:51,477
that they're away
from that line.

325
00:16:51,477 --> 00:16:53,746
So, just engaging the
brain a little bit

326
00:16:53,746 --> 00:16:56,215
to look at it visually,
a lot of times

327
00:16:56,215 --> 00:16:58,617
is the right thing to
do and can save you

328
00:16:58,617 --> 00:17:00,486
a lot of analysis time.

329
00:17:01,620 --> 00:17:04,490
Just as a simple example,

330
00:17:04,490 --> 00:17:08,727
I've been using this Python
library called Plotly

331
00:17:08,727 --> 00:17:10,362
'cause I like the way it
makes it's graphs look

332
00:17:10,362 --> 00:17:12,131
and it's pretty easy to use

333
00:17:12,131 --> 00:17:14,767
and you can see, I've
got it basically,

334
00:17:14,767 --> 00:17:16,568
I did that thing in
like six lines of code

335
00:17:16,568 --> 00:17:18,503
and it's only six lines
really 'cause I tried

336
00:17:18,503 --> 00:17:22,206
to make it readable and
separated things out.

337
00:17:22,207 --> 00:17:24,443
You could actually combine
all this into one line of code

338
00:17:24,443 --> 00:17:26,377
if you wanted to,

339
00:17:26,377 --> 00:17:29,348
so it's actually pretty simple.

340
00:17:29,348 --> 00:17:32,283
I'm not gonna go
into all this detail

341
00:17:32,284 --> 00:17:34,053
but it basically just says

342
00:17:34,053 --> 00:17:36,055
here's one axis of data points

343
00:17:36,055 --> 00:17:38,424
and here's one axis of data
points for the other axis

344
00:17:38,424 --> 00:17:39,825
and then plot it.

345
00:17:42,661 --> 00:17:44,897
That's the basic idea there
and most of the other things

346
00:17:44,897 --> 00:17:47,066
are making it look pretty.

347
00:17:48,233 --> 00:17:51,336
So, scatter plots then
are most useful when

348
00:17:51,336 --> 00:17:55,007
you have, first of all,
obviously, numeric data,

349
00:17:55,007 --> 00:17:58,677
not gonna help you if
everything is a string

350
00:18:00,112 --> 00:18:03,949
and usually when you have
two sets of numeric data

351
00:18:03,949 --> 00:18:07,219
that you want to
compare to each other.

352
00:18:10,756 --> 00:18:13,859
They're most useful
in two cases,

353
00:18:13,859 --> 00:18:16,562
one where your hypothesis is

354
00:18:16,562 --> 00:18:20,399
such that malicious
activity will violate

355
00:18:20,399 --> 00:18:22,501
some clear visual correlation.

356
00:18:22,501 --> 00:18:24,870
In my case it was,
they fall on the line

357
00:18:24,870 --> 00:18:26,972
but here may be other
cases where they are

358
00:18:26,972 --> 00:18:31,877
a curve or you would say,
everything should cluster into

359
00:18:31,877 --> 00:18:36,348
say three main clusters
of points on the graph

360
00:18:36,348 --> 00:18:38,817
and you're looking
for things that don't

361
00:18:38,817 --> 00:18:41,687
fall on that line or
that curve or that are

362
00:18:41,687 --> 00:18:43,822
clearly far from any
other established cluster,

363
00:18:43,822 --> 00:18:45,256
things like that.

364
00:18:46,692 --> 00:18:49,161
So that's the first use case
where it's really good at.

365
00:18:49,161 --> 00:18:51,630
The second use case is
actually when you're not sure

366
00:18:51,630 --> 00:18:54,566
if there is a correlation and
if there is a correlation,

367
00:18:54,566 --> 00:18:56,001
what it might be.

368
00:18:57,436 --> 00:19:00,239
It's actually really nice
to just be able to say,

369
00:19:00,239 --> 00:19:02,207
are these things
correlated at all?

370
00:19:02,207 --> 00:19:04,243
I don't know, let's put
them on a scatter plot

371
00:19:04,243 --> 00:19:07,212
and if we see a line or
a pattern of some sort,

372
00:19:07,212 --> 00:19:09,681
we can engage that
brain to identify

373
00:19:09,681 --> 00:19:12,317
what that pattern might be
and if there is no pattern

374
00:19:12,317 --> 00:19:16,255
you'll see, most likely,
a random distribution,

375
00:19:17,356 --> 00:19:20,025
like static on a old TV channel,

376
00:19:22,761 --> 00:19:24,963
but, of course,
like all of these,

377
00:19:24,963 --> 00:19:26,298
it has some weaknesses too.

378
00:19:26,298 --> 00:19:27,533
First of all, I already said,

379
00:19:27,533 --> 00:19:29,901
if you're not working
with numeric data,

380
00:19:29,902 --> 00:19:33,639
you're probably not gonna
be doing a scatter plot.

381
00:19:33,639 --> 00:19:36,341
It also is kind of weak if

382
00:19:36,341 --> 00:19:40,512
the correlation is not really
a fairly strong correlation.

383
00:19:40,512 --> 00:19:41,812
If it's a very weak correlation,

384
00:19:41,813 --> 00:19:45,350
it may not be as easy
to find the outliers.

385
00:19:45,350 --> 00:19:48,620
Say instead of a line that
they would fall under,

386
00:19:48,620 --> 00:19:50,956
if they were in a wide band.

387
00:19:52,391 --> 00:19:56,328
That correlation might
be kind of iffy and weak

388
00:19:56,328 --> 00:19:58,163
and it would fall apart
at the edges of the band

389
00:19:58,163 --> 00:20:00,032
so it would be harder
to find out if things

390
00:20:00,032 --> 00:20:01,600
were actually in that band

391
00:20:01,600 --> 00:20:04,336
or if they were
outliers because,

392
00:20:04,336 --> 00:20:06,905
not a strong correlation

393
00:20:06,905 --> 00:20:10,209
and the other big
weakness is maybe you have

394
00:20:10,209 --> 00:20:13,412
data that needs to be
compared on more than two axis

395
00:20:13,412 --> 00:20:14,246
at a time,

396
00:20:15,480 --> 00:20:18,417
so if you do data analysis

397
00:20:18,417 --> 00:20:21,119
and you have a lot
of different fields

398
00:20:21,119 --> 00:20:24,689
it's actually common to take
all the different fields

399
00:20:24,690 --> 00:20:28,727
in combination and do a
matrix of scatter plots

400
00:20:28,727 --> 00:20:31,964
so you can see which fields
correlate with each other

401
00:20:31,964 --> 00:20:33,732
but that's not what I'm
really talking about here,

402
00:20:33,732 --> 00:20:35,367
I'm talking about
if, for example,

403
00:20:35,367 --> 00:20:39,638
you have four lines of data
that need to all go together,

404
00:20:39,638 --> 00:20:43,809
you can't really do that easily
on a typical scatter plot.

405
00:20:48,013 --> 00:20:51,483
In this case, again,
think of it like

406
00:20:51,483 --> 00:20:53,784
a near perfect case for
scatter plots would be

407
00:20:53,785 --> 00:20:56,588
what I had here, most
users don't change

408
00:20:56,588 --> 00:20:58,322
their upload habits, so
benign activity should

409
00:20:58,323 --> 00:21:00,158
fall close to the
no change line.

410
00:21:00,158 --> 00:21:03,762
The closer your problem
statement is to that

411
00:21:05,264 --> 00:21:07,632
model of a problem statement,

412
00:21:07,633 --> 00:21:09,968
the more likely it is
that you would find

413
00:21:09,968 --> 00:21:13,405
a scatter plot be useful to you.

414
00:21:13,405 --> 00:21:14,873
So, now let's talk
about something

415
00:21:14,873 --> 00:21:17,576
maybe some of you
have not really dealt

416
00:21:17,576 --> 00:21:19,044
with very much.

417
00:21:19,044 --> 00:21:23,382
The box plots, also called
box and whisker plots.

418
00:21:23,382 --> 00:21:27,185
Box and whisker plots are
really interesting because

419
00:21:27,185 --> 00:21:30,589
they get you a visualization
of the distribution

420
00:21:30,589 --> 00:21:33,558
of your data, the shape
of that column of data,

421
00:21:33,558 --> 00:21:37,829
as well as, they actually
show you some information

422
00:21:37,829 --> 00:21:42,067
that you can use to later
on, after you're done

423
00:21:42,067 --> 00:21:45,804
visualizing the problem,
compute the outliers

424
00:21:46,905 --> 00:21:48,173
in the data set.

425
00:21:48,173 --> 00:21:51,209
So, and you'll see, here we have

426
00:21:51,209 --> 00:21:52,711
two different versions of it.

427
00:21:52,711 --> 00:21:56,148
So let's talk about the blue
version here on the left first.

428
00:21:56,148 --> 00:21:58,684
What I've done is
I've taken a data set

429
00:21:58,684 --> 00:22:01,687
of command line
lengths for processes

430
00:22:02,988 --> 00:22:06,325
that were either
command.exe or PowerShell,

431
00:22:07,993 --> 00:22:09,127
in an environment.

432
00:22:09,127 --> 00:22:11,797
My hypothesis for this hunt was,

433
00:22:14,066 --> 00:22:16,535
especially with PowerShell,

434
00:22:16,535 --> 00:22:19,638
command, like attackers
trying to live off the land

435
00:22:19,638 --> 00:22:21,673
and use PowerShell
things in my environment

436
00:22:21,673 --> 00:22:23,642
to do their dirty work

437
00:22:23,642 --> 00:22:26,712
tend to have like,
long lines that have

438
00:22:26,712 --> 00:22:29,981
PowerShell scripts,
basically, built into them

439
00:22:29,981 --> 00:22:34,052
and so, I'm interested in
knowing whether I think

440
00:22:34,052 --> 00:22:37,356
I could use that
length of the line

441
00:22:37,356 --> 00:22:39,958
as a possible indicator
of maliciousness.

442
00:22:39,958 --> 00:22:42,427
So, the first thing I
wanted to kind of do

443
00:22:42,427 --> 00:22:45,796
is find out, what
is that distribution

444
00:22:45,797 --> 00:22:47,299
of that data look like?

445
00:22:47,299 --> 00:22:48,600
I have a bunch of data points,

446
00:22:48,600 --> 00:22:50,869
I'm not sure if this is
a thing that I should

447
00:22:50,869 --> 00:22:53,138
be looking for or if it's
a good enough indicator

448
00:22:53,138 --> 00:22:55,139
by itself, so what I did

449
00:22:56,341 --> 00:22:58,577
was I created a
box plot of it all

450
00:22:58,577 --> 00:23:00,846
and you can see I even have,

451
00:23:01,980 --> 00:23:05,050
I've a scatter plot
built into this box plot

452
00:23:05,050 --> 00:23:07,853
to kind of show you how
the box plot actually

453
00:23:07,853 --> 00:23:10,689
shows the shape of the data,

454
00:23:10,689 --> 00:23:14,626
so, first of all, it starts
with these two whiskers

455
00:23:14,626 --> 00:23:16,128
and that's really
what they're called,

456
00:23:16,128 --> 00:23:17,662
that's their technical
name, the whiskers,

457
00:23:17,662 --> 00:23:20,499
it's the minimum and
the maximum things

458
00:23:20,499 --> 00:23:21,833
in that data set

459
00:23:23,435 --> 00:23:26,071
and just pay attention
to these three lines here

460
00:23:26,071 --> 00:23:27,272
that make up the box.

461
00:23:27,272 --> 00:23:31,176
The bottom line is
the line at which 25%

462
00:23:31,176 --> 00:23:33,912
of the data points
fall below that line.

463
00:23:33,912 --> 00:23:38,083
The 25% line is also
called the first quartile

464
00:23:39,885 --> 00:23:43,355
but I rarely call it that
'cause I can't remember

465
00:23:43,355 --> 00:23:47,192
complicated statistics,
things like quartiles.

466
00:23:48,360 --> 00:23:52,264
The middle line here is
the line at which 50%

467
00:23:53,532 --> 00:23:56,601
of all the values fall below it

468
00:23:56,601 --> 00:23:58,603
and does anybody remember
what that's called,

469
00:23:58,603 --> 00:24:00,338
from high school?

470
00:24:00,338 --> 00:24:01,706
(audience member mumbles)

471
00:24:01,706 --> 00:24:03,375
Yeah, it's the median.

472
00:24:03,375 --> 00:24:05,343
So, if this is 25 and 50

473
00:24:05,343 --> 00:24:07,679
what do you think this is?

474
00:24:07,679 --> 00:24:09,948
75, the third quartile, right?

475
00:24:09,948 --> 00:24:11,349
Technically
speaking, by the way,

476
00:24:11,349 --> 00:24:15,053
they call the box from
the 25 to the 75 line

477
00:24:15,053 --> 00:24:18,023
the interportile distance,

478
00:24:18,023 --> 00:24:19,558
I don't know why you'd
need to care about that

479
00:24:19,558 --> 00:24:21,893
but I'm mentioning it anyway

480
00:24:23,061 --> 00:24:25,496
and then you have
here, this top.

481
00:24:27,732 --> 00:24:30,035
If you read about
box plots online,

482
00:24:30,035 --> 00:24:31,770
they will tell you
usually that this

483
00:24:31,770 --> 00:24:34,039
is the minimum and this is
the maximum in the data set

484
00:24:34,039 --> 00:24:37,142
but in fact, that's
not entirely true

485
00:24:38,143 --> 00:24:39,978
in this case because

486
00:24:39,978 --> 00:24:41,980
we've actually computed,

487
00:24:41,980 --> 00:24:44,182
look, there's the max, right?

488
00:24:44,182 --> 00:24:47,619
The 100% of the data is
supposed to fall below this

489
00:24:47,619 --> 00:24:50,120
but we have something up here,

490
00:24:51,356 --> 00:24:53,191
the outlier.

491
00:24:53,191 --> 00:24:55,260
So the cool thing
about the box plots

492
00:24:55,260 --> 00:24:57,329
is the box plots

493
00:24:57,329 --> 00:24:59,431
actually have these whiskers

494
00:24:59,431 --> 00:25:03,168
that tell you this
is the high outlier

495
00:25:03,168 --> 00:25:05,504
or the low outlier threshold

496
00:25:06,638 --> 00:25:08,439
and the reason I
like that is because

497
00:25:08,440 --> 00:25:10,275
as you visualize this,

498
00:25:12,878 --> 00:25:16,648
and actually you can
read right off the line,

499
00:25:16,648 --> 00:25:20,519
well, here's the threshold
that I should automate against.

500
00:25:20,519 --> 00:25:23,722
If it's above this,
we'll call it an outlier

501
00:25:23,722 --> 00:25:25,190
because in my sample data sets,

502
00:25:25,190 --> 00:25:28,960
everything should be
within the two whiskers.

503
00:25:30,128 --> 00:25:32,898
So we have a high outlier here.

504
00:25:32,898 --> 00:25:34,765
There's another version
of the same box plot,

505
00:25:34,766 --> 00:25:38,203
I did not put the
scatter plot on here.

506
00:25:38,203 --> 00:25:41,139
This actually, this
orange one gives you

507
00:25:41,139 --> 00:25:43,207
a tiny bit more information.

508
00:25:43,208 --> 00:25:45,510
The middle dotted line here

509
00:25:45,510 --> 00:25:47,279
is actually the mean,

510
00:25:49,080 --> 00:25:52,751
so spoiler alert for
high school math,

511
00:25:52,751 --> 00:25:56,655
the median and the
mean are not the same.

512
00:25:56,655 --> 00:26:00,225
Sorry, I know some of
you are just waiting,

513
00:26:01,927 --> 00:26:05,230
you're queuing those
textbooks up to read later,

514
00:26:05,230 --> 00:26:07,265
sorry I spoiled it for you

515
00:26:07,265 --> 00:26:09,034
but the reason that
that's interesting

516
00:26:09,034 --> 00:26:11,202
is because using the mean,

517
00:26:13,238 --> 00:26:15,840
you can compute the
standard deviation.

518
00:26:15,840 --> 00:26:19,276
Does anyone remember,
that's not Alex Pinto,

519
00:26:19,277 --> 00:26:22,080
what the standard deviation is?

520
00:26:22,080 --> 00:26:23,881
You can just yell it out.

521
00:26:23,882 --> 00:26:26,685
(audience member mumbles)

522
00:26:26,685 --> 00:26:28,787
Yeah, I kind of
heard a little bit.

523
00:26:28,787 --> 00:26:31,890
It's actually, if you
take all the data points

524
00:26:31,890 --> 00:26:34,526
in the data set and you
compute their distance

525
00:26:34,526 --> 00:26:38,530
from the mean and then
you average all those up,

526
00:26:40,632 --> 00:26:42,033
you find the standard deviation.

527
00:26:42,033 --> 00:26:45,303
It's the average distance
of each data point

528
00:26:45,303 --> 00:26:48,106
from the average and
the reason that that's

529
00:26:48,106 --> 00:26:50,342
also interesting is because

530
00:26:50,342 --> 00:26:51,876
and this is kind of a bonus tip

531
00:26:51,876 --> 00:26:53,845
that I didn't really
built into the slides,

532
00:26:53,845 --> 00:26:56,448
it's actually a really
common thing to say

533
00:26:56,448 --> 00:27:00,318
my outlier filter is, say,
three standard deviations

534
00:27:00,318 --> 00:27:01,786
away from the mean.

535
00:27:01,786 --> 00:27:04,756
Anything above two or three
deviations is an outlier

536
00:27:04,756 --> 00:27:07,459
and in this case, it's
actually close to two standard

537
00:27:07,459 --> 00:27:10,228
deviations, it's not quite,

538
00:27:10,228 --> 00:27:12,130
but it's actually close
to two standard deviations

539
00:27:12,130 --> 00:27:15,166
that it computed the
outlier threshold.

540
00:27:15,166 --> 00:27:17,569
It's just a little bonus fact

541
00:27:18,970 --> 00:27:20,505
and you can get the
standard deviations

542
00:27:20,505 --> 00:27:23,575
at the same time
you do the box plots

543
00:27:26,845 --> 00:27:28,380
and again, just
like the other ones,

544
00:27:28,380 --> 00:27:31,850
also with Plotly, I didn't
really have to do that much.

545
00:27:31,850 --> 00:27:33,318
The main thing is here,

546
00:27:33,318 --> 00:27:36,388
here's the list of
all of the data points

547
00:27:36,388 --> 00:27:40,558
in this array here, it's
actually a pandas data series

548
00:27:41,926 --> 00:27:44,696
but basically Python
doesn't really care.

549
00:27:44,696 --> 00:27:46,031
It's just a list

550
00:27:47,432 --> 00:27:50,301
and all this stuff is
just like making it pretty

551
00:27:50,301 --> 00:27:54,139
so I can put a title on it so
I know what it is later on,

552
00:27:54,139 --> 00:27:56,640
so it's actually not
really very difficult

553
00:27:56,641 --> 00:27:58,610
to make this box plot either.

554
00:27:58,610 --> 00:28:01,212
So the box plots
are really good at

555
00:28:01,212 --> 00:28:04,215
when you have numeric
data, first of all,

556
00:28:04,215 --> 00:28:06,384
it needs to be numeric and

557
00:28:07,819 --> 00:28:10,388
I used a big term on here
to make myself sound smart,

558
00:28:10,388 --> 00:28:13,323
univariate, which basically
just means one variable,

559
00:28:13,324 --> 00:28:17,595
you have one data column
that you're dealing with,

560
00:28:17,595 --> 00:28:20,598
so if you have
univariate numeric data

561
00:28:20,598 --> 00:28:23,001
and you want to get an
idea of the distribution

562
00:28:23,001 --> 00:28:25,437
of that data, a box plot
might be really good.

563
00:28:25,437 --> 00:28:27,338
It's a quick visual
representation

564
00:28:27,338 --> 00:28:30,375
of the data shape
and it also do,

565
00:28:30,375 --> 00:28:31,810
what we call the skew,

566
00:28:31,810 --> 00:28:33,812
like it'll show you visually
if most of the things

567
00:28:33,812 --> 00:28:35,714
are at the bottom of the
range or the top of the range

568
00:28:35,714 --> 00:28:38,450
or if they're evenly
distributed, things like that

569
00:28:38,450 --> 00:28:40,452
and the outliers are
explicitly shown,

570
00:28:40,452 --> 00:28:45,390
anything that's outside the
top or the bottom whisker

571
00:28:45,390 --> 00:28:47,826
and you can take
those and read them

572
00:28:47,826 --> 00:28:49,260
right off the graph and say,

573
00:28:49,260 --> 00:28:53,131
now I know my outlier
threshold should be 4.7,

574
00:28:53,131 --> 00:28:55,233
so I'm gonna put it
in my Spunk query

575
00:28:55,233 --> 00:28:57,135
or whatever when I
compute this metric

576
00:28:57,135 --> 00:28:58,770
and if it's greater than 4.7,

577
00:28:58,770 --> 00:29:03,141
fire an alert or do
whatever you're gonna do.

578
00:29:03,141 --> 00:29:05,810
Though the main weakness
of it though is that

579
00:29:05,810 --> 00:29:07,611
as a kind of high level summary,

580
00:29:07,612 --> 00:29:10,882
the box plot, without all
of the scatter plots on it

581
00:29:10,882 --> 00:29:14,319
kind of loses the
individual data points.

582
00:29:15,653 --> 00:29:17,922
I don't usually think
that's a big deal though

583
00:29:17,922 --> 00:29:22,393
'cause I'm just trying to
figure out the shape of it but

584
00:29:22,393 --> 00:29:24,262
if you have a lot
of data points,

585
00:29:24,262 --> 00:29:26,931
it's hard to generate
that scatter plot

586
00:29:26,931 --> 00:29:29,768
on a regular laptop
or a computer

587
00:29:29,768 --> 00:29:33,805
and again, here, I
don't know what's normal

588
00:29:33,805 --> 00:29:36,474
for this column of numbers,

589
00:29:36,474 --> 00:29:38,842
let alone whether there
are any outliers in it,

590
00:29:38,843 --> 00:29:41,012
but I need to find out.

591
00:29:41,012 --> 00:29:44,381
If that's your hypothesis,
looks like that,

592
00:29:44,382 --> 00:29:48,486
this is probably a good
technique for you to use.

593
00:29:50,922 --> 00:29:52,123
Alright, first of all,

594
00:29:52,123 --> 00:29:55,226
take a breath, we're
done with visualization.

595
00:29:55,226 --> 00:29:56,895
No more graphs.

596
00:29:56,895 --> 00:30:01,366
I know it feels like you're
back in high school, maybe.

597
00:30:01,366 --> 00:30:03,134
The bad news is now I'm
gonna talk about something

598
00:30:03,134 --> 00:30:06,805
a lot cooler and maybe
conceptually a little

599
00:30:08,206 --> 00:30:10,108
bit more involved, but I'm gonna
try to walk you through it.

600
00:30:10,108 --> 00:30:12,177
The payoff though is that

601
00:30:15,346 --> 00:30:17,148
I get to join the
ranks of the people

602
00:30:17,148 --> 00:30:21,319
that get up here on stage and
talk about machine learning.

603
00:30:21,319 --> 00:30:23,221
It's a payoff for me, I didn't
say it was payoff for you.

604
00:30:23,221 --> 00:30:26,057
(audience laughs)

605
00:30:28,126 --> 00:30:30,728
So, and I'm not gonna
tell you that this

606
00:30:30,728 --> 00:30:32,330
is the only machine
learning you can do

607
00:30:32,330 --> 00:30:34,365
to find outliers, it's
just a cool one and

608
00:30:34,365 --> 00:30:37,669
it's something that I
work with occasionally

609
00:30:37,669 --> 00:30:41,439
that a friend of mine
from Squirrel actually,

610
00:30:42,841 --> 00:30:44,408
their Chief of Data
Science, Chris McCubbins,

611
00:30:44,409 --> 00:30:45,844
introduced me to.

612
00:30:46,778 --> 00:30:49,747
It's called isolation forests

613
00:30:49,747 --> 00:30:52,417
and remember I
talked earlier about

614
00:30:52,417 --> 00:30:55,019
the scatter plot, one
of the possible things

615
00:30:55,019 --> 00:30:57,322
might be clusters of
data on the scatter plot

616
00:30:57,322 --> 00:30:59,623
and you're looking for
things outside the clusters,

617
00:30:59,624 --> 00:31:03,361
great for, and you're
looking at it with your mind

618
00:31:03,361 --> 00:31:05,430
or your brain and your mind
can interpret all that,

619
00:31:05,430 --> 00:31:07,966
but not so great, how
do you interpret that

620
00:31:07,966 --> 00:31:09,367
if you're a computer?

621
00:31:09,367 --> 00:31:12,136
This is a technique that
you would do to automate

622
00:31:12,136 --> 00:31:15,907
finding things that are
not part of clusters.

623
00:31:17,842 --> 00:31:20,545
It's a form of unsupervised
machine learning,

624
00:31:20,545 --> 00:31:24,382
basically meaning the
machine does not have

625
00:31:24,382 --> 00:31:28,052
a list of things that are known
good and known bad to go by,

626
00:31:28,052 --> 00:31:29,954
it's actually just
saying which things

627
00:31:29,954 --> 00:31:31,222
are different from the others

628
00:31:31,222 --> 00:31:33,458
without really having context or

629
00:31:33,458 --> 00:31:35,627
giving you a strict
interpretation

630
00:31:35,627 --> 00:31:37,829
of what that difference means.

631
00:31:37,829 --> 00:31:39,630
It basically says

632
00:31:39,631 --> 00:31:42,700
you have a big data
set of data points

633
00:31:42,700 --> 00:31:44,669
and these data points can be

634
00:31:44,669 --> 00:31:48,840
two dimensional, so like
we have here on the graph

635
00:31:50,108 --> 00:31:52,010
or they could actually
be multidimensional,

636
00:31:52,010 --> 00:31:54,779
you could have 10
or 20 dimensions,

637
00:31:54,779 --> 00:31:58,850
more than that, it's hard
to visualize at that level,

638
00:31:58,850 --> 00:32:00,451
so we're gonna show
you on two dimensions

639
00:32:00,451 --> 00:32:04,989
but it actually works with
many more dimensions on that.

640
00:32:04,989 --> 00:32:07,392
What you basically do is
you find a random data point

641
00:32:07,392 --> 00:32:10,228
and you take that
data set and you

642
00:32:12,096 --> 00:32:15,600
find a random dimension
and a random value

643
00:32:15,600 --> 00:32:18,803
within that dimension
and you make a split.

644
00:32:18,803 --> 00:32:20,004
You see they've done that here.

645
00:32:20,004 --> 00:32:22,639
You basically are saying
everything above it

646
00:32:22,640 --> 00:32:24,409
is on one side of the split
and everything below it

647
00:32:24,409 --> 00:32:27,178
is on the other
side of the split

648
00:32:28,579 --> 00:32:31,049
and you do that again, you
pick a data point on one side

649
00:32:31,049 --> 00:32:32,917
and you say, okay, I'm
gonna make another split,

650
00:32:32,917 --> 00:32:37,088
random split on random value
of random dimension and

651
00:32:38,356 --> 00:32:39,357
you keep doing that,

652
00:32:39,357 --> 00:32:40,758
I'm gonna make this split

653
00:32:40,758 --> 00:32:42,593
then I'm gonna work with
everything over here,

654
00:32:42,593 --> 00:32:43,795
I'm gonna make a split,
I'm gonna make a split,

655
00:32:43,795 --> 00:32:47,498
I'm gonna make, you
get focused down

656
00:32:47,498 --> 00:32:49,634
and then they make this,
this is called a tree,

657
00:32:49,634 --> 00:32:52,170
this basically, this
record of all the splits

658
00:32:52,170 --> 00:32:54,439
you took to get to each
data point is a tree

659
00:32:54,439 --> 00:32:57,375
and you're gonna split all
the data points in that.

660
00:32:57,375 --> 00:33:00,645
You do that a bunch
of times as well so,

661
00:33:01,512 --> 00:33:02,981
because this is random,

662
00:33:02,981 --> 00:33:06,384
you split all of them until
everyone has been split

663
00:33:06,384 --> 00:33:09,153
and you have a record
of all the splits

664
00:33:09,153 --> 00:33:11,689
to go to each data point
and then you start over

665
00:33:11,689 --> 00:33:14,025
and you do it again, getting
different random choices

666
00:33:14,025 --> 00:33:15,893
each time and you do
this a bunch of times.

667
00:33:15,893 --> 00:33:18,196
You generate a lot of trees,

668
00:33:18,196 --> 00:33:20,865
that's why they call it a forest

669
00:33:23,401 --> 00:33:25,536
and then basically what
you do is you end up with

670
00:33:25,536 --> 00:33:27,171
a bunch of trees
that for each point,

671
00:33:27,171 --> 00:33:30,241
they have a depth of how
many splits you had to do,

672
00:33:30,241 --> 00:33:32,543
random splits you had to
do to get to that point.

673
00:33:32,543 --> 00:33:34,312
You average all those

674
00:33:36,347 --> 00:33:37,682
and you say, well,
for this point,

675
00:33:37,682 --> 00:33:39,684
the average depth is two

676
00:33:40,718 --> 00:33:43,488
or the average depth is 24

677
00:33:43,488 --> 00:33:45,356
and if you think about this,

678
00:33:45,356 --> 00:33:49,560
this tells you how close
it is to other data points

679
00:33:49,560 --> 00:33:52,062
because the lower your number,

680
00:33:54,032 --> 00:33:56,801
the fewer splits you had
to do until it was isolated

681
00:33:56,801 --> 00:33:59,102
into it's own area.

682
00:33:59,103 --> 00:34:01,406
That implies that
it's probably farther

683
00:34:01,406 --> 00:34:04,408
from all the data
points because look,

684
00:34:04,409 --> 00:34:07,211
I mean, this guy had to
do basically probably

685
00:34:07,211 --> 00:34:10,281
one split or maybe a few splits,

686
00:34:10,281 --> 00:34:12,583
depending on the
random things went.

687
00:34:12,583 --> 00:34:16,120
These guys we had to do a
lot of splits to get to,

688
00:34:16,120 --> 00:34:17,388
so you can see,

689
00:34:19,090 --> 00:34:22,894
this is things that are
really close to the rest

690
00:34:22,893 --> 00:34:25,662
of the cluster, they're
the inliers and these

691
00:34:25,663 --> 00:34:28,266
things are kind of the
things that are really far

692
00:34:28,266 --> 00:34:31,502
from the cluster,
they're the outliers.

693
00:34:33,271 --> 00:34:37,041
Now, this actually
is something that

694
00:34:37,041 --> 00:34:41,212
Tim Cruthers mentioned this
morning in his ML presentation.

695
00:34:43,281 --> 00:34:45,116
So Chris McCubbins and I have

696
00:34:45,116 --> 00:34:47,752
this demonstration
tool for finding odd

697
00:34:47,752 --> 00:34:51,822
Bro HTTP logs and I
put it out on GitHub.

698
00:34:51,822 --> 00:34:56,560
It's called Clearcut and it
uses two different algorithms.

699
00:34:56,561 --> 00:34:57,728
It does a random forest,

700
00:34:57,728 --> 00:34:59,030
which I'm not
gonna get into here

701
00:34:59,030 --> 00:35:01,632
and then does the
isolation forests.

702
00:35:01,632 --> 00:35:03,935
So, rather than paste
the code in here again,

703
00:35:03,935 --> 00:35:07,105
I would just say go and
look at the Clearcut code.

704
00:35:07,105 --> 00:35:11,275
It is designed so that it is
a reference implementation,

705
00:35:12,777 --> 00:35:15,780
basically, simplified so
that you can see the steps

706
00:35:15,780 --> 00:35:19,851
of how to implement
isolation forests in Python

707
00:35:19,851 --> 00:35:21,853
with scikit-learn.

708
00:35:21,853 --> 00:35:24,122
It's not very difficult.

709
00:35:24,122 --> 00:35:26,089
The harder part is doing

710
00:35:26,090 --> 00:35:27,658
what they call the
feature engineering,

711
00:35:27,658 --> 00:35:29,060
like looking at
all the data points

712
00:35:29,060 --> 00:35:31,796
and converting non-numeric
data into numbers

713
00:35:31,796 --> 00:35:35,633
but the actual implementation
of the isolation forest

714
00:35:35,633 --> 00:35:36,701
is built into scikit-learn,

715
00:35:36,701 --> 00:35:39,036
so it's just some API calls.

716
00:35:41,005 --> 00:35:44,008
So, when might you
want to use this?

717
00:35:45,076 --> 00:35:47,178
Well, it has some strengths.

718
00:35:47,178 --> 00:35:49,547
The first one is when you have

719
00:35:49,547 --> 00:35:52,884
a lot of different
columns in your data,

720
00:35:55,453 --> 00:35:58,389
they can be numeric
columns or possibly things

721
00:35:58,389 --> 00:36:01,225
that can be converted
into numbers,

722
00:36:02,960 --> 00:36:07,198
such that, unique
strings might be numbered

723
00:36:07,198 --> 00:36:09,400
so that you have
strings one through five

724
00:36:09,400 --> 00:36:11,068
and you'll just put one,
two, three, four, five

725
00:36:11,068 --> 00:36:14,038
in there instead of
the actual strings

726
00:36:14,038 --> 00:36:18,776
and it can accept a pretty
large number of those columns

727
00:36:18,776 --> 00:36:20,111
per data point.

728
00:36:20,111 --> 00:36:22,879
The dimensionality can
be pretty large here.

729
00:36:22,880 --> 00:36:26,984
It's also, it's a form of
unsupervised clustering

730
00:36:28,186 --> 00:36:30,688
but it tends to be
a pretty fast one

731
00:36:30,688 --> 00:36:33,991
compared to other ones
that, like data scientists

732
00:36:33,991 --> 00:36:36,928
and hobbyists like me
like to throw around,

733
00:36:36,928 --> 00:36:39,363
like K means clustering
or something like that,

734
00:36:39,363 --> 00:36:40,631
this is actually pretty fast.

735
00:36:40,631 --> 00:36:42,466
You can get good results
on a reasonable data set

736
00:36:42,466 --> 00:36:44,067
with like a laptop,

737
00:36:45,436 --> 00:36:48,005
don't need a lot of hardware
necessarily to do this

738
00:36:48,005 --> 00:36:50,908
and low memory
requirements as well

739
00:36:52,476 --> 00:36:55,980
but to me, probably the
best use case of this

740
00:36:55,980 --> 00:36:58,249
you can use this and
then you get to say,

741
00:36:58,249 --> 00:37:02,352
yeah, we have a machine
learning solution for that.

742
00:37:04,455 --> 00:37:07,424
It's a little bit
weak in the sense that

743
00:37:07,425 --> 00:37:10,294
creating those features,
deciding which features

744
00:37:10,294 --> 00:37:13,096
are important and converting
non-numeric things

745
00:37:13,097 --> 00:37:16,167
into numbers is not
really rocket science

746
00:37:16,167 --> 00:37:18,903
but there's a lot of work
kind of involved there

747
00:37:18,903 --> 00:37:23,406
and it's difficult to visualize
this at high dimensions.

748
00:37:23,407 --> 00:37:26,844
You can do two or three
dimensions pretty easily

749
00:37:26,844 --> 00:37:29,814
and then afterwards,
if you wanted to see

750
00:37:29,814 --> 00:37:32,482
what the output was, to
understand it a little bit more,

751
00:37:32,483 --> 00:37:34,185
it'd be kind of
difficult to show it

752
00:37:34,185 --> 00:37:37,054
in four or more dimensions

753
00:37:37,054 --> 00:37:40,891
but good thing is, that's
not always necessary

754
00:37:42,493 --> 00:37:44,962
and so, here's an example
and this is directly

755
00:37:44,962 --> 00:37:47,698
from out Clearcut
implementation.

756
00:37:49,000 --> 00:37:51,602
Which of these HTTP
log entries are most

757
00:37:51,602 --> 00:37:53,203
unlike the others?

758
00:37:53,204 --> 00:37:56,274
So, we took the
typical Bro HTTP log

759
00:37:56,274 --> 00:37:59,710
and featurized it, I
can tell you offline

760
00:38:00,845 --> 00:38:02,480
if you're interested
like what kind of things

761
00:38:02,480 --> 00:38:04,682
we were looking for
but we converted them

762
00:38:04,682 --> 00:38:07,618
to a set of numbers for
each line in the log

763
00:38:07,618 --> 00:38:10,121
and we ran isolation
forests against them

764
00:38:10,121 --> 00:38:12,323
and showed the ones
that were less like

765
00:38:12,323 --> 00:38:13,924
all the other ones,

766
00:38:15,693 --> 00:38:18,162
works out pretty good.

767
00:38:18,162 --> 00:38:20,330
So, your brains can relax.

768
00:38:22,600 --> 00:38:26,103
We're done talking
about machine learning

769
00:38:26,103 --> 00:38:29,340
but I want to sum up by saying,

770
00:38:29,340 --> 00:38:33,244
if there's one key take away
I would like you to have,

771
00:38:33,244 --> 00:38:36,180
don't just automatically
jump to stack counting.

772
00:38:36,180 --> 00:38:38,649
Sometimes that's useful but
you have a lot of options.

773
00:38:38,649 --> 00:38:40,183
You can do stack counting,

774
00:38:40,184 --> 00:38:42,953
least frequency of occurrence,

775
00:38:42,953 --> 00:38:45,656
you can do scatter plots now.

776
00:38:45,656 --> 00:38:48,893
You know how to
interpret box plots now

777
00:38:48,893 --> 00:38:50,995
and you could even bust
out some machine learning

778
00:38:50,995 --> 00:38:54,065
and impress your
boss and get a raise

779
00:38:55,366 --> 00:38:57,401
and these are not the only ones.

780
00:38:57,401 --> 00:38:59,636
These are just like
three common ones

781
00:38:59,637 --> 00:39:01,672
and then one interesting one

782
00:39:01,672 --> 00:39:03,674
that I threw up in here.

783
00:39:04,875 --> 00:39:06,877
There's tons of
different options

784
00:39:06,877 --> 00:39:09,145
and please don't be
afraid to play around,

785
00:39:09,146 --> 00:39:11,482
get out from under the stack

786
00:39:12,917 --> 00:39:16,520
and go do some other,
play with some other ways

787
00:39:16,520 --> 00:39:18,788
of finding the
outliers in your data

788
00:39:18,789 --> 00:39:21,325
and see if you can
achieve a better result

789
00:39:21,325 --> 00:39:23,527
or a quicker time or both.

790
00:39:23,527 --> 00:39:26,197
(intense music)

