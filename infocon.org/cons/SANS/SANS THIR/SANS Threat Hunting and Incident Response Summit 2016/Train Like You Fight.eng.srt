1
00:00:14,570 --> 00:00:21,869
this November 18 2015 three armed

2
00:00:19,470 --> 00:00:23,549
robbers stormed one of our banks became

3
00:00:21,869 --> 00:00:25,529
one of the most violent robberies our

4
00:00:23,550 --> 00:00:28,829
branch had seen at the end of the

5
00:00:25,529 --> 00:00:30,180
episode they got away with $50,000 so

6
00:00:28,829 --> 00:00:31,500
the question I want to ask you what

7
00:00:30,180 --> 00:00:35,250
we're talking about threat hunting

8
00:00:31,500 --> 00:00:37,079
incident response is are you prepared to

9
00:00:35,250 --> 00:00:39,329
face the enemy and maybe more

10
00:00:37,079 --> 00:00:41,399
importantly are your employees prepared

11
00:00:39,329 --> 00:00:43,140
the people on the front line who are

12
00:00:41,399 --> 00:00:45,739
going to you know receive the email

13
00:00:43,140 --> 00:00:48,150
click the link notice something unusual

14
00:00:45,739 --> 00:00:49,860
so in this talk we're going to explore

15
00:00:48,150 --> 00:00:52,010
how do you prepare your teams how you

16
00:00:49,860 --> 00:00:56,079
prepare your employees to face

17
00:00:52,010 --> 00:00:57,968
adversaries in your environment

18
00:00:56,079 --> 00:01:00,879
turns out one of the three suspects

19
00:00:57,969 --> 00:01:03,280
ended up being one of the most was bi

20
00:01:00,879 --> 00:01:06,100
top 10 most wanted and he was on that

21
00:01:03,280 --> 00:01:08,590
list for about three months it was

22
00:01:06,100 --> 00:01:10,149
captured in January of 18 it turns out

23
00:01:08,590 --> 00:01:11,979
when you take something from a bank and

24
00:01:10,149 --> 00:01:13,420
I'll leave it at this there's things

25
00:01:11,979 --> 00:01:15,630
that we could do to figure out where you

26
00:01:13,420 --> 00:01:18,039
went after you left the bank alright so

27
00:01:15,630 --> 00:01:19,630
this suspect was captured all three

28
00:01:18,039 --> 00:01:21,340
suspects were apprehended primarily

29
00:01:19,630 --> 00:01:24,250
based on the fact that our employees

30
00:01:21,340 --> 00:01:26,649
followed the procedures despite the

31
00:01:24,250 --> 00:01:28,929
despite the episode we had practice

32
00:01:26,649 --> 00:01:31,500
trained and prepared for that particular

33
00:01:28,929 --> 00:01:35,890
event they follow through led to the

34
00:01:31,500 --> 00:01:38,649
arrest of these three suspects I like

35
00:01:35,890 --> 00:01:40,060
this quote in particular the very last

36
00:01:38,649 --> 00:01:42,819
sentence if you've ever read ender's

37
00:01:40,060 --> 00:01:45,340
game there is no teacher but the enemy

38
00:01:42,819 --> 00:01:48,009
you're not going to know how they're

39
00:01:45,340 --> 00:01:50,259
going to act on your network or operate

40
00:01:48,009 --> 00:01:52,119
until they show up so we can do our best

41
00:01:50,259 --> 00:01:53,979
to prepare we can do our best to train

42
00:01:52,119 --> 00:01:55,899
but in reality like you've heard some of

43
00:01:53,979 --> 00:01:58,509
the talks before well the incident goes

44
00:01:55,899 --> 00:02:00,149
down it's a very dynamic process so

45
00:01:58,509 --> 00:02:04,300
there really is no teacher but the enemy

46
00:02:00,149 --> 00:02:06,129
when they arrive on your network so my

47
00:02:04,300 --> 00:02:08,619
name is Casey Smith you can connect with

48
00:02:06,129 --> 00:02:11,019
me on Twitter at sub T the title of this

49
00:02:08,619 --> 00:02:13,030
talk is trained like you fight so I work

50
00:02:11,019 --> 00:02:16,030
for a regional bank in Colorado we have

51
00:02:13,030 --> 00:02:18,730
about 3,000 employees and my primary

52
00:02:16,030 --> 00:02:20,860
role is to test our defensive systems so

53
00:02:18,730 --> 00:02:22,720
I'm a threat intelligence analyst so I

54
00:02:20,860 --> 00:02:25,150
actually sit right next to our blue team

55
00:02:22,720 --> 00:02:27,430
operate the red team and Travis use here

56
00:02:25,150 --> 00:02:29,440
sits right next to me hey Mike hey did

57
00:02:27,430 --> 00:02:31,000
you see that no ok well let's fix this

58
00:02:29,440 --> 00:02:33,129
let's tune our systems ok so we're

59
00:02:31,000 --> 00:02:36,700
constantly testing and preparing our

60
00:02:33,129 --> 00:02:39,159
environment to see and act out actors

61
00:02:36,700 --> 00:02:41,260
you know indicators on our network so

62
00:02:39,159 --> 00:02:44,769
that's my primary role a lot of fun

63
00:02:41,260 --> 00:02:46,540
actually so our team matured from

64
00:02:44,769 --> 00:02:48,970
physical security so if you think about

65
00:02:46,540 --> 00:02:52,090
the physical security space we have

66
00:02:48,970 --> 00:02:54,580
robbery training we have mock robberies

67
00:02:52,090 --> 00:02:56,890
our teams can conduct we have procedures

68
00:02:54,580 --> 00:02:58,840
we have alarms we have alt the physical

69
00:02:56,890 --> 00:03:01,089
security environment is instrumented to

70
00:02:58,840 --> 00:03:04,990
handle this type of you know event a

71
00:03:01,090 --> 00:03:06,580
robbery ok a camera verification you

72
00:03:04,990 --> 00:03:08,170
know every morning when the branch opens

73
00:03:06,580 --> 00:03:09,790
up one of the things our employees do is

74
00:03:08,170 --> 00:03:12,939
they check the camera

75
00:03:09,790 --> 00:03:14,679
is it recording okay is it actually not

76
00:03:12,939 --> 00:03:15,700
pointing up a wall in the floor is it

77
00:03:14,680 --> 00:03:17,079
actually pointed in the right direction

78
00:03:15,700 --> 00:03:18,548
the last thing you want to have happen

79
00:03:17,079 --> 00:03:20,200
is the FBI show up and say we need

80
00:03:18,549 --> 00:03:22,359
pictures of the suspect and you've got a

81
00:03:20,200 --> 00:03:24,700
picture of a wall okay so think of your

82
00:03:22,359 --> 00:03:26,799
incident response stools you want to

83
00:03:24,700 --> 00:03:28,480
train them tune them if you can tell me

84
00:03:26,799 --> 00:03:30,670
you can find a hash on your network

85
00:03:28,480 --> 00:03:32,768
prove it to me I'm going to drop a hash

86
00:03:30,670 --> 00:03:35,018
in your environment tell me what systems

87
00:03:32,769 --> 00:03:36,280
it landed on okay so we're going to take

88
00:03:35,019 --> 00:03:37,359
the things we've learned from physical

89
00:03:36,280 --> 00:03:41,560
security we're going to try and apply

90
00:03:37,359 --> 00:03:43,329
those to the infosec space a lot of ways

91
00:03:41,560 --> 00:03:46,239
to process threat intelligence for us

92
00:03:43,329 --> 00:03:48,489
there's an FSI sack for banks and the

93
00:03:46,239 --> 00:03:51,040
way we process threat intelligence is we

94
00:03:48,489 --> 00:03:53,139
basically say okay that happened at a

95
00:03:51,040 --> 00:03:54,548
bank in Missouri what happened if it's

96
00:03:53,139 --> 00:03:56,799
showing up on our network so what would

97
00:03:54,549 --> 00:03:59,439
happen if that event occurred in our

98
00:03:56,799 --> 00:04:02,709
environment the second thing we ask is

99
00:03:59,439 --> 00:04:04,989
are we prepared can we detect it can we

100
00:04:02,709 --> 00:04:06,340
prevent it how do we respond all right

101
00:04:04,989 --> 00:04:08,409
so you heard you know talk about like

102
00:04:06,340 --> 00:04:10,480
the Pollack's malware earlier today a

103
00:04:08,409 --> 00:04:12,040
file asst now or memory resident Bauer

104
00:04:10,480 --> 00:04:13,988
these are the type of things we're

105
00:04:12,040 --> 00:04:16,269
thinking and our team creates or drafts

106
00:04:13,989 --> 00:04:20,798
prototypes we can execute to tune our

107
00:04:16,269 --> 00:04:23,440
tools against so my job is to be the

108
00:04:20,798 --> 00:04:25,599
threat that we hope never shows up on

109
00:04:23,440 --> 00:04:28,300
our network okay so essentially we do a

110
00:04:25,599 --> 00:04:29,919
lot of threat emulation we simulate you

111
00:04:28,300 --> 00:04:32,380
know we get a report we read about a

112
00:04:29,919 --> 00:04:34,359
particular virus or malware and we write

113
00:04:32,380 --> 00:04:35,979
prototypes and we run them in our

114
00:04:34,360 --> 00:04:37,539
network in production ok now it's a lot

115
00:04:35,979 --> 00:04:39,760
of stuff I published on github so you

116
00:04:37,539 --> 00:04:41,349
guys can follow my github and run some

117
00:04:39,760 --> 00:04:42,669
of the same type of tools they're not

118
00:04:41,349 --> 00:04:44,169
malicious they're more like Canaries

119
00:04:42,669 --> 00:04:45,940
like Heather talked about earlier today

120
00:04:44,169 --> 00:04:47,680
all right so it's just something to make

121
00:04:45,940 --> 00:04:50,080
sure your school sets are dialed in that

122
00:04:47,680 --> 00:04:55,240
your rightful is cited okay so that's

123
00:04:50,080 --> 00:04:57,250
that's what we do all right when we talk

124
00:04:55,240 --> 00:04:58,750
about it soon compromise or assume

125
00:04:57,250 --> 00:05:00,220
breach or whatever you want to call it

126
00:04:58,750 --> 00:05:02,139
for us is a bank it means you're going

127
00:05:00,220 --> 00:05:04,360
to get robbed okay that you can't

128
00:05:02,139 --> 00:05:05,889
prevent that at any given moment a

129
00:05:04,360 --> 00:05:07,870
suspect to decide to enter our

130
00:05:05,889 --> 00:05:10,360
organization steal money and that's just

131
00:05:07,870 --> 00:05:12,460
the fact we do it so what do we do we

132
00:05:10,360 --> 00:05:14,680
instrument we have cameras alarms vaults

133
00:05:12,460 --> 00:05:19,020
so we've gone to the steps necessary to

134
00:05:14,680 --> 00:05:19,020
handle and absorb that particular event

135
00:05:24,220 --> 00:05:30,319
there we go all right so my role for our

136
00:05:27,590 --> 00:05:33,560
team is I introduce artifacts into the

137
00:05:30,319 --> 00:05:35,240
network so they can hunt our activity ok

138
00:05:33,560 --> 00:05:36,889
so again like I mentioned earlier if you

139
00:05:35,240 --> 00:05:40,099
if you can tell me you can detect a hash

140
00:05:36,889 --> 00:05:42,289
executed on system or process a injected

141
00:05:40,099 --> 00:05:44,210
into process be proved it to me I'm

142
00:05:42,289 --> 00:05:46,099
going to run it I'm going to run invoke

143
00:05:44,210 --> 00:05:47,930
shellcode and powershell jump into

144
00:05:46,099 --> 00:05:50,449
explorer.exe and I want you to tell me

145
00:05:47,930 --> 00:05:51,800
which machines I did that on ok this is

146
00:05:50,449 --> 00:05:54,650
this is the way we train and practice

147
00:05:51,800 --> 00:05:57,050
for our teams here's what it looks like

148
00:05:54,650 --> 00:05:58,609
in a very very high level we run

149
00:05:57,050 --> 00:06:01,250
quarterly exercises these are

150
00:05:58,610 --> 00:06:02,750
pre-approved drills that are incident

151
00:06:01,250 --> 00:06:04,639
responders they don't know it's coming

152
00:06:02,750 --> 00:06:06,889
it may be a small number of them know

153
00:06:04,639 --> 00:06:09,889
it's coming we have executive buy-in

154
00:06:06,889 --> 00:06:12,050
alright so we have pre-approved missions

155
00:06:09,889 --> 00:06:13,430
that we want to accomplish and I only

156
00:06:12,050 --> 00:06:16,039
had time to really talk about four of

157
00:06:13,430 --> 00:06:16,969
those missions today but i'm happy i'm

158
00:06:16,039 --> 00:06:18,289
going to be here for the rest of the

159
00:06:16,969 --> 00:06:19,849
summit so i want to share if you will

160
00:06:18,289 --> 00:06:23,990
have questions about other exercises we

161
00:06:19,849 --> 00:06:26,840
do my job my role is attack to get

162
00:06:23,990 --> 00:06:30,139
caught ok red team doesn't win by

163
00:06:26,840 --> 00:06:32,419
beating blue team ok red team wins when

164
00:06:30,139 --> 00:06:34,280
red team teaches blue team about a gap

165
00:06:32,419 --> 00:06:35,990
and blue team then goes out and detects

166
00:06:34,280 --> 00:06:38,929
an actual adversary on your network

167
00:06:35,990 --> 00:06:40,279
that's a win for the red team ok so that

168
00:06:38,930 --> 00:06:43,190
we want to get caught we want to be

169
00:06:40,279 --> 00:06:46,190
detected we want to be tracked in the

170
00:06:43,190 --> 00:06:48,680
network ok so let me take you through

171
00:06:46,190 --> 00:06:51,770
four simple scenarios I think everybody

172
00:06:48,680 --> 00:06:53,529
can relate to these exercises again each

173
00:06:51,770 --> 00:06:55,818
quarter we run a specific mission

174
00:06:53,529 --> 00:06:58,520
spearfishing weaponized documents

175
00:06:55,819 --> 00:06:59,630
credential theft command and control and

176
00:06:58,520 --> 00:07:00,680
we're not going to have a lot of time to

177
00:06:59,630 --> 00:07:01,849
go deep dive but I want you to

178
00:07:00,680 --> 00:07:04,900
understand what we're doing when we

179
00:07:01,849 --> 00:07:09,620
conduct these tests in our environment

180
00:07:04,900 --> 00:07:12,138
so spearfishing we do our own we write

181
00:07:09,620 --> 00:07:13,729
some powershell we get a linux server

182
00:07:12,139 --> 00:07:15,650
for like fifty eight cents an hour spin

183
00:07:13,729 --> 00:07:17,389
it up we can run the exercise its

184
00:07:15,650 --> 00:07:19,489
trivial there's there's minimal cost to

185
00:07:17,389 --> 00:07:22,190
do this what's different about this is

186
00:07:19,490 --> 00:07:24,080
I'm not true I'm not testing users I'm

187
00:07:22,190 --> 00:07:27,500
not having users click a link and end up

188
00:07:24,080 --> 00:07:29,240
at a cbt not helpful okay what I want to

189
00:07:27,500 --> 00:07:32,599
do is I want to test the Securities team

190
00:07:29,240 --> 00:07:33,289
response can you detect the fish how can

191
00:07:32,599 --> 00:07:35,270
you block

192
00:07:33,289 --> 00:07:36,469
the attachments or the links or whatever

193
00:07:35,270 --> 00:07:38,869
it is it's entered in our environment

194
00:07:36,469 --> 00:07:43,699
these exercises are tests of our

195
00:07:38,869 --> 00:07:46,099
security team here's an example we ran

196
00:07:43,699 --> 00:07:49,129
the test and one of the analysts

197
00:07:46,099 --> 00:07:50,389
detected to maliciously get 756 let me

198
00:07:49,129 --> 00:07:53,719
know in the chat i'm going to block this

199
00:07:50,389 --> 00:07:55,909
by 756 and 42 seconds employees were

200
00:07:53,719 --> 00:07:57,979
clicking the link ok but what you see

201
00:07:55,909 --> 00:08:00,020
there is blocked rapid response ok so

202
00:07:57,979 --> 00:08:02,029
they detect our I detected our activity

203
00:08:00,020 --> 00:08:03,830
and we were able to you know contain the

204
00:08:02,029 --> 00:08:07,249
incident much quicker because they were

205
00:08:03,830 --> 00:08:09,800
able to find the indicators now we use

206
00:08:07,249 --> 00:08:11,360
when we do spearfishing exercises we

207
00:08:09,800 --> 00:08:13,819
rely on what I call distributed hunting

208
00:08:11,360 --> 00:08:14,959
I grew up in Colorado and there's a lot

209
00:08:13,819 --> 00:08:16,520
different there's a lot of difference

210
00:08:14,959 --> 00:08:18,800
between the way hunt pheasant the way on

211
00:08:16,520 --> 00:08:20,568
an elk ok when you hunt pheasant you

212
00:08:18,800 --> 00:08:22,819
line up in the field and walk across the

213
00:08:20,569 --> 00:08:25,159
field so when you hunt spear phishing or

214
00:08:22,819 --> 00:08:26,629
phishing attacks I want employees to let

215
00:08:25,159 --> 00:08:28,430
us know all of our employees have a

216
00:08:26,629 --> 00:08:30,949
button in their outlook this look weird

217
00:08:28,430 --> 00:08:32,479
click spam reporting deletes the message

218
00:08:30,949 --> 00:08:35,209
from their inbox sends it to the

219
00:08:32,479 --> 00:08:36,889
security team they get feedback thanks

220
00:08:35,208 --> 00:08:38,539
that was actually a really a bad thing

221
00:08:36,889 --> 00:08:40,190
thanks for reporting it to us or no

222
00:08:38,539 --> 00:08:42,529
that's ok we scan the attachment

223
00:08:40,190 --> 00:08:44,930
whatever you can open it ok so we're

224
00:08:42,529 --> 00:08:46,730
pushing our hunting out to the edge for

225
00:08:44,930 --> 00:08:49,550
these type of exercises so when we run a

226
00:08:46,730 --> 00:08:50,870
red team test it may be the security

227
00:08:49,550 --> 00:08:52,339
team that catches us but it may actually

228
00:08:50,870 --> 00:08:55,069
just be an employee that thinks this

229
00:08:52,339 --> 00:08:58,130
looks a little strange in their inbox so

230
00:08:55,069 --> 00:09:01,160
we rely on that these are the questions

231
00:08:58,130 --> 00:09:03,019
we ask post-incident first of all how

232
00:09:01,160 --> 00:09:04,790
will we detect this we sent a phishing

233
00:09:03,019 --> 00:09:06,920
email into your environment what was the

234
00:09:04,790 --> 00:09:10,160
indicator who caught it and employed the

235
00:09:06,920 --> 00:09:11,959
security analyst the filter how is it

236
00:09:10,160 --> 00:09:13,969
detected how quickly was it detected

237
00:09:11,959 --> 00:09:16,430
times an important metric right are you

238
00:09:13,970 --> 00:09:18,019
getting better or are you getting works

239
00:09:16,430 --> 00:09:19,638
you could use time as you're really good

240
00:09:18,019 --> 00:09:21,170
metric to see how well you're detecting

241
00:09:19,639 --> 00:09:23,990
these incidents and hunting and looking

242
00:09:21,170 --> 00:09:25,910
for things where we contained what

243
00:09:23,990 --> 00:09:27,649
caused this particular phishing attack

244
00:09:25,910 --> 00:09:29,779
to get through the filters what would

245
00:09:27,649 --> 00:09:31,730
the impact of bin did a domain admin

246
00:09:29,779 --> 00:09:33,860
receive this did an accounting staff

247
00:09:31,730 --> 00:09:36,949
receive this what were the common

248
00:09:33,860 --> 00:09:40,009
attributes you know sender subject line

249
00:09:36,949 --> 00:09:41,300
detachment name sending IP address

250
00:09:40,009 --> 00:09:43,130
whatever it might be we're trying to

251
00:09:41,300 --> 00:09:45,410
train our teams to look for those common

252
00:09:43,130 --> 00:09:47,089
artifacts and surface those and then

253
00:09:45,410 --> 00:09:49,100
write rules to provide feed

254
00:09:47,089 --> 00:09:51,230
back on other incidents that might

255
00:09:49,100 --> 00:09:53,720
happen in the future here so that's so

256
00:09:51,230 --> 00:09:55,160
when we run those drills those are the

257
00:09:53,720 --> 00:09:56,180
things that we do as a follow-up those

258
00:09:55,160 --> 00:09:57,709
are the questions they have to answer

259
00:09:56,180 --> 00:09:59,930
how did that email get into our

260
00:09:57,709 --> 00:10:02,839
environment we feed that back in tune

261
00:09:59,930 --> 00:10:04,069
our systems another exercise we run is

262
00:10:02,839 --> 00:10:07,459
weaponize documents we've all

263
00:10:04,069 --> 00:10:09,559
experienced this so yeah we write you

264
00:10:07,459 --> 00:10:11,569
know Word and Excel spreadsheets with

265
00:10:09,559 --> 00:10:13,009
macros and we execute them we see what

266
00:10:11,569 --> 00:10:14,779
happens when they run shellcode and they

267
00:10:13,009 --> 00:10:17,089
call back to Kali Linux right we run

268
00:10:14,779 --> 00:10:18,379
that stuff on our production network so

269
00:10:17,089 --> 00:10:19,970
these are some of the indicators that we

270
00:10:18,379 --> 00:10:23,240
use to detect this in our environment

271
00:10:19,970 --> 00:10:25,160
new file on network hey that binary has

272
00:10:23,240 --> 00:10:26,300
never executed on any other endpoint in

273
00:10:25,160 --> 00:10:29,959
the environment we might want to look at

274
00:10:26,300 --> 00:10:32,240
it new suspicious parent process okay

275
00:10:29,959 --> 00:10:35,869
did words bond command prompt or swered

276
00:10:32,240 --> 00:10:38,029
spawn PowerShell processes that contain

277
00:10:35,870 --> 00:10:41,120
the word zip in the path or the profile

278
00:10:38,029 --> 00:10:44,660
in the path suspicious executions Who am

279
00:10:41,120 --> 00:10:45,800
I doesn't get executed that often oh it

280
00:10:44,660 --> 00:10:49,129
depends on your environment right but

281
00:10:45,800 --> 00:10:50,389
like said HC net user Q user Q user just

282
00:10:49,129 --> 00:10:53,209
shows you who else is logged into the

283
00:10:50,389 --> 00:10:55,879
system set HC attacks this is a rare

284
00:10:53,209 --> 00:10:57,378
execution so if I see these happening

285
00:10:55,879 --> 00:11:01,550
from a weaponized document those are the

286
00:10:57,379 --> 00:11:02,720
indicators we're hunting for what it

287
00:11:01,550 --> 00:11:04,099
looks like in my environment kind of

288
00:11:02,720 --> 00:11:07,699
like a picture of the suspect you saw

289
00:11:04,100 --> 00:11:10,550
before is microsoft word spawns command

290
00:11:07,699 --> 00:11:12,679
prompt spawns Who am I that's the

291
00:11:10,550 --> 00:11:14,059
workflow we see in our environment ok so

292
00:11:12,679 --> 00:11:18,350
again just like a suspect we have a

293
00:11:14,059 --> 00:11:19,670
workflow we process on detection how do

294
00:11:18,350 --> 00:11:22,040
we do this there's a lot of different

295
00:11:19,670 --> 00:11:24,410
tools to do this primarily we're looking

296
00:11:22,040 --> 00:11:26,748
at the endpoint visibility so endpoint

297
00:11:24,410 --> 00:11:29,149
execution events new unapproved files

298
00:11:26,749 --> 00:11:30,740
introduced into the network suspicious

299
00:11:29,149 --> 00:11:32,660
network connections IPS whatever

300
00:11:30,740 --> 00:11:35,240
artifacts it might be and we actually

301
00:11:32,660 --> 00:11:36,709
introduce artifacts to make sure that

302
00:11:35,240 --> 00:11:39,379
our tools are tuned and trained properly

303
00:11:36,709 --> 00:11:44,599
so that we can detect actual actors in

304
00:11:39,379 --> 00:11:47,329
our environment we get credential theft

305
00:11:44,600 --> 00:11:48,980
another mission we run so we this one's

306
00:11:47,329 --> 00:11:50,329
you know actually very difficult to

307
00:11:48,980 --> 00:11:52,249
detect there's a number of tools you can

308
00:11:50,329 --> 00:11:53,689
use to try and you know detect did

309
00:11:52,249 --> 00:11:55,699
somebody steal credentials I'll take you

310
00:11:53,689 --> 00:11:57,110
through a couple scenarios here alright

311
00:11:55,699 --> 00:11:58,459
but without instrumentation this can be

312
00:11:57,110 --> 00:12:01,870
a little bit more difficult to try to

313
00:11:58,459 --> 00:12:03,680
understand sometimes it's noisy right so

314
00:12:01,870 --> 00:12:05,600
everybody hears we don't you know I

315
00:12:03,680 --> 00:12:06,949
heard earlier you know Mimi cats there

316
00:12:05,600 --> 00:12:09,320
was a you know talk about from in-game

317
00:12:06,950 --> 00:12:11,720
about Mimi cats detection and auto runs

318
00:12:09,320 --> 00:12:13,070
and invoked Mimi cats everybody I'm

319
00:12:11,720 --> 00:12:15,110
guessing it's heard of that that in you

320
00:12:13,070 --> 00:12:18,740
know runs Mimi cats inside a PowerShell

321
00:12:15,110 --> 00:12:21,020
exe our team wrote a tool that we use

322
00:12:18,740 --> 00:12:22,790
install util because everybody is

323
00:12:21,020 --> 00:12:25,460
watching PowerShell so we just run it in

324
00:12:22,790 --> 00:12:28,069
another dotnet tool okay so the fact is

325
00:12:25,460 --> 00:12:30,440
though however you run Mimi cats there's

326
00:12:28,070 --> 00:12:32,000
actually ways to detect that that

327
00:12:30,440 --> 00:12:33,920
particular event has occurred or

328
00:12:32,000 --> 00:12:36,290
whatever credential dumping tool of the

329
00:12:33,920 --> 00:12:38,689
day it might be okay the question I have

330
00:12:36,290 --> 00:12:39,829
for you is in a lab or in a test

331
00:12:38,690 --> 00:12:42,080
environment have you ever actually

332
00:12:39,830 --> 00:12:43,760
executed Mimi cats for example and

333
00:12:42,080 --> 00:12:46,220
recorded activity to see if you can

334
00:12:43,760 --> 00:12:48,560
detect it it's probably worth doing with

335
00:12:46,220 --> 00:12:50,270
permission of course right on out of

336
00:12:48,560 --> 00:12:51,829
dedicated system if you're if you've

337
00:12:50,270 --> 00:12:55,189
instrumented your environment to detect

338
00:12:51,830 --> 00:12:56,270
this take a look at the artifacts here's

339
00:12:55,190 --> 00:12:59,420
what it looks like in our environment

340
00:12:56,270 --> 00:13:02,360
when we run you know Mimi cats and I

341
00:12:59,420 --> 00:13:04,010
executed inside of install util turns

342
00:13:02,360 --> 00:13:06,800
out there's a lot of dependencies that

343
00:13:04,010 --> 00:13:08,150
maybe catch brings with it okay so I

344
00:13:06,800 --> 00:13:09,589
there's some more indicators I'll

345
00:13:08,150 --> 00:13:11,480
publish online but you know this gives

346
00:13:09,590 --> 00:13:14,330
you the sense that you know install you

347
00:13:11,480 --> 00:13:17,150
till may have se 510 dependencies all

348
00:13:14,330 --> 00:13:19,730
the sudden it starts loading 32 other

349
00:13:17,150 --> 00:13:22,040
dll's that's a suspicious indicator and

350
00:13:19,730 --> 00:13:24,080
specifically the ones that Mimi cats

351
00:13:22,040 --> 00:13:26,120
might use so that's the way we'll run

352
00:13:24,080 --> 00:13:28,580
that tool we'll see what our indicators

353
00:13:26,120 --> 00:13:29,930
show can we detect it in our environment

354
00:13:28,580 --> 00:13:33,770
so we're trying to understand it

355
00:13:29,930 --> 00:13:37,069
credentials that happen sometimes it

356
00:13:33,770 --> 00:13:39,500
happens offline okay so this is sort of

357
00:13:37,070 --> 00:13:41,240
all the rage now is I'm not going to

358
00:13:39,500 --> 00:13:42,500
drop Mimi cats in your network the

359
00:13:41,240 --> 00:13:43,790
network's instrumented you're going to

360
00:13:42,500 --> 00:13:47,930
detect the binary you'll detect

361
00:13:43,790 --> 00:13:51,110
execution all I have to do is run a mini

362
00:13:47,930 --> 00:13:53,870
cats against the dump file offline okay

363
00:13:51,110 --> 00:13:55,280
so here's an example everybody knowing

364
00:13:53,870 --> 00:13:56,720
we're on task manage you can right-click

365
00:13:55,280 --> 00:13:58,790
dump a process if you have admin rights

366
00:13:56,720 --> 00:14:01,580
in the box you can dump elsass process

367
00:13:58,790 --> 00:14:03,589
and now you just exfil a file that's got

368
00:14:01,580 --> 00:14:05,540
the grit initials inside of it what are

369
00:14:03,590 --> 00:14:07,580
the indicators here okay how would I

370
00:14:05,540 --> 00:14:10,280
know that that happened we look at

371
00:14:07,580 --> 00:14:12,830
things like cross process connections

372
00:14:10,280 --> 00:14:14,610
all right so we're looking for you know

373
00:14:12,830 --> 00:14:17,160
create remote thread essentially

374
00:14:14,610 --> 00:14:20,070
did something connect to elsass changed

375
00:14:17,160 --> 00:14:21,750
permissions that's almost always a bad

376
00:14:20,070 --> 00:14:24,000
thing okay so from an indicator

377
00:14:21,750 --> 00:14:25,829
perspective we're able to detect you

378
00:14:24,000 --> 00:14:27,600
know I don't know exactly what happened

379
00:14:25,829 --> 00:14:30,089
but I know something just connected to

380
00:14:27,600 --> 00:14:32,370
elsass and dump that process and wrote

381
00:14:30,089 --> 00:14:33,690
it to disk we should probably go explore

382
00:14:32,370 --> 00:14:35,880
that or though we should go look through

383
00:14:33,690 --> 00:14:39,269
our logs and find those indicators in

384
00:14:35,880 --> 00:14:41,490
our environment all right command and

385
00:14:39,269 --> 00:14:43,440
control so we looked at you know spear

386
00:14:41,490 --> 00:14:46,110
phishing attacks that we test we looked

387
00:14:43,440 --> 00:14:48,300
at weaponized documents credential theft

388
00:14:46,110 --> 00:14:50,360
what about command and control here's a

389
00:14:48,300 --> 00:14:53,040
couple of things that our team does

390
00:14:50,360 --> 00:14:54,750
proxy hunting proxies can be a huge

391
00:14:53,040 --> 00:14:56,599
source of information for hunting if

392
00:14:54,750 --> 00:14:59,130
you're not hunting in your proxy logs

393
00:14:56,600 --> 00:15:01,140
and Rob really challenged us to say you

394
00:14:59,130 --> 00:15:02,970
know sort of define hunting and what

395
00:15:01,140 --> 00:15:05,189
does that mean for our team it means

396
00:15:02,970 --> 00:15:06,990
you're not waiting for an alert you're

397
00:15:05,190 --> 00:15:08,850
going to look for something okay so

398
00:15:06,990 --> 00:15:10,680
you're going to just get it a conference

399
00:15:08,850 --> 00:15:13,019
room and go look in the proxy logs and

400
00:15:10,680 --> 00:15:15,810
say how would I detect bad activity the

401
00:15:13,019 --> 00:15:18,899
proxy logs ok here's a couple tips user

402
00:15:15,810 --> 00:15:20,969
agent strings dump those out look at

403
00:15:18,899 --> 00:15:22,709
unique user agent strings look for

404
00:15:20,970 --> 00:15:24,449
what's normal and look for the outliers

405
00:15:22,709 --> 00:15:27,060
okay there's a lot of good information

406
00:15:24,449 --> 00:15:29,519
in there about weird stuff executing on

407
00:15:27,060 --> 00:15:31,349
your network mime type downloads all

408
00:15:29,519 --> 00:15:34,529
right did they download a jar file an

409
00:15:31,350 --> 00:15:37,380
exe dll a lot of times the actors leave

410
00:15:34,529 --> 00:15:39,600
the mime type so if you drop an exe or

411
00:15:37,380 --> 00:15:41,670
dll you can detect that in your proxy

412
00:15:39,600 --> 00:15:43,560
log ok so we've written some custom

413
00:15:41,670 --> 00:15:47,040
scripts that we use to you know harvest

414
00:15:43,560 --> 00:15:49,410
our logs and go do custom queries DNS

415
00:15:47,040 --> 00:15:50,610
we've heard about DNS one things that

416
00:15:49,410 --> 00:15:52,980
aren't one of the things our team does

417
00:15:50,610 --> 00:15:55,230
is look at qf DS question focus datasets

418
00:15:52,980 --> 00:15:57,300
very simple rules have I seen the domain

419
00:15:55,230 --> 00:15:59,310
yes or no ok that's all I want I have a

420
00:15:57,300 --> 00:16:02,490
database that tells me this is the

421
00:15:59,310 --> 00:16:04,050
domain i saw this is the data saw so I'm

422
00:16:02,490 --> 00:16:05,970
just answering a simple question so we

423
00:16:04,050 --> 00:16:08,099
pull all the communications out of our

424
00:16:05,970 --> 00:16:10,350
proxy logs and build a simple data set

425
00:16:08,100 --> 00:16:11,790
from DNS those are actual communications

426
00:16:10,350 --> 00:16:15,209
not the dns lookups but an actual

427
00:16:11,790 --> 00:16:17,519
connection request ok so what does this

428
00:16:15,209 --> 00:16:22,260
mean in terms of you know we've run

429
00:16:17,519 --> 00:16:24,410
these tests look bear with me one second

430
00:16:22,260 --> 00:16:24,410
here

431
00:16:24,920 --> 00:16:30,240
there we go okay so after action report

432
00:16:28,050 --> 00:16:32,130
it we run one of these drills as a red

433
00:16:30,240 --> 00:16:34,170
team what is the follow-up what's the

434
00:16:32,130 --> 00:16:35,580
takeaway what's the feedback so the

435
00:16:34,170 --> 00:16:37,140
first question we would say what did the

436
00:16:35,580 --> 00:16:38,670
team to you know did you detect the

437
00:16:37,140 --> 00:16:40,740
attack or were you hunting you found

438
00:16:38,670 --> 00:16:43,199
this activity in the logs if so how

439
00:16:40,740 --> 00:16:45,060
quickly did you respond didn't you

440
00:16:43,200 --> 00:16:47,490
detect the attack in the way it was

441
00:16:45,060 --> 00:16:49,349
expected if I expected you to get caught

442
00:16:47,490 --> 00:16:51,690
in the email filter and you caught me in

443
00:16:49,350 --> 00:16:53,130
the proxy log that you know let's take

444
00:16:51,690 --> 00:16:55,530
that and maybe use that as a way to

445
00:16:53,130 --> 00:16:57,090
learn other ways of detecting our

446
00:16:55,530 --> 00:16:58,949
environment so we expected the attack

447
00:16:57,090 --> 00:17:00,300
could be detected one way and maybe it

448
00:16:58,950 --> 00:17:02,610
was detected a completely different way

449
00:17:00,300 --> 00:17:04,319
we sit down in a conference room Red

450
00:17:02,610 --> 00:17:07,949
Team Blue team we sit down and we go

451
00:17:04,319 --> 00:17:10,740
over the logs at 453 I did this what do

452
00:17:07,949 --> 00:17:12,180
you see in the logs at 453 we can comb

453
00:17:10,740 --> 00:17:17,880
through the noise and practice and drill

454
00:17:12,180 --> 00:17:20,070
our teams on what they actually saw okay

455
00:17:17,880 --> 00:17:21,600
does the data and the logs and then you

456
00:17:20,069 --> 00:17:23,129
know the data in the log and the network

457
00:17:21,599 --> 00:17:25,409
traffic does does it meet the

458
00:17:23,130 --> 00:17:27,180
expectations do you have gaps it's one

459
00:17:25,410 --> 00:17:29,970
of the best things these these exercises

460
00:17:27,180 --> 00:17:32,340
bring up for us is we didn't see it at

461
00:17:29,970 --> 00:17:34,680
all and it's better to find that out

462
00:17:32,340 --> 00:17:36,870
before the adversary shows up if your

463
00:17:34,680 --> 00:17:39,150
logs are not working properly if your

464
00:17:36,870 --> 00:17:40,889
camera is pointed at the ceiling okay

465
00:17:39,150 --> 00:17:43,200
those are things you want to learn and

466
00:17:40,890 --> 00:17:45,030
then what can be done to react more

467
00:17:43,200 --> 00:17:46,980
effectively next time what do we learn

468
00:17:45,030 --> 00:17:53,280
how do we feed that back to the blue

469
00:17:46,980 --> 00:17:54,990
team to get better okay so I'm going to

470
00:17:53,280 --> 00:17:57,149
leave you with this as far as you know

471
00:17:54,990 --> 00:18:00,120
thoughts on training like you fight

472
00:17:57,150 --> 00:18:02,640
we've all got tools the question I'm

473
00:18:00,120 --> 00:18:05,459
asking you is are they working are you

474
00:18:02,640 --> 00:18:07,500
practicing are they accurate you know if

475
00:18:05,460 --> 00:18:09,360
you played sports you've had like like

476
00:18:07,500 --> 00:18:11,160
in football you have a scout team okay

477
00:18:09,360 --> 00:18:13,229
that mimics the defense you if you if

478
00:18:11,160 --> 00:18:15,150
you did acting or theater you did

479
00:18:13,230 --> 00:18:16,800
rehearsals all right if you're going to

480
00:18:15,150 --> 00:18:19,320
sign in your rifle you go to the range

481
00:18:16,800 --> 00:18:22,409
all right so you have a lot of tools

482
00:18:19,320 --> 00:18:23,760
test those tools use some expertise on

483
00:18:22,410 --> 00:18:26,550
your teams to make sure you can catch

484
00:18:23,760 --> 00:18:27,750
those Canaries or those indicators so

485
00:18:26,550 --> 00:18:29,460
when the time comes you know they're

486
00:18:27,750 --> 00:18:35,040
working properly you can rely on you can

487
00:18:29,460 --> 00:18:36,300
trust the tool set all right I love this

488
00:18:35,040 --> 00:18:38,040
quote if you're not the man who's

489
00:18:36,300 --> 00:18:39,899
practiced 10,000 kicks one

490
00:18:38,040 --> 00:18:43,290
but I fear the man whose practice one

491
00:18:39,900 --> 00:18:45,180
kick 10,000 times so somebody gets

492
00:18:43,290 --> 00:18:47,220
really really good hunting in the proxy

493
00:18:45,180 --> 00:18:49,380
I mean really really good they're the

494
00:18:47,220 --> 00:18:51,540
go-to person okay so that's the kind of

495
00:18:49,380 --> 00:18:53,490
expertise and practice you want to prep

496
00:18:51,540 --> 00:18:56,820
you don't prepare your teams and drill

497
00:18:53,490 --> 00:18:58,200
for your teams I've got some references

498
00:18:56,820 --> 00:19:02,010
like they said earlier these slides will

499
00:18:58,200 --> 00:19:03,960
be published questions feedback again

500
00:19:02,010 --> 00:19:05,610
connect with me on Twitter at subsea I

501
00:19:03,960 --> 00:19:07,410
hope this is helpful i'll prob have time

502
00:19:05,610 --> 00:19:13,139
for questions i know we're tight on time

503
00:19:07,410 --> 00:19:18,320
so what's up ok questions helpful not

504
00:19:13,140 --> 00:19:18,320
helpful yes sir back here

505
00:19:33,539 --> 00:19:38,609
okay so the question was where you know

506
00:19:35,850 --> 00:19:40,769
I think of this right how do you remain

507
00:19:38,609 --> 00:19:44,428
stealthy but also introduce artifacts

508
00:19:40,769 --> 00:19:46,320
that would be detected it's a great

509
00:19:44,429 --> 00:19:47,820
question we you know we try like I said

510
00:19:46,320 --> 00:19:49,678
earlier we try and use for example

511
00:19:47,820 --> 00:19:52,320
threat intelligence reports so we think

512
00:19:49,679 --> 00:19:54,690
actual attacks and try and mimic those

513
00:19:52,320 --> 00:19:56,639
right so we try and use are things that

514
00:19:54,690 --> 00:19:59,519
are known like POW licks the run dll

515
00:19:56,639 --> 00:20:01,408
calling it you know ms HTML application

516
00:19:59,519 --> 00:20:03,570
so we try and focus on actual indicators

517
00:20:01,409 --> 00:20:05,279
and that's where that's I guess the best

518
00:20:03,570 --> 00:20:07,049
place we draw the line I mean if you

519
00:20:05,279 --> 00:20:08,909
look at for example like robberies like

520
00:20:07,049 --> 00:20:10,440
most robberies are just note passers

521
00:20:08,909 --> 00:20:11,700
right they don't they don't end up like

522
00:20:10,440 --> 00:20:13,619
the robbery I talked about at the

523
00:20:11,700 --> 00:20:14,970
beginning so we try and train our

524
00:20:13,619 --> 00:20:16,470
environment to be what is actually

525
00:20:14,970 --> 00:20:18,509
happening in the field what are we

526
00:20:16,470 --> 00:20:24,799
actually seeing what can we detect does

527
00:20:18,509 --> 00:20:24,799
that answer your question okay yes sir

528
00:20:34,889 --> 00:20:40,000
yeah so that's one area I'm explored so

529
00:20:37,539 --> 00:20:42,370
the question was some of the tools that

530
00:20:40,000 --> 00:20:43,539
I publish on Twitter or github do i do I

531
00:20:42,370 --> 00:20:45,610
use those in our missions those are

532
00:20:43,539 --> 00:20:46,929
usually a direct result of something we

533
00:20:45,610 --> 00:20:48,879
did so one of the things the question

534
00:20:46,929 --> 00:20:51,760
was on Twitter recently we started

535
00:20:48,880 --> 00:20:53,529
tampering with as a Red Team your log so

536
00:20:51,760 --> 00:20:55,090
system on injecting into system on or

537
00:20:53,529 --> 00:20:57,220
just shutting logs down completely

538
00:20:55,090 --> 00:20:59,649
because I know analyst rely on those

539
00:20:57,220 --> 00:21:01,720
logs so we we use those techniques and

540
00:20:59,649 --> 00:21:04,149
we would say how how would we detect

541
00:21:01,720 --> 00:21:06,250
this activity to say logs were gone or

542
00:21:04,149 --> 00:21:07,989
we can't trust the logs that so yes we

543
00:21:06,250 --> 00:21:10,419
those are those most of what I post is a

544
00:21:07,990 --> 00:21:13,750
direct result of our tests that answer

545
00:21:10,419 --> 00:21:16,019
the question okay thank you very much

546
00:21:13,750 --> 00:21:16,019
for your time

