1
00:00:00,834 --> 00:00:03,570
(dramatic music)

2
00:00:11,978 --> 00:00:14,981
(audience applauds)

3
00:00:18,018 --> 00:00:19,519
- That was way too kind.

4
00:00:20,920 --> 00:00:22,789
One of my colleagues
from Tanium pointed out

5
00:00:22,789 --> 00:00:24,424
that the date on
the slides is wrong.

6
00:00:24,424 --> 00:00:26,558
That's actually April Fool's so,

7
00:00:26,559 --> 00:00:29,129
maybe this is a gag
against you guys.

8
00:00:29,129 --> 00:00:30,363
I don't know.

9
00:00:30,363 --> 00:00:33,333
So this is Seeing Red
Improving Blue Teams

10
00:00:33,333 --> 00:00:34,300
Through Red Teaming.

11
00:00:35,535 --> 00:00:37,003
This is a slide I showed
here a couple years ago

12
00:00:37,003 --> 00:00:39,606
when I was here
talking about Kansa.

13
00:00:39,606 --> 00:00:42,175
This is the first
persistence mechanism

14
00:00:42,175 --> 00:00:43,843
I ever found at Microsoft

15
00:00:43,843 --> 00:00:46,479
during a Red Team,
Blue Team engagement.

16
00:00:46,479 --> 00:00:50,016
What we did was we
ran list dlls across

17
00:00:50,016 --> 00:00:51,650
several thousand machines

18
00:00:51,651 --> 00:00:54,954
in a particular online service
environment at Microsoft.

19
00:00:54,954 --> 00:00:57,390
We took the data from list dlls.

20
00:00:57,390 --> 00:00:59,325
If you haven't run it,
you get the process name

21
00:00:59,325 --> 00:01:02,395
and all of the dlls that
are loaded in that process.

22
00:01:02,395 --> 00:01:04,731
We aggregated based
on the process name.

23
00:01:04,730 --> 00:01:08,333
So in this case you're looking
at data for spoolsv.exe.

24
00:01:08,334 --> 00:01:10,904
So we tool all that data
from thousands of machines,

25
00:01:10,904 --> 00:01:13,106
aggregated it, and started
looking through it,

26
00:01:13,106 --> 00:01:15,809
looking for interesting things.

27
00:01:15,809 --> 00:01:17,844
About halfway down, you
can see this black line

28
00:01:17,844 --> 00:01:19,779
that sticks out
like a sore thumb.

29
00:01:19,779 --> 00:01:24,783
That is for us, luckily
a long named dll

30
00:01:26,119 --> 00:01:28,221
that the red team had injected
into a spoolsv process

31
00:01:28,221 --> 00:01:29,689
on one machine.

32
00:01:29,689 --> 00:01:31,157
That was their
persistence mechanism

33
00:01:31,157 --> 00:01:32,892
in this particular environment.

34
00:01:34,227 --> 00:01:36,763
We should this slide to
them, to the red team,

35
00:01:36,763 --> 00:01:40,033
during a postmortem meeting

36
00:01:40,033 --> 00:01:44,003
and they looked at it and said,
you know, face palm moment,

37
00:01:44,003 --> 00:01:45,872
we've gotta change our tactics

38
00:01:45,872 --> 00:01:48,074
and make it harder for them
to find this in the future.

39
00:01:48,074 --> 00:01:51,544
And it was never this
easy again, unfortunately.

40
00:01:51,544 --> 00:01:54,179
So the red team playing
off the blue team,

41
00:01:54,180 --> 00:01:56,683
the red team improving because
of things the blue team does

42
00:01:56,683 --> 00:01:57,984
and the blue team
having to improve

43
00:01:57,984 --> 00:01:59,786
because of things
the red team does,

44
00:01:59,786 --> 00:02:02,822
is largely what this
talk is gonna be about.

45
00:02:02,822 --> 00:02:04,791
So Robert already gave an intro,

46
00:02:04,791 --> 00:02:08,228
so now I regret dedicating
15 slides to intro.

47
00:02:08,228 --> 00:02:10,597
So let me get through
this as quickly as I can.

48
00:02:10,597 --> 00:02:12,398
I've been doing
information security work

49
00:02:12,398 --> 00:02:15,101
for a little over 10 years.

50
00:02:15,101 --> 00:02:16,870
Most of that time
has been focused on

51
00:02:16,870 --> 00:02:18,705
incident response and forensics.

52
00:02:18,705 --> 00:02:21,174
I've been doing IT related
work for over 20 years now,

53
00:02:21,174 --> 00:02:22,809
which is scary.

54
00:02:22,809 --> 00:02:26,112
I was working at a higher
education institution

55
00:02:26,112 --> 00:02:27,780
during this time,

56
00:02:27,780 --> 00:02:30,483
and that was not fun.

57
00:02:30,483 --> 00:02:31,951
No firewalls.

58
00:02:31,951 --> 00:02:34,220
Every machine on the network
was an IP version four address,

59
00:02:34,220 --> 00:02:38,691
routable, no NAT, not patch
requirements, no update.

60
00:02:39,559 --> 00:02:40,927
It was just awful.

61
00:02:42,028 --> 00:02:44,464
So in response to that,
I worked on a team

62
00:02:44,464 --> 00:02:46,833
that tried to build an network
access control solution,

63
00:02:46,833 --> 00:02:49,135
because the university
too cheap to buy one,

64
00:02:49,135 --> 00:02:50,670
so we built our own.

65
00:02:50,670 --> 00:02:52,204
And during the process
of building our own

66
00:02:52,205 --> 00:02:55,608
we discovered that we could
use DHCP option requests,

67
00:02:55,608 --> 00:02:57,810
you know DHCP client
comes on the network,

68
00:02:57,810 --> 00:03:00,547
it asks for things
from the DHCP server.

69
00:03:00,547 --> 00:03:02,515
We figured out that, hey,
every operating system

70
00:03:02,515 --> 00:03:03,783
asks for different things.

71
00:03:03,783 --> 00:03:05,285
They ask for it in
a different order.

72
00:03:05,285 --> 00:03:08,188
We can use this to remotely
and passively fingerprint OSs.

73
00:03:08,188 --> 00:03:11,256
And that sort of started
me down the path to

74
00:03:11,257 --> 00:03:12,859
getting into the weird machines.

75
00:03:14,027 --> 00:03:15,795
We didn't really think
this was all that novel.

76
00:03:15,795 --> 00:03:18,298
Our patent attorneys as the
university agreed with us,

77
00:03:18,298 --> 00:03:20,567
so we didn't pursue
patent protection

78
00:03:20,567 --> 00:03:23,269
and Infoblox
applied for a patent

79
00:03:23,269 --> 00:03:25,905
on basically the same
technique couple years later,

80
00:03:25,905 --> 00:03:27,440
and it was eventually awarded.

81
00:03:27,440 --> 00:03:30,176
Like Rob said, I was a SANS
instructor for a few years.

82
00:03:30,176 --> 00:03:32,978
I managed and was one of
the leading contributors

83
00:03:32,979 --> 00:03:35,215
to the Digital Forensics blog,

84
00:03:35,215 --> 00:03:37,584
the award winning
Digital Forensics blog,

85
00:03:37,584 --> 00:03:39,085
by the way.
(audience laughs)

86
00:03:39,085 --> 00:03:42,188
I have written a number of
open source tools for DFIR,

87
00:03:42,188 --> 00:03:44,357
and most recently
before coming to Tanium,

88
00:03:44,357 --> 00:03:46,059
I was the Technical Lead

89
00:03:46,059 --> 00:03:48,795
for Security Incident
Response on Office 365,

90
00:03:48,795 --> 00:03:52,298
very large distributed
environment.

91
00:03:52,298 --> 00:03:54,867
So definitely familiar with
the challenges of that.

92
00:03:54,867 --> 00:03:57,403
While I was there I read
this tool called Kansa

93
00:03:57,403 --> 00:03:59,272
that I talked about
here a couple years ago,

94
00:03:59,272 --> 00:04:01,673
a PowerShell framework for
doing incident response.

95
00:04:01,674 --> 00:04:03,176
And today I'm at Tanium.

96
00:04:03,176 --> 00:04:05,477
So that's a digression.

97
00:04:05,478 --> 00:04:07,013
That's my background.

98
00:04:07,013 --> 00:04:08,047
This is really why we're here.

99
00:04:08,047 --> 00:04:09,349
We're here to talk about

100
00:04:09,349 --> 00:04:11,184
why you should be
doing red teaming,

101
00:04:11,184 --> 00:04:14,087
what red teaming
is, how I define it,

102
00:04:14,087 --> 00:04:15,787
some highlights
and lessons learned

103
00:04:15,788 --> 00:04:17,357
from my experience of doing this

104
00:04:17,357 --> 00:04:19,192
over four years at Microsoft,

105
00:04:19,192 --> 00:04:21,394
who I think should
be doing it and when,

106
00:04:21,394 --> 00:04:23,463
and some practicalities
of red teaming,

107
00:04:23,463 --> 00:04:26,599
and finally we'll wrap it
all up in a nice conclusion.

108
00:04:26,599 --> 00:04:29,269
So just outta curiosity,
show of hands,

109
00:04:29,269 --> 00:04:31,971
how many in here are doing
red team engagements?

110
00:04:33,406 --> 00:04:35,908
How many in here think they're
doing red team engagements,

111
00:04:35,908 --> 00:04:36,909
they're not sure?

112
00:04:38,344 --> 00:04:40,880
How many are doing penetration
tests in your organization?

113
00:04:42,048 --> 00:04:44,450
Wow, I'm surprised at
the number of hands.

114
00:04:44,450 --> 00:04:46,385
Okay, so why red teaming?

115
00:04:47,587 --> 00:04:49,022
Because it delivers
a security incident.

116
00:04:49,022 --> 00:04:50,857
If you don't know the
difference between read teaming

117
00:04:50,857 --> 00:04:54,027
and penetration testing, I'll
get to that as we go here.

118
00:04:54,027 --> 00:04:56,062
Red teaming, in my mind,

119
00:04:57,730 --> 00:04:59,966
what differentiates
from pen testing,

120
00:04:59,966 --> 00:05:02,368
is that it delivers
a security incident.

121
00:05:02,368 --> 00:05:04,704
Contrast this with pen testing,

122
00:05:04,704 --> 00:05:06,706
which delivers a
nice bound report

123
00:05:06,706 --> 00:05:09,375
or unfortunately a lotta times,

124
00:05:09,375 --> 00:05:10,643
it just delivers a report,

125
00:05:10,643 --> 00:05:12,277
it's not even that
nice of a report.

126
00:05:14,414 --> 00:05:16,316
Why should you be red teaming?

127
00:05:16,316 --> 00:05:18,618
Because you will play
like you practice.

128
00:05:18,618 --> 00:05:21,921
Coaches like to say this to
their sports teams all the time.

129
00:05:21,921 --> 00:05:24,857
So to drive this point
home a little bit,

130
00:05:25,992 --> 00:05:27,393
I've got this little clip here

131
00:05:27,393 --> 00:05:29,328
from last year's National
Championship game.

132
00:05:29,329 --> 00:05:31,497
Ooh, there's audio.

133
00:05:34,500 --> 00:05:37,036
So that's a beautiful moment.

134
00:05:37,036 --> 00:05:40,973
4.7 seconds left in the
game, it's tied at 74,

135
00:05:40,973 --> 00:05:44,477
Chris Jenkins in-bounds the
ball to Ryan Arcidiacono

136
00:05:44,477 --> 00:05:47,380
or Diacano, I
can't say the same.

137
00:05:47,380 --> 00:05:50,116
He passes the ball back,
Chris Jenkins takes the shot

138
00:05:50,116 --> 00:05:51,383
from the top of the key.

139
00:05:52,518 --> 00:05:53,986
You know, I'm not
just showing you this

140
00:05:53,986 --> 00:05:56,789
because I love seeing North
Carolina lose basketball games.

141
00:05:56,789 --> 00:05:58,457
(audience laughs)

142
00:05:58,458 --> 00:05:59,792
Rock Chalk, Jayhawk.

143
00:06:00,993 --> 00:06:03,096
I'm showing you this
because I found,

144
00:06:03,096 --> 00:06:06,499
after the game, I was
looking for some examples of

145
00:06:07,633 --> 00:06:09,234
playing how you practice.

146
00:06:09,235 --> 00:06:11,371
This Villanova clip seemed good.

147
00:06:11,371 --> 00:06:14,272
They run this play at the
end of every practice.

148
00:06:14,273 --> 00:06:17,610
So can you image, practice
starts in like November,

149
00:06:17,610 --> 00:06:19,479
the season runs through April.

150
00:06:19,479 --> 00:06:20,880
At the end of every
single practice,

151
00:06:20,880 --> 00:06:22,849
these guys run
through this drill.

152
00:06:22,849 --> 00:06:24,650
They do this when
they're exhausted

153
00:06:24,650 --> 00:06:26,318
and ready to go focus
on something else,

154
00:06:26,319 --> 00:06:29,322
go to take a shower, go
get dinner what have you.

155
00:06:29,322 --> 00:06:31,958
So their coach does
this because he knows

156
00:06:31,958 --> 00:06:33,960
that they're gonna play
like they practice,

157
00:06:33,960 --> 00:06:35,762
especially under
stressful situations.

158
00:06:35,762 --> 00:06:39,098
And it's the same for
your organizations.

159
00:06:39,098 --> 00:06:40,733
Doing red team drills

160
00:06:40,733 --> 00:06:43,703
gives you a chance to practice
security incident response

161
00:06:43,703 --> 00:06:47,306
under somewhat
realistic circumstances.

162
00:06:47,306 --> 00:06:49,342
So that's a little bit
about why red teaming,

163
00:06:49,342 --> 00:06:50,409
why it's important.

164
00:06:50,410 --> 00:06:51,778
So what is it exactly.

165
00:06:53,179 --> 00:06:56,048
There's some different
opinions about what it is.

166
00:06:56,048 --> 00:06:59,285
So I kinda like to define it
in terms of maybe what it isn't

167
00:06:59,285 --> 00:07:01,687
or what its
constituent parts are.

168
00:07:01,687 --> 00:07:04,190
So red teaming is
not threat modeling.

169
00:07:04,190 --> 00:07:05,124
Threat modeling's that process

170
00:07:05,124 --> 00:07:06,492
that organizations go through,

171
00:07:06,492 --> 00:07:07,960
they try to enumerate
what they think

172
00:07:07,960 --> 00:07:09,861
all the threats are
to their organization

173
00:07:09,862 --> 00:07:12,198
or to some software
package they're building

174
00:07:12,198 --> 00:07:14,767
and they talk about how
they'll mitigate those threats.

175
00:07:14,767 --> 00:07:16,669
Red teaming may include
threat modeling,

176
00:07:16,669 --> 00:07:18,438
but it's not limited to that.

177
00:07:18,438 --> 00:07:19,972
It's not a vulnerability
assessment.

178
00:07:19,972 --> 00:07:21,741
You can run Nessus
in your enterprise,

179
00:07:21,741 --> 00:07:23,376
find out what all your
vulnerabilities are,

180
00:07:23,376 --> 00:07:25,277
build out a nice project plan

181
00:07:25,278 --> 00:07:27,246
for how you're gonna go
patch all those things.

182
00:07:27,246 --> 00:07:29,816
It may include that, but
it's not limited to that.

183
00:07:29,816 --> 00:07:31,150
It's not penetration testing.

184
00:07:31,150 --> 00:07:34,085
I worked in a big
tier two regional bank

185
00:07:34,086 --> 00:07:37,523
and we hired a big four letter
consulting firms to come in

186
00:07:37,523 --> 00:07:39,492
and do pen tests for us

187
00:07:39,492 --> 00:07:41,994
and they delivered
those nice bound reports

188
00:07:41,994 --> 00:07:43,396
and they would tell us up front,

189
00:07:43,396 --> 00:07:45,498
we're gonna start the
pen test on this date,

190
00:07:45,498 --> 00:07:46,732
we're gonna end it on this date.

191
00:07:46,732 --> 00:07:49,001
This is our IP ranges
that we're coming from.

192
00:07:49,001 --> 00:07:50,837
These are our browser
user agent strings.

193
00:07:50,837 --> 00:07:52,070
You know, don't shun us.

194
00:07:52,071 --> 00:07:53,306
Set exceptions in the firewall.

195
00:07:53,306 --> 00:07:55,140
Don't respond to us.

196
00:07:55,141 --> 00:07:57,109
That's penetration
testing in a nut shell.

197
00:07:57,109 --> 00:07:58,644
Red teams are different.

198
00:07:58,644 --> 00:08:00,012
They might tell you
when they're starting,

199
00:08:00,012 --> 00:08:01,547
they might give you some
of that information,

200
00:08:01,547 --> 00:08:03,282
but they expect you to respond.

201
00:08:03,282 --> 00:08:05,051
They expect you
try and combat them

202
00:08:05,051 --> 00:08:07,186
like you would a real adversary.

203
00:08:07,186 --> 00:08:09,087
So red teaming is different.

204
00:08:09,088 --> 00:08:11,557
Remember this great picture.

205
00:08:11,557 --> 00:08:14,126
That's what pen testing
can be thought of.

206
00:08:14,126 --> 00:08:15,561
Red teaming is
gonna be something

207
00:08:15,561 --> 00:08:17,796
that has a mission objective.

208
00:08:17,797 --> 00:08:20,633
Some people say the
enterprise or domain admin

209
00:08:20,633 --> 00:08:22,168
might be the mission objective.

210
00:08:22,168 --> 00:08:24,036
That's usually a
means to an end.

211
00:08:24,036 --> 00:08:25,571
Usually they're gonna be
trying to do something

212
00:08:25,571 --> 00:08:27,073
like customer pivot.

213
00:08:27,073 --> 00:08:29,174
In the online services
world where I worked,

214
00:08:29,175 --> 00:08:30,710
a customer pivot would be,

215
00:08:30,710 --> 00:08:33,078
customer A being able to
access customer B's data

216
00:08:33,078 --> 00:08:34,546
without authorization.

217
00:08:34,547 --> 00:08:38,918
So imagine, that makes sense
for Azure, AWS, GitHub,

218
00:08:38,918 --> 00:08:40,352
if you're running
some online service,

219
00:08:40,352 --> 00:08:41,853
that's a customer pivot.

220
00:08:41,854 --> 00:08:44,090
IP theft, I don't have
to explain that one.

221
00:08:44,090 --> 00:08:45,658
That could be a
mission objective.

222
00:08:45,658 --> 00:08:47,093
Burn it all down.

223
00:08:47,093 --> 00:08:50,062
Let's see if you can get
malware, or something like it,

224
00:08:50,062 --> 00:08:53,132
executing across every
machine in the environment.

225
00:08:53,132 --> 00:08:54,566
Burn it all down.

226
00:08:54,567 --> 00:08:57,837
So Saudi Aramco style,
Sony Pictures style attack.

227
00:08:57,837 --> 00:09:00,139
The ultimate goal
is obviously to test

228
00:09:00,139 --> 00:09:02,842
the incident response
capabilities and procedures,

229
00:09:02,842 --> 00:09:05,745
not just of the defenders,
not just of the blue team,

230
00:09:05,745 --> 00:09:07,213
if you have a real
security incident,

231
00:09:07,213 --> 00:09:10,449
you're gonna have
legal, communications,

232
00:09:10,449 --> 00:09:13,386
management, subject matter
experts, developers,

233
00:09:13,386 --> 00:09:16,756
network architects, people whose
primary job is not security

234
00:09:16,756 --> 00:09:18,057
they're all gonna be involved

235
00:09:18,057 --> 00:09:20,092
in the incident
response process.

236
00:09:20,092 --> 00:09:21,994
So red teaming gives
you a chance to test

237
00:09:21,994 --> 00:09:25,932
those lines of communication
and cooperation

238
00:09:25,932 --> 00:09:28,334
and collaboration between
those different teams.

239
00:09:29,502 --> 00:09:32,204
So that's how I define
red teaming, what it is.

240
00:09:32,204 --> 00:09:34,040
So some highlights
and lessons learned.

241
00:09:34,040 --> 00:09:35,708
I'll share just
a few highlights.

242
00:09:36,609 --> 00:09:38,444
I had a strip a lot of 'em out

243
00:09:38,444 --> 00:09:40,947
to make the content
fit the time.

244
00:09:40,947 --> 00:09:42,648
Also share some lessons learned.

245
00:09:42,648 --> 00:09:44,083
I'll be sprinkling
the lessons learned

246
00:09:44,083 --> 00:09:46,385
throughout the
remainder of the talk.

247
00:09:46,385 --> 00:09:48,420
So one lesson I learned

248
00:09:48,421 --> 00:09:51,023
in doing incident
response at Office 365,

249
00:09:51,023 --> 00:09:54,460
in smaller environments, this
outliers may be leads thing

250
00:09:54,460 --> 00:09:55,828
works really well.

251
00:09:55,828 --> 00:09:58,396
In really large
scale environments,

252
00:09:58,397 --> 00:10:00,099
despite what Dan Gear says,

253
00:10:00,099 --> 00:10:01,300
if you're familiar
with Dan Gear,

254
00:10:01,300 --> 00:10:03,169
he wrote this paper
years ago about

255
00:10:03,169 --> 00:10:05,103
the dangers of monoculture.

256
00:10:05,104 --> 00:10:07,406
If everybody goes to the
same operating system,

257
00:10:07,406 --> 00:10:09,141
it makes your environment
more susceptible

258
00:10:09,141 --> 00:10:11,410
to being completely owned.

259
00:10:11,410 --> 00:10:14,413
In very large environments,
the monoculture is a myth

260
00:10:14,413 --> 00:10:16,082
in my experience.

261
00:10:16,082 --> 00:10:17,984
You're gonna have
a very long tail

262
00:10:17,984 --> 00:10:20,953
of completely benign
outliers in your environment

263
00:10:20,953 --> 00:10:22,988
and unfortunately your
team has to rat hole

264
00:10:22,989 --> 00:10:25,291
on every single one them if
you wanna do a thorough job

265
00:10:25,291 --> 00:10:27,226
to figure out, are
these things malicious

266
00:10:27,226 --> 00:10:28,461
or are they benign?

267
00:10:28,461 --> 00:10:31,597
I would just like once
to go into an enterprise

268
00:10:31,597 --> 00:10:33,733
where the mythical
monoculture really exists

269
00:10:33,733 --> 00:10:36,267
and the outliers are
actually all malicious.

270
00:10:36,268 --> 00:10:37,837
That would be nice.

271
00:10:37,837 --> 00:10:40,806
I don't think Dan Gear ever
did incident response work.

272
00:10:40,806 --> 00:10:43,142
The opposite of
this is also true.

273
00:10:43,142 --> 00:10:45,945
So imagine the Saudi
Aramco style event

274
00:10:45,945 --> 00:10:48,314
or the Sony Pictures
style event,

275
00:10:48,314 --> 00:10:50,549
where you're just
looking at the anomalies,

276
00:10:50,549 --> 00:10:52,485
when there's malware planted
on every single machine

277
00:10:52,485 --> 00:10:53,819
that's gonna go wipe
all the hard drives

278
00:10:53,819 --> 00:10:55,554
when they flip the switch.

279
00:10:55,554 --> 00:10:59,091
So outliers may be
leads or they may not.

280
00:10:59,091 --> 00:11:00,426
Automate whatever you can.

281
00:11:00,426 --> 00:11:02,028
This should go without saying.

282
00:11:02,028 --> 00:11:05,464
By example, I worked an
incident at Microsoft,

283
00:11:05,464 --> 00:11:06,932
a red team engagement

284
00:11:06,932 --> 00:11:09,001
where I spent like
six hours massaging

285
00:11:09,001 --> 00:11:13,839
one day's worth of data
looking for red team activity.

286
00:11:13,839 --> 00:11:15,274
I was faced with the
prospect of doing this

287
00:11:15,274 --> 00:11:16,909
again and again and again

288
00:11:16,909 --> 00:11:18,811
for the course of
the investigation.

289
00:11:18,811 --> 00:11:21,013
So that night I went home
and I spent like 45 minutes

290
00:11:21,013 --> 00:11:22,214
writing a script.

291
00:11:22,214 --> 00:11:23,883
I ran that script
against that data set.

292
00:11:23,883 --> 00:11:27,319
I got the exact same results
back in less than a second.

293
00:11:27,319 --> 00:11:29,221
So automate whatever you can.

294
00:11:29,221 --> 00:11:31,657
It's gonna help you out
in your engagements.

295
00:11:31,657 --> 00:11:33,092
Remediation.

296
00:11:33,092 --> 00:11:34,593
This should be the ultimate
goal of any blue team

297
00:11:34,593 --> 00:11:36,228
is to get to remediation.

298
00:11:36,228 --> 00:11:37,729
This is another
slide I showed here

299
00:11:37,730 --> 00:11:39,799
when I was talking about
Kansa a couple years ago.

300
00:11:39,799 --> 00:11:43,302
This is my favorite slide
from my time at Microsoft.

301
00:11:43,302 --> 00:11:47,073
What this is, is the console
that the red team in Office 365

302
00:11:47,073 --> 00:11:49,208
used to control their botnet.

303
00:11:49,208 --> 00:11:52,178
So they would compromise
machines in O365

304
00:11:52,178 --> 00:11:53,412
and make them call home

305
00:11:53,412 --> 00:11:55,014
to their command
and control in Azure

306
00:11:55,014 --> 00:11:59,518
and this was their interface
for controlling those machines.

307
00:11:59,518 --> 00:12:01,787
At the top here, the
details are not important,

308
00:12:01,787 --> 00:12:04,490
each one of these lines
in the top section,

309
00:12:04,490 --> 00:12:08,194
are machines that are calling
home to the O365 red team.

310
00:12:09,628 --> 00:12:13,332
The lines that show up in
this burnt orange color

311
00:12:13,332 --> 00:12:15,801
are machines that we remediated.

312
00:12:15,801 --> 00:12:18,104
We kicked off a
script via Kansa,

313
00:12:18,104 --> 00:12:21,273
it ran over Windows Remote
Management and PowerShell

314
00:12:21,273 --> 00:12:22,708
and went and cleaned up

315
00:12:22,708 --> 00:12:24,477
and kicked them out
of the environment.

316
00:12:24,477 --> 00:12:26,645
You'll note there's one
machine here in gray.

317
00:12:26,645 --> 00:12:28,714
The Windows Remote
Management stack

318
00:12:28,714 --> 00:12:30,316
on this particular
machine was hosed

319
00:12:30,316 --> 00:12:32,051
and we couldn't
communicate with it,

320
00:12:32,051 --> 00:12:33,519
so we had to use
some other means

321
00:12:33,519 --> 00:12:36,522
to try and remediate
that particular machine.

322
00:12:36,522 --> 00:12:38,491
Which leads to
another lesson learned

323
00:12:38,491 --> 00:12:40,526
and all incident responders
should know this,

324
00:12:40,526 --> 00:12:43,061
incident response like
security is process

325
00:12:43,062 --> 00:12:44,430
not a destination,

326
00:12:44,430 --> 00:12:46,498
so you gotta lather,
rinse, and repeat,

327
00:12:46,499 --> 00:12:49,101
or investigate,
remediate, and repeat.

328
00:12:49,101 --> 00:12:50,636
So those are a few highlights.

329
00:12:50,636 --> 00:12:54,106
I'll share some more
lessons learned as we go.

330
00:12:54,106 --> 00:12:55,908
Who do I think should
be red teaming?

331
00:12:55,908 --> 00:12:57,209
In my mind, any organization

332
00:12:57,209 --> 00:12:58,643
that can have a
security incident,

333
00:12:58,644 --> 00:13:01,680
should probably be doing
red team activities.

334
00:13:01,680 --> 00:13:04,883
Any organization with
something worth protecting,

335
00:13:04,884 --> 00:13:06,118
but there's some caveats.

336
00:13:06,118 --> 00:13:07,653
If you don't have monitoring,

337
00:13:07,653 --> 00:13:09,188
if you don't have
defensive capabilities,

338
00:13:09,188 --> 00:13:10,856
if you don't have
IR capabilities,

339
00:13:10,856 --> 00:13:12,591
go work on those things first.

340
00:13:12,591 --> 00:13:13,826
Don't start red teaming.

341
00:13:13,826 --> 00:13:16,529
You'll be in for a
very, very bad time.

342
00:13:16,529 --> 00:13:18,197
Once you have these
things in place,

343
00:13:18,197 --> 00:13:19,999
you'll just be in
for a bad time.

344
00:13:19,999 --> 00:13:23,235
But make sure you get these
things in place first.

345
00:13:23,235 --> 00:13:24,737
Don't wait for them to be good,

346
00:13:24,737 --> 00:13:26,972
or even, especially don't
wait for them to be perfect,

347
00:13:26,972 --> 00:13:29,141
but don't even have to
wait for them to be good.

348
00:13:29,141 --> 00:13:31,911
When your red team comes
in, if they're a good team,

349
00:13:31,911 --> 00:13:34,213
they'll be able to
help you identify that,

350
00:13:34,213 --> 00:13:36,815
hey, you've made the wrong
investments in monitoring

351
00:13:36,816 --> 00:13:39,718
or your defensive
capabilities that you

352
00:13:39,718 --> 00:13:41,086
spent time and effort on

353
00:13:41,086 --> 00:13:42,688
are not what you
thought they were.

354
00:13:42,688 --> 00:13:44,122
So they can help you identify

355
00:13:44,123 --> 00:13:46,692
and strategize about
what you should be doing.

356
00:13:46,692 --> 00:13:48,661
So who should be
doing the red teaming?

357
00:13:49,962 --> 00:13:51,230
Probably an internal team.

358
00:13:51,230 --> 00:13:53,666
At Microsoft we had a
dedicated team for this,

359
00:13:53,666 --> 00:13:56,101
but not just the security team.

360
00:13:56,101 --> 00:13:57,670
The red team can't
know everything.

361
00:13:57,670 --> 00:14:00,005
They're gonna need to bring
in subject matter experts

362
00:14:00,005 --> 00:14:02,808
to help them understand
details about the environments

363
00:14:02,808 --> 00:14:04,610
they're trying to attack.

364
00:14:06,045 --> 00:14:07,780
You're gonna find though,

365
00:14:07,780 --> 00:14:10,983
as you do incidents that
documentation is wrong,

366
00:14:10,983 --> 00:14:13,618
that your architecture
diagrams are gonna be wrong,

367
00:14:13,619 --> 00:14:15,187
comments in the code
are gonna be wrong.

368
00:14:15,187 --> 00:14:17,489
The code will get updated
and the comments won't.

369
00:14:17,489 --> 00:14:19,959
People are gonna tell you
things that they're wrong about.

370
00:14:19,959 --> 00:14:21,392
Oh this section of the network

371
00:14:21,393 --> 00:14:22,862
is not actually reachable
from the internet

372
00:14:22,862 --> 00:14:24,697
or this system management portal

373
00:14:24,697 --> 00:14:26,532
requires two factor
authentication

374
00:14:26,532 --> 00:14:28,100
and there's always
going to be exceptions

375
00:14:28,100 --> 00:14:30,302
that they forgot about
or they don't know about,

376
00:14:30,302 --> 00:14:32,371
so always question
the assumptions,

377
00:14:32,371 --> 00:14:35,007
when you're having to
deal with real adversaries

378
00:14:35,007 --> 00:14:36,608
or red team engagements.

379
00:14:36,609 --> 00:14:38,177
When should you be
doing red teaming?

380
00:14:38,177 --> 00:14:40,846
I originally said
as often as you can

381
00:14:40,846 --> 00:14:42,715
and I've since recanted.

382
00:14:42,715 --> 00:14:45,050
I think I look back
on my time on at O365

383
00:14:45,050 --> 00:14:46,886
a little more fondly than

384
00:14:46,886 --> 00:14:49,121
maybe it was when
I was really there.

385
00:14:49,121 --> 00:14:52,625
I think probably three times a
year, for most organizations,

386
00:14:52,625 --> 00:14:54,994
depending on your
maturity level is plenty.

387
00:14:54,994 --> 00:14:57,897
The reason you don't wanna
do it more often than that,

388
00:14:57,897 --> 00:15:00,065
is because you're gonna
find a lotta things

389
00:15:00,065 --> 00:15:01,700
your team needs
to work on and fix

390
00:15:01,700 --> 00:15:03,369
and you need time
to fix those things.

391
00:15:03,369 --> 00:15:05,137
In O365 the strategy was,

392
00:15:05,137 --> 00:15:07,439
we're just gonna constantly
red team the environment.

393
00:15:07,439 --> 00:15:08,674
It's gonna be great

394
00:15:08,674 --> 00:15:10,342
and it was great
for the red team,

395
00:15:11,510 --> 00:15:12,912
but not so great
for the blue team.

396
00:15:12,912 --> 00:15:16,081
Doing it more often
can be demoralizing

397
00:15:16,081 --> 00:15:17,316
and lead to burnout.

398
00:15:17,316 --> 00:15:18,717
The other thing you
don't wanna do is,

399
00:15:18,717 --> 00:15:20,552
you don't wanna get cute
with your incidents.

400
00:15:20,552 --> 00:15:22,488
I had a friend who worked
at a big social network

401
00:15:22,488 --> 00:15:26,091
in Silicon Valley and they
started doing red team exercises

402
00:15:26,091 --> 00:15:29,295
and they thought, oh let's
do a Valentine's Day themed

403
00:15:29,295 --> 00:15:31,063
red team engagement.

404
00:15:31,063 --> 00:15:33,799
So they kicked off an
engagement on Valentine's Day.

405
00:15:33,799 --> 00:15:36,602
The blue team didn't know it
was a red team engagement.

406
00:15:36,602 --> 00:15:38,069
A lotta the blue team guys,

407
00:15:38,070 --> 00:15:40,606
you know they're are well
paid Silicon Valley employees.

408
00:15:40,606 --> 00:15:42,107
They had made reservations

409
00:15:42,107 --> 00:15:44,443
at really hard to get into
restaurants in San Francisco

410
00:15:44,443 --> 00:15:46,612
and they had to cancel
their reservations,

411
00:15:46,612 --> 00:15:49,247
because they had to stay and
work a red team engagement.

412
00:15:49,248 --> 00:15:50,950
So don't do stuff like that.

413
00:15:50,950 --> 00:15:52,618
Keep it professional.

414
00:15:52,618 --> 00:15:55,020
Avoid concurrent
red team incidents.

415
00:15:55,020 --> 00:15:56,255
I think at one point in time,

416
00:15:56,255 --> 00:15:59,458
John's here, I think
I saw John here,

417
00:15:59,458 --> 00:16:01,060
did we have three
or four concurrent

418
00:16:01,060 --> 00:16:02,928
red team engagements
running at once?

419
00:16:04,330 --> 00:16:06,565
I wanted to say it was
three and it felt like four,

420
00:16:06,565 --> 00:16:08,233
but I think you're
probably right.

421
00:16:08,233 --> 00:16:11,637
Avoid concurrent red team
engagements, it's awful.

422
00:16:11,637 --> 00:16:14,439
Your team is gonna
have real incidents

423
00:16:14,440 --> 00:16:15,674
they should be working on,

424
00:16:15,674 --> 00:16:17,443
so having multiple
red team engagements

425
00:16:17,443 --> 00:16:19,578
to work on simultaneously
is terrible.

426
00:16:19,578 --> 00:16:21,547
So don't do that.

427
00:16:21,547 --> 00:16:24,650
Some practicalities
of red teaming.

428
00:16:24,650 --> 00:16:26,285
You wanna have
rules of engagement

429
00:16:26,285 --> 00:16:30,089
subject to annual review
by legal, by the blue team,

430
00:16:30,089 --> 00:16:31,423
by the stakeholders
that are gonna be

431
00:16:31,423 --> 00:16:33,559
targeted by the exercises.

432
00:16:33,559 --> 00:16:36,094
You need to get approval
from management and legal.

433
00:16:36,095 --> 00:16:38,597
Your red team, once your blue
team starts getting good,

434
00:16:38,597 --> 00:16:39,865
your defenses
start getting good,

435
00:16:39,865 --> 00:16:41,967
your red team is gonna
wanna do things like,

436
00:16:41,967 --> 00:16:44,303
let's install key loggers
in the environment,

437
00:16:44,303 --> 00:16:46,972
or let's start reading
employee email.

438
00:16:46,972 --> 00:16:49,675
And you definitely want
legal on the hook for that.

439
00:16:49,675 --> 00:16:51,510
You know our red team
started doing things like,

440
00:16:51,510 --> 00:16:55,114
let's search email archives
for password or user names

441
00:16:55,114 --> 00:16:57,049
and we'll pull those out emails,

442
00:16:57,049 --> 00:16:58,283
'cause people get lazy

443
00:16:58,283 --> 00:16:59,918
and they send that stuff
around through email.

444
00:16:59,918 --> 00:17:04,223
So you wanna have legal
engaged in this process.

445
00:17:04,223 --> 00:17:07,358
No accessing or tampering
with customer data,

446
00:17:07,358 --> 00:17:09,293
should also be in your
rules of engagement,

447
00:17:09,294 --> 00:17:11,964
at least no accessing
or tampering with
real customer data.

448
00:17:11,964 --> 00:17:13,232
If you're an online service,

449
00:17:13,232 --> 00:17:15,300
your red team's gonna
set up bogus accounts,

450
00:17:15,300 --> 00:17:17,668
and they're gonna see if
they can exfiltrate data

451
00:17:17,669 --> 00:17:19,371
from one to the other.

452
00:17:19,371 --> 00:17:20,339
No outages.

453
00:17:20,339 --> 00:17:21,874
So no denial of service attacks.

454
00:17:21,874 --> 00:17:23,342
Those were off the table for us.

455
00:17:23,342 --> 00:17:25,778
No weakening of the
company's security posture.

456
00:17:25,778 --> 00:17:28,447
That should probably be in
your rules of engagement.

457
00:17:28,446 --> 00:17:30,114
Give the red team access.

458
00:17:30,115 --> 00:17:32,484
Don't make the red team
prove that your organization

459
00:17:32,484 --> 00:17:34,485
is just like every
organization in the world,

460
00:17:34,486 --> 00:17:36,422
because you probably are.

461
00:17:36,422 --> 00:17:38,390
You can get phished.

462
00:17:38,390 --> 00:17:41,994
If you want to prove
that you can get phished,

463
00:17:41,994 --> 00:17:43,861
have the red team do
a phishing exercise

464
00:17:43,862 --> 00:17:46,732
one or twice a year,
but you can get phished.

465
00:17:46,732 --> 00:17:48,267
What we did at Microsoft was,

466
00:17:48,267 --> 00:17:50,069
the red team had
corporate access.

467
00:17:50,069 --> 00:17:51,937
They access to the
corporate network

468
00:17:51,937 --> 00:17:53,405
and from there they had to see,

469
00:17:53,405 --> 00:17:55,574
can I get into a data center?

470
00:17:55,574 --> 00:17:57,042
So just give the
red team access.

471
00:17:57,042 --> 00:17:59,178
Don't make them prove that
you're susceptible to phishing

472
00:17:59,178 --> 00:18:00,779
because you are.

473
00:18:00,779 --> 00:18:01,914
Give the red team source code.

474
00:18:01,914 --> 00:18:03,148
Give 'em whatever they want.

475
00:18:03,148 --> 00:18:04,616
Give 'em the network
architecture diagrams.

476
00:18:04,616 --> 00:18:06,618
You're gonna find out
that stuff's wrong anyway.

477
00:18:06,618 --> 00:18:07,785
Keep the blue team in the dark

478
00:18:07,786 --> 00:18:10,355
or at least in
poorly lit offices.

479
00:18:10,355 --> 00:18:13,926
Real incidents should
trump red team incidents.

480
00:18:13,926 --> 00:18:14,960
Should go without saying.

481
00:18:14,960 --> 00:18:16,195
A real incident pops up

482
00:18:16,195 --> 00:18:17,830
during the middle of
a red team engagement,

483
00:18:17,830 --> 00:18:19,764
the red team engagement
gets put on hold,

484
00:18:19,765 --> 00:18:21,900
until the real incident
is taken care of.

485
00:18:21,900 --> 00:18:23,702
Red incidents are
core hours only.

486
00:18:23,702 --> 00:18:24,937
Now some of you are
probably saying,

487
00:18:24,937 --> 00:18:26,839
how do you ensure that
they're core hours only?

488
00:18:26,839 --> 00:18:30,142
If a red team member trips over
some monitor on the weekend

489
00:18:30,142 --> 00:18:31,577
and the blue team
gets called in,

490
00:18:31,577 --> 00:18:34,480
how do you know, that's
outside core hours

491
00:18:34,480 --> 00:18:36,849
that the blue team
is responding to it.

492
00:18:36,849 --> 00:18:38,283
Red teams are lazy.

493
00:18:38,283 --> 00:18:39,885
They wanna write tools once

494
00:18:39,885 --> 00:18:41,420
and use them in
every engagement.

495
00:18:41,420 --> 00:18:44,123
So that was the way
it was at Office 365,

496
00:18:44,123 --> 00:18:45,224
I'm sure it's gonna be that way

497
00:18:45,224 --> 00:18:47,091
in other organizations as well.

498
00:18:47,092 --> 00:18:48,994
We got really good
at being able to

499
00:18:48,994 --> 00:18:51,996
see some process that was
doing something malicious,

500
00:18:51,997 --> 00:18:54,666
dump the process memory
and start going through it

501
00:18:54,666 --> 00:18:58,003
and find designs that it
was red team activity,

502
00:18:58,003 --> 00:19:00,906
because they leave nice
indicators or markers.

503
00:19:00,906 --> 00:19:03,142
So we got to attribution
very quickly.

504
00:19:03,142 --> 00:19:05,377
So I would say,
red team incidents,

505
00:19:05,377 --> 00:19:07,779
core hours only plus a little.

506
00:19:07,779 --> 00:19:09,181
Sometimes they would
trip over things

507
00:19:09,181 --> 00:19:10,482
Friday afternoon at four o'clock

508
00:19:10,482 --> 00:19:12,151
and we would be
there until seven.

509
00:19:12,151 --> 00:19:15,254
But it didn't happen
all that often.

510
00:19:16,688 --> 00:19:19,358
So practice how you wanna
play and by this I mean,

511
00:19:19,358 --> 00:19:21,059
you're gonna need cross
team collaboration.

512
00:19:21,059 --> 00:19:24,830
You want comms involved,
subject matter experts,

513
00:19:24,830 --> 00:19:26,398
developers, networking teams,

514
00:19:26,398 --> 00:19:28,634
people outside of just the core

515
00:19:28,634 --> 00:19:30,636
security incident
response skill set,

516
00:19:30,636 --> 00:19:32,404
because you wanna test,
how would we do this

517
00:19:32,404 --> 00:19:34,239
during a real engagement.

518
00:19:34,239 --> 00:19:37,075
It's important that you know
how these things are gonna work

519
00:19:37,075 --> 00:19:39,144
during a real engagement.

520
00:19:39,144 --> 00:19:42,681
Establish a situation room
or at least a phone bridge.

521
00:19:42,681 --> 00:19:44,650
Designate incident and
investigative leads,

522
00:19:44,650 --> 00:19:46,218
just like you would
for a real incident.

523
00:19:46,218 --> 00:19:48,520
Your incident lead is gonna
be an interface to management

524
00:19:48,520 --> 00:19:51,389
and people outside the
core investigative team.

525
00:19:51,390 --> 00:19:54,293
The investigative lead is
going to delegate and PM

526
00:19:54,293 --> 00:19:55,960
all the activities
for the investigation,

527
00:19:55,961 --> 00:19:57,729
and then you just run this
like you would any IR.

528
00:19:57,729 --> 00:20:00,432
So investigate,
document your findings,

529
00:20:00,432 --> 00:20:01,633
report your findings.

530
00:20:01,633 --> 00:20:04,036
Nobody like reports
writing, right,

531
00:20:04,036 --> 00:20:08,574
so I like to say analyze
for show, report for dough.

532
00:20:08,574 --> 00:20:10,008
Plan for remediation.

533
00:20:10,008 --> 00:20:11,176
All the while you're
running your investigation

534
00:20:11,176 --> 00:20:12,543
you should be planning
for remediation.

535
00:20:12,544 --> 00:20:13,779
How are we gonna
clean this thing up?

536
00:20:13,779 --> 00:20:15,480
That should always be in
the back of your mind,

537
00:20:15,480 --> 00:20:16,748
develop that plan.

538
00:20:16,748 --> 00:20:18,550
Execute the remediation plan,

539
00:20:18,550 --> 00:20:20,418
go into post-remediation
monitoring,

540
00:20:20,419 --> 00:20:22,254
look for anything
you may have missed,

541
00:20:22,254 --> 00:20:24,856
look for any new
indicators, any new activity

542
00:20:24,856 --> 00:20:26,058
related to that team.

543
00:20:26,058 --> 00:20:27,826
And when you feel
like you've got it all

544
00:20:27,826 --> 00:20:29,428
or you're just ready to give up,

545
00:20:29,428 --> 00:20:31,563
you move into the
postmortem phase.

546
00:20:31,563 --> 00:20:34,266
This is the most important
phase of the entire process.

547
00:20:34,266 --> 00:20:35,567
You get the stakeholders,
the blue team,

548
00:20:35,567 --> 00:20:37,169
and the red team in a room

549
00:20:37,169 --> 00:20:38,937
and you talk about
what happened.

550
00:20:38,937 --> 00:20:40,871
It's not about assigning blame.

551
00:20:40,872 --> 00:20:42,874
People are gonna be
to blame for sure,

552
00:20:42,874 --> 00:20:44,142
but do hold yourself
accountable.

553
00:20:44,142 --> 00:20:45,377
If you screw something up,

554
00:20:45,377 --> 00:20:46,645
and I screwed up
stuff all the time,

555
00:20:46,645 --> 00:20:48,280
I would miss things
that were obvious,

556
00:20:48,280 --> 00:20:49,848
hold yourself accountable

557
00:20:49,848 --> 00:20:52,149
and have a plan for how are
we gonna fix this next time,

558
00:20:52,150 --> 00:20:54,553
how are we gonna do
better next time.

559
00:20:54,553 --> 00:20:56,488
I like for the blue
team to go first

560
00:20:56,488 --> 00:20:58,023
during the read out.

561
00:20:58,023 --> 00:21:00,626
They give the fictional
account of what happened.

562
00:21:00,626 --> 00:21:01,994
All cards on the table.

563
00:21:01,994 --> 00:21:03,728
I showed that slide with the dll

564
00:21:03,729 --> 00:21:04,863
and they never did that again.

565
00:21:04,863 --> 00:21:06,531
They switched to
reflected dll injection

566
00:21:06,531 --> 00:21:08,934
and we never saw them write
anything to disk again,

567
00:21:08,934 --> 00:21:11,670
except for one regression
in one engagement.

568
00:21:11,670 --> 00:21:14,673
So it was very tempting when
they changed their tactics

569
00:21:14,673 --> 00:21:16,308
and made it more
difficult for us,

570
00:21:16,308 --> 00:21:18,243
I wanted to keep the
cards close to my vest,

571
00:21:18,243 --> 00:21:21,379
but it's about improving
the organization

572
00:21:21,380 --> 00:21:22,581
and the capabilities all out,

573
00:21:22,581 --> 00:21:24,216
so put it all out on the table,

574
00:21:24,216 --> 00:21:26,351
give 'em your best
investigative techniques

575
00:21:26,351 --> 00:21:28,854
so that they can improve
and make you better.

576
00:21:29,755 --> 00:21:31,223
The red team goes second.

577
00:21:31,223 --> 00:21:32,758
They tell the factual
account of what happened.

578
00:21:32,758 --> 00:21:34,359
The blue team tells
the fictional account

579
00:21:34,359 --> 00:21:35,827
of what they thinking happened.

580
00:21:35,827 --> 00:21:37,963
The difference between
the facts and the fiction

581
00:21:37,963 --> 00:21:42,601
is the gap where you
need to take bugs

582
00:21:42,601 --> 00:21:45,604
and feature requests and
go improve your processes.

583
00:21:45,604 --> 00:21:47,739
Your stakeholders are gonna
have bugs in feature requests,

584
00:21:47,739 --> 00:21:49,875
there's gonna be
misconfigurations
they've gotta go fix.

585
00:21:49,875 --> 00:21:51,977
There's gonna be
zero-day vulnerabilities

586
00:21:51,977 --> 00:21:54,546
they've gotta go take care of
if you're a development shop.

587
00:21:56,014 --> 00:21:57,983
So some final lesson learned.

588
00:21:57,983 --> 00:21:59,283
Some of these are obvious.

589
00:21:59,284 --> 00:22:00,686
No one run should run as admin.

590
00:22:00,686 --> 00:22:03,522
This is something that
Microsoft still has to learn.

591
00:22:03,522 --> 00:22:05,023
No on should run as admin.

592
00:22:05,023 --> 00:22:06,457
What do you do instead?

593
00:22:06,458 --> 00:22:08,293
We set up this thing
called Just-In-Time admin,

594
00:22:08,293 --> 00:22:10,529
where if somebody need
to get into Office 365

595
00:22:10,529 --> 00:22:12,164
and manage a mailbox server

596
00:22:12,164 --> 00:22:14,099
or do something on
a domain controller,

597
00:22:14,099 --> 00:22:15,466
they had to go
through a web form

598
00:22:15,467 --> 00:22:17,936
and apply for the level
of access they wanted.

599
00:22:17,936 --> 00:22:20,605
A Just-In-Time account
was created for them

600
00:22:20,605 --> 00:22:22,307
with a machine
generated password.

601
00:22:22,307 --> 00:22:23,942
The manager had to approve it

602
00:22:23,942 --> 00:22:25,911
and that account was good
for four to eight hours.

603
00:22:25,911 --> 00:22:27,813
They had enough time
to get the job done

604
00:22:27,813 --> 00:22:30,482
and then if they
didn't finish task,

605
00:22:30,482 --> 00:22:33,118
the account expired, sorry.

606
00:22:33,118 --> 00:22:35,419
This made doing IR
kind of a nightmare,

607
00:22:35,420 --> 00:22:37,589
because we had to go through
the same process to do IR

608
00:22:37,589 --> 00:22:40,524
and that was one aspect of
Just-In-Time that I hated.

609
00:22:40,525 --> 00:22:42,294
You do have to give the IR team

610
00:22:42,294 --> 00:22:44,996
the same level of
access as the adversary.

611
00:22:44,996 --> 00:22:46,031
Segment the network.

612
00:22:46,031 --> 00:22:47,198
Goes with out saying.

613
00:22:47,199 --> 00:22:48,133
Segment the accounts.

614
00:22:48,133 --> 00:22:49,768
This goes back to the JIT thing.

615
00:22:50,902 --> 00:22:52,437
Use dedicated
admin workstations.

616
00:22:52,437 --> 00:22:55,474
We tried this in Office 365
couple of different times.

617
00:22:55,474 --> 00:22:57,208
I don't know how it
ended up the second time,

618
00:22:57,209 --> 00:22:58,744
but the idea was,

619
00:22:58,744 --> 00:23:00,212
if you need to get into
a data center to do work,

620
00:23:00,212 --> 00:23:02,581
you do this from a machine
that can't access the internet,

621
00:23:02,581 --> 00:23:04,949
that you can't read email from.

622
00:23:04,950 --> 00:23:07,185
Operators weren't huge on it.

623
00:23:07,185 --> 00:23:09,020
Get away from human
generated passwords.

624
00:23:09,020 --> 00:23:11,256
Humans are a terrible
source of entropy.

625
00:23:11,256 --> 00:23:13,558
Two factor
authentication everywhere

626
00:23:13,558 --> 00:23:14,993
and then you gotta

627
00:23:14,993 --> 00:23:18,263
go verify these things a couple
a times a year, at least.

628
00:23:18,263 --> 00:23:20,197
Do we really have two factor
authentication everywhere?

629
00:23:20,198 --> 00:23:22,401
Do we have service accounts
that can get into the account

630
00:23:22,401 --> 00:23:24,102
without two fact authentication?

631
00:23:24,102 --> 00:23:25,904
'Cause the red team will
find all of that stuff

632
00:23:25,904 --> 00:23:27,372
and make your life miserable.

633
00:23:28,740 --> 00:23:31,810
So finally, in conclusion,
red teaming is hard,

634
00:23:31,810 --> 00:23:34,079
but I think it's worth doing.

635
00:23:34,079 --> 00:23:36,348
Real incidents may be harder.

636
00:23:36,348 --> 00:23:39,451
When you do red team
incidents, you get to do this,

637
00:23:39,451 --> 00:23:41,086
practice how you wanna play.

638
00:23:41,086 --> 00:23:42,020
And that's it for me.

639
00:23:42,020 --> 00:23:44,889
Any questions about this topic?

640
00:23:46,091 --> 00:23:47,758
- [Audience Member]
Do you feel that

641
00:23:47,759 --> 00:23:52,063
you always need to involve,
let's say, a non-core IT

642
00:23:52,063 --> 00:23:57,068
like comms, IT ops,
management in your exercises?

643
00:23:58,236 --> 00:24:00,138
- I don't think
you always need to.

644
00:24:00,138 --> 00:24:02,240
Initially, so we kind of
made this up as we went along

645
00:24:02,240 --> 00:24:05,644
in Office 365, and people
have real jobs to do

646
00:24:05,644 --> 00:24:08,246
and for them to drop the
ball on their real work

647
00:24:08,246 --> 00:24:10,749
and focus on this kinda
thing, it's kind of tedious

648
00:24:10,749 --> 00:24:12,484
and they don't like doing it.

649
00:24:12,484 --> 00:24:14,820
We would at least do
like a regular sync.

650
00:24:14,820 --> 00:24:18,456
We would send out a
communication email once a day

651
00:24:18,457 --> 00:24:22,461
or have one hour call
every few days with them,

652
00:24:22,461 --> 00:24:24,029
to catch them up to date.

653
00:24:24,029 --> 00:24:26,164
But you're right, having
those teams involved

654
00:24:26,164 --> 00:24:27,933
to the same level that
the incident response team

655
00:24:27,933 --> 00:24:30,235
is involved is not
practical, yep.

656
00:24:33,638 --> 00:24:34,872
- [Audience Member] Yeah I had
a question in the beginning

657
00:24:34,873 --> 00:24:36,675
when you start your
red team collaboration

658
00:24:36,675 --> 00:24:38,076
and blue team collaboration,

659
00:24:38,076 --> 00:24:40,212
what kind of things
do you target,

660
00:24:40,212 --> 00:24:43,014
based on knowing what the
blue team's capabilities are?

661
00:24:44,716 --> 00:24:47,452
- (laughs) So initially
red team didn't know

662
00:24:47,452 --> 00:24:49,221
what the blue team's
capabilities were.

663
00:24:49,221 --> 00:24:51,223
And the blue team had no idea
of red team capabilities,

664
00:24:51,223 --> 00:24:54,392
so initially it was
kind of an open book,

665
00:24:54,392 --> 00:24:56,962
where anything was on the table.

666
00:24:56,962 --> 00:24:59,231
Red team exercises in Office 365

667
00:24:59,231 --> 00:25:01,066
were focused on the service.

668
00:25:01,066 --> 00:25:02,467
So there's a lot of
different services

669
00:25:02,467 --> 00:25:03,835
that make up Office 365, right?

670
00:25:03,835 --> 00:25:06,004
There's Exchange online,
SharePoint online.

671
00:25:06,004 --> 00:25:08,305
So they would pick
a particular service

672
00:25:08,306 --> 00:25:11,076
and even within those major
branches of the service,

673
00:25:11,076 --> 00:25:13,044
there are subsets of the service

674
00:25:13,044 --> 00:25:14,946
that they could
target specifically.

675
00:25:14,946 --> 00:25:16,348
And we generally had a heads up

676
00:25:16,348 --> 00:25:17,682
that they were
gonna be targeting

677
00:25:17,682 --> 00:25:21,386
something in Exchange or
something in SharePoint.

678
00:25:21,386 --> 00:25:23,288
It was open ended as to
when they were gonna start

679
00:25:23,288 --> 00:25:24,589
and when it was gonna end.

680
00:25:25,724 --> 00:25:28,326
But in terms of
trying to prove out

681
00:25:28,326 --> 00:25:30,195
specific blue team capabilities,

682
00:25:30,195 --> 00:25:32,731
can you recover malware,
can you do attribution,

683
00:25:32,731 --> 00:25:34,032
we never got to that level.

684
00:25:34,032 --> 00:25:37,636
For us it was, we'll
do whatever we can.

685
00:25:37,636 --> 00:25:39,070
Try and treat it
like a real incident

686
00:25:39,070 --> 00:25:40,405
and do whatever we can.

687
00:25:42,841 --> 00:25:44,309
Any other questions?

688
00:25:44,309 --> 00:25:46,811
- [Audience Member] So
speaking as a blue teamer,

689
00:25:46,811 --> 00:25:49,680
I've made requests
of our red team,

690
00:25:49,681 --> 00:25:51,650
'cause I'm specifically
interested in

691
00:25:51,650 --> 00:25:55,420
what certain tools look
like when they use them,

692
00:25:55,420 --> 00:25:58,890
so we can see them used in
controlled circumstances

693
00:25:58,890 --> 00:26:00,325
and we'd be able to detect 'em.

694
00:26:00,325 --> 00:26:01,960
The response of the red team is,

695
00:26:01,960 --> 00:26:04,062
oh we'd like to
actually use that tool

696
00:26:04,062 --> 00:26:05,863
one of these days,
so we decline.

697
00:26:09,434 --> 00:26:10,668
Do you have suggestions--

698
00:26:10,669 --> 00:26:12,070
- Go set up your own
lab and go use it.

699
00:26:12,070 --> 00:26:14,873
See what forensic
artifacts it leaves behind.

700
00:26:14,873 --> 00:26:17,075
The red team in Office 365
got to the point where,

701
00:26:17,075 --> 00:26:20,245
for some other security
initiatives like monitoring,

702
00:26:20,245 --> 00:26:23,415
where every action
they took was logged

703
00:26:23,415 --> 00:26:24,883
and went into a log file

704
00:26:24,883 --> 00:26:26,151
and the could provide that
to the monitoring team

705
00:26:26,151 --> 00:26:28,219
after the fact and the
monitoring team could go

706
00:26:28,219 --> 00:26:29,487
through that log file

707
00:26:29,487 --> 00:26:30,755
and they could start
building detections

708
00:26:30,755 --> 00:26:32,324
for specific kinds of things,

709
00:26:32,324 --> 00:26:36,161
like MiniCats running in memory
or other activity like that.

710
00:26:36,161 --> 00:26:38,663
So, yeah, I mean, in that
case I would just say,

711
00:26:38,663 --> 00:26:40,231
if you're curious to know
what a tool looks like,

712
00:26:40,231 --> 00:26:42,467
set up some virtual
machines and go run it

713
00:26:42,467 --> 00:26:45,070
and do the forensic analysis.

714
00:26:45,070 --> 00:26:46,638
I wouldn't wait
for the cooperation

715
00:26:46,638 --> 00:26:48,807
from the red team on that one.

716
00:26:48,807 --> 00:26:50,308
- [Audience Member] I mean
Dave, I really wanna ask you

717
00:26:50,308 --> 00:26:52,644
what the hell happened to
the Jayhawks this year, but

718
00:26:52,644 --> 00:26:53,612
(audience laughs)

719
00:26:53,612 --> 00:26:54,980
instead, all ask--

720
00:26:54,980 --> 00:26:56,514
- Are you a Tar Heel fan?

721
00:26:56,514 --> 00:26:57,514
- [Audience Member]
When you don't have,

722
00:26:57,515 --> 00:26:58,350
no I'm not.

723
00:26:59,751 --> 00:27:03,622
At O365 you guys had dedicated
red teams and blue teams,

724
00:27:03,622 --> 00:27:06,891
what about an organization
that has far fewer resources?

725
00:27:06,891 --> 00:27:10,195
Is it ever a good idea to
do part time red teaming

726
00:27:10,195 --> 00:27:13,164
or would you be better
advised to hire in

727
00:27:13,164 --> 00:27:14,633
an outside consultant?

728
00:27:14,633 --> 00:27:16,067
- I like the model at O365,

729
00:27:16,067 --> 00:27:18,370
which obviously not every
organization can do,

730
00:27:18,370 --> 00:27:20,572
because the internal
team is gonna know things

731
00:27:20,572 --> 00:27:22,607
better than an external team.

732
00:27:22,607 --> 00:27:26,177
But yeah, if you can hire
good external red team,

733
00:27:26,177 --> 00:27:27,379
that'd be good.

734
00:27:27,379 --> 00:27:28,913
I would imagine it's
gonna be more expensive.

735
00:27:28,913 --> 00:27:30,515
It's gonna take some time
to ramp up on the details

736
00:27:30,515 --> 00:27:32,417
of the environment and get savvy

737
00:27:32,417 --> 00:27:34,485
about how they
could attack things.

738
00:27:40,792 --> 00:27:42,894
- [Audience Members] How do
you talk down your red team

739
00:27:42,894 --> 00:27:46,498
from just refusing to talk
about their tools and techniques

740
00:27:46,498 --> 00:27:48,600
'cause they want an easy card,

741
00:27:48,600 --> 00:27:49,868
an easy pass the
next way through?

742
00:27:49,868 --> 00:27:52,404
How do you force them
to actually play right?

743
00:27:53,505 --> 00:27:55,106
- So that was something
we struggled with.

744
00:27:55,106 --> 00:27:58,810
My boss used to say that they
were acting like space aliens,

745
00:27:58,810 --> 00:28:01,212
'cause they were the ones
who like invoked MiniCats,

746
00:28:01,212 --> 00:28:05,550
the PowerShell
injected dll thing,

747
00:28:05,550 --> 00:28:07,585
that whole thing came
out of the O365 red team.

748
00:28:07,585 --> 00:28:09,621
You can thank
Office 365 for that

749
00:28:09,621 --> 00:28:12,057
if you're having to deal
with it in your networks.

750
00:28:12,057 --> 00:28:14,259
So we used to ask them like,

751
00:28:14,259 --> 00:28:17,762
can you just drop files on disk,
give us something to go on,

752
00:28:17,762 --> 00:28:19,798
'cause that makes it
super, super difficult,

753
00:28:19,798 --> 00:28:22,067
especially at a large
scale environment.

754
00:28:23,501 --> 00:28:27,906
And eventually after seeing
the blue team demoralized

755
00:28:29,040 --> 00:28:30,175
for things like that,
they come around.

756
00:28:31,309 --> 00:28:32,677
But you need to be able to

757
00:28:32,677 --> 00:28:34,512
model different
adversaries, I would say.

758
00:28:34,512 --> 00:28:37,048
Not every adversary is
doing super advanced stuff,

759
00:28:37,048 --> 00:28:38,483
because they don't
nescessarily have to.

760
00:28:38,483 --> 00:28:40,752
So I would challenge
'em in that regard.

761
00:28:40,752 --> 00:28:42,787
Let's play different
levels of adversary.

762
00:28:48,793 --> 00:28:50,428
- [Host] Last question.

763
00:28:50,428 --> 00:28:51,763
- [Audience Member]
Actually not a question,

764
00:28:51,763 --> 00:28:53,465
but I'm just gonna,
off of that question,

765
00:28:53,465 --> 00:28:56,201
one of the things we tried
was we have a management group

766
00:28:56,201 --> 00:28:58,570
that's red team experienced
and blue team both

767
00:28:58,570 --> 00:29:01,339
and they kind of tabletop how
the game's gonna be played

768
00:29:01,339 --> 00:29:02,874
and then they bring in
the red team, blue team

769
00:29:02,874 --> 00:29:04,876
after the engagement
and they kind of drive

770
00:29:04,876 --> 00:29:06,211
what's gonna be done.

771
00:29:06,211 --> 00:29:08,146
So that helped us out a lot.

772
00:29:08,146 --> 00:29:09,848
- Yeah, we did
tabletop exercises too

773
00:29:09,848 --> 00:29:11,483
as a, I think it
FedRAMP requirement

774
00:29:11,483 --> 00:29:12,783
or something of that nature.

775
00:29:12,784 --> 00:29:14,352
That was separate from
our red team activities,

776
00:29:14,352 --> 00:29:15,353
but also useful.

777
00:29:16,421 --> 00:29:17,722
Thanks everybody, appreciate it.

778
00:29:17,722 --> 00:29:20,558
(dramatic music)

