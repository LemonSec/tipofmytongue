1
00:00:00,834 --> 00:00:03,403
(light music)

2
00:00:13,680 --> 00:00:15,782
(audience clapping)

3
00:00:15,782 --> 00:00:16,616
- Great.

4
00:00:16,616 --> 00:00:17,884
Thank you, Jake.

5
00:00:17,884 --> 00:00:19,285
You know, you can
go back on Twitter

6
00:00:19,285 --> 00:00:22,122
and actually watch the collapse
at my NetWars experience

7
00:00:22,122 --> 00:00:25,258
as I started falling in
the standings. (laughs)

8
00:00:25,258 --> 00:00:26,291
But welcome, everyone.

9
00:00:26,292 --> 00:00:27,327
Welcome back from lunch.

10
00:00:27,327 --> 00:00:28,595
My name is Kevin Perlow

11
00:00:28,595 --> 00:00:30,497
and to my right is
Allen Swackhamer.

12
00:00:30,497 --> 00:00:34,034
We're just gonna go
ahead and jump right in.

13
00:00:34,034 --> 00:00:36,536
We have a lot of technical
content that we want to cover

14
00:00:36,536 --> 00:00:39,205
and that we have for you to
digest along with your meal.

15
00:00:39,205 --> 00:00:43,176
We're gonna start with
just basic YARA rules here

16
00:00:43,176 --> 00:00:45,211
and what we're gonna do
is build out a framework

17
00:00:45,211 --> 00:00:47,280
for how you can implement
these YARA rules

18
00:00:48,681 --> 00:00:51,550
in a way that you can actionable
intelligence for your SOC.

19
00:00:51,551 --> 00:00:54,387
We're gonna come back to
this diagram a couple times.

20
00:00:55,588 --> 00:00:58,091
So if you're ever lost
as to where we are,

21
00:00:58,091 --> 00:00:59,626
we'll bring it back up

22
00:00:59,626 --> 00:01:02,262
so that way you can keep
track of what's going on.

23
00:01:02,262 --> 00:01:04,664
The first thing here
is, what is a YARA rule?

24
00:01:04,664 --> 00:01:05,832
We're not gonna
spend too much time

25
00:01:05,832 --> 00:01:07,232
getting into the intricacies

26
00:01:07,233 --> 00:01:08,768
of hey, how do you actually
write one of these.

27
00:01:08,768 --> 00:01:10,770
It's a little bit
too dry for this,

28
00:01:10,770 --> 00:01:13,073
but come talk to us afterwards.

29
00:01:13,073 --> 00:01:15,375
A YARA rule is a way
that you can take strings

30
00:01:15,375 --> 00:01:18,411
and other artifacts left
over from compiling a program

31
00:01:18,411 --> 00:01:19,979
and you can write a rule on it.

32
00:01:19,979 --> 00:01:21,481
The idea behind this is,

33
00:01:21,481 --> 00:01:25,884
if you have malware samples
that are from the same family

34
00:01:25,885 --> 00:01:27,954
or made by the same authors,

35
00:01:27,954 --> 00:01:29,955
you can put in these YARA rules

36
00:01:29,956 --> 00:01:32,459
and you can start to
group and categorize them

37
00:01:32,459 --> 00:01:34,694
and do additional research here.

38
00:01:34,694 --> 00:01:37,163
Some of the things you can
do, we mentioned strings,

39
00:01:37,163 --> 00:01:39,466
there are also occasionally
indicators of compromise

40
00:01:39,466 --> 00:01:41,234
that are in strings but leftover

41
00:01:42,469 --> 00:01:46,071
and you can do it based
on a opcode, hex, regex,

42
00:01:46,072 --> 00:01:47,874
a couple different ways
to write these rules.

43
00:01:47,874 --> 00:01:50,009
The one up there on the
screen is extremely basic

44
00:01:50,009 --> 00:01:51,244
but it's just to
give you an idea

45
00:01:51,244 --> 00:01:53,012
of what this
literally looks like.

46
00:01:54,180 --> 00:01:55,815
Now we do have a couple
of examples up here.

47
00:01:55,815 --> 00:01:57,283
We're gonna go through
them pretty quickly,

48
00:01:57,283 --> 00:01:59,419
but when yeah, you review
the slides later on

49
00:01:59,419 --> 00:02:02,387
when they're posted online,
feel free to jump in on these.

50
00:02:08,061 --> 00:02:09,529
This first one here

51
00:02:09,529 --> 00:02:11,731
is actually a ransomware
sample that we were tracking

52
00:02:11,731 --> 00:02:14,733
back in I think it was
September of last year

53
00:02:14,734 --> 00:02:18,771
and this had some fairly
unique strings inside of it.

54
00:02:18,771 --> 00:02:20,239
You can see some file password,

55
00:02:20,240 --> 00:02:22,942
the executable is being
built out if you look at it.

56
00:02:22,942 --> 00:02:24,711
And so, after about
a month and 1/2,

57
00:02:24,711 --> 00:02:26,813
this disappeared, but
this was just an example

58
00:02:26,813 --> 00:02:29,015
of where you can
track a campaign.

59
00:02:30,483 --> 00:02:33,119
This slide here, this shows a
point-of-sale malware example.

60
00:02:33,119 --> 00:02:34,120
It's a little bit different.

61
00:02:34,120 --> 00:02:35,588
This is hex-based.

62
00:02:35,588 --> 00:02:37,423
It's really opcode-based.

63
00:02:37,423 --> 00:02:39,259
So that's something
else you can look at

64
00:02:39,259 --> 00:02:41,361
while you write these rules.

65
00:02:42,795 --> 00:02:45,899
This one here is, I'm gonna
call it a Vawtrak dropper,

66
00:02:45,899 --> 00:02:47,767
but that's really
kind of a misnomer.

67
00:02:50,570 --> 00:02:55,174
This is a rule based
on a malicious Office
document campaign

68
00:02:55,175 --> 00:02:57,677
that was dropping Pony
in the user's temp file

69
00:02:57,677 --> 00:03:00,412
and you see that in the strings
in the box on the right.

70
00:03:01,581 --> 00:03:03,816
And so, if you back and
look at the YARA rules

71
00:03:03,816 --> 00:03:07,987
to the left there, you'll see
a couple of different things.

72
00:03:07,987 --> 00:03:12,892
We've got the Office document
file header written out.

73
00:03:12,892 --> 00:03:14,994
We've got executable
written out there.

74
00:03:14,994 --> 00:03:16,262
A couple of
different hex values,

75
00:03:16,262 --> 00:03:18,598
one of which is to track
if the document has VBA,

76
00:03:18,598 --> 00:03:20,099
and so, that way,
we're not just pulling

77
00:03:20,099 --> 00:03:22,734
any old Office document on
that's getting triggered

78
00:03:22,735 --> 00:03:25,471
on the rule and we have
some file paths out there

79
00:03:25,471 --> 00:03:27,273
and a little bit
of whitelisting.

80
00:03:27,273 --> 00:03:29,442
One of the things that we
really do like to track

81
00:03:29,442 --> 00:03:31,177
are these Office documents

82
00:03:31,177 --> 00:03:34,614
and the next slide will have
the JavaScripts I think.

83
00:03:34,614 --> 00:03:37,483
These are all from
malicious spam campaigns.

84
00:03:38,785 --> 00:03:40,286
The reason we want
to track those

85
00:03:40,286 --> 00:03:42,655
is because you can actually
go both forwards and backwards

86
00:03:42,655 --> 00:03:44,490
in the malware kill chain.

87
00:03:44,490 --> 00:03:46,593
In going forwards, you
can see what indicators

88
00:03:46,593 --> 00:03:49,429
it's gonna be pulling off, if
it's downloading something.

89
00:03:49,429 --> 00:03:52,865
In this case, these
files, these Pony files

90
00:03:52,865 --> 00:03:56,102
will send POST requests
to Russian C2 servers,

91
00:03:56,102 --> 00:03:58,238
then they'll send a GET
request and pull down Vawtrak

92
00:03:58,238 --> 00:03:59,839
from a compromised web server.

93
00:04:01,341 --> 00:04:02,842
That's what I mean
by going forwards.

94
00:04:02,842 --> 00:04:04,377
Now going backwards
in the kill chain,

95
00:04:04,377 --> 00:04:06,879
you can actually go
and look at what email

96
00:04:06,879 --> 00:04:08,347
contain these attachments

97
00:04:08,348 --> 00:04:10,550
if you're talking about the
VirusTotal Intelligence portal.

98
00:04:10,550 --> 00:04:13,052
We'll get to that specific
part a little bit later

99
00:04:14,287 --> 00:04:16,956
but that's what
we mean with that.

100
00:04:18,257 --> 00:04:19,424
Clicker.

101
00:04:19,425 --> 00:04:20,727
Clicker not working.

102
00:04:20,726 --> 00:04:21,994
Come on.

103
00:04:21,995 --> 00:04:24,163
The next slide, when I
get it up here, is...

104
00:04:25,265 --> 00:04:26,332
Does anyone, battery?

105
00:04:28,468 --> 00:04:29,335
Ah, there we are.

106
00:04:29,335 --> 00:04:30,303
We're good.

107
00:04:30,303 --> 00:04:31,904
Excellent, thank you.

108
00:04:31,904 --> 00:04:35,742
So this is a
JavaScript's dropper

109
00:04:36,943 --> 00:04:38,144
that we wanted to go off of.

110
00:04:38,144 --> 00:04:39,612
I actually we want
to start here.

111
00:04:39,612 --> 00:04:41,447
When you talk about a
malicious JavaScript file,

112
00:04:41,447 --> 00:04:44,250
it tends to be this
giant block of text

113
00:04:44,250 --> 00:04:45,318
that you see on the left,

114
00:04:45,318 --> 00:04:46,486
but what you can do is run it

115
00:04:46,486 --> 00:04:47,920
through what's
called a beautifier.

116
00:04:47,920 --> 00:04:51,157
That'll actually put it in
what's a more readable structure

117
00:04:51,157 --> 00:04:54,994
and it gives you a visual idea
of what the file looks like.

118
00:04:54,994 --> 00:04:57,230
That really helps in terms
of categorizing these

119
00:04:57,230 --> 00:04:59,265
and in terms of writing
your YARA rules here

120
00:04:59,265 --> 00:05:01,868
because what tends to happen
is through a spam campaign,

121
00:05:01,868 --> 00:05:04,904
there will be a couple
different variants of this.

122
00:05:04,904 --> 00:05:06,406
But the thing's
that'll be consistent

123
00:05:06,406 --> 00:05:09,409
are that visual structure
and then the variables.

124
00:05:09,409 --> 00:05:10,510
And so, you can
start writing a rule

125
00:05:10,510 --> 00:05:12,512
based on the logic around that.

126
00:05:12,512 --> 00:05:14,514
We're gonna be sticking
with this JavaScript file

127
00:05:14,514 --> 00:05:17,183
as we move forward
in the presentation.

128
00:05:17,183 --> 00:05:22,188
What this did was, this was
from a Proofpoint article,

129
00:05:23,289 --> 00:05:24,524
they did some
really good research

130
00:05:24,524 --> 00:05:25,692
and they found that
these JavaScript files

131
00:05:25,692 --> 00:05:28,261
were actually pulling
down RockLoader.

132
00:05:28,261 --> 00:05:30,396
RockLoader was being
an intermediary file,

133
00:05:30,396 --> 00:05:32,265
which was then
downloading Locky.

134
00:05:32,265 --> 00:05:35,168
Obviously Locky has been in
the news quite a bit recently.

135
00:05:36,369 --> 00:05:37,904
We're gonna be tracking that

136
00:05:37,904 --> 00:05:40,373
throughout the rest
of this presentation.

137
00:05:40,373 --> 00:05:42,675
When we talk about
writing the rule here,

138
00:05:42,675 --> 00:05:44,911
we want to write it, like I
said, off of these structures.

139
00:05:44,911 --> 00:05:46,713
We've got a couple of
things going on here.

140
00:05:46,713 --> 00:05:50,216
On the left, we have,
if you deobfuscate this,

141
00:05:50,216 --> 00:05:54,153
it takes time to do but you
wind up with the executable path

142
00:05:54,153 --> 00:05:57,090
that the file is gonna be
placed in and run from.

143
00:05:57,090 --> 00:05:59,292
And then on the right, you
wind up with a GET request

144
00:05:59,292 --> 00:06:00,827
and that's your
network-based indicator.

145
00:06:00,827 --> 00:06:02,795
We also have two
blue boxes there.

146
00:06:02,795 --> 00:06:06,099
Those are just other checks
that the JavaScript file ran.

147
00:06:06,099 --> 00:06:08,034
By putting all of
these things together,

148
00:06:08,034 --> 00:06:10,603
you can write an YARA
role based on that.

149
00:06:12,372 --> 00:06:14,407
From there, you
take your YARA rule

150
00:06:14,407 --> 00:06:17,043
and you put into the
VirusTotal Intelligence portal.

151
00:06:18,344 --> 00:06:21,180
Whenever someone
uploads a file to it,

152
00:06:21,180 --> 00:06:23,883
it's gonna go and it's gonna
trigger off of that file

153
00:06:23,883 --> 00:06:25,518
if it matches the criteria here

154
00:06:25,518 --> 00:06:27,285
and it's gonna send
a notification.

155
00:06:27,286 --> 00:06:28,788
Now I'm gonna turn
it over to Allen

156
00:06:28,788 --> 00:06:31,424
who's gonna talk about you can
do with these notifications.

157
00:06:31,424 --> 00:06:32,258
- Okay.

158
00:06:33,693 --> 00:06:35,628
How many people here have
actually used Elasticsearch

159
00:06:35,628 --> 00:06:38,765
or Kibana to visualize data?

160
00:06:38,765 --> 00:06:39,599
Okay.

161
00:06:39,599 --> 00:06:40,566
All right.

162
00:06:40,566 --> 00:06:42,068
You guys should be familiar

163
00:06:42,068 --> 00:06:43,369
with some of these concepts
that I'm about to go through.

164
00:06:43,369 --> 00:06:44,570
(clears throat)

165
00:06:44,570 --> 00:06:47,873
Once we have put the
YARA rule on VirusTotal

166
00:06:47,874 --> 00:06:50,410
and files have actually flagged,

167
00:06:50,410 --> 00:06:52,678
we've retrieved a notification.

168
00:06:52,678 --> 00:06:55,615
We can actually receive that
notification through VirusTotal

169
00:06:55,615 --> 00:06:58,050
in a couple of different ways.

170
00:06:58,050 --> 00:07:00,987
You can have VirusTotal email
you the notification hit

171
00:07:00,987 --> 00:07:04,023
so it'll come into your mailbox.

172
00:07:04,023 --> 00:07:06,025
You may get spammed with them

173
00:07:06,025 --> 00:07:07,292
if you get a lot
of notifications

174
00:07:07,293 --> 00:07:09,862
or you can pull it off
of a REST API endpoint

175
00:07:09,862 --> 00:07:12,365
and get it JSON-formatted.

176
00:07:12,365 --> 00:07:14,634
We're actually gonna
use the JSON formatting.

177
00:07:15,935 --> 00:07:17,203
(clears throat)

178
00:07:17,203 --> 00:07:18,905
Let me just step back
a little bit here too.

179
00:07:18,905 --> 00:07:21,974
Everything that we have up
here as far as source code,

180
00:07:21,974 --> 00:07:23,643
I've released this project.

181
00:07:23,643 --> 00:07:24,943
There's working code on GitHub,

182
00:07:24,944 --> 00:07:26,579
which there'll be
a link at the end

183
00:07:26,579 --> 00:07:28,748
where you can actually
implement everything

184
00:07:28,748 --> 00:07:31,217
that we talk about
here in your own

185
00:07:31,217 --> 00:07:33,686
if you have VirusTotal
Intelligence subscription.

186
00:07:34,620 --> 00:07:36,088
Anyway, so what we're gonna do

187
00:07:36,088 --> 00:07:40,293
once we get the notification
document from VirusTotal

188
00:07:40,293 --> 00:07:43,162
is we're going to
index and parse,

189
00:07:43,162 --> 00:07:45,298
then push it into
Elasticsearch stack.

190
00:07:46,332 --> 00:07:47,700
Let's take a look at

191
00:07:47,700 --> 00:07:50,670
what we actually get
back from VirusTotal.

192
00:07:50,670 --> 00:07:53,306
This is the JSON document.

193
00:07:53,306 --> 00:07:55,073
We get back a couple
of different things.

194
00:07:55,074 --> 00:07:58,144
We get the rule name, the
YARA rule name that fired,

195
00:07:58,144 --> 00:08:00,112
the ruleset, so
that's a collection

196
00:08:00,112 --> 00:08:01,948
of YARA rules that fired.

197
00:08:01,948 --> 00:08:04,683
We also get basic file
metadata about that information

198
00:08:04,684 --> 00:08:08,020
such as hashes, file type.

199
00:08:08,020 --> 00:08:13,025
And we also get antivirus scan
data and match information,

200
00:08:14,093 --> 00:08:15,928
so the specific string matches

201
00:08:15,928 --> 00:08:19,866
that the YARA engine on
VirusTotal's side matched on.

202
00:08:21,334 --> 00:08:23,102
Once we actually get
this notification,

203
00:08:23,102 --> 00:08:25,337
we're gonna want to
do some stuff with it.

204
00:08:27,073 --> 00:08:29,674
We're gonna want to try to
extract out some indicators.

205
00:08:29,675 --> 00:08:32,411
There's a couple of
different ways of doing that,

206
00:08:32,410 --> 00:08:36,549
static extraction, then it
has a RAT decoder framework

207
00:08:36,549 --> 00:08:38,049
where you can
actually extract out

208
00:08:38,049 --> 00:08:41,786
obfuscated configuration
files from malware.

209
00:08:41,787 --> 00:08:42,855
That's a good way of doing it,

210
00:08:42,855 --> 00:08:44,190
In this room, after this talk,

211
00:08:44,190 --> 00:08:45,391
there is gonna be FLOSS,

212
00:08:45,391 --> 00:08:47,526
which talks about
using the binary itself

213
00:08:47,527 --> 00:08:50,763
to deobfuscate some strings
that reside in that binary.

214
00:08:50,763 --> 00:08:53,666
But we're gonna focus on, for
this talk, dynamic execution

215
00:08:53,666 --> 00:08:55,768
and specifically Cuckoo Sandbox

216
00:08:55,768 --> 00:08:59,639
to extract out both file
system and network behaviors

217
00:08:59,639 --> 00:09:02,308
on mass VirusTotal
notification alerts.

218
00:09:03,576 --> 00:09:06,145
At this point, we've
got the notification

219
00:09:06,145 --> 00:09:08,314
sent in in VirusTotal

220
00:09:08,314 --> 00:09:10,616
and we're gonna take
that notification down,

221
00:09:10,616 --> 00:09:12,852
that JSON document and
we're gonna index that

222
00:09:12,852 --> 00:09:16,555
into Elasticsearch for
visualization and data storage

223
00:09:16,556 --> 00:09:18,324
and we're also gonna
send that notification

224
00:09:18,324 --> 00:09:21,359
over to Cuckoo for
Cuckoo to process it.

225
00:09:22,562 --> 00:09:24,630
So why even put this
into Elasticsearch?

226
00:09:24,630 --> 00:09:28,200
Why not MySQL or SQLite
or something like that?

227
00:09:29,435 --> 00:09:30,936
(clears throat)

228
00:09:30,937 --> 00:09:34,173
Because Elasticsearch allows
you to aggregate on this data,

229
00:09:34,173 --> 00:09:35,808
give you counts
of how many times

230
00:09:35,808 --> 00:09:37,310
certain notifications has hit,

231
00:09:37,310 --> 00:09:41,180
as well as do trend base
analysis of data histograms,

232
00:09:41,180 --> 00:09:44,083
so you can see notifications
over time, how they appear,

233
00:09:44,083 --> 00:09:46,117
their spikes, or
any other things.

234
00:09:46,118 --> 00:09:48,621
You can also see if a
file has been resubmitted

235
00:09:48,621 --> 00:09:49,989
multiple different times.

236
00:09:49,989 --> 00:09:52,325
You could also export the data.

237
00:09:52,325 --> 00:09:55,595
You can export this through
the Kibana web interface

238
00:09:55,595 --> 00:09:57,496
with the data
table visualization

239
00:09:57,496 --> 00:10:00,632
or you can export
this programmatically

240
00:10:00,633 --> 00:10:02,668
through the Elasticsearch API.

241
00:10:04,103 --> 00:10:07,640
This is a dashboard,
a Kibana dashboard.

242
00:10:07,640 --> 00:10:08,874
You guys probably are
familiar with this

243
00:10:08,874 --> 00:10:10,109
but essentially what this is,

244
00:10:10,109 --> 00:10:12,778
is it's just five
visualizations.

245
00:10:13,879 --> 00:10:17,083
The two here are
area charts over time

246
00:10:17,083 --> 00:10:20,685
and you can see the
notifications for.

247
00:10:20,686 --> 00:10:23,823
I'm limiting this down
to just the ruleset RAT,

248
00:10:23,823 --> 00:10:26,759
so I've got a RAT ruleset

249
00:10:26,759 --> 00:10:28,728
with a multitude of YARA rules

250
00:10:28,728 --> 00:10:30,662
on VirusTotal, its flagging.

251
00:10:30,663 --> 00:10:33,432
Over time, you can see
it going up and down.

252
00:10:33,432 --> 00:10:36,335
In the top middle, you
see that's split by type,

253
00:10:36,335 --> 00:10:39,672
so you can see overwhelmingly
Windows 32 executables

254
00:10:39,672 --> 00:10:42,341
but there is a little
bit of unknown as well

255
00:10:42,341 --> 00:10:44,443
at the very top of that
area chart as well.

256
00:10:45,911 --> 00:10:46,845
Cuckoo Sandbox.

257
00:10:48,247 --> 00:10:50,382
Why are we submitting
this to Cuckoo Sandbox

258
00:10:50,383 --> 00:10:51,984
when I know they're sandbox?

259
00:10:51,984 --> 00:10:54,887
Cuckoo, it's very customizable.

260
00:10:54,887 --> 00:10:55,988
It's an open source project.

261
00:10:55,988 --> 00:10:57,390
It's written in Python.

262
00:10:57,390 --> 00:11:00,425
I'm using Cuckoo 2.0.

263
00:11:00,426 --> 00:11:02,495
I've modified the
Elasticsearch reporting module

264
00:11:02,495 --> 00:11:07,400
just a little bit to
basically visualize data

265
00:11:07,400 --> 00:11:08,934
a little bit better
in Elasticsearch.

266
00:11:08,934 --> 00:11:12,605
There's a pull request in
Cuckoo 2.0's main branch.

267
00:11:12,605 --> 00:11:13,773
You guys may be familiar

268
00:11:13,773 --> 00:11:16,475
with the Cuckoo modified forks.

269
00:11:16,475 --> 00:11:19,578
Cuckoo 2.0, Cuckoo main
line has actually integrated

270
00:11:19,578 --> 00:11:20,946
a lot of those features in.

271
00:11:22,381 --> 00:11:23,915
This is actually integrated
into the main line Cuckoo,

272
00:11:23,916 --> 00:11:24,784
not the forks.

273
00:11:26,152 --> 00:11:27,820
There's a lot of other
popular sandboxes out there

274
00:11:27,820 --> 00:11:30,289
that we could be pushing
this information into.

275
00:11:30,289 --> 00:11:32,658
VirusTotal does send it through
their own Cuckoo Sandbox.

276
00:11:32,658 --> 00:11:36,429
You can retrieve that data,
however, it's very limited.

277
00:11:36,429 --> 00:11:38,097
But your best case analysis,

278
00:11:38,097 --> 00:11:40,232
malware is also VirusTotal
or Cuckoo-backed

279
00:11:40,232 --> 00:11:42,901
and you could also send it
into another proprietor sandbox

280
00:11:42,902 --> 00:11:44,737
such as Hybrid Analysis.

281
00:11:44,737 --> 00:11:45,971
What really did we do

282
00:11:45,971 --> 00:11:47,673
with the Elasticsearch
reporting module?

283
00:11:48,607 --> 00:11:50,443
We added this template.

284
00:11:50,443 --> 00:11:51,711
It's simple.

285
00:11:51,711 --> 00:11:53,245
It does a couple of
different things,

286
00:11:53,245 --> 00:11:58,084
set your shard count to
one, login type ingestion.

287
00:11:58,084 --> 00:12:00,118
We turned on compression.

288
00:12:00,119 --> 00:12:01,554
We added task_id.

289
00:12:01,554 --> 00:12:03,488
That task_id maps directly back

290
00:12:03,489 --> 00:12:07,226
to the task ID that Cuckoo
has in its database.

291
00:12:08,694 --> 00:12:11,262
Report_time, the time which
Cuckoo actually process that.

292
00:12:11,263 --> 00:12:13,599
And we also turned
strings to not_analyzed.

293
00:12:13,599 --> 00:12:15,267
This is very
important for later on

294
00:12:15,267 --> 00:12:16,802
when we do data aggregations

295
00:12:17,970 --> 00:12:21,373
because it won't split
on common delimiters

296
00:12:21,373 --> 00:12:24,510
like white space,
dots, or dashes,

297
00:12:24,510 --> 00:12:27,646
so IPs will actually
aggregate on the full IP

298
00:12:27,646 --> 00:12:28,948
and not break it apart.

299
00:12:31,117 --> 00:12:32,450
Back to the Elasticsearch stack

300
00:12:32,451 --> 00:12:34,887
and what we're wanting
to see out of Cuckoo.

301
00:12:34,887 --> 00:12:38,189
We're gonna want to try to
get the files written to disk,

302
00:12:39,024 --> 00:12:40,626
our network IOCs.

303
00:12:40,626 --> 00:12:42,928
Cuckoo also does
some normalization of
the antivirus data.

304
00:12:42,928 --> 00:12:44,563
They also ping in
VirusTotal too.

305
00:12:46,232 --> 00:12:47,533
How are we gonna do this?

306
00:12:47,533 --> 00:12:50,102
Once we have actually
got the notifications

307
00:12:50,102 --> 00:12:54,473
into Elasticsearch, we
need to pull them somehow.

308
00:12:54,473 --> 00:12:57,242
This is an example of
using Elasticsearch

309
00:12:57,243 --> 00:12:59,645
to scan and scroll
APIs, an efficient way

310
00:12:59,645 --> 00:13:04,483
of programmatically exporting
results from indexes.

311
00:13:06,285 --> 00:13:08,187
You can see page
equals es.search.

312
00:13:08,187 --> 00:13:10,689
That's the main function here
that's doing all this stuff.

313
00:13:10,689 --> 00:13:12,324
The q equals at the
very bottom of that,

314
00:13:12,324 --> 00:13:14,425
that's actually Lucene
search query syntax.

315
00:13:14,426 --> 00:13:17,062
That's the same syntax
that you guys know and love

316
00:13:17,062 --> 00:13:18,297
if you use Kibana.

317
00:13:18,297 --> 00:13:19,565
It's in the top
of the text field.

318
00:13:21,000 --> 00:13:24,136
You can basically go into
the discover tab in Kibana,

319
00:13:24,136 --> 00:13:25,838
type out whatever request
you want in there,

320
00:13:25,838 --> 00:13:28,607
the search syntax, and pull
that exact search string out

321
00:13:28,607 --> 00:13:30,276
and put it right here.

322
00:13:30,276 --> 00:13:34,313
You'll retrieve all of the
documents that match that.

323
00:13:34,313 --> 00:13:36,715
At the end of this
code being executed,

324
00:13:36,715 --> 00:13:39,151
hashes, it's a Python set

325
00:13:39,151 --> 00:13:42,854
and you'll have a unique
place of all the hashes

326
00:13:42,855 --> 00:13:45,858
that hits for a specific query.

327
00:13:45,858 --> 00:13:47,193
This query is limited down

328
00:13:47,193 --> 00:13:49,562
to just the rockdownloader
notifications.

329
00:13:49,562 --> 00:13:51,864
At the end, hashes
is just gonna be

330
00:13:51,864 --> 00:13:54,033
all the rockdownloader
notifications.

331
00:13:54,033 --> 00:13:56,735
And then we're gonna send
that over into the Cuckoo API

332
00:13:56,735 --> 00:13:58,070
using Python request.

333
00:13:59,505 --> 00:14:01,373
Again I've got all these
codes up on GitHub as well.

334
00:14:01,373 --> 00:14:05,845
It does it automatically
from notification time,

335
00:14:05,845 --> 00:14:07,546
from VirusTotal being
the notification,

336
00:14:07,546 --> 00:14:09,181
it sends it through
Elasticsearch

337
00:14:09,181 --> 00:14:10,683
and also sends it into Cuckoo.

338
00:14:11,851 --> 00:14:12,852
What do we really
get from Cuckoo?

339
00:14:12,852 --> 00:14:14,954
We get a ton of stuff actually.

340
00:14:14,954 --> 00:14:16,421
In the summary information,

341
00:14:17,590 --> 00:14:19,725
we get files that
are manipulated,

342
00:14:21,193 --> 00:14:25,698
written, touched, registries,
mutexes, command line called,

343
00:14:26,799 --> 00:14:28,733
a lot of other different
things like that.

344
00:14:29,602 --> 00:14:30,870
(clears throat)

345
00:14:30,870 --> 00:14:32,404
What you actually see
on the top right here

346
00:14:32,404 --> 00:14:36,208
is the actual Elasticsearch
reporting module in Cuckoo,

347
00:14:36,208 --> 00:14:37,409
what it's indexing.

348
00:14:38,811 --> 00:14:42,648
By default, it's just indexing
the target file metadata,

349
00:14:42,648 --> 00:14:44,817
the behavioral
summary information,

350
00:14:44,817 --> 00:14:47,219
which is what you see on here,

351
00:14:47,219 --> 00:14:48,687
and also the VirusTotal results.

352
00:14:48,687 --> 00:14:49,822
If you wanted to,
you can modify this

353
00:14:49,822 --> 00:14:51,290
and add in additional things.

354
00:14:53,259 --> 00:14:54,660
Here is a dashboard.

355
00:14:55,861 --> 00:14:57,363
We're limiting this down.

356
00:14:57,363 --> 00:15:01,834
You see at the top, it says
target.file.name star dot js,

357
00:15:01,834 --> 00:15:04,369
so this is just the
rockdownloader stuff.

358
00:15:04,370 --> 00:15:08,073
We're limiting the
Elasticsearch database

359
00:15:08,073 --> 00:15:10,576
to just the rockdownloader
notification in here.

360
00:15:12,011 --> 00:15:13,679
You see the data aggregations,

361
00:15:13,679 --> 00:15:16,448
which is every single run.

362
00:15:16,448 --> 00:15:21,153
52 of these runs, 52 of these
unique files on the top left.

363
00:15:21,153 --> 00:15:24,490
Resolves host, you can
see that diesel-cn.lms.hk.

364
00:15:26,492 --> 00:15:29,461
That means that 52
different samples

365
00:15:29,461 --> 00:15:30,896
beaconed out to that domain.

366
00:15:30,896 --> 00:15:32,330
So you can come in here

367
00:15:32,331 --> 00:15:35,334
and do some sort of stacking
analysis of this data

368
00:15:35,334 --> 00:15:38,002
and I'm gonna give it over
to Kevin to talk about.

369
00:15:39,939 --> 00:15:40,772
- Cool.

370
00:15:40,773 --> 00:15:42,308
Thanks, Allen.

371
00:15:42,308 --> 00:15:45,010
What we've done here is a
lot of technical content.

372
00:15:45,010 --> 00:15:46,045
We built a YARA rule.

373
00:15:46,045 --> 00:15:47,279
We built all this infrastructure

374
00:15:47,279 --> 00:15:48,781
with Elasticsearch and Cuckoo.

375
00:15:50,716 --> 00:15:52,217
What's the point?

376
00:15:52,217 --> 00:15:53,619
What you see on the screen

377
00:15:53,619 --> 00:15:56,722
is the result of
running that YARA rule

378
00:15:56,722 --> 00:15:58,757
integrated into the
VirusTotal Intelligence portal

379
00:15:58,757 --> 00:16:00,258
and you can see we
actually came up

380
00:16:00,259 --> 00:16:04,530
with I think it's 700, yeah
747 different files here.

381
00:16:04,530 --> 00:16:05,898
What we get out of this

382
00:16:05,898 --> 00:16:09,668
is we get a lot of
actionable data for our SOC.

383
00:16:09,668 --> 00:16:11,670
A lot of times, you'll see
a threat intelligence report

384
00:16:11,670 --> 00:16:14,606
that says Russia is
pushing out ransomware.

385
00:16:14,606 --> 00:16:15,874
I guess that's nice.

386
00:16:15,874 --> 00:16:17,142
That doesn't do a
whole lot for us.

387
00:16:17,142 --> 00:16:20,012
But when we wind up with
these actual indicators,

388
00:16:20,012 --> 00:16:21,880
we have domains and
we have IP addresses,

389
00:16:21,880 --> 00:16:23,314
we have host-based indicators,

390
00:16:23,315 --> 00:16:25,551
we can do something with that.

391
00:16:25,551 --> 00:16:27,586
In this example, we
have these domain-based

392
00:16:27,586 --> 00:16:29,688
and IP address-based indicators.

393
00:16:29,688 --> 00:16:31,924
With a lot of
ransomware variants,

394
00:16:31,924 --> 00:16:33,726
it's pretty common
for a key exchange

395
00:16:33,726 --> 00:16:35,928
to be done over the network

396
00:16:35,928 --> 00:16:40,265
in order to actually stop
performing the encryption.

397
00:16:40,265 --> 00:16:42,266
What we can do is we can
take these indicators

398
00:16:42,267 --> 00:16:45,337
and before our users even
run into the spam email

399
00:16:45,337 --> 00:16:48,273
that they have been sent, we
can already have them blocked.

400
00:16:48,273 --> 00:16:50,743
We might wind up with
that case of beaconing

401
00:16:51,677 --> 00:16:52,745
but nothing will happen.

402
00:16:52,745 --> 00:16:54,013
No files will be encrypted,

403
00:16:54,013 --> 00:16:56,181
no network tribes
will be encrypted.

404
00:16:56,181 --> 00:16:57,416
From a protection standpoint,

405
00:16:57,416 --> 00:16:59,018
we're in a pretty good spot.

406
00:16:59,018 --> 00:17:00,586
For the host-based indicators,

407
00:17:00,586 --> 00:17:02,254
if we aren't able to
block them in time

408
00:17:02,254 --> 00:17:04,223
or if we search,
from beforehand,

409
00:17:04,223 --> 00:17:05,257
we see we've already got people

410
00:17:05,257 --> 00:17:07,559
calling out to those locations,

411
00:17:07,559 --> 00:17:08,993
the host-based indicators

412
00:17:08,993 --> 00:17:10,728
will help us go and identify

413
00:17:10,729 --> 00:17:14,033
where the binary in this
case might be located

414
00:17:14,933 --> 00:17:16,635
on the hard drive itself,

415
00:17:16,635 --> 00:17:19,570
and so, here you would see
it's in the temp folder.

416
00:17:19,570 --> 00:17:21,439
At the bottom of this, it's
a little bit hard to see

417
00:17:21,440 --> 00:17:26,178
but there's also VirusTotal
antivirus vendor normalization.

418
00:17:26,178 --> 00:17:27,579
With that is it's taking

419
00:17:27,579 --> 00:17:31,050
all the different
antivirus detection rates

420
00:17:31,050 --> 00:17:34,019
across all the vendors and
it's aggregating them for you.

421
00:17:34,019 --> 00:17:36,522
Again it's not a perfect match

422
00:17:36,522 --> 00:17:37,523
but it gives you an idea

423
00:17:37,523 --> 00:17:39,024
of what you might be looking at

424
00:17:39,024 --> 00:17:40,391
especially if you
were talking about

425
00:17:40,392 --> 00:17:41,627
a more generic YARA rule.

426
00:17:43,429 --> 00:17:46,398
This next slide here just is
a couple of different ways

427
00:17:46,398 --> 00:17:47,698
to look at the data.

428
00:17:47,699 --> 00:17:50,536
But we want to get to
this one over here.

429
00:17:50,536 --> 00:17:53,672
This is another run
from a different rule.

430
00:17:53,672 --> 00:17:56,041
This was off of TreasureHunter
point-of-sale malware.

431
00:17:56,041 --> 00:17:57,810
What's happening
here, you wind up

432
00:17:57,810 --> 00:17:59,511
with a network-based
indicators again of course

433
00:17:59,511 --> 00:18:01,713
but you also wind up
on the host-based ones

434
00:18:01,713 --> 00:18:03,282
with these alternative
data streams.

435
00:18:03,282 --> 00:18:06,217
What you can do with Kibana here

436
00:18:06,218 --> 00:18:08,220
is if you were to
click on one of these,

437
00:18:09,922 --> 00:18:13,725
it would filter out
all of the other files

438
00:18:13,725 --> 00:18:15,194
that don't match that,

439
00:18:15,194 --> 00:18:16,628
that weren't creating that
alternate data stream,

440
00:18:16,628 --> 00:18:19,164
and it would trash all
your files that match that.

441
00:18:19,164 --> 00:18:20,532
A hypothetical third case here

442
00:18:20,532 --> 00:18:23,101
would be if you had
network-based indicators

443
00:18:23,102 --> 00:18:26,805
that were maybe calling
out to France and Russia.

444
00:18:26,805 --> 00:18:28,140
You could filter out

445
00:18:28,140 --> 00:18:33,145
based on that geographical
characteristic

446
00:18:34,012 --> 00:18:35,813
and then you would hop back in

447
00:18:35,814 --> 00:18:38,283
and see which files are
communicating with those,

448
00:18:38,283 --> 00:18:39,685
are those from a
different threat actor,

449
00:18:39,685 --> 00:18:42,120
are those from a
different spam campaign,

450
00:18:42,121 --> 00:18:44,490
has this infrastructure
changed over time.

451
00:18:44,490 --> 00:18:46,992
You can start to build
that level of intelligence.

452
00:18:48,627 --> 00:18:50,129
What we want to get to last year

453
00:18:50,129 --> 00:18:53,232
is this case of additional
API calls that you can make.

454
00:18:54,066 --> 00:18:55,601
In VirusTotal itself,

455
00:18:56,969 --> 00:18:59,438
if you have access to
the Intelligence portal,

456
00:18:59,438 --> 00:19:00,606
you can do a couple
different things here.

457
00:19:00,606 --> 00:19:02,808
You can look at parent
objects for one.

458
00:19:02,808 --> 00:19:06,245
A parent objects is
typically gonna be a zip file

459
00:19:06,245 --> 00:19:10,215
or an email file that someone's
uploaded to VirusTotal.

460
00:19:10,215 --> 00:19:12,951
What it does is it takes out
the components of a zip file

461
00:19:12,951 --> 00:19:15,220
or it takes the attachment
from an email file.

462
00:19:15,220 --> 00:19:16,722
It includes that and
what you've uploaded

463
00:19:16,722 --> 00:19:20,692
but it also puts it as its own
separate hash value and file

464
00:19:20,692 --> 00:19:22,961
with information
reporting on VirusTotal.

465
00:19:24,196 --> 00:19:25,764
The advantage there, I
mentioned there earlier

466
00:19:25,764 --> 00:19:27,366
you take these
malicious attachments,

467
00:19:27,366 --> 00:19:31,036
these JavaScript files,
these Word documents.

468
00:19:31,036 --> 00:19:32,905
You can go backwards
and you can see hey,

469
00:19:32,905 --> 00:19:35,072
who's uploaded this attachment.

470
00:19:36,408 --> 00:19:38,209
Obviously I think
everyone in this room

471
00:19:38,210 --> 00:19:40,279
knows we shouldn't be
uploading emails to VirusTotal

472
00:19:40,279 --> 00:19:42,414
but people do it so they can
get the information from it

473
00:19:42,414 --> 00:19:43,515
since they're so kind.

474
00:19:45,083 --> 00:19:47,753
You wind up in a case
where you can say

475
00:19:47,753 --> 00:19:50,455
are people spoofing the
sender address, for example.

476
00:19:51,823 --> 00:19:53,025
What you would do then

477
00:19:53,025 --> 00:19:54,526
is you might go and
look at ARN report logs

478
00:19:54,526 --> 00:19:55,527
and you would say
we're not seeing

479
00:19:55,527 --> 00:19:57,196
these network-based indicators.

480
00:19:57,196 --> 00:19:58,730
Is it because we're
blocking the emails

481
00:19:58,730 --> 00:20:01,333
or is it because we're just
not being targeted by them?

482
00:20:01,333 --> 00:20:03,035
A good use case
for the zip files

483
00:20:03,035 --> 00:20:05,604
is if you had an executable

484
00:20:05,604 --> 00:20:08,473
that was using a
side-loaded DLL.

485
00:20:08,473 --> 00:20:10,442
Sometimes people will
upload the executable

486
00:20:10,442 --> 00:20:13,212
and they'll upload
the DLL on a zip file.

487
00:20:13,212 --> 00:20:14,713
Because they became
subcomponents,

488
00:20:14,713 --> 00:20:16,648
maybe your rule only
matched on the executable

489
00:20:16,648 --> 00:20:19,351
but in order to do dynamic
testing or reverse engineering,

490
00:20:19,351 --> 00:20:21,520
you also need the library.

491
00:20:21,520 --> 00:20:24,256
You would go back to that
zip file as a parent object

492
00:20:24,256 --> 00:20:26,191
and you could pull
it down from that.

493
00:20:26,191 --> 00:20:28,493
There's also some network
infrastructure pivoting

494
00:20:28,493 --> 00:20:29,794
that you can do from this.

495
00:20:30,963 --> 00:20:32,764
On the right, you
see the results

496
00:20:32,764 --> 00:20:35,766
of running a whole
bunch of IP addresses

497
00:20:35,767 --> 00:20:39,137
across the VirusTotal
Intelligence API.

498
00:20:40,572 --> 00:20:42,341
You can get executables
that were either downloaded

499
00:20:42,341 --> 00:20:45,577
from the same URL or
executables that called out

500
00:20:45,577 --> 00:20:47,346
to the same IP address.

501
00:20:47,346 --> 00:20:50,382
That lets you expand your
network infrastructure as well

502
00:20:50,382 --> 00:20:51,550
or your understanding

503
00:20:51,550 --> 00:20:53,452
of their network
infrastructure as well.

504
00:20:54,920 --> 00:20:57,656
Some other things we've
put up there, CentralOps,

505
00:20:57,656 --> 00:20:59,890
that's a really
good whois resource.

506
00:20:59,891 --> 00:21:02,060
We have a pretty interesting
case from last fall

507
00:21:02,060 --> 00:21:06,398
where someone was pushing
out the Swifi banking trojan.

508
00:21:06,398 --> 00:21:07,733
Now I'll say right
now, CentralOps,

509
00:21:07,733 --> 00:21:09,400
if you want to use their
API, it's not free,

510
00:21:09,401 --> 00:21:12,137
it's I think $20
for 1,000 API calls

511
00:21:12,137 --> 00:21:14,206
but that's still a
fairly large amount

512
00:21:14,206 --> 00:21:15,607
depending on what you're doing.

513
00:21:15,607 --> 00:21:16,742
In this case, we had
someone pushing out

514
00:21:16,742 --> 00:21:18,377
the Swifi banking trojan.

515
00:21:18,377 --> 00:21:20,279
We went and we looked
up the IP there.

516
00:21:22,714 --> 00:21:25,583
The person registered to that
IP address and that domain,

517
00:21:27,586 --> 00:21:29,321
(laughs)

518
00:21:29,321 --> 00:21:30,856
three years prior to this,

519
00:21:30,856 --> 00:21:33,358
he'd been involved in a search
engine optimization scheme

520
00:21:33,358 --> 00:21:34,826
out in the Ukraine.

521
00:21:34,826 --> 00:21:37,863
What we found to
doing additional
research on this person

522
00:21:37,863 --> 00:21:39,665
and he'd been involved
in a kidnapping scheme.

523
00:21:39,665 --> 00:21:41,332
It was kind of ridiculous.

524
00:21:41,333 --> 00:21:44,703
But it turned he
got into malware

525
00:21:44,703 --> 00:21:47,004
and the Ukrainians went and
put a bounty on his head,

526
00:21:47,005 --> 00:21:49,474
literally like go kill
this person bounty.

527
00:21:49,474 --> 00:21:50,742
We got that from CentralOps

528
00:21:50,742 --> 00:21:52,610
and for doing
research off of that.

529
00:21:53,845 --> 00:21:55,981
That's an example of
where you want to do

530
00:21:55,981 --> 00:21:57,482
this sort of pivoting.

531
00:21:57,482 --> 00:21:59,985
The last thing we have
up there is PassiveTotal.

532
00:21:59,985 --> 00:22:02,654
We had a really passive
DNS talk here earlier on.

533
00:22:02,654 --> 00:22:05,557
Just a reminder, you can
expand your understanding

534
00:22:05,557 --> 00:22:08,026
of network infrastructure
based on that.

535
00:22:08,026 --> 00:22:10,762
With PassiveTotal, you can also
get some historical records

536
00:22:10,762 --> 00:22:14,032
as far as DNS is concerned.

537
00:22:14,032 --> 00:22:16,201
You can see if
for example a page

538
00:22:16,201 --> 00:22:17,536
had been previously flagged

539
00:22:17,536 --> 00:22:20,105
by Kaspersky as being
malicious or not.

540
00:22:20,105 --> 00:22:22,341
You can use that API as well.

541
00:22:22,341 --> 00:22:26,043
These are just ways to take
your research to the next step

542
00:22:26,044 --> 00:22:28,213
and get real threat
intelligence out of it.

543
00:22:29,681 --> 00:22:31,249
Just to bring it
all back together,

544
00:22:31,249 --> 00:22:33,085
what we did is we
built a YARA rule

545
00:22:33,085 --> 00:22:35,320
for a JavaScript's dropper.

546
00:22:35,320 --> 00:22:40,325
We identified over 700 files
that were triggering this rule.

547
00:22:41,793 --> 00:22:43,661
In doing that, we
pulled these files down.

548
00:22:43,662 --> 00:22:46,298
We indexed these notifications
into Elasticsearch,

549
00:22:46,298 --> 00:22:47,999
we ran the files in Cuckoo,

550
00:22:47,999 --> 00:22:50,502
and we were able to
put the results of that

551
00:22:50,502 --> 00:22:53,071
into Elasticsearch and
into Kibana as well.

552
00:22:53,071 --> 00:22:54,973
From there, we did
additional pivoting

553
00:22:54,973 --> 00:22:57,008
in the VirusTotal
Intelligence portal.

554
00:22:57,008 --> 00:22:59,544
We wound up with something
that we can deliver to our SOC

555
00:22:59,544 --> 00:23:03,181
that is truly actionable and
something that they can handle.

556
00:23:03,181 --> 00:23:05,717
Again the source code is
available in Allen's GitHub page

557
00:23:05,717 --> 00:23:07,252
if you want to
take a look at it.

558
00:23:07,252 --> 00:23:09,955
At this point, we'll go ahead
and we'll take questions.

559
00:23:13,125 --> 00:23:14,726
- [Asker] On the
original JavaScript

560
00:23:14,726 --> 00:23:16,561
that you were talking about,

561
00:23:16,561 --> 00:23:18,330
how long did it take
you to decode that

562
00:23:18,330 --> 00:23:21,198
and figure out the
obfuscation, et cetera?

563
00:23:21,199 --> 00:23:23,635
How much time are
you guys spending?

564
00:23:23,635 --> 00:23:25,804
And then maybe you're
really good at it

565
00:23:25,804 --> 00:23:27,372
'cause you've been doing
it for a long time.

566
00:23:27,372 --> 00:23:28,907
- Yeah.

567
00:23:28,907 --> 00:23:29,875
- [Asker] What's the uptime
to get up to speed on that?

568
00:23:29,875 --> 00:23:31,610
- That's a really good question.

569
00:23:31,610 --> 00:23:32,878
Unfortunately the answer,

570
00:23:32,878 --> 00:23:34,379
I'll give you something
more specific than this,

571
00:23:34,379 --> 00:23:36,814
but my first answer would
be of course it depends.

572
00:23:37,749 --> 00:23:39,217
With JavaScript in particular,

573
00:23:39,217 --> 00:23:41,753
if you look a month back
on those Locky downloaders,

574
00:23:41,753 --> 00:23:43,621
you can look at the
JavaScript in two seconds,

575
00:23:43,622 --> 00:23:44,823
put the pieces together,

576
00:23:44,823 --> 00:23:46,458
and say here is
where it's gonna go.

577
00:23:46,458 --> 00:23:50,228
In that case, that one took
me probably about a day.

578
00:23:50,228 --> 00:23:51,430
If I were to do it again,

579
00:23:51,430 --> 00:23:53,665
it would take maybe
an hour or two.

580
00:23:53,665 --> 00:23:57,735
But that particular one was
kind of confusing to me.

581
00:23:57,736 --> 00:23:59,171
There are a couple of things

582
00:23:59,171 --> 00:24:00,939
specific to these
JavaScript droppers

583
00:24:00,939 --> 00:24:02,507
that you'll usually see
that will help though.

584
00:24:02,507 --> 00:24:05,911
One of 'em is they almost
don't make a try and a catch

585
00:24:05,911 --> 00:24:07,579
for the GET request.

586
00:24:07,579 --> 00:24:09,781
My understanding is
the purpose behind that

587
00:24:09,781 --> 00:24:12,250
is so if for some reason
it can't call out,

588
00:24:12,250 --> 00:24:13,485
it doesn't hit
you with an error.

589
00:24:13,485 --> 00:24:15,086
The user just doesn't
see anything happen.

590
00:24:15,086 --> 00:24:18,590
That's like one tip I
guess to look there.

591
00:24:18,590 --> 00:24:22,994
Office documents, the
Vawtrak ones from the fall

592
00:24:22,994 --> 00:24:24,361
were pretty easy
but the Dridex ones

593
00:24:24,362 --> 00:24:26,898
and some Locky ones
can take a while.

594
00:24:26,898 --> 00:24:28,433
We did have a live incident

595
00:24:28,433 --> 00:24:32,437
where we were dealing with a
brand new ransomware sample

596
00:24:32,437 --> 00:24:34,406
that hadn't been reported.

597
00:24:34,406 --> 00:24:35,841
We've never seen it again.

598
00:24:35,841 --> 00:24:38,709
But that one, just in the
interest of getting information

599
00:24:38,710 --> 00:24:40,512
really quickly, I
ran it in the sandbox

600
00:24:40,512 --> 00:24:41,745
with the Office debugger online,

601
00:24:41,746 --> 00:24:43,215
put a couple of breakpoints

602
00:24:43,215 --> 00:24:46,016
and just took my
chance like that.

603
00:24:46,017 --> 00:24:48,520
If you're ever in a
pinch, that's something
else you can do.

604
00:24:48,520 --> 00:24:50,622
- One thing to note too
about the Office documents

605
00:24:50,622 --> 00:24:53,458
is that if they are DOCX
and they're zipped up,

606
00:24:53,458 --> 00:24:55,994
VirusTotal will actually
decompress those

607
00:24:55,994 --> 00:24:57,462
and extract up the macros

608
00:24:57,462 --> 00:24:59,898
and you can write your YARA
signatures based off the macros,

609
00:24:59,898 --> 00:25:02,399
so you don't have to match
on the actual zip file,

610
00:25:02,400 --> 00:25:04,169
you can match on
the child documents.

611
00:25:04,169 --> 00:25:05,871
Something that's very
powerful about the VirusTotal

612
00:25:05,871 --> 00:25:07,506
is the YARA implementation.

613
00:25:07,506 --> 00:25:08,340
- [Kevin] Yeah.

614
00:25:09,808 --> 00:25:11,309
- [Asker] Hi.

615
00:25:11,309 --> 00:25:13,645
In terms of use cases, how
does your process work?

616
00:25:13,645 --> 00:25:15,947
Is this primarily
something you go to

617
00:25:15,947 --> 00:25:18,716
after you have some kind of
trigger in your environment

618
00:25:18,717 --> 00:25:20,385
or is it coming
out the other way

619
00:25:20,385 --> 00:25:22,754
where you say okay, there's
a campaign out there,

620
00:25:22,754 --> 00:25:24,389
let's see if anything
similar is happening

621
00:25:24,389 --> 00:25:25,623
in our environment?

622
00:25:25,624 --> 00:25:27,926
I'm just curious about
the human process side.

623
00:25:27,926 --> 00:25:29,793
- Yeah, a multitude,
different ways.

624
00:25:29,794 --> 00:25:32,063
There is a lot of
mailing list out there

625
00:25:32,063 --> 00:25:34,799
where you can see like a lot
of the current spam campaigns.

626
00:25:34,799 --> 00:25:37,068
I've been able to signature
off of like techniques

627
00:25:37,068 --> 00:25:38,937
that are used in a spam campaign

628
00:25:38,937 --> 00:25:42,474
and then later on detect
that same spam campaign

629
00:25:42,474 --> 00:25:44,408
inside of our environment.

630
00:25:44,409 --> 00:25:45,644
That's very common.

631
00:25:45,644 --> 00:25:47,612
But if you get a
targeted campaign,

632
00:25:47,612 --> 00:25:51,650
you can start to track those
target threat actors to you

633
00:25:51,650 --> 00:25:55,487
such as TA530 recently
had a Word document

634
00:25:55,487 --> 00:25:58,356
macro spam campaign
where they were making,

635
00:25:58,356 --> 00:26:00,992
the file name was
like the company name

636
00:26:00,992 --> 00:26:03,161
and then space like
invoice or orders,

637
00:26:03,161 --> 00:26:04,629
something like that, dot doc.

638
00:26:05,997 --> 00:26:08,300
We were able to signature
on the PNG actually

639
00:26:08,300 --> 00:26:10,402
inside of that that
they are using,

640
00:26:10,402 --> 00:26:12,504
upload that to VirusTotal.

641
00:26:12,504 --> 00:26:14,139
Not only did we see
we got hit by it

642
00:26:14,139 --> 00:26:16,408
but we also saw because
the company name

643
00:26:16,408 --> 00:26:19,777
was inside the actual file
name of the document file.

644
00:26:19,778 --> 00:26:21,212
We saw all these other companies

645
00:26:21,212 --> 00:26:22,914
get hit by it as well.

646
00:26:22,914 --> 00:26:24,449
We could actually go
through and be like yep,

647
00:26:24,449 --> 00:26:26,618
that guy from this company
submitted this file,

648
00:26:26,618 --> 00:26:28,320
that guy from this company
submitted this file,

649
00:26:28,320 --> 00:26:29,854
and stuff like that.

650
00:26:29,854 --> 00:26:33,325
So you can see how the threat
landscape as a whole is taking

651
00:26:33,325 --> 00:26:35,427
'cause your company
is just one part

652
00:26:35,427 --> 00:26:37,094
of the bigger landscape
that these people

653
00:26:37,095 --> 00:26:38,797
are sending the
spam waves out too

654
00:26:38,797 --> 00:26:40,398
if you're focused on spam waves.

655
00:26:43,268 --> 00:26:44,102
Yeah, definitely.

656
00:26:46,037 --> 00:26:47,505
With the TA530 stuff,

657
00:26:47,505 --> 00:26:49,941
we were able to
identify network IOCs,

658
00:26:52,177 --> 00:26:53,978
same campaign but
from other people

659
00:26:53,979 --> 00:26:57,015
before it hit our network,
so we were able to detect C2

660
00:26:58,683 --> 00:27:00,151
(clears throat)

661
00:27:00,151 --> 00:27:02,587
from like a file that they
sent to another people

662
00:27:02,587 --> 00:27:03,955
who uploaded it to VirusTotal.

663
00:27:03,955 --> 00:27:05,991
We pulled it down,
submitted it to our sandbox,

664
00:27:05,991 --> 00:27:07,225
got that domain out,

665
00:27:07,225 --> 00:27:08,959
and we're able to put
blocking detection

666
00:27:08,960 --> 00:27:11,763
into our own environment
before we saw documents

667
00:27:11,763 --> 00:27:13,764
that were triggering
out to that domain.

668
00:27:14,966 --> 00:27:16,533
- One thing to
add onto that too.

669
00:27:16,534 --> 00:27:18,136
If for some reason
you don't have access

670
00:27:18,136 --> 00:27:20,038
to the VirusTotal
Intelligence portal

671
00:27:20,038 --> 00:27:21,806
because it's for example
too cost-prohibitive

672
00:27:21,806 --> 00:27:23,308
to have this unlimited,

673
00:27:23,308 --> 00:27:28,013
other organizations do aggregate
like a known good database,

674
00:27:28,013 --> 00:27:29,447
so you can go that route.

675
00:27:29,447 --> 00:27:31,081
You just start aggregating
your own database

676
00:27:31,082 --> 00:27:33,251
for this kind of
research and development.

677
00:27:33,251 --> 00:27:34,819
That's another option you have.

678
00:27:36,221 --> 00:27:37,822
- [Host] Hey guys, thank
you so much for presenting.

679
00:27:37,822 --> 00:27:38,756
Awesome presentation.

680
00:27:38,757 --> 00:27:39,591
(audience clapping)

681
00:27:39,591 --> 00:27:40,425
Well done.

682
00:27:40,425 --> 00:27:42,927
(light music)

