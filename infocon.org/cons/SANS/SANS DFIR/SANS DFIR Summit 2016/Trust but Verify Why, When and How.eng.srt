1
00:00:12,979 --> 00:00:15,248
(clapping)

2
00:00:18,051 --> 00:00:19,284
- Thank you Heather.

3
00:00:19,285 --> 00:00:22,088
I always enjoy coming
out to the DFIR summit.

4
00:00:22,088 --> 00:00:24,357
The best people are here,
we're all learning a lot,

5
00:00:24,357 --> 00:00:25,892
I think it's a great community.

6
00:00:25,892 --> 00:00:28,762
We want to see the
community advance together

7
00:00:28,762 --> 00:00:30,530
and contribute in
any way we can.

8
00:00:30,530 --> 00:00:33,600
So today I wanted to talk
about trust but verify,

9
00:00:33,600 --> 00:00:36,336
specifically when it comes
to the tools that we use

10
00:00:36,336 --> 00:00:39,472
in digital forensics
and incident response.

11
00:00:39,472 --> 00:00:42,609
I'm gonna talk about
why we need to do it,

12
00:00:42,609 --> 00:00:44,644
I'm gonna talk about
when we need to do it,

13
00:00:44,644 --> 00:00:46,146
and then I'm gonna wrap up

14
00:00:46,146 --> 00:00:48,915
with a couple of examples
of how you can do it.

15
00:00:50,350 --> 00:00:52,318
Just to give you a little
bit of background information

16
00:00:52,318 --> 00:00:54,687
about myself, my name
is Mari DeGrazia.

17
00:00:54,687 --> 00:00:58,491
I'm the director at
Kroll Cyber Security.

18
00:00:58,491 --> 00:01:00,994
I also have a blog, where
I blog about research

19
00:01:00,994 --> 00:01:03,329
that I've done, tools
that I've tested,

20
00:01:03,329 --> 00:01:06,399
and also some scripts and some
parsers that I've written.

21
00:01:06,399 --> 00:01:09,369
I also have these available
for download on my GitHub site,

22
00:01:09,369 --> 00:01:12,105
and of course, you can
reach me on Twitter

23
00:01:12,105 --> 00:01:15,275
@MariDegrazia if you have
any questions for me.

24
00:01:15,275 --> 00:01:18,678
But really the most important
thing is not about me,

25
00:01:18,678 --> 00:01:20,313
it's about Super Troopers.

26
00:01:20,313 --> 00:01:24,050
Okay, so today in this
presentation, we're
gonna play a game

27
00:01:24,050 --> 00:01:25,551
in celebration, or really,

28
00:01:25,552 --> 00:01:29,622
in honor of Super Troopers
2 coming out this year.

29
00:01:29,622 --> 00:01:33,293
How many of you are
familiar with the meow game?

30
00:01:34,494 --> 00:01:36,763
All right, so if you're
not, in Super Troopers,

31
00:01:36,763 --> 00:01:39,933
the original one, they
would pull someone over,

32
00:01:39,933 --> 00:01:42,802
walk up to a car, and
say something like,

33
00:01:42,802 --> 00:01:45,405
"Meow ma'am, do you know
how fast you were going?"

34
00:01:45,405 --> 00:01:48,441
So in this presentation, I'm
going to slip in the word

35
00:01:48,441 --> 00:01:50,143
meow several times.

36
00:01:50,143 --> 00:01:52,212
And if you hear me say meow,

37
00:01:52,212 --> 00:01:53,780
I want you to raise your hand.

38
00:01:53,780 --> 00:01:55,915
And I have some prizes here.

39
00:01:55,915 --> 00:01:57,383
There are these
little bobbleheads.

40
00:01:57,383 --> 00:01:59,719
I think I've got a
Deadpool in there, Hulk,

41
00:01:59,719 --> 00:02:02,755
and for the ladies, I've got
Thor, because who would not

42
00:02:02,755 --> 00:02:06,960
want a Thor bobblehead,
sitting on their desk, right?

43
00:02:06,960 --> 00:02:08,828
Okay, so if you
hear, just be ready,

44
00:02:08,828 --> 00:02:12,866
raise your hand, and either
Darren or Cheeky Forensic Monkey

45
00:02:12,866 --> 00:02:14,434
will come on over
and give you one.

46
00:02:14,434 --> 00:02:17,003
First person to raise
their hand, I should say.

47
00:02:17,003 --> 00:02:21,673
Okay, so, why do we want to
validate our tools, right?

48
00:02:21,674 --> 00:02:24,511
We want to trust them, and
you always kind of hear

49
00:02:24,511 --> 00:02:27,447
about this term,
community-vetted, right?

50
00:02:27,447 --> 00:02:30,350
If this tool is being
used out in the community,

51
00:02:30,350 --> 00:02:32,986
and my coworkers
are using this tool,

52
00:02:32,986 --> 00:02:36,822
everybody's using it, it
must be accurate, right?

53
00:02:36,823 --> 00:02:39,926
This is not always the case,
and this was really driven

54
00:02:39,926 --> 00:02:42,695
home to me in the case
that I was working.

55
00:02:42,695 --> 00:02:46,533
We had some IOCs
identified, and we needed

56
00:02:46,533 --> 00:02:49,501
to find them quickly
on a lot of machines.

57
00:02:49,502 --> 00:02:51,371
Since we already knew
where they were at,

58
00:02:51,371 --> 00:02:53,773
we didn't to pull
full disk images.

59
00:02:53,773 --> 00:02:55,975
So we just pulled the MFT file.

60
00:02:55,975 --> 00:02:59,245
And we used the parser to
parse out the MFT files.

61
00:02:59,245 --> 00:03:01,347
And as I was
reviewing the outputs,

62
00:03:01,347 --> 00:03:03,983
I noticed something
was a little bit off.

63
00:03:03,983 --> 00:03:08,288
We had seen this malware,
typically in, you know,

64
00:03:08,288 --> 00:03:10,089
app data folder of
something like that.

65
00:03:10,089 --> 00:03:12,525
And all of a sudden
we saw the meow-ware,

66
00:03:12,525 --> 00:03:15,995
I think I saw, I'm not
sure, did you guys catch it?

67
00:03:15,995 --> 00:03:17,096
- [Man] We got it for you.

68
00:03:17,096 --> 00:03:18,865
- Okay, right here.

69
00:03:18,865 --> 00:03:22,535
So, aha, gotta be ready, you
gotta be paying attention.

70
00:03:22,535 --> 00:03:25,505
So after we found the
malware in these locations,

71
00:03:25,505 --> 00:03:27,874
I noticed in a couple
of these systems,

72
00:03:27,874 --> 00:03:30,810
it was appearing in a
Windows update folder

73
00:03:30,810 --> 00:03:33,379
and then in another
one, a program folder.

74
00:03:33,379 --> 00:03:34,647
And I said, "Wait a minute,

75
00:03:34,647 --> 00:03:37,450
"this doesn't make
very much sense."

76
00:03:37,450 --> 00:03:40,720
So I pulled an image, and I
just double-checked to see

77
00:03:40,720 --> 00:03:43,389
and it turned out that
the MFT parser was

78
00:03:43,389 --> 00:03:47,527
incorrectly showing where
deleted files were at.

79
00:03:47,527 --> 00:03:49,862
So in instances like
this, can you imagine

80
00:03:49,862 --> 00:03:53,132
the ramifications of,
you know, passing on

81
00:03:53,132 --> 00:03:56,569
inaccurate information
in our exams?

82
00:03:56,569 --> 00:03:59,172
It can lead us to the
wrong conclusions.

83
00:03:59,172 --> 00:04:01,073
It can put you in the
hot seat, if you are

84
00:04:01,074 --> 00:04:04,177
testifying in court and it
comes out that your tools

85
00:04:04,177 --> 00:04:07,013
are not working correctly
or they're not accurate.

86
00:04:07,013 --> 00:04:08,414
That could potentially
put everything

87
00:04:08,414 --> 00:04:11,351
that you've done into question.

88
00:04:11,351 --> 00:04:14,621
And the same thing, if you're
answering the CEO of a company

89
00:04:14,621 --> 00:04:17,857
and you're saying, hey,
we found the malware here,

90
00:04:17,857 --> 00:04:20,226
and maybe their IT guy goes
to check, and you know,

91
00:04:20,226 --> 00:04:22,095
it's not there, and your tools

92
00:04:22,095 --> 00:04:24,764
are not giving you
the right information,

93
00:04:24,764 --> 00:04:26,666
it can put you in the
hot seat pretty quickly

94
00:04:26,666 --> 00:04:28,701
and that's really uncomfortable.

95
00:04:28,701 --> 00:04:31,871
And ultimately, tools are
not perfect, you know.

96
00:04:31,871 --> 00:04:34,007
Humans develop tools,
most of the times,

97
00:04:34,007 --> 00:04:35,475
and we're not perfect.

98
00:04:35,475 --> 00:04:38,878
I write my own code, and I
know it's not always perfect.

99
00:04:38,878 --> 00:04:41,546
And so tools, they have bugs.

100
00:04:41,547 --> 00:04:45,351
I mean, we have terminology
for that: bugs, right?

101
00:04:45,351 --> 00:04:48,955
So when we talk about our
tools, everything is suspect.

102
00:04:48,955 --> 00:04:51,824
Just because you pay for a tool,

103
00:04:51,824 --> 00:04:54,627
that does not mean that
it's not gonna have issues.

104
00:04:54,627 --> 00:04:57,430
You think about the
Casey Anthony trial,

105
00:04:57,430 --> 00:04:58,898
and the cache back issue.

106
00:04:58,898 --> 00:05:01,868
How many of you have heard
about that, or remember that?

107
00:05:01,868 --> 00:05:05,838
This was a for-pay tool,
that incorrectly parsed out

108
00:05:05,838 --> 00:05:08,908
internet history,
which, you know,

109
00:05:08,908 --> 00:05:10,810
this could lead to
the difference between

110
00:05:10,810 --> 00:05:13,579
someone going to jail
and not going jail,

111
00:05:13,579 --> 00:05:14,881
getting away with something,

112
00:05:14,881 --> 00:05:16,849
or not getting away
with something.

113
00:05:16,849 --> 00:05:18,885
When we talk about
open source tools,

114
00:05:18,885 --> 00:05:21,721
I know when I develop
my open source tools,

115
00:05:21,721 --> 00:05:23,356
the nice thing
about open source is

116
00:05:23,356 --> 00:05:26,192
you can actually go and review
the source code, you know.

117
00:05:26,192 --> 00:05:29,095
If you want to how a time
stamp is being converted,

118
00:05:29,095 --> 00:05:31,964
you can go see how that time
stamp is being converted.

119
00:05:31,964 --> 00:05:36,269
But on the flip side, you
know, I have a full time job,

120
00:05:36,269 --> 00:05:38,471
I don't always get around
to updating my tools

121
00:05:38,471 --> 00:05:40,340
as quickly as I
should, so sometimes

122
00:05:40,340 --> 00:05:42,008
they might be lagging behind.

123
00:05:43,276 --> 00:05:45,978
When we talk about tool issues,

124
00:05:45,978 --> 00:05:49,015
it's not always black and white.

125
00:05:49,015 --> 00:05:51,851
And I have to thank Adrian
for doing this artwork for me:

126
00:05:51,851 --> 00:05:54,253
got a little guy here
with some tool envy.

127
00:05:55,888 --> 00:05:59,758
But these issues are not
always black and white.

128
00:05:59,759 --> 00:06:01,894
And it's not always
easy to pick out

129
00:06:01,894 --> 00:06:05,365
when your tools are not giving
you accurate information.

130
00:06:05,365 --> 00:06:07,200
And we're gonna
actually walk through

131
00:06:07,200 --> 00:06:11,236
some real-world tool
fails to demonstrate that.

132
00:06:11,237 --> 00:06:13,106
So the first game
we're gonna play

133
00:06:13,106 --> 00:06:16,442
is inaccurate information.

134
00:06:16,442 --> 00:06:19,779
So inaccurate information
is very dangerous,

135
00:06:19,779 --> 00:06:23,282
'cause it can lead you down
a completely wrong path.

136
00:06:23,282 --> 00:06:27,085
So I was doing some testing,
and, so here's the picture

137
00:06:27,086 --> 00:06:29,622
of a directory structure,
just in Windows,

138
00:06:29,622 --> 00:06:31,824
and then I took an
image of this machine

139
00:06:31,824 --> 00:06:34,894
to pull into FEK
to do my research.

140
00:06:34,894 --> 00:06:36,262
Now, I'm gonna put
up another slide

141
00:06:36,262 --> 00:06:38,297
and I'm curious to see
if you guys can tell

142
00:06:38,297 --> 00:06:40,533
what might be inaccurate
between the two.

143
00:06:42,135 --> 00:06:44,871
Now this actually happened.

144
00:06:44,871 --> 00:06:47,774
Can everybody see what
the difference is here?

145
00:06:49,475 --> 00:06:52,245
It's showing deleted folders.

146
00:06:52,245 --> 00:06:56,149
When I saw this, I about
fell out of my chair.

147
00:06:56,149 --> 00:07:00,820
This wasn't some new
artifact that got pushed out.

148
00:07:00,820 --> 00:07:02,522
You know, the NTFS file system

149
00:07:02,522 --> 00:07:03,756
has been around for a while.

150
00:07:03,756 --> 00:07:05,625
I couldn't believe
it when I saw this.

151
00:07:05,625 --> 00:07:07,527
I went back to the computer

152
00:07:07,527 --> 00:07:09,562
that I took the image
of, and looked at it.

153
00:07:09,562 --> 00:07:11,798
You know, it was a test
machine, logged onto it.

154
00:07:11,798 --> 00:07:13,566
I even went to the
folders and like,

155
00:07:13,566 --> 00:07:15,835
I'm not losing my
mind here, right?

156
00:07:15,835 --> 00:07:18,938
FTK Imager is
showing these files

157
00:07:18,938 --> 00:07:21,941
as deleted and they were not.

158
00:07:21,941 --> 00:07:23,775
This is dangerous.

159
00:07:23,776 --> 00:07:25,344
Could you imagine
what would happen

160
00:07:25,344 --> 00:07:28,080
if you acted on
this information?

161
00:07:28,080 --> 00:07:32,585
What if it was contraband
material in there,

162
00:07:32,585 --> 00:07:34,419
and you say, you know what,
we're not gonna charge

163
00:07:34,420 --> 00:07:36,556
this guy, he deleted
these folders.

164
00:07:36,556 --> 00:07:38,491
Or, what if there
was malware in there,

165
00:07:38,491 --> 00:07:40,126
and you went back to the
client, and you said,

166
00:07:40,126 --> 00:07:42,294
You know what, the malware
is not in the system.

167
00:07:42,295 --> 00:07:43,863
I show it as being deleted.

168
00:07:43,863 --> 00:07:45,498
Don't worry about it.

169
00:07:45,498 --> 00:07:47,433
These kinds of
issues are out there,

170
00:07:47,433 --> 00:07:49,669
and they're happening in
the tools that we use.

171
00:07:49,669 --> 00:07:52,405
This tool has been
around for a long time.

172
00:07:52,405 --> 00:07:54,739
We would use something like
this if all of our teammates

173
00:07:54,740 --> 00:07:58,377
were using it, and not even
give it a second thought.

174
00:07:59,545 --> 00:08:01,280
That other issue I
wanted to talk about

175
00:08:01,280 --> 00:08:03,950
was missing information.

176
00:08:03,950 --> 00:08:05,751
So this isn't necessarily bad.

177
00:08:05,751 --> 00:08:07,520
It can be a feature, in fact.

178
00:08:07,520 --> 00:08:09,287
The developer just
may not want to

179
00:08:09,288 --> 00:08:11,624
put that information
in their tool.

180
00:08:11,624 --> 00:08:13,459
So it may not lead
us down the path

181
00:08:13,459 --> 00:08:18,097
of making a wrong decision
or a wrong conclusion,

182
00:08:18,097 --> 00:08:20,399
but sometimes we need
that additional data.

183
00:08:20,399 --> 00:08:24,203
So my example here is a
Windows 8 Prefetch file.

184
00:08:24,203 --> 00:08:27,039
In this particular parser,
it pulled a file name,

185
00:08:27,039 --> 00:08:31,777
a created time, modified time,
run count and last run time.

186
00:08:31,777 --> 00:08:34,112
Now, just concentrating
on the top section here,

187
00:08:34,113 --> 00:08:37,183
can anybody tell me
what might be missing

188
00:08:37,183 --> 00:08:40,720
that could be there from
a Windows 8 Prefetch file?

189
00:08:40,720 --> 00:08:42,855
- [Audience Member] The
time it was last run.

190
00:08:42,855 --> 00:08:45,992
- Right, so with Windows
8 Prefetch files,

191
00:08:45,992 --> 00:08:49,829
you actually have eight
times that that program ran.

192
00:08:49,829 --> 00:08:52,665
So this tool is just
not displaying that.

193
00:08:52,665 --> 00:08:53,799
It's displaying one.

194
00:08:53,799 --> 00:08:55,101
So is it inaccurate?

195
00:08:55,101 --> 00:08:55,968
No.

196
00:08:55,968 --> 00:08:57,336
Did the tool fail?

197
00:08:57,336 --> 00:08:58,538
No.

198
00:08:58,538 --> 00:08:59,372
Is it a bug?

199
00:08:59,372 --> 00:09:00,640
No.

200
00:09:00,640 --> 00:09:03,074
But we could use those
additional time stamps

201
00:09:03,075 --> 00:09:05,378
to help further
our investigation.

202
00:09:05,378 --> 00:09:08,247
So if I have someone that's
using something like VNC

203
00:09:08,247 --> 00:09:10,550
and connecting into
another computer,

204
00:09:10,550 --> 00:09:14,620
I can use those eight times
to do some cross-correlation

205
00:09:14,620 --> 00:09:16,088
on that other computer to see

206
00:09:16,088 --> 00:09:18,925
what they may have accessed
during that time frame.

207
00:09:20,660 --> 00:09:22,728
The other issue, and
this is one that I think

208
00:09:22,728 --> 00:09:26,732
is really hard to catch,
is misleading information.

209
00:09:26,732 --> 00:09:29,334
This can be as simple as just
some vague column headings

210
00:09:29,335 --> 00:09:32,038
that leave things open
to interpretation,

211
00:09:32,038 --> 00:09:33,973
missing time zone information.

212
00:09:33,973 --> 00:09:37,310
So in this one, there's
no time zone information

213
00:09:37,310 --> 00:09:40,279
listed with these dates, right?

214
00:09:40,279 --> 00:09:42,949
An examiner might
jump to conclusions,

215
00:09:42,949 --> 00:09:45,651
or might be used to working
in UTC or local time

216
00:09:45,651 --> 00:09:47,853
and kind of infer
the wrong things

217
00:09:47,853 --> 00:09:50,189
out of what the tool is showing.

218
00:09:50,189 --> 00:09:52,625
And I think the other thing
that's really difficult

219
00:09:52,625 --> 00:09:55,561
is when a tool just
parses partial data,

220
00:09:55,561 --> 00:09:59,365
especially when it doesn't
give you an indication

221
00:09:59,365 --> 00:10:01,267
that it didn't parse everything.

222
00:10:01,267 --> 00:10:03,536
This became really clear
to me when I had to work

223
00:10:03,536 --> 00:10:08,540
with the Thunderbird
email default profile.

224
00:10:09,642 --> 00:10:11,110
So in this case, I
opened it up, and I saw

225
00:10:11,110 --> 00:10:13,546
that there was
about 7,000 emails.

226
00:10:13,546 --> 00:10:17,249
The first tool that I
tried didn't pull anything.

227
00:10:17,249 --> 00:10:19,218
Now, when a tool
doesn't pull anything,

228
00:10:19,218 --> 00:10:21,087
that's really easy
to tell, right?

229
00:10:21,087 --> 00:10:23,889
You have a two gig file,
it doesn't pull anything,

230
00:10:23,889 --> 00:10:26,025
you know something's wrong.

231
00:10:26,025 --> 00:10:29,996
But when it only pulls partial
data like half the emails,

232
00:10:29,996 --> 00:10:31,564
that might seem
reasonable, right?

233
00:10:31,564 --> 00:10:33,632
I have a two gig email file,

234
00:10:33,633 --> 00:10:36,736
it pulls out half
the information.

235
00:10:36,736 --> 00:10:41,474
How would you know it didn't
pull 3,000 other emails?

236
00:10:41,474 --> 00:10:42,975
And one of those emails could be

237
00:10:42,975 --> 00:10:45,044
your smoking gun
that you needed.

238
00:10:45,044 --> 00:10:47,545
And all of this is based
off of real, tested at,

239
00:10:47,546 --> 00:10:52,518
and real world situations that
I've come across in my exams.

240
00:10:54,353 --> 00:10:58,391
The next thing I wanted to
talk about is examiner error.

241
00:10:58,391 --> 00:11:00,425
Now, this is a big issue.

242
00:11:01,594 --> 00:11:02,962
Just saw someone over here.

243
00:11:05,698 --> 00:11:08,233
Okay, so examiner
error, how many of you

244
00:11:08,234 --> 00:11:11,404
have heard about that story,
cause there's always someone

245
00:11:11,404 --> 00:11:14,340
that image their own hard drive?

246
00:11:14,340 --> 00:11:15,841
I know it's been passed around,

247
00:11:15,841 --> 00:11:17,810
I've worked at
several places, right?

248
00:11:17,810 --> 00:11:20,179
I don't know if
tool verification
is really gonna help

249
00:11:20,179 --> 00:11:24,016
with that, but I think how we
can avoid examiner error is,

250
00:11:24,016 --> 00:11:28,521
the more we understand the
artifacts that we work with,

251
00:11:28,521 --> 00:11:32,425
we reduce the situations where
we're inferring wrong things

252
00:11:32,425 --> 00:11:36,328
or not noticing that our
tools are working correctly.

253
00:11:38,431 --> 00:11:41,467
So when do we need to
do our verification?

254
00:11:41,467 --> 00:11:44,336
Do we do it just when
a new tool comes out?

255
00:11:44,336 --> 00:11:45,771
You know, we get
a brand new tool

256
00:11:45,771 --> 00:11:47,573
that parses internet
histories so we use it,

257
00:11:47,573 --> 00:11:49,074
and we check it
against the tools

258
00:11:49,075 --> 00:11:50,643
that we're currently using?

259
00:11:50,643 --> 00:11:52,411
Or what about a new
operating system?

260
00:11:52,411 --> 00:11:54,946
Windows 10 comes out, so
everybody in the community

261
00:11:54,947 --> 00:11:58,818
that's writing great tools,
they'll check the new OS

262
00:11:58,818 --> 00:12:01,754
to make sure that their
tools are working correctly.

263
00:12:01,754 --> 00:12:03,622
Or what about when
there's a tool update?

264
00:12:03,622 --> 00:12:06,692
How many people remember
when NK6 came out?

265
00:12:06,692 --> 00:12:09,995
How many people
immediately jumped to NK7?

266
00:12:09,995 --> 00:12:11,897
You know, I heard a
lot in the community,

267
00:12:11,897 --> 00:12:15,034
"I'm gonna wait a while,
to make sure," what,

268
00:12:15,034 --> 00:12:17,770
all the bugs get
worked out, right?

269
00:12:17,770 --> 00:12:20,573
So when a new tool comes
out, we also need to be

270
00:12:20,573 --> 00:12:22,675
testing and
validating our tools.

271
00:12:22,675 --> 00:12:25,243
What about in between
minor versions, right?

272
00:12:25,244 --> 00:12:26,712
'Cause usually when
someone pushes out

273
00:12:26,712 --> 00:12:29,648
a minor version,
it's to fix bugs.

274
00:12:29,648 --> 00:12:32,118
Well, here we go
back to my example

275
00:12:32,118 --> 00:12:35,621
of access data, FTK imager.

276
00:12:35,621 --> 00:12:40,626
Here we have just a minor
change, from 3.12 to 3.146.

277
00:12:42,628 --> 00:12:45,664
And this is when,
somewhere in between here,

278
00:12:45,664 --> 00:12:49,335
this deleted folder
issue came up.

279
00:12:49,335 --> 00:12:52,037
So as you can see, even
when there's a minor change

280
00:12:52,037 --> 00:12:56,041
in the program, sometimes
that can introduce a huge bug.

281
00:12:57,243 --> 00:12:59,812
So I propose in the
community that we need

282
00:12:59,812 --> 00:13:02,848
to be testing our
tools all the time.

283
00:13:02,848 --> 00:13:04,916
Every single time
that we work a case,

284
00:13:04,917 --> 00:13:07,253
every single time
that we use a tool,

285
00:13:07,253 --> 00:13:09,655
we need to be
checking the outputs

286
00:13:09,655 --> 00:13:13,659
to make sure that
they make sense.

287
00:13:13,659 --> 00:13:14,960
And this is really easy to do.

288
00:13:14,960 --> 00:13:16,729
You just take a step back.

289
00:13:16,729 --> 00:13:19,198
You think about the
totally of your exam.

290
00:13:19,198 --> 00:13:21,934
You think about the
artifacts that you know,

291
00:13:21,934 --> 00:13:23,736
and what you know about them.

292
00:13:23,736 --> 00:13:28,207
And just take a step back, look
at that big picture, and see

293
00:13:28,207 --> 00:13:31,710
if your tools are giving you
the output that they should.

294
00:13:31,710 --> 00:13:33,612
And this should be easy to do.

295
00:13:33,612 --> 00:13:37,248
So, here's an example
of a directory listing

296
00:13:37,249 --> 00:13:38,717
with a deleted folder up on top.

297
00:13:38,717 --> 00:13:42,988
Can anybody tell me, what may
not make sense about this?

298
00:13:45,491 --> 00:13:47,425
So here we have
a deleted folder,

299
00:13:47,426 --> 00:13:50,429
what about all the
folders underneath it?

300
00:13:50,429 --> 00:13:51,997
Why aren't they deleted?

301
00:13:51,997 --> 00:13:53,933
That does not make any sense.

302
00:13:53,933 --> 00:13:55,835
Now, is this because
I'm not understanding

303
00:13:55,835 --> 00:13:58,237
how the tool is presenting
the information?

304
00:13:58,237 --> 00:14:01,307
Is it because the GUI on the
tool is kind of messed up?

305
00:14:01,307 --> 00:14:04,176
I mean, why is this happening?

306
00:14:04,176 --> 00:14:06,078
Here's another example.

307
00:14:06,078 --> 00:14:07,680
Can anybody tell
me what might be

308
00:14:07,680 --> 00:14:10,348
a little bit off about
these file listings?

309
00:14:12,918 --> 00:14:15,087
Yeah, the file
sizes are all zero.

310
00:14:15,087 --> 00:14:17,723
Sometimes when you're
working with this,

311
00:14:17,723 --> 00:14:20,526
it may not be as clear if you're
doing timeline generation.

312
00:14:20,526 --> 00:14:22,962
These prefetched files
might have been spread out

313
00:14:22,962 --> 00:14:24,930
all over the place,
so an error like this

314
00:14:24,930 --> 00:14:26,799
may not be as obvious.

315
00:14:26,799 --> 00:14:29,001
But when we're working and
looking at our outputs,

316
00:14:29,001 --> 00:14:32,137
sometimes just stepping back
and looking at the outputs,

317
00:14:32,137 --> 00:14:36,242
and asking ourselves,
does this make sense

318
00:14:36,242 --> 00:14:39,511
can really go a long ways
to helping to vet the tools

319
00:14:39,511 --> 00:14:42,448
as you work with them
on a daily basis.

320
00:14:43,883 --> 00:14:47,620
Okay, so we've talked about
why, we've talked about when,

321
00:14:47,620 --> 00:14:50,589
and now I want to talk about
meow you're gonna do it.

322
00:14:53,492 --> 00:14:54,425
Are we lost?

323
00:14:55,427 --> 00:14:57,062
That whole row!

324
00:14:57,062 --> 00:15:00,599
Okay, you guys rock, paper,
scissors, afterwards, all right?

325
00:15:00,599 --> 00:15:04,470
Okay, so when we talk about...

326
00:15:09,241 --> 00:15:12,311
Oh, that's excellent, you guys
can fight over Thor, okay.

327
00:15:12,311 --> 00:15:13,812
He'll like that.

328
00:15:17,783 --> 00:15:21,253
So, digital forensics
incident response,

329
00:15:21,253 --> 00:15:23,822
digital forensics
is a science, right?

330
00:15:23,822 --> 00:15:26,759
We need to approach this in
a scientific way, you know.

331
00:15:26,759 --> 00:15:28,427
We don't want to be
like Beaker here,

332
00:15:28,427 --> 00:15:30,329
where we blow up the lab.

333
00:15:30,329 --> 00:15:31,930
We need to test our tools

334
00:15:31,931 --> 00:15:35,968
against known and
expected results.

335
00:15:35,968 --> 00:15:39,070
And we can do this by
using some of the data sets

336
00:15:39,071 --> 00:15:40,973
that are already out there, like

337
00:15:40,973 --> 00:15:42,974
NIST has some data
sets that we can use.

338
00:15:42,975 --> 00:15:44,910
Now, the issue with
their data sets is,

339
00:15:44,910 --> 00:15:47,913
they're kind of small,
they're not very current,

340
00:15:47,913 --> 00:15:49,181
they're not gonna
address some of the

341
00:15:49,181 --> 00:15:51,884
very specific artifacts
that we deal with.

342
00:15:51,884 --> 00:15:55,220
The other thing we can do, is
we can generate our test data.

343
00:15:55,220 --> 00:15:57,323
In Sarah Edwards'
talk this morning,

344
00:15:57,323 --> 00:15:59,391
she talked about how
she took her cell phone,

345
00:15:59,391 --> 00:16:01,926
and how she did some
of this tracking,

346
00:16:01,927 --> 00:16:04,163
and when she was doing that,
looking at the time stamp,

347
00:16:04,163 --> 00:16:05,864
she found out that
these time stamps

348
00:16:05,864 --> 00:16:08,167
were each off by nine minutes.

349
00:16:08,167 --> 00:16:09,668
Now she never would
have known that

350
00:16:09,668 --> 00:16:11,870
if she had just grabbed
someone else's cell phone

351
00:16:11,870 --> 00:16:13,339
and looked at the time stamps.

352
00:16:13,339 --> 00:16:15,641
How would you have known that
they were consistently off

353
00:16:15,641 --> 00:16:18,276
by nine minutes, unless
you don't generate

354
00:16:18,277 --> 00:16:21,580
your own test data to
validate your tools?

355
00:16:21,580 --> 00:16:24,283
The other thing we can do
is use real world data.

356
00:16:24,283 --> 00:16:26,986
And I like this approach
too because, let's say

357
00:16:26,986 --> 00:16:29,588
you're doing something
like internet history.

358
00:16:29,588 --> 00:16:31,656
There's no way you're gonna
be able to generate two years

359
00:16:31,657 --> 00:16:35,127
of internet history to really
put your tools to the test.

360
00:16:35,127 --> 00:16:37,695
And you're also not gonna
come across all those weird,

361
00:16:37,696 --> 00:16:41,834
one-off situations that we
kind of see out in the wild.

362
00:16:41,834 --> 00:16:43,835
But ultimately, I
think the best approach

363
00:16:43,836 --> 00:16:47,039
is to use a combination
of different sets of data

364
00:16:47,039 --> 00:16:50,442
to really make sure that your
tools are working correctly

365
00:16:50,442 --> 00:16:53,846
and that you can really
trust those results.

366
00:16:53,846 --> 00:16:58,617
The next thing is something
called dual tool testing.

367
00:16:58,617 --> 00:17:02,554
In this, we take one tool
that's known and trusted,

368
00:17:02,554 --> 00:17:06,825
and we run that tool, and
then we compare that output

369
00:17:06,825 --> 00:17:11,230
against whatever tool it is
that we're trying to validate.

370
00:17:11,230 --> 00:17:13,799
Eric Zimmerman did
some great testing

371
00:17:13,799 --> 00:17:16,135
recently on ShimCacheParsers.

372
00:17:16,135 --> 00:17:18,470
But what he found out,
and one of the issues

373
00:17:18,470 --> 00:17:20,172
with the dual tool testing is,

374
00:17:20,172 --> 00:17:22,674
you really have to
know that the tool

375
00:17:22,674 --> 00:17:25,944
that you're kind of benchmarking
against is accurate.

376
00:17:25,944 --> 00:17:27,713
He found out that
there were a couple

377
00:17:27,713 --> 00:17:30,616
of ShimCacheParsers out
there, and one was actually

378
00:17:30,616 --> 00:17:32,718
based off of the
code of another.

379
00:17:32,718 --> 00:17:35,320
And both of them
had the same issue.

380
00:17:35,320 --> 00:17:39,992
So even though two, if
compared those two tools,

381
00:17:39,992 --> 00:17:43,861
the output would have been the
same, they were both wrong.

382
00:17:43,862 --> 00:17:46,131
So when you something like
this, you really have to

383
00:17:46,131 --> 00:17:49,034
make sure the tool that
you're testing against

384
00:17:49,034 --> 00:17:50,702
is giving you
accurate information

385
00:17:50,702 --> 00:17:53,105
and that tool has been verified.

386
00:17:54,540 --> 00:17:57,341
The next thing you can do is
actually look at the raw data.

387
00:17:57,342 --> 00:17:59,011
Especially if it's
an artifact that

388
00:17:59,011 --> 00:18:01,346
someone's already done
research on, you can go

389
00:18:01,346 --> 00:18:03,982
and find the white paper
like Mandiant wrote,

390
00:18:03,982 --> 00:18:06,452
a great white paper
on the ShimCache.

391
00:18:06,452 --> 00:18:09,855
Here's an example, again,
of a prefetched file.

392
00:18:09,855 --> 00:18:13,092
So here, you could go
out to the forensic wiki,

393
00:18:13,092 --> 00:18:17,463
you could pull up the structure
of this prefetch file,

394
00:18:17,463 --> 00:18:21,667
and you can actually see
where those file time offsets,

395
00:18:21,667 --> 00:18:23,735
those eight file
times are supposed

396
00:18:23,735 --> 00:18:25,504
to be at in the raw data.

397
00:18:25,504 --> 00:18:29,274
And then you can go in and
you can actually look at that.

398
00:18:29,274 --> 00:18:32,543
So if I have a brand new
program that I want to test

399
00:18:32,544 --> 00:18:35,647
on prefetch files, the way I
would go about doing it, is

400
00:18:35,647 --> 00:18:38,884
I would actually execute
a program eight times,

401
00:18:38,884 --> 00:18:43,889
document what time that I
ran those eight occurrences,

402
00:18:45,224 --> 00:18:46,992
and then you could actually
go in, and you know,

403
00:18:46,992 --> 00:18:48,594
you can go in as far as
you want, you can go in

404
00:18:48,594 --> 00:18:50,295
and manually convert
the time stamps

405
00:18:50,295 --> 00:18:52,297
or you can use an
automated approach.

406
00:18:53,665 --> 00:18:56,401
The other option is
to use a native tool.

407
00:18:56,401 --> 00:19:00,239
When I was doing my research
on the Thunderbird parser,

408
00:19:00,239 --> 00:19:03,509
and I eventually wrote a parser
for the Thunderbird email,

409
00:19:03,509 --> 00:19:06,044
I used the native viewer
to go in and view it,

410
00:19:06,044 --> 00:19:08,313
because I found that my
tools were not consistently

411
00:19:08,313 --> 00:19:11,283
showing me, you know, how
many emails, so I figured,

412
00:19:11,283 --> 00:19:13,017
well, what's the
best way to do it?

413
00:19:13,018 --> 00:19:15,787
I'll open it up in
Thunderbird and see

414
00:19:15,787 --> 00:19:17,723
how many emails it's showing me.

415
00:19:17,723 --> 00:19:20,626
Of course, the
disadvantage to this is

416
00:19:20,626 --> 00:19:23,128
that forensically, there
may be some data there

417
00:19:23,128 --> 00:19:25,097
that a native viewer
isn't going to show you.

418
00:19:25,097 --> 00:19:29,334
You can recover deleted data
from a Thunderbird email

419
00:19:29,334 --> 00:19:34,273
profile, but you're not gonna
see that in the native viewer.

420
00:19:35,440 --> 00:19:38,143
So, each of these
methods kind of

421
00:19:38,143 --> 00:19:42,114
have their advantages
and disadvantages.

422
00:19:42,114 --> 00:19:43,849
Really, I think the best way is

423
00:19:43,849 --> 00:19:47,785
to combine these methods, right?

424
00:19:47,786 --> 00:19:52,791
Don't rely on just one method
to do your verification,

425
00:19:53,926 --> 00:19:56,895
'cause as you see, they
all have weaknesses,

426
00:19:56,895 --> 00:19:58,864
and they all have strengths.

427
00:19:58,864 --> 00:20:02,668
So in order to get the
best, I don't know,

428
00:20:02,668 --> 00:20:05,904
super power here, you need
to combine these methods.

429
00:20:05,904 --> 00:20:07,906
So maybe you test
it with the tool,

430
00:20:07,906 --> 00:20:10,242
you go in and you
look at the raw data.

431
00:20:10,242 --> 00:20:12,077
Or maybe you open
up the native viewer

432
00:20:12,077 --> 00:20:13,712
and go look at the raw data.

433
00:20:13,712 --> 00:20:15,814
So by combining these
different methods,

434
00:20:15,814 --> 00:20:18,250
you get stronger results.

435
00:20:19,718 --> 00:20:24,723
So just some final thoughts:
one, know your artifacts.

436
00:20:26,191 --> 00:20:28,560
Coming to a conference like
this, and listening to talks

437
00:20:28,560 --> 00:20:31,062
like Eric Zimmerman's, where
he goes into the registry

438
00:20:31,063 --> 00:20:33,665
and he explains
the binary format,

439
00:20:33,665 --> 00:20:37,703
knowing your artifacts
will really go a long way.

440
00:20:37,703 --> 00:20:41,173
That way, for instance, when
there's misleading information,

441
00:20:41,173 --> 00:20:42,741
you'll go, you know what?

442
00:20:42,741 --> 00:20:45,777
I remember learning about the
prefetched files of Windows 8,

443
00:20:45,777 --> 00:20:48,480
that there's supposed to
be eight time stamps there.

444
00:20:48,480 --> 00:20:50,816
Ultimately, our
tools are just that:

445
00:20:50,816 --> 00:20:54,686
they're tools for us
to use, not to rely on.

446
00:20:54,686 --> 00:20:56,588
We're the important tool, right?

447
00:20:56,588 --> 00:21:00,492
That's why we're all working
and we all have jobs,

448
00:21:00,492 --> 00:21:03,428
because someone
ultimately needs to take

449
00:21:03,428 --> 00:21:05,831
the information that
the tool is given.

450
00:21:05,831 --> 00:21:08,466
Ultimately, it falls
upon us as examiners.

451
00:21:08,467 --> 00:21:11,136
Do you think in
courts, you know,

452
00:21:11,136 --> 00:21:12,937
that the tool's gonna
get discounted, or,

453
00:21:12,938 --> 00:21:14,473
I guess the tool may, right?

454
00:21:14,473 --> 00:21:17,009
But ultimately it's
up to us as examiners

455
00:21:17,009 --> 00:21:19,077
to vet the results
that we're getting,

456
00:21:19,077 --> 00:21:21,313
to make sure they make
sense, and to make sure

457
00:21:21,313 --> 00:21:23,915
that we're getting
accurate results.

458
00:21:23,915 --> 00:21:26,218
Check the release
notes of the programs

459
00:21:26,218 --> 00:21:27,386
when they get released.

460
00:21:27,386 --> 00:21:29,154
Sometimes they'll
discuss or they'll say,

461
00:21:29,154 --> 00:21:31,657
this bug got fixed in
the previous version.

462
00:21:31,657 --> 00:21:33,692
Or they may mention,
hey, in the next version,

463
00:21:33,692 --> 00:21:36,762
this is what we're gonna
look at addressing.

464
00:21:36,762 --> 00:21:38,429
Check the GitHub for issues.

465
00:21:38,430 --> 00:21:40,232
If you're using
open source code,

466
00:21:40,232 --> 00:21:42,668
go and look at the
issue tracker to see

467
00:21:42,668 --> 00:21:45,704
what bugs people ahead of
you may already have found,

468
00:21:45,704 --> 00:21:49,073
and may have submitted that
just haven't been addressed yet.

469
00:21:49,074 --> 00:21:50,909
That's a really
great way to find out

470
00:21:50,909 --> 00:21:53,845
what may not be working
correctly in the code,

471
00:21:53,845 --> 00:21:55,881
or maybe it's not
supporting that.

472
00:21:55,881 --> 00:21:57,783
I know if someone's
like, there's a

473
00:21:57,783 --> 00:21:59,351
brand new version
of Mozilla out,

474
00:21:59,351 --> 00:22:01,953
if your parser doesn't support
it, they put it on GitHub.

475
00:22:01,953 --> 00:22:04,256
At least that way, before
you start using the tool,

476
00:22:04,256 --> 00:22:07,459
you'll know, okay, it's not
gonna support these things.

477
00:22:07,459 --> 00:22:10,362
And then, if you find
an issue with the tool,

478
00:22:10,362 --> 00:22:12,264
let the developers know.

479
00:22:12,264 --> 00:22:16,168
This is how we can really
grow as a community.

480
00:22:16,168 --> 00:22:19,271
Don't keep in it; share it.

481
00:22:19,271 --> 00:22:21,340
I wanna know when there's
an issue with my tool.

482
00:22:21,340 --> 00:22:23,507
I wanna know when a new
version of Safari comes out,

483
00:22:23,508 --> 00:22:25,410
and my tool doesn't support it.

484
00:22:25,410 --> 00:22:27,746
Let me know, and
I'm sure a lot of

485
00:22:27,746 --> 00:22:29,414
the other people here
feel the same way.

486
00:22:29,414 --> 00:22:32,384
Sometimes, I can't
generate that data,

487
00:22:32,384 --> 00:22:35,120
or that situation that
caused a bug in that program,

488
00:22:35,120 --> 00:22:38,223
because I didn't even
think that that existed.

489
00:22:38,223 --> 00:22:40,926
So let us know and so
that we can fix it.

490
00:22:40,926 --> 00:22:42,894
And then, share
your test results.

491
00:22:42,894 --> 00:22:45,464
When you see an
issue with something,

492
00:22:45,464 --> 00:22:47,366
don't be afraid
to blog about it.

493
00:22:47,366 --> 00:22:50,469
Of course, be gentle, right?

494
00:22:50,469 --> 00:22:53,505
We don't want to shame those
people that are sharing

495
00:22:53,505 --> 00:22:57,008
all their time and their spare
time to write these tools.

496
00:22:57,008 --> 00:22:59,511
But let people in the community
know what you're seeing

497
00:22:59,511 --> 00:23:01,146
and what kind of issues
you're running into,

498
00:23:01,146 --> 00:23:02,681
so they can be
aware of it, until

499
00:23:02,681 --> 00:23:07,686
those issues in these
programs get fixed.

500
00:23:09,054 --> 00:23:12,824
So that's all I have on testing
and validating your tools,

501
00:23:13,792 --> 00:23:15,159
are there any questions?

