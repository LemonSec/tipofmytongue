1
00:00:05,640 --> 00:00:08,880
Well, as I said in the presentation, this

2
00:00:08,880 --> 00:00:11,940
member Leonardo Ernesto currently

3
00:00:11,940 --> 00:00:14,219
worked for me as knowing Security operation

4
00:00:14,219 --> 00:00:17,100
designing in the local company and well,

5
00:00:17,100 --> 00:00:19,619
I have also gone through roles such as in 100

6
00:00:19,619 --> 00:00:23,400
answers Angelina soccer in different

7
00:00:23,400 --> 00:00:25,380
companies

8
00:00:25,380 --> 00:00:29,220
The idea of ​​presenting this talk

9
00:00:29,220 --> 00:00:32,880
arose more than anything  reading

10
00:00:32,880 --> 00:00:35,420
a report from the Times company a few months ago

11
00:00:35,420 --> 00:00:39,739
called the voice of social analyst in which,

12
00:00:39,739 --> 00:00:43,559
based on a survey of some

13
00:00:43,559 --> 00:00:47,100
500,600 security analysts, I think it gave an

14
00:00:47,100 --> 00:00:49,500
overview of what is understood as

15
00:00:49,500 --> 00:00:52,620
relevant skills in

16
00:00:52,620 --> 00:00:55,260
cybersecurity not  as well as

17
00:00:55,260 --> 00:00:57,960
recommendations and conclusions in this

18
00:00:57,960 --> 00:00:59,420
regard

19
00:00:59,420 --> 00:01:03,080
and one of these points concluded

20
00:01:03,080 --> 00:01:05,900
that coding In other words, programming

21
00:01:05,900 --> 00:01:08,640
was among the top skills

22
00:01:08,640 --> 00:01:11,760
necessary to succeed as an

23
00:01:11,760 --> 00:01:14,520
analyst personally I don't know if the

24
00:01:14,520 --> 00:01:16,740
correct word is succeed No, I

25
00:01:16,740 --> 00:01:19,979
think it's too pretentious  by the

26
00:01:19,979 --> 00:01:22,140
number of specializations within

27
00:01:22,140 --> 00:01:24,060
what we call cybersecurity p  But it

28
00:01:24,060 --> 00:01:26,520
could be said that it is a skill

29
00:01:26,520 --> 00:01:28,740
which helps us in the execution of

30
00:01:28,740 --> 00:01:32,720
certain tasks like this

31
00:01:32,720 --> 00:01:36,119
security professionals at the end

32
00:01:36,119 --> 00:01:39,000
of the talk I am going to give you the link of the

33
00:01:39,000 --> 00:01:41,520
report in case you are interested

34
00:01:41,520 --> 00:01:45,000
so well without further ado this preamble I will

35
00:01:45,000 --> 00:01:48,380


36
00:01:48,380 --> 00:01:51,000


37
00:01:51,000 --> 00:01:55,560


38
00:01:55,560 --> 00:01:58,140


39
00:01:58,140 --> 00:02:00,479
Let me tell you about some methods that we could use to detect threats based on the enrichment and correlation of the data using, in this case, Google collapse, also trying,

40
00:02:00,479 --> 00:02:02,579
well, not to explain it in a

41
00:02:02,579 --> 00:02:05,159
simpler way for those who are perhaps just

42
00:02:05,159 --> 00:02:08,479
new to this area.

43
00:02:08,479 --> 00:02:12,000
As I was saying, this talk

44
00:02:12,000 --> 00:02:14,360
aims to introduce you to a solution

45
00:02:14,360 --> 00:02:18,720
that is practical and effective, not when it

46
00:02:18,720 --> 00:02:20,120
comes to investigating and detecting

47
00:02:20,120 --> 00:02:22,400
potential threats,

48
00:02:22,400 --> 00:02:24,780
always through the use of these

49
00:02:24,780 --> 00:02:26,940
notebooks.

50
00:02:26,940 --> 00:02:30,420


51
00:02:30,420 --> 00:02:32,760
they used it

52
00:02:32,760 --> 00:02:35,459
Well I hope that from this talk you

53
00:02:35,459 --> 00:02:38,099
consider giving it a look

54
00:02:38,099 --> 00:02:40,620
or the meeting in an appr end  opiated not

55
00:02:40,620 --> 00:02:44,580
for their use cases what I am going to

56
00:02:44,580 --> 00:02:47,700
show you is a scenario where a

57
00:02:47,700 --> 00:02:50,760
site receives constant and successful

58
00:02:50,760 --> 00:02:53,819
free voice attempts and how they can

59
00:02:53,819 --> 00:02:56,400
How can Google use this as

60
00:02:56,400 --> 00:02:59,879
a complementary tool not

61
00:02:59,879 --> 00:03:01,920
only for event enrichment

62
00:03:01,920 --> 00:03:04,680
but through  this data enrichment to be

63
00:03:04,680 --> 00:03:08,420
able to detect And why not

64
00:03:08,420 --> 00:03:10,440
mitigate different indicators of

65
00:03:10,440 --> 00:03:12,780
compromise and we are going to be seeing

66
00:03:12,780 --> 00:03:14,840
first an introduction to Google colab

67
00:03:14,840 --> 00:03:18,300
the basic concepts not for what we are going

68
00:03:18,300 --> 00:03:20,900
to use the use case in particular

69
00:03:20,900 --> 00:03:23,239
the

70
00:03:23,239 --> 00:03:26,700
process methodology and well Then we are going to  see a

71
00:03:26,700 --> 00:03:30,239
Step by Step this this of how we obtain

72
00:03:30,239 --> 00:03:32,760
the data sources where we

73
00:03:32,760 --> 00:03:34,739
take it and store it How we create

74
00:03:34,739 --> 00:03:36,659
some Data frames that are the objects

75
00:03:36,659 --> 00:03:38,099
within

76
00:03:38,099 --> 00:03:40,980
the last day our

77
00:03:40,980 --> 00:03:43,980
pandas python library we are going to do just the

78
00:03:43,980 --> 00:03:46,080
obtaining by geolocation the

79
00:03:46,080 --> 00:03:47,780
enrichment  from different

80
00:03:47,780 --> 00:03:51,180
apis and good from that the

81
00:03:51,180 --> 00:03:53,459
unification of the results and Good  or

82
00:03:53,459 --> 00:03:56,760
I'm going to show you how to graph some

83
00:03:56,760 --> 00:03:59,700
examples of graphs more than anything else this and

84
00:03:59,700 --> 00:04:02,400
then well present the complete analytics

85
00:04:02,400 --> 00:04:04,700


86
00:04:08,959 --> 00:04:10,640
well

87
00:04:10,640 --> 00:04:13,500
first and before talking about the

88
00:04:13,500 --> 00:04:17,779
platform What do we call a Notebook not

89
00:04:17,779 --> 00:04:20,220
in broad strokes let's say that a Notebook

90
00:04:20,220 --> 00:04:23,000
is like a document that combines text

91
00:04:23,000 --> 00:04:25,639
execution code, that is, source code

92
00:04:25,639 --> 00:04:29,699
and graphics all in one, in this

93
00:04:29,699 --> 00:04:31,860
way it is easier for us Not only to

94
00:04:31,860 --> 00:04:34,880
describe a problem but also to be able to

95
00:04:34,880 --> 00:04:37,340
program the code that solves it, to

96
00:04:37,340 --> 00:04:40,740
execute it and also Show the result

97
00:04:40,740 --> 00:04:43,560
obtained as a table, a graph,

98
00:04:43,560 --> 00:04:46,639
any

99
00:04:48,419 --> 00:04:51,620
other possible  possible result

100
00:04:51,620 --> 00:04:55,259
Google colab provides us with just that,

101
00:04:55,259 --> 00:04:57,600
not being able to use these notebooks

102
00:04:57,600 --> 00:04:59,400
from the cloud has pre-installed a

103
00:04:59,400 --> 00:05:02,580
variety of already exclusive

104
00:05:02,580 --> 00:05:04,620


105
00:05:04,620 --> 00:05:08,820


106
00:05:08,820 --> 00:05:11,220
libraries for data processing.  at

107
00:05:11,220 --> 00:05:13,699
least up to a certain limit

108
00:05:13,699 --> 00:05:17,100
I chose queue since well firstly it

109
00:05:17,100 --> 00:05:19,560
allows to have from an ent  Orno to

110
00:05:19,560 --> 00:05:22,560
carry out tasks

111
00:05:22,560 --> 00:05:25,620
that would rather be somewhat

112
00:05:25,620 --> 00:05:27,840
more complex to perform on a personal computer,

113
00:05:27,840 --> 00:05:30,539
and added to this, it gives us the

114
00:05:30,539 --> 00:05:32,520
possibility of sharing the

115
00:05:32,520 --> 00:05:34,740
source code, which is not ideal

116
00:05:34,740 --> 00:05:37,740
for teamwork or group work.  Through an

117
00:05:37,740 --> 00:05:39,240
investigation of a particular incident,

118
00:05:39,240 --> 00:05:41,300


119
00:05:48,419 --> 00:05:50,240
well,

120
00:05:50,240 --> 00:05:52,919
in this process, use python as the language as I told you,

121
00:05:52,919 --> 00:05:55,460
since it is

122
00:05:55,460 --> 00:05:57,840
probably one of the

123
00:05:57,840 --> 00:05:59,039
most used languages ​​for

124
00:05:59,039 --> 00:06:01,979
data processing. Also, it is

125
00:06:01,979 --> 00:06:03,900
the default language used

126
00:06:03,900 --> 00:06:07,080
by Google colab. We are going to  use a

127
00:06:07,080 --> 00:06:08,940
library called pandas, which is the

128
00:06:08,940 --> 00:06:11,880
library almost par excellence for

129
00:06:11,880 --> 00:06:13,380
data processing and analysis.

130
00:06:13,380 --> 00:06:17,580
This Panda provides us with the Data frame class,

131
00:06:17,580 --> 00:06:20,639
which is an object that will allow us to

132
00:06:20,639 --> 00:06:24,780
store the data,

133
00:06:24,780 --> 00:06:27,020
rather it will not work for us.  to allow

134
00:06:27,020 --> 00:06:29,699
storing data any data that we have

135
00:06:29,699 --> 00:06:32,699
within a source to an object similar

136
00:06:32,699 --> 00:06:34,620
to a database table which,

137
00:06:34,620 --> 00:06:35,940
well, also has  different

138
00:06:35,940 --> 00:06:40,460
properties this for its use

139
00:06:41,699 --> 00:06:45,180
going well as I told you our

140
00:06:45,180 --> 00:06:47,479
main

141
00:06:47,880 --> 00:06:50,840
point of pain is the so-called scrapping

142
00:06:50,840 --> 00:06:53,580
mainly in these two stages that

143
00:06:53,580 --> 00:06:56,460
are seeing why

144
00:06:56,460 --> 00:06:58,680
in this case of use to generate a

145
00:06:58,680 --> 00:07:00,479
quote within the site first

146
00:07:00,479 --> 00:07:03,600
a user must register with an

147
00:07:03,600 --> 00:07:05,639
email  to be able to Access the

148
00:07:05,639 --> 00:07:08,600
online quote system but many times

149
00:07:08,600 --> 00:07:10,620
probably using some type of

150
00:07:10,620 --> 00:07:16,880
Vote this x Users considered valid access the site

151
00:07:16,880 --> 00:07:19,740
precisely to

152
00:07:19,740 --> 00:07:22,080
obtain data from the catalog but when

153
00:07:22,080 --> 00:07:24,360
accessing indiscriminate wood they generate

154
00:07:24,360 --> 00:07:27,539
substantial traffic many times even

155
00:07:27,539 --> 00:07:30,860
undesirable on our web platform

156
00:07:30,860 --> 00:07:33,860
companies often

157
00:07:33,860 --> 00:07:36,180
underestimate the potential risk of an

158
00:07:36,180 --> 00:07:38,060
escaped egg Not because let's say

159
00:07:38,060 --> 00:07:41,400
technically it's not an intrusion attempt

160
00:07:41,400 --> 00:07:42,479


161
00:07:42,479 --> 00:07:45,840
or a security breach it's

162
00:07:45,840 --> 00:07:48,419
just a method of obtaining and gathering

163
00:07:48,419 --> 00:07:52,099
information about a site

164
00:07:52,099 --> 00:07:54,419
this practice itself Yes in most cases

165
00:07:54,419 --> 00:07:58,080
countries neither  It is illegal but it could

166
00:07:58,080 --> 00:08:00,000
become illegal if

167
00:08:00,000 --> 00:08:00,919


168
00:08:00,919 --> 00:08:04,319
copyright or intellectual property rights are violated through this practice

169
00:08:04,319 --> 00:08:06,360
or precisely not to

170
00:08:06,360 --> 00:08:08,699
carry out some type of

171
00:08:08,699 --> 00:08:11,580
unfair competition and it is worth clarifying that

172
00:08:11,580 --> 00:08:12,680
many times to

173
00:08:12,680 --> 00:08:15,120
detect or escape It is not easy

174
00:08:15,120 --> 00:08:18,680
but we can always use it  Certain

175
00:08:18,680 --> 00:08:21,660
unusual behaviors within the

176
00:08:21,660 --> 00:08:23,580
platform, such as the amount of wealth on

177
00:08:23,580 --> 00:08:27,660
pages, types of userations and malicious fish,

178
00:08:27,660 --> 00:08:29,580
and suspicious countries of origin,

179
00:08:29,580 --> 00:08:30,840


180
00:08:30,840 --> 00:08:33,479
among others, do not exist until cases in

181
00:08:33,479 --> 00:08:36,799
which, through excessive and persistent web scrapping,

182
00:08:36,799 --> 00:08:41,099
they can

183
00:08:41,099 --> 00:08:44,580
not even emulate an attack from God.  at

184
00:08:44,580 --> 00:08:47,519
the application level Obviously, if there was

185
00:08:47,519 --> 00:08:49,459
no conscious development and maintenance

186
00:08:49,459 --> 00:08:53,180
of the site,

187
00:08:55,019 --> 00:08:58,500
well, then our methodology for

188
00:08:58,500 --> 00:09:01,500
the detection of these cases is

189
00:09:01,500 --> 00:09:04,440
designed as follows:

190
00:09:04,440 --> 00:09:06,899
the first phase, the load, that is, the

191
00:09:06,899 --> 00:09:09,360
transfer of one or more

192
00:09:09,360 --> 00:09:12,420
data sources to an environment  development for

193
00:09:12,420 --> 00:09:14,420
processing

194
00:09:14,420 --> 00:09:17,459
these data sources could be b

195
00:09:17,459 --> 00:09:21,440
data aces files and Excel

196
00:09:21,440 --> 00:09:25,260
whatever as well as then there are the

197
00:09:25,260 --> 00:09:27,060
online services the apis with

198
00:09:27,060 --> 00:09:29,100
information on known or

199
00:09:29,100 --> 00:09:30,779
reported threats these are the so-called

200
00:09:30,779 --> 00:09:33,660
threat intelligence services the

201
00:09:33,660 --> 00:09:34,800
second phase will be the

202
00:09:34,800 --> 00:09:37,200
restructuring as you can see or the

203
00:09:37,200 --> 00:09:38,760
transformation towards a

204
00:09:38,760 --> 00:09:40,620
friendlier data structure

205
00:09:40,620 --> 00:09:43,080
in our case of the so-called

206
00:09:43,080 --> 00:09:45,899
Data frames to then somehow leave

207
00:09:45,899 --> 00:09:48,060
all this data prepared for

208
00:09:48,060 --> 00:09:50,779
the analysis and detection process

209
00:09:50,779 --> 00:09:53,160
the third good and last

210
00:09:53,160 --> 00:09:55,440
phase is the detection That is, the

211
00:09:55,440 --> 00:09:58,740
identification of potential

212
00:09:58,740 --> 00:10:01,380
threats based on  the results obtained

213
00:10:01,380 --> 00:10:03,360
from the correlation of all these

214
00:10:03,360 --> 00:10:06,180
Data frames were prepared

215
00:10:06,180 --> 00:10:08,160
previously,

216
00:10:08,160 --> 00:10:11,160
something that I forgot, as you can see

217
00:10:11,160 --> 00:10:13,080
in phase 2, there are different

218
00:10:13,080 --> 00:10:15,240
platform alternatives to

219
00:10:15,240 --> 00:10:18,260
carry out the ones that I have just written

220
00:10:18,260 --> 00:10:21,380
in our case, we will be using

221
00:10:21,380 --> 00:10:25,740
as I told you  welcolab for a reason

222
00:10:25,740 --> 00:10:27,060
which well we will be seeing at the end

223
00:10:27,060 --> 00:10:29,420
of  e presentation but

224
00:10:29,420 --> 00:10:32,580
currently there are other

225
00:10:32,580 --> 00:10:34,440
Cloud type options so that they know of their

226
00:10:34,440 --> 00:10:37,080
existence and Well then it will depend on the

227
00:10:37,080 --> 00:10:40,620
taste of each one with which to get more and

228
00:10:40,620 --> 00:10:43,040
better use of the whole process

229
00:10:43,040 --> 00:10:47,220
here for example including tamaritz

230
00:10:47,220 --> 00:10:48,720
which good allows you to use languages

231
00:10:48,720 --> 00:10:51,680
like sql  java scale i think up to r

232
00:10:51,680 --> 00:10:55,560
besides python there is not also jupiter

233
00:10:55,560 --> 00:10:57,720
notebooks these can also be

234
00:10:57,720 --> 00:11:00,060
implemented in prime and accessed

235
00:11:00,060 --> 00:11:02,240
through the browser without problems

236
00:11:02,240 --> 00:11:03,920
we have

237
00:11:03,920 --> 00:11:10,459
deep note and nas also these are

238
00:11:10,760 --> 00:11:13,920
more basically new states they

239
00:11:13,920 --> 00:11:16,320
also use python as a language and a

240
00:11:16,320 --> 00:11:19,680
feature of nas  What is one of the ones

241
00:11:19,680 --> 00:11:20,880
that I liked the most is that it not only works

242
00:11:20,880 --> 00:11:23,519
internally through Jupiter but

243
00:11:23,519 --> 00:11:26,399
also allows you to clone or schedule the

244
00:11:26,399 --> 00:11:28,860
execution of your nodes without the need

245
00:11:28,860 --> 00:11:31,279
for an apache arflow or any other

246
00:11:31,279 --> 00:11:35,579
automation tool and another

247
00:11:35,579 --> 00:11:37,560
that is not specified in this slide

248
00:11:37,560 --> 00:11:41,040
it's the Amazon platform it's called if

249
00:11:41,040 --> 00:11:42,120
I'm not mistaken

250
00:11:42,120 --> 00:11:43,200
stage Maker

251
00:11:43,200 --> 00:11:44,540
Studio  lab

252
00:11:44,540 --> 00:11:47,040
for this last reality Well, being,

253
00:11:47,040 --> 00:11:49,640
let's say, a recent version requires

254
00:11:49,640 --> 00:11:52,079
signing up for a list and waiting

255
00:11:52,079 --> 00:11:54,899
for approval to be able to use it and Well,

256
00:11:54,899 --> 00:11:56,399
I think it also works with Jupiter

257
00:11:56,399 --> 00:11:57,660
notebooks But well, it's

258
00:11:57,660 --> 00:12:00,240
also worth taking a look at it like this if you

259
00:12:00,240 --> 00:12:02,480
want it

260
00:12:03,000 --> 00:12:04,880
well

261
00:12:04,880 --> 00:12:07,620
here the main ones  components for

262
00:12:07,620 --> 00:12:11,399
our case consists of first a

263
00:12:11,399 --> 00:12:13,560
database table with information about

264
00:12:13,560 --> 00:12:15,240
users who constantly register on the site

265
00:12:15,240 --> 00:12:18,060
and good other

266
00:12:18,060 --> 00:12:20,940
external sources as I had told them no file

267
00:12:20,940 --> 00:12:23,339
if it is bistatic with the detail of

268
00:12:23,339 --> 00:12:26,220
branches of the ISO code company

269
00:12:26,220 --> 00:12:28,260
countries, etc. That is information

270
00:12:28,260 --> 00:12:30,540
that the company has per se for

271
00:12:30,540 --> 00:12:33,660
different validations and

272
00:12:33,660 --> 00:12:36,140
we also use a database from the company

273
00:12:36,140 --> 00:12:39,839
Matchmind called geolitos, which

274
00:12:39,839 --> 00:12:41,820
is good. It is precisely the

275
00:12:41,820 --> 00:12:45,600
IP geolocation database. This is

276
00:12:45,600 --> 00:12:47,600
free,

277
00:12:47,600 --> 00:12:49,680
with this same database we  It will allow

278
00:12:49,680 --> 00:12:54,440
obtaining data such as latitude, longitude, country,

279
00:12:54,440 --> 00:12:57,899
city or region from as  I was

280
00:12:57,899 --> 00:13:00,120
telling you an IP address, the Lite version

281
00:13:00,120 --> 00:13:02,180
works with

282
00:13:02,180 --> 00:13:04,100
version 4 IP addresses,

283
00:13:04,100 --> 00:13:06,899
obviously the pay also works

284
00:13:06,899 --> 00:13:09,959
with versions 6, however, if

285
00:13:09,959 --> 00:13:12,120
we also need geolocation

286
00:13:12,120 --> 00:13:14,880
from these version 6 IPs,

287
00:13:14,880 --> 00:13:18,260
there is another service, various services,

288
00:13:18,260 --> 00:13:20,639
Apps that allow us to obtain the same

289
00:13:20,639 --> 00:13:23,279
information if I'm not mistaken one is

290
00:13:23,279 --> 00:13:26,459
called hay piso location.io then later

291
00:13:26,459 --> 00:13:28,920
I'll give you this link that if I'm not

292
00:13:28,920 --> 00:13:32,480
mistaken allows up to a thousand memories

293
00:13:32,480 --> 00:13:35,660
per day

294
00:13:35,700 --> 00:13:38,480
well

295
00:13:39,120 --> 00:13:40,279
Ok

296
00:13:40,279 --> 00:13:43,019
for this example we are going to use two

297
00:13:43,019 --> 00:13:45,180
free services that are also well

298
00:13:45,180 --> 00:13:47,579
known in what is intelligence  of

299
00:13:47,579 --> 00:13:51,240
threats one came out in bolt or tiex and the

300
00:13:51,240 --> 00:13:52,700
other Silva

301
00:13:52,700 --> 00:13:56,779
someone voltios offers

302
00:13:56,779 --> 00:14:00,540
open access to a global group

303
00:14:00,540 --> 00:14:03,000
of security professionals and provides

304
00:14:03,000 --> 00:14:05,579
data on different threats already

305
00:14:05,579 --> 00:14:09,540
reported by this community this

306
00:14:09,540 --> 00:14:13,320
service alerts us in the form of something

307
00:14:13,320 --> 00:14:16,440
they call pulses or  you press which are

308
00:14:16,440 --> 00:14:18,899
the format in which the community shares

309
00:14:18,899 --> 00:14:20,399
this information

310
00:14:20,399 --> 00:14:22,440
these courses  also good they provide

311
00:14:22,440 --> 00:14:25,200
a summary of the threat with their

312
00:14:25,200 --> 00:14:26,940
respective indicators of compromise

313
00:14:26,940 --> 00:14:29,339
good these indicators can be

314
00:14:29,339 --> 00:14:32,519
just not IP addresses

315
00:14:32,519 --> 00:14:34,980
domain names hatcher files even

316
00:14:34,980 --> 00:14:38,940
civil code of vulnerabilities and then

317
00:14:38,940 --> 00:14:41,519
we have IVA IVA is also

318
00:14:41,519 --> 00:14:43,519
free

319
00:14:43,519 --> 00:14:47,220
unapi which analyzes and validates email addresses  It is

320
00:14:47,220 --> 00:14:50,760
very similar to a sirobans call that

321
00:14:50,760 --> 00:14:53,339
just verifies and analyzes if the

322
00:14:53,339 --> 00:14:55,500
mail is valid if the mail is

323
00:14:55,500 --> 00:14:58,740
temporary or if the mail itself is

324
00:14:58,740 --> 00:15:03,079
deliverable among other functions

325
00:15:06,199 --> 00:15:10,399
well Let's start then with phase 1

326
00:15:10,399 --> 00:15:14,519
as the first step of the database and

327
00:15:14,519 --> 00:15:16,500
files  csb we are going to generate different

328
00:15:16,500 --> 00:15:18,899
Data frames to be able to

329
00:15:18,899 --> 00:15:20,940
not only segment the source information in some way,

330
00:15:20,940 --> 00:15:25,079
but then to be able or allow

331
00:15:25,079 --> 00:15:28,079
Better said, to relate it to each other, here

332
00:15:28,079 --> 00:15:30,300
we see the Data frame, I am naming them

333
00:15:30,300 --> 00:15:33,000
according to the data that each one has,

334
00:15:33,000 --> 00:15:35,699
we do not have  the Data frame 10 with Data

335
00:15:35,699 --> 00:15:37,620
with the records from the

336
00:15:37,620 --> 00:15:40,079
database the Data frame of  offices

337
00:15:40,079 --> 00:15:43,740
with details of the branches and a Data

338
00:15:43,740 --> 00:15:46,440
frame with the world codes and

339
00:15:46,440 --> 00:15:49,399
country names to also use

340
00:15:49,399 --> 00:15:53,000
use later

341
00:15:53,000 --> 00:15:56,519
well later to play continue with the

342
00:15:56,519 --> 00:15:59,040
processing we must first

343
00:15:59,040 --> 00:16:02,519
eliminate from our Data frame all the

344
00:16:02,519 --> 00:16:03,899
duplicate IPs and email addresses

345
00:16:03,899 --> 00:16:06,060
so that

346
00:16:06,060 --> 00:16:09,779
from these enrich the

347
00:16:09,779 --> 00:16:11,279
other Data frames by using the

348
00:16:11,279 --> 00:16:13,440
Api services that we saw

349
00:16:13,440 --> 00:16:15,420
previously for this reason we generate

350
00:16:15,420 --> 00:16:18,060
two lists with unique values ​​of ips and

351
00:16:18,060 --> 00:16:20,660
another with unique values ​​of emails

352
00:16:20,660 --> 00:16:23,220
using the python set function

353
00:16:23,220 --> 00:16:25,500
we obtain these unique values ​​since

354
00:16:25,500 --> 00:16:28,079
Well, this function just

355
00:16:28,079 --> 00:16:33,360
truncates the systems with the same value

356
00:16:33,360 --> 00:16:35,100
because they are duplicated,

357
00:16:35,100 --> 00:16:36,660
we are precisely obtaining information

358
00:16:36,660 --> 00:16:38,940
about the registration within a database

359
00:16:38,940 --> 00:16:39,560


360
00:16:39,560 --> 00:16:43,320
of certain ips a user or certain

361
00:16:43,320 --> 00:16:45,000
users a user Generally does not

362
00:16:45,000 --> 00:16:47,519
access only once in the whole day or in

363
00:16:47,519 --> 00:16:49,199
two hours a user can be

364
00:16:49,199 --> 00:16:52,440
accessing thousands of times if it is for a

365
00:16:52,440 --> 00:16:54,839
B  ot or

366
00:16:54,839 --> 00:16:57,839
4 or 5 times a day for that reason the

367
00:16:57,839 --> 00:16:58,920
ips the email addresses

368
00:16:58,920 --> 00:17:01,019
Generally they tend to be duplicated

369
00:17:01,019 --> 00:17:04,099
obviously we have the

370
00:17:04,099 --> 00:17:06,540
timestamp index to be able to differentiate them somehow we

371
00:17:06,540 --> 00:17:09,438


372
00:17:10,339 --> 00:17:12,020
continue

373
00:17:12,020 --> 00:17:13,640
well

374
00:17:13,640 --> 00:17:18,079
Now that we have the list with

375
00:17:18,079 --> 00:17:21,959
unique IP values ​​we generate the so-called el

376
00:17:21,959 --> 00:17:24,359
python, which is nothing more than a

377
00:17:24,359 --> 00:17:26,220
functionality that does not allow us to create

378
00:17:26,220 --> 00:17:29,340
lists in the same line of code, what

379
00:17:29,340 --> 00:17:30,840
we do is to simplify the syntax,

380
00:17:30,840 --> 00:17:34,080
actually in broad strokes,

381
00:17:34,080 --> 00:17:37,559
we call the get Geo Data function

382
00:17:37,559 --> 00:17:40,320
to obtain the geolocation

383
00:17:40,320 --> 00:17:42,900
for each of  the ips at the same time that

384
00:17:42,900 --> 00:17:45,840
we define the forum this will generate

385
00:17:45,840 --> 00:17:48,539
a new Data frame called y fgo y

386
00:17:48,539 --> 00:17:52,260
pedata with the detail of the geoletration

387
00:17:52,260 --> 00:17:54,480
of carip the detail I refer to all

388
00:17:54,480 --> 00:17:56,700
the other Fields that we are now going to

389
00:17:56,700 --> 00:17:59,280
enrich from this one  this

390
00:17:59,280 --> 00:18:02,480
IP address

391
00:18:02,480 --> 00:18:04,679
we carry out the same procedure but

392
00:18:04,679 --> 00:18:07,200
now calling the function that te

393
00:18:07,200 --> 00:18:10,080
indicator to obtain

394
00:18:10,080 --> 00:18:12,480
threat information from No from someone  in volt

395
00:18:12,480 --> 00:18:16,080
again another Data frame

396
00:18:16,080 --> 00:18:19,140
called 10 otx is generated with the findings

397
00:18:19,140 --> 00:18:24,260
obtained for for each IP

398
00:18:25,799 --> 00:18:29,340
and here we are calling the check

399
00:18:29,340 --> 00:18:32,820
VAT function to obtain information about the

400
00:18:32,820 --> 00:18:35,280
email addresses using its

401
00:18:35,280 --> 00:18:38,460
API service same method we generate

402
00:18:38,460 --> 00:18:41,039
platform called 10 viva with the

403
00:18:41,039 --> 00:18:42,960
findings obtained for each

404
00:18:42,960 --> 00:18:45,200
email address

405
00:18:45,200 --> 00:18:48,860
here when it comes to making

406
00:18:48,860 --> 00:18:51,679
requests in this case massive

407
00:18:51,679 --> 00:18:54,960
obviously there are libraries in python

408
00:18:54,960 --> 00:18:56,660
Like

409
00:18:56,660 --> 00:18:58,880
this

410
00:18:58,880 --> 00:19:01,919
little guy if I'm not mistaken what they

411
00:19:01,919 --> 00:19:04,260
provide this type of functionality

412
00:19:04,260 --> 00:19:06,240
not what they do is allow

413
00:19:06,240 --> 00:19:09,179
asynchronous calls to API services

414
00:19:09,179 --> 00:19:11,039
obviously increasing  the response speed

415
00:19:11,039 --> 00:19:12,419


416
00:19:12,419 --> 00:19:15,179
with this mechanism an asynchronous code

417
00:19:15,179 --> 00:19:17,419
facilitates the

418
00:19:17,419 --> 00:19:20,880
as they say the concurrent execution

419
00:19:20,880 --> 00:19:23,640
to actually see the asynchronous code gives

420
00:19:23,640 --> 00:19:26,039
the appearance of concurrency that is, the

421
00:19:26,039 --> 00:19:28,260
code somehow waits for the

422
00:19:28,260 --> 00:19:30,900
result allowing other code to be

423
00:19:30,900 --> 00:19:33,120
executed in the background So  to make

424
00:19:33,120 --> 00:19:34,799
a request to 5 hours  would be the most

425
00:19:34,799 --> 00:19:37,020
appropriate because Well we can

426
00:19:37,020 --> 00:19:39,299
let the event loop work with

427
00:19:39,299 --> 00:19:41,700
other tasks instead of Blocking the

428
00:19:41,700 --> 00:19:44,700
entire thread while we wait for a

429
00:19:44,700 --> 00:19:47,039
response obviously in productive environments it

430
00:19:47,039 --> 00:19:51,419
is the ideal to implement

431
00:19:51,419 --> 00:19:54,480
now We are in phase 2 of this entire

432
00:19:54,480 --> 00:19:56,460
process that  it is precisely the

433
00:19:56,460 --> 00:19:57,559
restructuring

434
00:19:57,559 --> 00:20:00,720
in pandas there is the merge method with

435
00:20:00,720 --> 00:20:01,760
which you can

436
00:20:01,760 --> 00:20:05,220
combine or dream data from two

437
00:20:05,220 --> 00:20:08,820
Data frame objects in a simple way this method

438
00:20:08,820 --> 00:20:11,059
requires two parameters to be passed to it,

439
00:20:11,059 --> 00:20:14,400
that is, the Data frames and

440
00:20:14,400 --> 00:20:16,039
the fields that we use to be able to

441
00:20:16,039 --> 00:20:19,500
shore them or  combine them in this case of

442
00:20:19,500 --> 00:20:21,980
the Data frame 10 with the Data field

443
00:20:21,980 --> 00:20:25,080
and on the side of the 10th floor countries the

444
00:20:25,080 --> 00:20:29,160
ISO 2 field we only do this

445
00:20:29,160 --> 00:20:30,860
to

446
00:20:30,860 --> 00:20:33,480
add the field to our main Data frame

447
00:20:33,480 --> 00:20:36,660
made with trading

448
00:20:36,660 --> 00:20:38,460
that corresponds to each of the

449
00:20:38,460 --> 00:20:40,980
records and  then we will see why this is

450
00:20:40,980 --> 00:20:45,120
for what or we are not obtaining it in

451
00:20:45,120 --> 00:20:47,039
this way

452
00:20:47,039 --> 00:20:48,960
in the same way we combine here

453
00:20:48,960 --> 00:20:51,360
again not the Data frame  e 10 with Data

454
00:20:51,360 --> 00:20:52,919
with dilation resulting from someone

455
00:20:52,919 --> 00:20:55,799
volt And so we will enrich the

456
00:20:55,799 --> 00:20:58,200
main one with all the others with all

457
00:20:58,200 --> 00:21:01,440
the other findings we

458
00:21:02,100 --> 00:21:03,960
also combine the data from the

459
00:21:03,960 --> 00:21:05,299
VAT Data frame

460
00:21:05,299 --> 00:21:07,679
obtained from the email addresses

461
00:21:07,679 --> 00:21:10,340


462
00:21:11,360 --> 00:21:13,880
and up to here we have

463
00:21:13,880 --> 00:21:17,160
enriched the Daphne of would be

464
00:21:17,160 --> 00:21:19,260
User connections, no data

465
00:21:19,260 --> 00:21:22,320
obtained from files, as if it were

466
00:21:22,320 --> 00:21:25,280
the geolocation and services base,

467
00:21:25,280 --> 00:21:27,320
now

468
00:21:27,320 --> 00:21:30,000
talking in more detail later with the

469
00:21:30,000 --> 00:21:32,520
business area, at one point they told us

470
00:21:32,520 --> 00:21:34,020
that

471
00:21:34,020 --> 00:21:37,140
events that they consider to

472
00:21:37,140 --> 00:21:39,299
be Non-

473
00:21:39,299 --> 00:21:41,400
server should also be taken into account.  a case is completed in a service,

474
00:21:41,400 --> 00:21:43,039
for

475
00:21:43,039 --> 00:21:45,840
example, a periodic contribution of

476
00:21:45,840 --> 00:21:50,159
a user x was made for which through

477
00:21:50,159 --> 00:21:52,500
our geolocation by IP said

478
00:21:52,500 --> 00:21:54,780
user appears to us located outside the

479
00:21:54,780 --> 00:21:58,020
coverage area east of one

480
00:21:58,020 --> 00:22:00,419
of the company's branches or itself  It

481
00:22:00,419 --> 00:22:02,159
appears to us that the user is directly in another country,

482
00:22:02,159 --> 00:22:04,559
so as on our

483
00:22:04,559 --> 00:22:07,020
side we already have available the

484
00:22:07,020 --> 00:22:09,120
location by IP, that is, latitude and

485
00:22:09,120 --> 00:22:11,400
longitude, as well as the Data frame of

486
00:22:11,400 --> 00:22:14,520
branches created, if I am not mistaken in

487
00:22:14,520 --> 00:22:17,039
the steps, in the first steps we can

488
00:22:17,039 --> 00:22:19,280
identify perhaps

489
00:22:19,280 --> 00:22:22,440
anomalous or suspicious events by comparing

490
00:22:22,440 --> 00:22:24,380
latitude and longitude of the free source

491
00:22:24,380 --> 00:22:27,480
against the attitude of longitude that

492
00:22:27,480 --> 00:22:29,340
Data fragment branches

493
00:22:29,340 --> 00:22:32,400
how we do this by calculating the

494
00:22:32,400 --> 00:22:35,159
distance between two points precisely the

495
00:22:35,159 --> 00:22:37,320
haversine python library that also

496
00:22:37,320 --> 00:22:39,780
exists precisely the formula allows us to

497
00:22:39,780 --> 00:22:42,000
obtain this distance in kilometers in

498
00:22:42,000 --> 00:22:43,440
miles according to what they need

499
00:22:43,440 --> 00:22:47,520
then only in our case we will have to

500
00:22:47,520 --> 00:22:49,220
identify the  value

501
00:22:49,220 --> 00:22:52,500
with less distance and add it to our

502
00:22:52,500 --> 00:22:54,260
record

503
00:22:54,260 --> 00:22:57,900
one thing that should be clarified that the calculation

504
00:22:57,900 --> 00:23:00,659
of these two points is carried out in a

505
00:23:00,659 --> 00:23:02,760
straight line which obviously will give us

506
00:23:02,760 --> 00:23:05,280
an approximate idea says it is an

507
00:23:05,280 --> 00:23:08,240
anomalous event or not to be seen because

508
00:23:08,240 --> 00:23:11,340
Let's say yes  they are coming out obtained

509
00:23:11,340 --> 00:23:14,880
between an IP an IP origin and a branch

510
00:23:14,880 --> 00:23:16,740
exceeds let's say

511
00:23:16,740 --> 00:23:19,320
and in kilometers  s is clearly an

512
00:23:19,320 --> 00:23:21,059
event which we need to validate more in

513
00:23:21,059 --> 00:23:22,919
depth and it can be considered

514
00:23:22,919 --> 00:23:25,440
anomalous on a television

515
00:23:25,440 --> 00:23:28,919
so here we then call the

516
00:23:28,919 --> 00:23:30,919
get Office function

517
00:23:30,919 --> 00:23:33,600
to obtain said distance and

518
00:23:33,600 --> 00:23:35,360
obviously

519
00:23:35,360 --> 00:23:37,919
we repeat we do not add the result to

520
00:23:37,919 --> 00:23:42,200
our to our main Data frame

521
00:23:43,860 --> 00:23:46,520
pass me

522
00:23:50,220 --> 00:23:52,380
well

523
00:23:52,380 --> 00:23:54,419
here optionally we can also

524
00:23:54,419 --> 00:23:57,659
filter by a particular column in the

525
00:23:57,659 --> 00:24:00,840
form of a particular field not in the

526
00:24:00,840 --> 00:24:02,640
form of

527
00:24:02,640 --> 00:24:05,220
filtering or limiting our results to

528
00:24:05,220 --> 00:24:07,580
certain criteria that we consider

529
00:24:07,580 --> 00:24:09,260
important

530
00:24:09,260 --> 00:24:12,360
using the query method this

531
00:24:12,360 --> 00:24:15,480
of pandas we specify the name

532
00:24:15,480 --> 00:24:17,580
of the fields to use  As a filter, as

533
00:24:17,580 --> 00:24:20,480
we would do in that rocket

534
00:24:20,480 --> 00:24:22,700
, we can additionally include variables

535
00:24:22,700 --> 00:24:26,159
inside the rocket. As shown in the

536
00:24:26,159 --> 00:24:29,400
image, the image below and well,

537
00:24:29,400 --> 00:24:32,340
obviously, it

538
00:24:32,340 --> 00:24:35,340
doesn't hurt to tell them that whenever they

539
00:24:35,340 --> 00:24:39,000
have an important coffee and an important size,

540
00:24:39,000 --> 00:24:40,039


541
00:24:40,039 --> 00:24:42,659
it is always a good practice.  start

542
00:24:42,659 --> 00:24:45,480
filtering the results and don't start

543
00:24:45,480 --> 00:24:48,059
going  deal with everything we have all the

544
00:24:48,059 --> 00:24:51,260
findings just let's always try to

545
00:24:51,260 --> 00:24:54,179
focus on the

546
00:24:54,179 --> 00:24:57,659
important findings that we need later or

547
00:24:57,659 --> 00:25:01,520
validate or send a 100

548
00:25:01,520 --> 00:25:03,659
or somehow work on it in some

549
00:25:03,659 --> 00:25:06,440
other way but let's never start downloading

550
00:25:06,440 --> 00:25:09,620
too much indiscriminate information

551
00:25:09,620 --> 00:25:11,940
I wanted to show you well just this

552
00:25:11,940 --> 00:25:13,740
leather method  and that is why it is not

553
00:25:13,740 --> 00:25:15,900
quite friendly when it comes to unpainting

554
00:25:15,900 --> 00:25:16,880
records,

555
00:25:16,880 --> 00:25:20,480
always within a Data frame

556
00:25:20,480 --> 00:25:24,240
and as I was saying, not once we have

557
00:25:24,240 --> 00:25:25,640
all this information.

558
00:25:25,640 --> 00:25:29,039
At least from this step on,

559
00:25:29,039 --> 00:25:32,700
nothing prevents us from sending them, for example, a

560
00:25:32,700 --> 00:25:34,799
lock file  to monitor it by

561
00:25:34,799 --> 00:25:37,220
some people and to have all this data

562
00:25:37,220 --> 00:25:39,840
on a platform 100

563
00:25:39,840 --> 00:25:43,799
at this stage of the process it is up to

564
00:25:43,799 --> 00:25:46,140
us to decide what to do with all

565
00:25:46,140 --> 00:25:48,480
the information and how to get the most

566
00:25:48,480 --> 00:25:50,960
out of it

567
00:25:51,559 --> 00:25:54,960
well here it is and well as I told you

568
00:25:54,960 --> 00:25:56,520
at the beginning not within a  Notebook

569
00:25:56,520 --> 00:25:58,980
We also have the possibility of

570
00:25:58,980 --> 00:26:00,559
generating different types of graphs

571
00:26:00,559 --> 00:26:02,960
Here I show you a pa  r of

572
00:26:02,960 --> 00:26:06,140
simple examples but obviously this subject already

573
00:26:06,140 --> 00:26:09,320
exceeds the Scott of this talk but

574
00:26:09,320 --> 00:26:12,539
as I tell you now that we have all

575
00:26:12,539 --> 00:26:13,340
this information

576
00:26:13,340 --> 00:26:16,020
to see how we can present it in a

577
00:26:16,020 --> 00:26:20,039
more efficient or graphically understandable way

578
00:26:20,039 --> 00:26:23,279
if we wanted, for example, to generate a

579
00:26:23,279 --> 00:26:26,400
management report

580
00:26:36,919 --> 00:26:41,159
for this height what  It is what I

581
00:26:41,159 --> 00:26:43,279
just sold to us as a management report.

582
00:26:43,279 --> 00:26:46,200
The answer in my case was simpler by

583
00:26:46,200 --> 00:26:49,159
not using Google,

584
00:26:49,159 --> 00:26:51,659
why did I choose it to export the

585
00:26:51,659 --> 00:26:55,559
data? Because as we already know, we continue to

586
00:26:55,559 --> 00:26:58,679
work under the Google ecosystem.

587
00:26:58,679 --> 00:27:01,260
So linking Google colab with Google

588
00:27:01,260 --> 00:27:04,440
sheets would be  Perhaps the most logical and

589
00:27:04,440 --> 00:27:06,440
easiest thing to implement

590
00:27:06,440 --> 00:27:09,299
in Google chip, firstly, a blank spreadsheet was created,

591
00:27:09,299 --> 00:27:11,580
here it is known as

592
00:27:11,580 --> 00:27:15,960
Fire 2022 sans, and a report name was assigned to it

593
00:27:15,960 --> 00:27:17,220
as the name of the

594
00:27:17,220 --> 00:27:18,020
tab,

595
00:27:18,020 --> 00:27:23,159
this same spreadsheet will be the one that will receive

596
00:27:23,159 --> 00:27:25,860
the prominent information.  of the main bowl,

597
00:27:25,860 --> 00:27:27,900
that is, all the main coffee

598
00:27:27,900 --> 00:27:29,279
that we put together in the

599
00:27:29,279 --> 00:27:31,919
previous steps will be exported and  sa

600
00:27:31,919 --> 00:27:34,320
spreadsheet what we do through code

601
00:27:34,320 --> 00:27:38,059
is through the absent call that user

602
00:27:38,059 --> 00:27:40,799
we use Google's default credentials

603
00:27:40,799 --> 00:27:42,720
, that is, the same ones with which

604
00:27:42,720 --> 00:27:43,580
we

605
00:27:43,580 --> 00:27:47,340
are currently logged in, what it

606
00:27:47,340 --> 00:27:48,600
will do is execute an

607
00:27:48,600 --> 00:27:51,080
interactive login code

608
00:27:51,080 --> 00:27:54,120
all inside  from the Notebook to later be

609
00:27:54,120 --> 00:27:56,700
able to interact from colab towards the

610
00:27:56,700 --> 00:27:58,260
different Google solutions, in this

611
00:27:58,260 --> 00:28:01,200
case it is exporting the final Data frame

612
00:28:01,200 --> 00:28:04,320
to Google sheet,

613
00:28:04,320 --> 00:28:07,740
that is, towards this our our

614
00:28:07,740 --> 00:28:10,460
spreadsheet,

615
00:28:13,260 --> 00:28:17,340
well once this spreadsheet is exported here it

616
00:28:17,340 --> 00:28:20,340
can be used as in our case

617
00:28:20,340 --> 00:28:23,700
source of  origin but using Google

618
00:28:23,700 --> 00:28:26,700
Data Studio we also continue under it

619
00:28:26,700 --> 00:28:28,940
as the Google environment commented

620
00:28:28,940 --> 00:28:31,580
here we can now generate

621
00:28:31,580 --> 00:28:33,799
much more

622
00:28:33,799 --> 00:28:37,080
aesthetic reports So to speak Google from the

623
00:28:37,080 --> 00:28:39,120
studio is a great tool that is

624
00:28:39,120 --> 00:28:42,360
also free for just not the

625
00:28:42,360 --> 00:28:43,980
visualization and analysis of data in

626
00:28:43,980 --> 00:28:47,039
addition Well it allows us  share these

627
00:28:47,039 --> 00:28:48,380
reports in a

628
00:28:48,380 --> 00:28:52,080
very simple way to make  ia the whole

629
00:28:52,080 --> 00:28:54,439
organization

630
00:28:55,200 --> 00:28:59,220
OK OK We are going to start with a brief

631
00:28:59,220 --> 00:29:01,340
demo

632
00:29:01,340 --> 00:29:03,659
so that you can better see the

633
00:29:03,659 --> 00:29:06,419
entire process No here

634
00:29:06,419 --> 00:29:08,880
firstly verified that our

635
00:29:08,880 --> 00:29:10,070
reports

636
00:29:10,070 --> 00:29:11,940
[Music]

637
00:29:11,940 --> 00:29:16,140
does not contain data from

638
00:29:16,140 --> 00:29:18,779
the Google spreadsheet that is, not yet

639
00:29:18,779 --> 00:29:20,279
We export nothing, it's just a

640
00:29:20,279 --> 00:29:22,159
blank spreadsheet

641
00:29:22,159 --> 00:29:26,720
like this. Well, then I can show you

642
00:29:26,720 --> 00:29:28,399


643
00:29:28,399 --> 00:29:30,620
This is

644
00:29:30,620 --> 00:29:34,679
all this, all the execution, when

645
00:29:34,679 --> 00:29:37,020
selecting execute everything,

646
00:29:37,020 --> 00:29:38,940
all the

647
00:29:38,940 --> 00:29:40,940
code fragments that make up our Notebook will begin to be executed,

648
00:29:40,940 --> 00:29:44,100
we see how all the libraries are installed

649
00:29:44,100 --> 00:29:46,620
and used and how they are  They execute

650
00:29:46,620 --> 00:29:48,240
the panels one by one within the

651
00:29:48,240 --> 00:29:51,240
Notebook,

652
00:29:51,419 --> 00:29:53,760
keep in mind that in a Notebook, in

653
00:29:53,760 --> 00:29:56,039
addition to the panels, each one of the

654
00:29:56,039 --> 00:29:58,919
panels. Rather, they are dependent and at

655
00:29:58,919 --> 00:30:00,659
the same time independent, what do I mean

656
00:30:00,659 --> 00:30:03,179
by this? I can have a Script that does

657
00:30:03,179 --> 00:30:05,340
a task in a panel and  in another I can

658
00:30:05,340 --> 00:30:06,960
perform another can you can perform

659
00:30:06,960 --> 00:30:09,000
another totally different task as long

660
00:30:09,000 --> 00:30:11,039
as you do not use the same  name of

661
00:30:11,039 --> 00:30:13,200
variables functions etc. not to

662
00:30:13,200 --> 00:30:16,080
confuse not to confuse each of

663
00:30:16,080 --> 00:30:17,460
the variants

664
00:30:17,460 --> 00:30:19,799
finishing I am going to update

665
00:30:19,799 --> 00:30:21,840
again the dashboard in googledard

666
00:30:21,840 --> 00:30:23,820
Studio which points to the

667
00:30:23,820 --> 00:30:26,820
default premise to show

668
00:30:26,820 --> 00:30:29,880
graphically all the all the findings not

669
00:30:29,880 --> 00:30:31,919
only that this one  dashboard we can

670
00:30:31,919 --> 00:30:34,460
already share it with the other teams

671
00:30:34,460 --> 00:30:37,740
or the people involved in an

672
00:30:37,740 --> 00:30:41,220
investigation and I think that good here

673
00:30:41,220 --> 00:30:44,940
this adds value to how we conduct

674
00:30:44,940 --> 00:30:48,020
an analysis not

675
00:30:48,080 --> 00:30:51,000
only that but also the way of reporting and

676
00:30:51,000 --> 00:30:52,679
presenting the results the

677
00:30:52,679 --> 00:30:54,779
results obtained

678
00:30:54,779 --> 00:30:57,779
well

679
00:31:04,620 --> 00:31:10,320
Ok then for  To finish,

680
00:31:10,320 --> 00:31:12,899
remember that

681
00:31:12,899 --> 00:31:15,059
to reach this instance we rely

682
00:31:15,059 --> 00:31:18,240
on a three-phase process, which would be

683
00:31:18,240 --> 00:31:20,840
loading data into the development environment,

684
00:31:20,840 --> 00:31:23,100
restructuring the data within

685
00:31:23,100 --> 00:31:26,039
the Data frame objects, and

686
00:31:26,039 --> 00:31:28,980
detection. In other words, the description of

687
00:31:28,980 --> 00:31:32,600
threats in  based on these results

688
00:31:32,779 --> 00:31:36,059
of the acronic in English of these three

689
00:31:36,059 --> 00:31:39,000
phases, a method was born  which he calls

690
00:31:39,000 --> 00:31:42,720
lords, which may serve as an initial kick

691
00:31:42,720 --> 00:31:44,520


692
00:31:44,520 --> 00:31:47,100
to somehow identify all these

693
00:31:47,100 --> 00:31:50,659
constants that exist in a

694
00:31:50,659 --> 00:31:53,820
data engineering process until reaching

695
00:31:53,820 --> 00:31:57,000
detection and thus be able to

696
00:31:57,000 --> 00:31:59,520
list in a simple way, I think,

697
00:31:59,520 --> 00:32:01,860
all the steps to  perform in terms

698
00:32:01,860 --> 00:32:03,779
of threat intelligence using

699
00:32:03,779 --> 00:32:05,220
standards

700
00:32:05,220 --> 00:32:08,700
here I make a clarification in my case

701
00:32:08,700 --> 00:32:10,820
I found that Data frames

702
00:32:10,820 --> 00:32:14,340
are or at least were the best way

703
00:32:14,340 --> 00:32:16,039
to process and work with data

704
00:32:16,039 --> 00:32:19,500
But it will obviously depend on the

705
00:32:19,500 --> 00:32:22,460
use cases that each area or organization

706
00:32:22,460 --> 00:32:27,020
have to be able to apply it,

707
00:32:27,020 --> 00:32:29,820
expand it and even improve it, thus the

708
00:32:29,820 --> 00:32:32,279
pre-inconveniences at the end of the talk.

709
00:32:32,279 --> 00:32:34,200
I share the link to the base document

710
00:32:34,200 --> 00:32:38,120
in case you are also interested.

711
00:32:38,460 --> 00:32:40,760


712
00:32:40,760 --> 00:32:42,960


713
00:32:42,960 --> 00:32:45,299


714
00:32:45,299 --> 00:32:47,880
We carry out a

715
00:32:47,880 --> 00:32:49,880
treatment,

716
00:32:49,880 --> 00:32:52,039
we categorize them, we

717
00:32:52,039 --> 00:32:54,600
enrich them with information and

718
00:32:54,600 --> 00:32:59,179
finally we apply analytics.  Ultimately we

719
00:32:59,179 --> 00:33:02,820
transform all this

720
00:33:02,820 --> 00:33:05,399
raw data into consumable data which is

721
00:33:05,399 --> 00:33:07,860
precisely the objective of all

722
00:33:07,860 --> 00:33:10,080
data engineering and added to this

723
00:33:10,080 --> 00:33:12,299
we now have useful information

724
00:33:12,299 --> 00:33:15,539
for perhaps a soc list or the soc area

725
00:33:15,539 --> 00:33:19,440
this is an incident to ponder who it is maybe

726
00:33:19,440 --> 00:33:21,840
they could block  or create

727
00:33:21,840 --> 00:33:24,720
blocking rules manually or better

728
00:33:24,720 --> 00:33:26,940
automate them according to these

729
00:33:26,940 --> 00:33:31,140
to all these findings

730
00:33:31,620 --> 00:33:35,039
well here I leave the links to the

731
00:33:35,039 --> 00:33:37,559
Tools and libraries used in this

732
00:33:37,559 --> 00:33:41,539
project as well as well the

733
00:33:42,559 --> 00:33:46,320
link finally and I think this is

734
00:33:46,320 --> 00:33:49,320
essential not  Don't just stay with what

735
00:33:49,320 --> 00:33:52,019
I talked about in this talk

736
00:33:52,019 --> 00:33:54,840
I want to say during

737
00:33:54,840 --> 00:33:56,760
all these minutes I showed you Just

738
00:33:56,760 --> 00:33:59,220
some of the possible ways to

739
00:33:59,220 --> 00:34:01,220
enrich events enrich events

740
00:34:01,220 --> 00:34:05,460
to identify threats Why do I say

741
00:34:05,460 --> 00:34:08,099
some because in our

742
00:34:08,099 --> 00:34:09,418
professional career we are going to find them with

743
00:34:09,418 --> 00:34:11,159
new technologies  platforms and

744
00:34:11,159 --> 00:34:13,099
solutions always

745
00:34:13,099 --> 00:34:17,219
new challenges Today I spoke to you in some

746
00:34:17,219 --> 00:34:20,820
ways but there are several  alternatives

747
00:34:20,820 --> 00:34:22,399
to implement

748
00:34:22,399 --> 00:34:27,899
try finally break think that this is

749
00:34:27,899 --> 00:34:30,359
just the tip of the iceberg on the

750
00:34:30,359 --> 00:34:33,960
use of notebooks with its hundreds

751
00:34:33,960 --> 00:34:36,359
of possibilities it is up to us perhaps to

752
00:34:36,359 --> 00:34:38,940
continue investigating and

753
00:34:38,940 --> 00:34:41,159
constantly challenge ourselves at least in

754
00:34:41,159 --> 00:34:43,260
regards to security firstly because

755
00:34:43,260 --> 00:34:45,899
well I assume that  that we like to continue

756
00:34:45,899 --> 00:34:48,239
learning but above all in

757
00:34:48,239 --> 00:34:51,199
some way we allow ourselves to

758
00:34:51,199 --> 00:34:55,580
feed this creativity and that is not

759
00:34:55,580 --> 00:34:58,740
our own confidence And for

760
00:34:58,740 --> 00:35:02,820
that there is no coach, no, that is, we are

761
00:35:02,820 --> 00:35:03,980


762
00:35:03,980 --> 00:35:06,660
marcoin said that a person with

763
00:35:06,660 --> 00:35:09,960
a new idea is just a  crazy until

764
00:35:09,960 --> 00:35:13,320
the idea becomes a reality So

765
00:35:13,320 --> 00:35:15,119
well I thank all the

766
00:35:15,119 --> 00:35:18,060
participants for joining me in this

767
00:35:18,060 --> 00:35:22,260
talk and well this is the time for

768
00:35:22,260 --> 00:35:24,560
the questions

