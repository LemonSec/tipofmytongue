1
00:00:00,659 --> 00:00:02,960
foreign

2
00:00:06,720 --> 00:00:08,160
okay

3
00:00:08,160 --> 00:00:09,660
good afternoon

4
00:00:09,660 --> 00:00:11,880
um today we're going to talk about a

5
00:00:11,880 --> 00:00:13,799
tool that we have developed at elastic

6
00:00:13,799 --> 00:00:15,839
to help us

7
00:00:15,839 --> 00:00:16,680
um

8
00:00:16,680 --> 00:00:20,220
do some automated analysis on beacons uh

9
00:00:20,220 --> 00:00:23,279
this in particular like our goal is to

10
00:00:23,279 --> 00:00:25,740
share this uh with the community in the

11
00:00:25,740 --> 00:00:27,840
hopes that maybe you guys can find ways

12
00:00:27,840 --> 00:00:29,880
to do this too and then we can help take

13
00:00:29,880 --> 00:00:31,740
down some of this commodity TurnKey

14
00:00:31,740 --> 00:00:34,079
malware a little bit faster than what we

15
00:00:34,079 --> 00:00:35,760
have today

16
00:00:35,760 --> 00:00:37,980
my name is Derek ditch

17
00:00:37,980 --> 00:00:40,379
um those of you that know me and a few

18
00:00:40,379 --> 00:00:42,899
you do most of my background has been in

19
00:00:42,899 --> 00:00:45,120
network forensics particularly using

20
00:00:45,120 --> 00:00:48,239
things like Zeke and netflow and pcap

21
00:00:48,239 --> 00:00:50,940
Analysis and I've done a fair amount of

22
00:00:50,940 --> 00:00:53,340
static malware analysis as well

23
00:00:53,340 --> 00:00:57,000
and I did those things way back in

24
00:00:57,000 --> 00:00:59,640
another lifetime it seems now at the

25
00:00:59,640 --> 00:01:02,399
National Security Agency tracking threat

26
00:01:02,399 --> 00:01:04,619
actors that were targeting

27
00:01:04,619 --> 00:01:07,380
friendly us critical infrastructure

28
00:01:07,380 --> 00:01:09,900
senior political leaders and those of

29
00:01:09,900 --> 00:01:12,600
our allies as well

30
00:01:12,600 --> 00:01:14,159
um I took that experience went into

31
00:01:14,159 --> 00:01:16,500
banking did some Consulting in the power

32
00:01:16,500 --> 00:01:19,619
grid industry as well and uh that

33
00:01:19,619 --> 00:01:21,360
brought me to elastic as a threat

34
00:01:21,360 --> 00:01:22,320
researcher

35
00:01:22,320 --> 00:01:25,380
today I live in Texas about an hour and

36
00:01:25,380 --> 00:01:26,640
a half ish from here depending on

37
00:01:26,640 --> 00:01:28,140
traffic

38
00:01:28,140 --> 00:01:31,200
um and then I guess the last note of me

39
00:01:31,200 --> 00:01:33,540
is I have been in the Missouri National

40
00:01:33,540 --> 00:01:36,180
Guard now for 22 years

41
00:01:36,180 --> 00:01:38,280
um Army National Guard and I'm part of

42
00:01:38,280 --> 00:01:40,500
the team of most cyber which has brought

43
00:01:40,500 --> 00:01:42,720
you such things as rock and a Sim The

44
00:01:42,720 --> 00:01:45,240
Capes project and they were thrunting

45
00:01:45,240 --> 00:01:46,860
which is a contraction for threat

46
00:01:46,860 --> 00:01:50,579
hunting so please start using that

47
00:01:50,579 --> 00:01:53,520
awesome hi my name is Jessica David

48
00:01:53,520 --> 00:01:55,140
um it says bonjour hi because I live in

49
00:01:55,140 --> 00:01:56,820
Toronto and I'm from Canada so you know

50
00:01:56,820 --> 00:01:58,799
gotta get the French and the English

51
00:01:58,799 --> 00:02:01,140
um I am part of the data engineering

52
00:02:01,140 --> 00:02:02,880
team as part of the protections team at

53
00:02:02,880 --> 00:02:05,159
elastic so I come from a very much not

54
00:02:05,159 --> 00:02:06,899
security background so this has been a

55
00:02:06,899 --> 00:02:08,699
very interesting uh it's going to be an

56
00:02:08,699 --> 00:02:10,560
interesting couple days for me um I have

57
00:02:10,560 --> 00:02:12,239
a pretty good knowledge of some of it

58
00:02:12,239 --> 00:02:13,860
but I am essentially the person who

59
00:02:13,860 --> 00:02:15,300
keeps the lights on for people like

60
00:02:15,300 --> 00:02:17,700
Derek I help build data pipelines as

61
00:02:17,700 --> 00:02:20,400
well as automation of tooling uh help

62
00:02:20,400 --> 00:02:22,319
maintain our cicd systems a whole bunch

63
00:02:22,319 --> 00:02:24,480
of other stuff and we help basically

64
00:02:24,480 --> 00:02:26,340
make sure the information from the

65
00:02:26,340 --> 00:02:27,780
outside world both our first and third

66
00:02:27,780 --> 00:02:29,879
party Intel gets to these researchers so

67
00:02:29,879 --> 00:02:31,080
we can continue to build awesome

68
00:02:31,080 --> 00:02:32,819
protections artifacts

69
00:02:32,819 --> 00:02:34,920
um I am a career data Pusher for lack of

70
00:02:34,920 --> 00:02:37,080
a better word I started with uh

71
00:02:37,080 --> 00:02:39,480
Microsoft SQL stuff and I've moved on to

72
00:02:39,480 --> 00:02:42,300
the teaser and Hadoop and now elastic I

73
00:02:42,300 --> 00:02:43,980
was using it before I worked there but I

74
00:02:43,980 --> 00:02:46,260
also use it while I'm at elastic as it

75
00:02:46,260 --> 00:02:48,000
said here I wear many hats um the

76
00:02:48,000 --> 00:02:50,519
automation scripting so I'll be talking

77
00:02:50,519 --> 00:02:52,080
talking a lot about how we have set up

78
00:02:52,080 --> 00:02:53,160
this code that we're going to show you

79
00:02:53,160 --> 00:02:55,200
I'm also devoted cat mom if you check

80
00:02:55,200 --> 00:02:56,700
out the pet lovers Channel you can see

81
00:02:56,700 --> 00:02:58,560
my my O2 for babies who are apparently

82
00:02:58,560 --> 00:03:00,780
watching with my husband hi

83
00:03:00,780 --> 00:03:02,280
um and I'm also an amateur woodworker

84
00:03:02,280 --> 00:03:03,599
which I love and yeah this is my first

85
00:03:03,599 --> 00:03:05,040
dance Summit thank you all for being so

86
00:03:05,040 --> 00:03:06,720
lovely and nice and it's really exciting

87
00:03:06,720 --> 00:03:09,080
to be here

88
00:03:09,239 --> 00:03:10,980
okay so we're gonna tell a little bit

89
00:03:10,980 --> 00:03:14,159
about the the problem how we got here

90
00:03:14,159 --> 00:03:15,780
um what our initial approach was and

91
00:03:15,780 --> 00:03:17,459
when we realized that wasn't the best

92
00:03:17,459 --> 00:03:18,360
approach

93
00:03:18,360 --> 00:03:20,580
and how we started quacking the code

94
00:03:20,580 --> 00:03:22,500
which will make a little more sense in a

95
00:03:22,500 --> 00:03:24,959
moment despite all the Ducks

96
00:03:24,959 --> 00:03:26,760
um and then we'll talk through sort of

97
00:03:26,760 --> 00:03:29,040
uh animated demo and like where we hope

98
00:03:29,040 --> 00:03:31,379
to go with this

99
00:03:31,379 --> 00:03:33,840
Okay so

100
00:03:33,840 --> 00:03:36,360
why are we here

101
00:03:36,360 --> 00:03:40,200
we are here in Texas somewhere roughly

102
00:03:40,200 --> 00:03:41,819
in the middle

103
00:03:41,819 --> 00:03:42,720
um

104
00:03:42,720 --> 00:03:46,980
but it's you know our motivation here is

105
00:03:46,980 --> 00:03:49,500
back to fronting so who doesn't love

106
00:03:49,500 --> 00:03:51,659
threatening so

107
00:03:51,659 --> 00:03:53,280
we've all been there many of us have

108
00:03:53,280 --> 00:03:56,519
been there uh is like you find you're

109
00:03:56,519 --> 00:03:58,080
going through logs you find something

110
00:03:58,080 --> 00:03:59,580
weird

111
00:03:59,580 --> 00:04:02,760
and you're like that's odd behavior but

112
00:04:02,760 --> 00:04:04,620
maybe it's just a misconfiguration you

113
00:04:04,620 --> 00:04:07,080
dig a little bit deeper you find some

114
00:04:07,080 --> 00:04:10,200
more incongruencies with re what you

115
00:04:10,200 --> 00:04:12,780
expect reality to be and then you dig

116
00:04:12,780 --> 00:04:13,739
deeper

117
00:04:13,739 --> 00:04:16,139
and then before you know it you're like

118
00:04:16,139 --> 00:04:18,000
looking through your network logs your

119
00:04:18,000 --> 00:04:20,639
endpoint logs like Neo sees the Matrix

120
00:04:20,639 --> 00:04:22,320
just like stuff scrolling by and you're

121
00:04:22,320 --> 00:04:24,540
like that's not right

122
00:04:24,540 --> 00:04:27,120
um that's probably a dated reference not

123
00:04:27,120 --> 00:04:28,620
for this audience maybe but for

124
00:04:28,620 --> 00:04:31,680
certainly a lot of audiences

125
00:04:31,680 --> 00:04:33,360
um and so

126
00:04:33,360 --> 00:04:35,820
finally you find maybe the process and

127
00:04:35,820 --> 00:04:39,479
the malware and you run strings on it or

128
00:04:39,479 --> 00:04:42,180
whatever sort of like Hasty triage tools

129
00:04:42,180 --> 00:04:46,020
you have and you can find things like

130
00:04:46,020 --> 00:04:49,500
file names and paths and C2 domains

131
00:04:49,500 --> 00:04:53,520
you're like awesome now you know if

132
00:04:53,520 --> 00:04:55,740
you're the the Soul seat Wizard or you

133
00:04:55,740 --> 00:04:57,120
pass it up to somebody in your team to

134
00:04:57,120 --> 00:04:59,040
write like this badass Powershell script

135
00:04:59,040 --> 00:05:00,780
that's going to just eradicate it from

136
00:05:00,780 --> 00:05:03,960
everywhere and maybe put in a exchange

137
00:05:03,960 --> 00:05:07,259
policy that is going to prevent that

138
00:05:07,259 --> 00:05:09,000
same Vector from coming in because

139
00:05:09,000 --> 00:05:12,620
that's it came through email of course

140
00:05:12,620 --> 00:05:15,900
okay now that was like a super short

141
00:05:15,900 --> 00:05:17,460
summary but you all know like that takes

142
00:05:17,460 --> 00:05:19,500
hours to do all that sort of stuff it's

143
00:05:19,500 --> 00:05:22,020
very manually intensive it's tedious

144
00:05:22,020 --> 00:05:23,600
well now we have to rinse and repeat

145
00:05:23,600 --> 00:05:26,759
because actors are using tools like

146
00:05:26,759 --> 00:05:29,580
Cobalt strike not just the red teamers

147
00:05:29,580 --> 00:05:31,139
but of course the nation state actors

148
00:05:31,139 --> 00:05:33,180
they're using stuff off of GitHub

149
00:05:33,180 --> 00:05:36,360
because it researches fun and it's

150
00:05:36,360 --> 00:05:39,900
collaborative which is a good thing

151
00:05:39,900 --> 00:05:42,720
but it becomes this TurnKey thing that

152
00:05:42,720 --> 00:05:44,220
makes it really easy to just crank out

153
00:05:44,220 --> 00:05:47,280
new campaigns and new campaigns

154
00:05:47,280 --> 00:05:47,940
um

155
00:05:47,940 --> 00:05:51,600
so what we did really going back uh I

156
00:05:51,600 --> 00:05:53,039
think back in December we initially

157
00:05:53,039 --> 00:05:56,340
wrote a tool that uh could do this on

158
00:05:56,340 --> 00:05:59,300
the Fly of extract that sort of process

159
00:05:59,300 --> 00:06:02,460
in big batches uh

160
00:06:02,460 --> 00:06:05,400
for Cobalt strike and it was cool and we

161
00:06:05,400 --> 00:06:07,740
wrote A Blog about it and yay

162
00:06:07,740 --> 00:06:09,660
um but I was like man it'd be real a

163
00:06:09,660 --> 00:06:12,300
couple strikes cool but like we could

164
00:06:12,300 --> 00:06:13,560
probably extend this to other things

165
00:06:13,560 --> 00:06:16,380
because we've got some malware reverse

166
00:06:16,380 --> 00:06:18,539
Engineers that need something more to do

167
00:06:18,539 --> 00:06:20,340
and so like they're like hey can we pull

168
00:06:20,340 --> 00:06:22,620
this out of other things

169
00:06:22,620 --> 00:06:23,280
um

170
00:06:23,280 --> 00:06:25,380
so the big thing is like if we can get

171
00:06:25,380 --> 00:06:28,319
this configuration data then we can do

172
00:06:28,319 --> 00:06:30,840
this at much bigger scale detect across

173
00:06:30,840 --> 00:06:33,780
the Enterprise all the endpoints and

174
00:06:33,780 --> 00:06:35,580
correlate all of these infections with a

175
00:06:35,580 --> 00:06:37,860
single Campaign which is where I come

176
00:06:37,860 --> 00:06:39,780
from come in because I'm an intrusion

177
00:06:39,780 --> 00:06:41,639
analyst and I care more about the

178
00:06:41,639 --> 00:06:43,800
campaign and like why are they doing

179
00:06:43,800 --> 00:06:45,840
this not just like how do they get in

180
00:06:45,840 --> 00:06:46,860
and all those other things which are

181
00:06:46,860 --> 00:06:49,740
also good but Okay so

182
00:06:49,740 --> 00:06:51,660
that brings us to

183
00:06:51,660 --> 00:06:53,039
Mel duck

184
00:06:53,039 --> 00:06:55,860
so if y'all haven't come across cert

185
00:06:55,860 --> 00:06:58,560
pulska they're awesome they love sharing

186
00:06:58,560 --> 00:07:00,300
information they have a plethora of

187
00:07:00,300 --> 00:07:03,600
tools on GitHub and and the twitters

188
00:07:03,600 --> 00:07:04,259
um

189
00:07:04,259 --> 00:07:06,300
and they have a malware repository that

190
00:07:06,300 --> 00:07:09,240
they'll freely you can register as if

191
00:07:09,240 --> 00:07:11,699
you have a legitimate

192
00:07:11,699 --> 00:07:15,000
um I guess reason uh then they will

193
00:07:15,000 --> 00:07:16,740
offer you access to their malware

194
00:07:16,740 --> 00:07:18,120
repository where you can contribute

195
00:07:18,120 --> 00:07:20,340
things and it does some of this analysis

196
00:07:20,340 --> 00:07:22,560
from the the repository there

197
00:07:22,560 --> 00:07:25,500
and you can also consume those things so

198
00:07:25,500 --> 00:07:28,319
we we ran across this tool called melduk

199
00:07:28,319 --> 00:07:30,360
because instead of writing all of our

200
00:07:30,360 --> 00:07:32,639
own tools one-off things to do all these

201
00:07:32,639 --> 00:07:34,139
other things

202
00:07:34,139 --> 00:07:36,479
um malduck already does this so it uses

203
00:07:36,479 --> 00:07:39,180
uh Yara rules

204
00:07:39,180 --> 00:07:41,400
and uh for some people that'll make your

205
00:07:41,400 --> 00:07:45,060
eyes closed over uh paired with python

206
00:07:45,060 --> 00:07:47,580
modules for the rest of you that'll make

207
00:07:47,580 --> 00:07:49,560
your eyes glaze over

208
00:07:49,560 --> 00:07:52,020
um but it combines those two things in

209
00:07:52,020 --> 00:07:54,840
like this magical way that you'll see

210
00:07:54,840 --> 00:07:57,599
um so that you can find things using

211
00:07:57,599 --> 00:08:00,000
Yara as a pattern language and then use

212
00:08:00,000 --> 00:08:02,699
Python to extract data based on those

213
00:08:02,699 --> 00:08:04,740
memory offsets

214
00:08:04,740 --> 00:08:05,280
um

215
00:08:05,280 --> 00:08:07,560
so it's really cool and if you can do

216
00:08:07,560 --> 00:08:10,199
this in like a pipeline fashion now we

217
00:08:10,199 --> 00:08:12,180
can do this in much bigger batches

218
00:08:12,180 --> 00:08:15,479
across a wide variety of families uh and

219
00:08:15,479 --> 00:08:18,780
then re-index it so that we can find new

220
00:08:18,780 --> 00:08:21,258
Badness

221
00:08:21,599 --> 00:08:22,740
okay

222
00:08:22,740 --> 00:08:24,720
bear with me a moment some are you going

223
00:08:24,720 --> 00:08:26,400
to be really excited because we've got

224
00:08:26,400 --> 00:08:28,500
some Ida pictures here

225
00:08:28,500 --> 00:08:29,160
um

226
00:08:29,160 --> 00:08:30,840
some of you have no idea what's going on

227
00:08:30,840 --> 00:08:32,760
and that's okay too this is all about

228
00:08:32,760 --> 00:08:35,458
exposure okay so this highlighted block

229
00:08:35,458 --> 00:08:38,940
here is uh extracted from a piece of

230
00:08:38,940 --> 00:08:40,860
malware called iced ID

231
00:08:40,860 --> 00:08:44,159
this is how it decodes its uh

232
00:08:44,159 --> 00:08:46,200
configuration information because the

233
00:08:46,200 --> 00:08:48,300
configuration for the campaigns is

234
00:08:48,300 --> 00:08:52,019
stored in memory in this encrypted blob

235
00:08:52,019 --> 00:08:54,060
um basically all it's doing is it's

236
00:08:54,060 --> 00:08:57,420
taking a 32 byte key at a particular

237
00:08:57,420 --> 00:09:00,300
memory offset and it's using it to xor

238
00:09:00,300 --> 00:09:03,779
against another 32 byte segment which

239
00:09:03,779 --> 00:09:07,760
has C2 domains URLs what have you

240
00:09:07,760 --> 00:09:10,680
but this is a very critical piece to how

241
00:09:10,680 --> 00:09:12,720
iced ID functions

242
00:09:12,720 --> 00:09:14,880
at least for this generation they could

243
00:09:14,880 --> 00:09:16,620
you know they could decide to do 64-bit

244
00:09:16,620 --> 00:09:19,380
blogs next time but for now

245
00:09:19,380 --> 00:09:21,180
this is a critical thing

246
00:09:21,180 --> 00:09:24,300
so what we do is we take that and we

247
00:09:24,300 --> 00:09:26,880
write a Yara role for that and what the

248
00:09:26,880 --> 00:09:28,440
r rule is doing is looking for those

249
00:09:28,440 --> 00:09:31,380
machine instructions that mimic that

250
00:09:31,380 --> 00:09:34,019
particular for Loop

251
00:09:34,019 --> 00:09:36,060
um and that's what this config

252
00:09:36,060 --> 00:09:38,519
decryption piece here is

253
00:09:38,519 --> 00:09:43,019
now what happens then is with maldock if

254
00:09:43,019 --> 00:09:44,820
this Yara rule hits on a particular

255
00:09:44,820 --> 00:09:48,120
sample it will pop over to the python

256
00:09:48,120 --> 00:09:50,640
module that's paired with it and it

257
00:09:50,640 --> 00:09:53,279
passes into a method and you get the

258
00:09:53,279 --> 00:09:55,620
address value of where that for Loop

259
00:09:55,620 --> 00:09:56,519
starts

260
00:09:56,519 --> 00:09:58,860
well if you knew that now you can figure

261
00:09:58,860 --> 00:10:02,220
out where's the 32 bytes of memory that

262
00:10:02,220 --> 00:10:04,440
is the key and where's the 32 bytes of

263
00:10:04,440 --> 00:10:06,300
memory that is the config data and now

264
00:10:06,300 --> 00:10:08,940
in Python we can xor it with a single

265
00:10:08,940 --> 00:10:11,160
line of the xor function

266
00:10:11,160 --> 00:10:13,200
a cool thing that maldoc does as well is

267
00:10:13,200 --> 00:10:15,360
a lot of those Primitives in malware

268
00:10:15,360 --> 00:10:17,820
reversing are just built right in such

269
00:10:17,820 --> 00:10:19,740
as the xor function to just xor the

270
00:10:19,740 --> 00:10:20,779
whole thing

271
00:10:20,779 --> 00:10:23,160
and extracting strings and things like

272
00:10:23,160 --> 00:10:24,180
that

273
00:10:24,180 --> 00:10:26,220
so

274
00:10:26,220 --> 00:10:29,160
this is seemingly terrible but what you

275
00:10:29,160 --> 00:10:31,560
get out of it is these plain text

276
00:10:31,560 --> 00:10:34,320
strings so an iced ID they're really

277
00:10:34,320 --> 00:10:35,940
helpful and they give us the actual

278
00:10:35,940 --> 00:10:38,279
campaign ID like the how they track it

279
00:10:38,279 --> 00:10:40,920
on their side like rates I don't have to

280
00:10:40,920 --> 00:10:42,420
like just jump to conclusions like this

281
00:10:42,420 --> 00:10:45,000
is all part of the same campaign

282
00:10:45,000 --> 00:10:46,740
um we also plot the domains the family

283
00:10:46,740 --> 00:10:49,980
is taken from the fact that the

284
00:10:49,980 --> 00:10:51,959
um the Yar will hit and the python

285
00:10:51,959 --> 00:10:54,240
module is able to process it and then

286
00:10:54,240 --> 00:10:56,220
lastly we get the key which if you count

287
00:10:56,220 --> 00:10:59,279
the letters there's 32 bytes

288
00:10:59,279 --> 00:11:00,300
okay

289
00:11:00,300 --> 00:11:03,300
so that's really awful

290
00:11:03,300 --> 00:11:05,940
this is great data the good news is like

291
00:11:05,940 --> 00:11:08,399
you don't everybody doesn't need this

292
00:11:08,399 --> 00:11:10,560
capability there's like there's there's

293
00:11:10,560 --> 00:11:12,779
uh there's teams out there there's other

294
00:11:12,779 --> 00:11:15,120
people contributing to these sort of

295
00:11:15,120 --> 00:11:18,720
modules in order to write yarn rules and

296
00:11:18,720 --> 00:11:20,700
python modules that can do this sort of

297
00:11:20,700 --> 00:11:23,459
uh processing so you don't need a team

298
00:11:23,459 --> 00:11:25,260
of malware experts to do this but if you

299
00:11:25,260 --> 00:11:26,279
have them

300
00:11:26,279 --> 00:11:28,500
they can also do this and contribute to

301
00:11:28,500 --> 00:11:29,760
the greater good

302
00:11:29,760 --> 00:11:33,660
okay now hold on

303
00:11:33,660 --> 00:11:35,399
we're in Texas

304
00:11:35,399 --> 00:11:38,040
there's really good tacos all around and

305
00:11:38,040 --> 00:11:40,560
deer and and booze

306
00:11:40,560 --> 00:11:41,339
um

307
00:11:41,339 --> 00:11:43,260
but what are we doing here

308
00:11:43,260 --> 00:11:46,079
so so far we talked about just this

309
00:11:46,079 --> 00:11:48,920
malware pipeline this problem of being

310
00:11:48,920 --> 00:11:51,180
adversaries being able to crank out new

311
00:11:51,180 --> 00:11:54,300
malware new campaigns like just

312
00:11:54,300 --> 00:11:56,519
following a GUI wizard

313
00:11:56,519 --> 00:11:57,480
um

314
00:11:57,480 --> 00:11:59,640
and I laid out like these yarn rules and

315
00:11:59,640 --> 00:12:01,680
python modules and these are all just

316
00:12:01,680 --> 00:12:03,120
kind of like the Lego blocks just kind

317
00:12:03,120 --> 00:12:04,440
of spreading them out we're going to

318
00:12:04,440 --> 00:12:06,660
bring them all together and build

319
00:12:06,660 --> 00:12:08,820
something really cool don't step on them

320
00:12:08,820 --> 00:12:11,360
it hurts

321
00:12:11,700 --> 00:12:14,519
okay so before we can move on we need

322
00:12:14,519 --> 00:12:15,540
samples

323
00:12:15,540 --> 00:12:17,100
there's a couple ways that we can get

324
00:12:17,100 --> 00:12:19,140
samples so

325
00:12:19,140 --> 00:12:21,360
um you can pull malware off of the disk

326
00:12:21,360 --> 00:12:23,579
so if you were doing the the process

327
00:12:23,579 --> 00:12:25,079
that we were talking about earlier of

328
00:12:25,079 --> 00:12:27,360
just doing the grind and fighting the

329
00:12:27,360 --> 00:12:29,399
malware samples on disk you can process

330
00:12:29,399 --> 00:12:31,440
those

331
00:12:31,440 --> 00:12:33,600
um if it's written to disk you know a

332
00:12:33,600 --> 00:12:35,640
lot of malware just does code injection

333
00:12:35,640 --> 00:12:39,120
as a dll and so it's never there uh we

334
00:12:39,120 --> 00:12:41,160
can do memory captures

335
00:12:41,160 --> 00:12:42,240
um

336
00:12:42,240 --> 00:12:44,160
kind of like Neo here just stick it in

337
00:12:44,160 --> 00:12:46,920
there scrape it out and now you have all

338
00:12:46,920 --> 00:12:48,720
the data

339
00:12:48,720 --> 00:12:50,399
um and there's lots of tools that can do

340
00:12:50,399 --> 00:12:53,459
that uh I guess we're from elastic we

341
00:12:53,459 --> 00:12:54,779
can do this with elastic security

342
00:12:54,779 --> 00:12:57,000
endpoint as well

343
00:12:57,000 --> 00:12:59,399
um and that's how we do it in our own

344
00:12:59,399 --> 00:13:03,720
sort of malware sandbox uh there's

345
00:13:03,720 --> 00:13:07,139
some details that that uh are in a blog

346
00:13:07,139 --> 00:13:09,540
post that is we'll link to in the slide

347
00:13:09,540 --> 00:13:11,880
uh or in these slides and then we'll

348
00:13:11,880 --> 00:13:13,740
kind of talk about the the big process

349
00:13:13,740 --> 00:13:16,800
of how this works but basically you can

350
00:13:16,800 --> 00:13:19,380
if there is a memory related event that

351
00:13:19,380 --> 00:13:21,060
the endpoint detects

352
00:13:21,060 --> 00:13:23,279
you can it's not turned on by default

353
00:13:23,279 --> 00:13:25,320
but you can extract up to four megabytes

354
00:13:25,320 --> 00:13:28,320
of memory of that process on the Fly you

355
00:13:28,320 --> 00:13:29,940
can do this across Windows Mac and Linux

356
00:13:29,940 --> 00:13:32,639
which is perfect for being able to run

357
00:13:32,639 --> 00:13:34,800
pipelines against this

358
00:13:34,800 --> 00:13:35,399
um

359
00:13:35,399 --> 00:13:37,920
which is what we do here so all that

360
00:13:37,920 --> 00:13:39,839
gets right into elasticsearch and then

361
00:13:39,839 --> 00:13:41,700
we can pull it down and analyze it in

362
00:13:41,700 --> 00:13:43,380
batches

363
00:13:43,380 --> 00:13:45,660
all right yeah

364
00:13:45,660 --> 00:13:47,220
yeah following Along by the way on slack

365
00:13:47,220 --> 00:13:49,139
I hope you're finding all the Ducks and

366
00:13:49,139 --> 00:13:50,399
if you're part of the discussion Channel

367
00:13:50,399 --> 00:13:52,019
you'll know what I'm talking about but

368
00:13:52,019 --> 00:13:53,339
there's one right there

369
00:13:53,339 --> 00:13:54,720
uh so yeah so now we're going to go into

370
00:13:54,720 --> 00:13:56,519
a quick demo and because we cannot live

371
00:13:56,519 --> 00:13:58,019
demo we have some pre-recorded

372
00:13:58,019 --> 00:13:59,880
animations to show you and we're going

373
00:13:59,880 --> 00:14:01,680
to show you how we do this from start to

374
00:14:01,680 --> 00:14:03,540
finish right from bringing up an elastic

375
00:14:03,540 --> 00:14:06,240
stack and elastic cluster to setting up

376
00:14:06,240 --> 00:14:08,579
our endpoint policy configuring that

377
00:14:08,579 --> 00:14:11,399
policy on an agent uh and then how we

378
00:14:11,399 --> 00:14:14,720
extract it uh Orcs quack it I should say

379
00:14:14,720 --> 00:14:17,399
and uh what we do with it after that and

380
00:14:17,399 --> 00:14:18,779
how we're currently automating this

381
00:14:18,779 --> 00:14:21,660
process um at elastic uh we'll also note

382
00:14:21,660 --> 00:14:23,940
uh we're big fans of elastic because we

383
00:14:23,940 --> 00:14:25,740
work there we promise this isn't like a

384
00:14:25,740 --> 00:14:27,839
big like vendor talk or anything we're

385
00:14:27,839 --> 00:14:29,040
just really excited about the product

386
00:14:29,040 --> 00:14:30,839
that we use so that's why we're so hyped

387
00:14:30,839 --> 00:14:32,639
about it I've been an elastic fan boy

388
00:14:32,639 --> 00:14:36,899
since version 0.95 way back yeah like

389
00:14:36,899 --> 00:14:38,639
2013. come talk to us about it we're

390
00:14:38,639 --> 00:14:40,860
really safe

391
00:14:40,860 --> 00:14:42,240
all right so the first thing we're going

392
00:14:42,240 --> 00:14:45,120
to do is set up elastic security so I

393
00:14:45,120 --> 00:14:47,220
did this on a demo cluster where I

394
00:14:47,220 --> 00:14:48,600
installed the last or it's on elastic

395
00:14:48,600 --> 00:14:50,579
Cloud it comes up in about five minutes

396
00:14:50,579 --> 00:14:52,920
elastic cloud is really great for that

397
00:14:52,920 --> 00:14:54,120
um so if you want to bring up a trial

398
00:14:54,120 --> 00:14:55,380
cluster to see what this is all about

399
00:14:55,380 --> 00:14:56,720
you can sign up for a free account

400
00:14:56,720 --> 00:14:59,339
otherwise you can bring up elasticsearch

401
00:14:59,339 --> 00:15:01,680
locally whether you do it dockerized or

402
00:15:01,680 --> 00:15:03,120
not you can kind of do whatever you want

403
00:15:03,120 --> 00:15:04,560
to do or maybe you already have a

404
00:15:04,560 --> 00:15:06,660
deployment set up which is great so here

405
00:15:06,660 --> 00:15:08,279
I'm setting up an integration called

406
00:15:08,279 --> 00:15:10,560
Sandstorm which seems appropriate for

407
00:15:10,560 --> 00:15:11,940
the spent

408
00:15:11,940 --> 00:15:13,740
um if you already have elastic security

409
00:15:13,740 --> 00:15:15,420
installed in this integration setup

410
00:15:15,420 --> 00:15:17,579
that's okay you can create a new policy

411
00:15:17,579 --> 00:15:19,860
as well so this is just going through

412
00:15:19,860 --> 00:15:21,720
very easily we create the integration

413
00:15:21,720 --> 00:15:23,760
and give it a description it's going to

414
00:15:23,760 --> 00:15:25,260
ask if you want to add it to existing

415
00:15:25,260 --> 00:15:27,240
hosts right now we have done those we're

416
00:15:27,240 --> 00:15:28,980
going to create a new policy I'm giving

417
00:15:28,980 --> 00:15:31,139
it a new policy name because maybe I

418
00:15:31,139 --> 00:15:32,639
want to create other policies to put on

419
00:15:32,639 --> 00:15:34,800
other hosts that I have this is a very

420
00:15:34,800 --> 00:15:36,360
simple straightforward setup and you'll

421
00:15:36,360 --> 00:15:38,220
be able to go

422
00:15:38,220 --> 00:15:39,480
next thing we're going to do though is

423
00:15:39,480 --> 00:15:41,459
configure this endpoint policy so the

424
00:15:41,459 --> 00:15:42,660
first thing we're going to do is we're

425
00:15:42,660 --> 00:15:44,220
going to register as an official

426
00:15:44,220 --> 00:15:45,540
antivirus

427
00:15:45,540 --> 00:15:47,279
um by disabling Windows Defender this

428
00:15:47,279 --> 00:15:50,160
helps us not get blocked by them uh

429
00:15:50,160 --> 00:15:51,180
we're going to show some Advanced

430
00:15:51,180 --> 00:15:52,560
options now and this is where we're

431
00:15:52,560 --> 00:15:54,540
going to enable that configuration

432
00:15:54,540 --> 00:15:56,699
setting that Derek talked about yeah

433
00:15:56,699 --> 00:16:01,139
just uh one quick caveat on the so we

434
00:16:01,139 --> 00:16:02,699
did this in sandbox so we don't want

435
00:16:02,699 --> 00:16:04,980
Windows Defender to help protect the Box

436
00:16:04,980 --> 00:16:06,660
because we want to see things run the

437
00:16:06,660 --> 00:16:07,820
fruition

438
00:16:07,820 --> 00:16:10,320
and then we also set the policies to

439
00:16:10,320 --> 00:16:12,540
detect only because otherwise the

440
00:16:12,540 --> 00:16:14,220
endpoint might block the malware before

441
00:16:14,220 --> 00:16:16,680
it even the process starts in which case

442
00:16:16,680 --> 00:16:18,959
you won't get any process memory yeah

443
00:16:18,959 --> 00:16:20,279
and as you can see at the end of the

444
00:16:20,279 --> 00:16:21,959
animation we showed the fields that

445
00:16:21,959 --> 00:16:23,220
you'll be setting this is also in a

446
00:16:23,220 --> 00:16:24,720
readme we have available for you all so

447
00:16:24,720 --> 00:16:26,160
you don't have to like take a billion

448
00:16:26,160 --> 00:16:28,500
pictures and memorize the field names

449
00:16:28,500 --> 00:16:30,540
um but yeah this they will capture now

450
00:16:30,540 --> 00:16:33,060
up to four megabytes of the uh what

451
00:16:33,060 --> 00:16:35,459
happens in memory and it is uh base64

452
00:16:35,459 --> 00:16:38,279
encoded and zlibbed as well elastic will

453
00:16:38,279 --> 00:16:40,620
also do its best to de-duplicate this

454
00:16:40,620 --> 00:16:42,660
field so it's not stored like in every

455
00:16:42,660 --> 00:16:43,980
single alert where this happens because

456
00:16:43,980 --> 00:16:45,480
that can get quite costly in terms of

457
00:16:45,480 --> 00:16:47,639
storage so if you do turn this on Note

458
00:16:47,639 --> 00:16:48,779
you'll be using a little bit more

459
00:16:48,779 --> 00:16:50,639
storage when this happens but we do try

460
00:16:50,639 --> 00:16:52,380
our best to make sure we're not using a

461
00:16:52,380 --> 00:16:53,820
lot of storage space

462
00:16:53,820 --> 00:16:55,920
and now we need to enroll some agents um

463
00:16:55,920 --> 00:16:57,480
so what we've done is you see this URL

464
00:16:57,480 --> 00:16:59,339
here we have this little short URL for

465
00:16:59,339 --> 00:17:01,019
where we have a vagrant file set up if

466
00:17:01,019 --> 00:17:03,180
you want to run a little sandbox VM uh

467
00:17:03,180 --> 00:17:04,679
it can run on anything that supports a

468
00:17:04,679 --> 00:17:06,540
vagrant file such as VMware or a

469
00:17:06,540 --> 00:17:08,400
virtualbox but it was tested on VMware

470
00:17:08,400 --> 00:17:10,980
uh by Derek and there's lots of

471
00:17:10,980 --> 00:17:12,240
instructions to read me about having it

472
00:17:12,240 --> 00:17:13,859
hook up to your elastic cluster and all

473
00:17:13,859 --> 00:17:15,299
this other stuff

474
00:17:15,299 --> 00:17:16,619
um we also have our own detonation

475
00:17:16,619 --> 00:17:18,299
environment which is what I use to kind

476
00:17:18,299 --> 00:17:20,280
of help onto some future slides here um

477
00:17:20,280 --> 00:17:21,359
it's really cool if you're really

478
00:17:21,359 --> 00:17:23,099
excited about automatic detonation also

479
00:17:23,099 --> 00:17:24,780
come talk to me later because I want to

480
00:17:24,780 --> 00:17:26,459
hear your thoughts

481
00:17:26,459 --> 00:17:27,720
um and it says here we need to create an

482
00:17:27,720 --> 00:17:29,280
elastic cluster but we already did that

483
00:17:29,280 --> 00:17:32,100
so once your agent is up you can go and

484
00:17:32,100 --> 00:17:33,419
double check to ensure that it's

485
00:17:33,419 --> 00:17:34,860
properly connected to elastic security

486
00:17:34,860 --> 00:17:37,620
but then we need to cause trouble and

487
00:17:37,620 --> 00:17:38,880
this is kind of like where we need to go

488
00:17:38,880 --> 00:17:40,860
figure out hmm where's something that we

489
00:17:40,860 --> 00:17:42,780
can detonate in our little sandboxes

490
00:17:42,780 --> 00:17:45,000
going to trigger an alert that will load

491
00:17:45,000 --> 00:17:46,200
something into memory that we can

492
00:17:46,200 --> 00:17:47,760
capture and have all these things put

493
00:17:47,760 --> 00:17:50,460
together this is a little bit more more

494
00:17:50,460 --> 00:17:52,500
adventurous than you might assume uh

495
00:17:52,500 --> 00:17:53,760
there's a hash on the next slide that is

496
00:17:53,760 --> 00:17:55,440
was able to use to do a little bit of

497
00:17:55,440 --> 00:17:57,179
this extracting

498
00:17:57,179 --> 00:17:59,039
um but we could probably have a whole

499
00:17:59,039 --> 00:18:00,660
other talk about how to do that so we're

500
00:18:00,660 --> 00:18:01,919
going to skip for now but yeah we want

501
00:18:01,919 --> 00:18:02,820
to find something that's going to

502
00:18:02,820 --> 00:18:04,260
trigger this Rule and cause some trouble

503
00:18:04,260 --> 00:18:06,059
so let's cause trouble

504
00:18:06,059 --> 00:18:08,460
so this is a bit from a little demo

505
00:18:08,460 --> 00:18:10,500
cluster that I have there's a field here

506
00:18:10,500 --> 00:18:12,120
apologies it's not very clear for you in

507
00:18:12,120 --> 00:18:13,679
the audience but it's it's the bytes

508
00:18:13,679 --> 00:18:15,720
compressed present and that essentially

509
00:18:15,720 --> 00:18:17,520
means that we have fired an alert where

510
00:18:17,520 --> 00:18:19,980
we have this compressed bytes field and

511
00:18:19,980 --> 00:18:21,059
you'll see a triggered a rule that's

512
00:18:21,059 --> 00:18:22,500
called Cobalt strike which is pretty fun

513
00:18:22,500 --> 00:18:24,840
uh you can then expand the document you

514
00:18:24,840 --> 00:18:26,400
can see kind of all the data that we you

515
00:18:26,400 --> 00:18:28,020
are collecting about it when the elastic

516
00:18:28,020 --> 00:18:30,600
endpoint alert fires uh so if we go here

517
00:18:30,600 --> 00:18:32,100
we're going to take a quick peek so we

518
00:18:32,100 --> 00:18:34,380
can take a look at that field with the

519
00:18:34,380 --> 00:18:36,059
um but it's compressed and you can see

520
00:18:36,059 --> 00:18:38,520
there it is a giant blob of words or

521
00:18:38,520 --> 00:18:40,440
letters and numbers which probably is

522
00:18:40,440 --> 00:18:41,760
what you would expect

523
00:18:41,760 --> 00:18:44,100
so now we have to do the fun part which

524
00:18:44,100 --> 00:18:46,559
is to exquack things so we're going to

525
00:18:46,559 --> 00:18:49,020
run some python code now which starts

526
00:18:49,020 --> 00:18:51,620
with a very awesome CLI ASCII art

527
00:18:51,620 --> 00:18:54,360
obviously for writing a tool you have to

528
00:18:54,360 --> 00:18:56,160
have cool ASCII art and what this is

529
00:18:56,160 --> 00:18:57,360
going to do is this is going to pull

530
00:18:57,360 --> 00:18:59,160
some alerts from your cluster and

531
00:18:59,160 --> 00:19:01,260
process them so the alerts here that

532
00:19:01,260 --> 00:19:02,940
we're looking for are ones that have

533
00:19:02,940 --> 00:19:04,740
intrusion detection as well as have

534
00:19:04,740 --> 00:19:06,660
these memory bytes present you could

535
00:19:06,660 --> 00:19:08,220
have thousands and thousands alerts over

536
00:19:08,220 --> 00:19:10,080
a couple days but you can see here maybe

537
00:19:10,080 --> 00:19:12,299
hopefully that we only get about 454

538
00:19:12,299 --> 00:19:14,280
hits on this cluster I'm running this on

539
00:19:14,280 --> 00:19:16,380
and I think there are over 20 000 alerts

540
00:19:16,380 --> 00:19:18,600
over the time period and then we have

541
00:19:18,600 --> 00:19:20,220
seven of them which we are now able to

542
00:19:20,220 --> 00:19:22,140
extract out and batch we have the fields

543
00:19:22,140 --> 00:19:23,580
that we need we found all these little

544
00:19:23,580 --> 00:19:25,559
bits that we've located and it's all

545
00:19:25,559 --> 00:19:29,460
awesome so we have found our alerts

546
00:19:29,460 --> 00:19:31,799
and now we have this in another elastic

547
00:19:31,799 --> 00:19:34,200
cluster so what this code will do is it

548
00:19:34,200 --> 00:19:36,240
pulls everything out from the source

549
00:19:36,240 --> 00:19:38,520
index does some Transformations uses

550
00:19:38,520 --> 00:19:40,260
maldock to find the fields that we need

551
00:19:40,260 --> 00:19:42,660
and then it loads it back into

552
00:19:42,660 --> 00:19:43,980
um elastic and Derek's going to talk a

553
00:19:43,980 --> 00:19:44,940
little bit more about kind of what

554
00:19:44,940 --> 00:19:46,620
you're seeing here in this animation

555
00:19:46,620 --> 00:19:48,600
yeah so what are the one of the big

556
00:19:48,600 --> 00:19:50,640
things that we're we're trying to do is

557
00:19:50,640 --> 00:19:53,580
treat all these malware in a similar

558
00:19:53,580 --> 00:19:56,100
fashion so that we can analyze them kind

559
00:19:56,100 --> 00:19:58,919
of in bulk as we go so

560
00:19:58,919 --> 00:20:01,080
um of these fields here you'll see

561
00:20:01,080 --> 00:20:04,080
threat.software.things

562
00:20:05,039 --> 00:20:06,780
um and that that's using the elastic

563
00:20:06,780 --> 00:20:10,080
common schema and so we try to it's not

564
00:20:10,080 --> 00:20:12,299
perfect we're making it better but we

565
00:20:12,299 --> 00:20:15,240
try to align things like identifying

566
00:20:15,240 --> 00:20:17,039
that this particular malware is using

567
00:20:17,039 --> 00:20:20,220
HTTP as the transport versus DNS or SSH

568
00:20:20,220 --> 00:20:23,039
or something like that but putting

569
00:20:23,039 --> 00:20:25,820
things like URLs in a common URL field

570
00:20:25,820 --> 00:20:28,740
DNS names on the common DNS field that

571
00:20:28,740 --> 00:20:30,600
way you can compare share those versus

572
00:20:30,600 --> 00:20:33,678
the other data sets

573
00:20:34,080 --> 00:20:35,940
with how we're using it here

574
00:20:35,940 --> 00:20:37,860
so

575
00:20:37,860 --> 00:20:39,539
this process right now by running it as

576
00:20:39,539 --> 00:20:41,280
a daily

577
00:20:41,280 --> 00:20:43,380
feedback using our CI solution which is

578
00:20:43,380 --> 00:20:47,220
Jenkins this is okay but even with the

579
00:20:47,220 --> 00:20:48,960
kind of okay implementation of this you

580
00:20:48,960 --> 00:20:50,280
can see here kind of some of the

581
00:20:50,280 --> 00:20:52,740
immediate awesome benefits we get this

582
00:20:52,740 --> 00:20:54,720
dashboard takes maybe 20 seconds to put

583
00:20:54,720 --> 00:20:56,520
together if ever while everything is in

584
00:20:56,520 --> 00:20:58,020
ECS

585
00:20:58,020 --> 00:20:59,820
um very simple for now but you could

586
00:20:59,820 --> 00:21:01,559
imagine like depending on what Fields

587
00:21:01,559 --> 00:21:03,179
you're Gathering or if this is

588
00:21:03,179 --> 00:21:04,980
incorporated into other dashboards or

589
00:21:04,980 --> 00:21:06,840
more meaningful information you can take

590
00:21:06,840 --> 00:21:08,700
a look kind of at what's going on and

591
00:21:08,700 --> 00:21:10,559
because these are all typed correctly

592
00:21:10,559 --> 00:21:12,960
using ECS you can see oh great like I

593
00:21:12,960 --> 00:21:14,700
have keyword Fields I can really easily

594
00:21:14,700 --> 00:21:17,039
make this dashboard this is awesome I'm

595
00:21:17,039 --> 00:21:18,419
very excited

596
00:21:18,419 --> 00:21:20,039
um so we run this batch job like I said

597
00:21:20,039 --> 00:21:22,620
once a day we look basically to the

598
00:21:22,620 --> 00:21:24,299
previous day rounded down to make sure

599
00:21:24,299 --> 00:21:26,280
we haven't missed any alerts and this is

600
00:21:26,280 --> 00:21:28,140
you know this does the job for now the

601
00:21:28,140 --> 00:21:29,880
researchers can look at it this is great

602
00:21:29,880 --> 00:21:33,360
but it is a day lag so

603
00:21:33,360 --> 00:21:35,820
what if it always ran and this is kind

604
00:21:35,820 --> 00:21:37,500
of what I'm really excited about and I

605
00:21:37,500 --> 00:21:39,059
think one of the very exciting parts of

606
00:21:39,059 --> 00:21:39,900
this project

607
00:21:39,900 --> 00:21:42,000
um for me so this is sort of where we're

608
00:21:42,000 --> 00:21:43,799
going to be in the near future so you

609
00:21:43,799 --> 00:21:46,679
can see we start with endpoints uh over

610
00:21:46,679 --> 00:21:48,539
here on the left they're going to fire

611
00:21:48,539 --> 00:21:50,039
alerts that are gathered by elastic

612
00:21:50,039 --> 00:21:51,539
security which is kind of the process

613
00:21:51,539 --> 00:21:53,100
we've already shown you in the last

614
00:21:53,100 --> 00:21:54,480
little bit of this talk

615
00:21:54,480 --> 00:21:56,400
we then instead of having this right now

616
00:21:56,400 --> 00:21:58,140
what's running in the malware quacker is

617
00:21:58,140 --> 00:21:59,940
kind of a monolithic python application

618
00:21:59,940 --> 00:22:02,039
that uses multi-processing but these

619
00:22:02,039 --> 00:22:03,539
could really easily be broken out into

620
00:22:03,539 --> 00:22:05,220
smaller Services

621
00:22:05,220 --> 00:22:06,299
um whether these are like Cloud

622
00:22:06,299 --> 00:22:07,860
functions if you're using something like

623
00:22:07,860 --> 00:22:11,700
a GC a gcp or AWS or you could have a

624
00:22:11,700 --> 00:22:13,500
little tiny batch job that's running and

625
00:22:13,500 --> 00:22:15,000
basically every like five minutes kind

626
00:22:15,000 --> 00:22:17,580
of doing a poll to see like hey do I

627
00:22:17,580 --> 00:22:19,860
have new alerts do I have new alerts

628
00:22:19,860 --> 00:22:20,760
um then we need to make sure they're

629
00:22:20,760 --> 00:22:22,980
quackable which as we mentioned it means

630
00:22:22,980 --> 00:22:24,240
it's a piece of malware that's doing

631
00:22:24,240 --> 00:22:25,860
intrusion detection that has these

632
00:22:25,860 --> 00:22:28,559
memory bytes uh present so can we quack

633
00:22:28,559 --> 00:22:31,020
it great throw it on a cue in this case

634
00:22:31,020 --> 00:22:32,340
we're using Kafka because that's what

635
00:22:32,340 --> 00:22:33,960
we're using internally as part of my

636
00:22:33,960 --> 00:22:36,360
team but you could use any other queuing

637
00:22:36,360 --> 00:22:38,640
system uh sqs

638
00:22:38,640 --> 00:22:40,980
um the Google equivalent of sqs which I

639
00:22:40,980 --> 00:22:42,299
know the name of off the top of my head

640
00:22:42,299 --> 00:22:43,500
right now

641
00:22:43,500 --> 00:22:44,820
um or anything else that you use for

642
00:22:44,820 --> 00:22:45,720
queuing

643
00:22:45,720 --> 00:22:48,120
it then goes into the X cracker uh which

644
00:22:48,120 --> 00:22:49,679
this is what's uh looking at the various

645
00:22:49,679 --> 00:22:51,360
maldock modules it's pulling everything

646
00:22:51,360 --> 00:22:53,400
in getting all the information out of

647
00:22:53,400 --> 00:22:54,900
those memory bytes as we possibly can

648
00:22:54,900 --> 00:22:57,900
after we uh decode and decompress it we

649
00:22:57,900 --> 00:22:59,220
then have these enriched alerts so we

650
00:22:59,220 --> 00:23:01,260
can pass on to another cue and then have

651
00:23:01,260 --> 00:23:03,179
another consumer which will post the

652
00:23:03,179 --> 00:23:05,460
data back to an elasticsearch index you

653
00:23:05,460 --> 00:23:07,140
could also have other processes that

654
00:23:07,140 --> 00:23:10,080
aren't this malware X quacking process

655
00:23:10,080 --> 00:23:11,460
that

656
00:23:11,460 --> 00:23:13,080
um can pull from these cues if there's

657
00:23:13,080 --> 00:23:14,400
additional information you want to pull

658
00:23:14,400 --> 00:23:15,960
out if you have other services that are

659
00:23:15,960 --> 00:23:17,039
running

660
00:23:17,039 --> 00:23:18,659
um even in general you could not have

661
00:23:18,659 --> 00:23:20,580
the is quackable happen and have your

662
00:23:20,580 --> 00:23:22,020
alert somewhere and do some cool stuff

663
00:23:22,020 --> 00:23:24,179
with that and then yeah you run it to

664
00:23:24,179 --> 00:23:25,919
elastic surge index and this way you can

665
00:23:25,919 --> 00:23:28,740
have a near real time maybe closest to

666
00:23:28,740 --> 00:23:31,799
real-time representation of how male

667
00:23:31,799 --> 00:23:33,480
duck is working with your system what

668
00:23:33,480 --> 00:23:34,919
kind of information you can see from

669
00:23:34,919 --> 00:23:37,080
these alerts and yeah this is something

670
00:23:37,080 --> 00:23:38,400
that we're looking forward to doing in

671
00:23:38,400 --> 00:23:40,080
the near future and I'm going to hand

672
00:23:40,080 --> 00:23:41,340
over to Derek speaking of the near

673
00:23:41,340 --> 00:23:44,640
future okay so next steps

674
00:23:44,640 --> 00:23:46,440
um that's Jessica mentioned we're going

675
00:23:46,440 --> 00:23:47,880
to continue this automation to make it

676
00:23:47,880 --> 00:23:49,440
like part of a bigger pipeline for us

677
00:23:49,440 --> 00:23:51,179
internally

678
00:23:51,179 --> 00:23:55,200
um and we as as we're writing uh the

679
00:23:55,200 --> 00:23:56,760
researchers in the in the malware

680
00:23:56,760 --> 00:23:58,559
reverse Engineers as we're writing like

681
00:23:58,559 --> 00:24:00,240
new blog posts and getting new content

682
00:24:00,240 --> 00:24:02,340
like we're always publishing Yar rules

683
00:24:02,340 --> 00:24:04,500
and things like that in order to detect

684
00:24:04,500 --> 00:24:06,840
this malware and analyze it

685
00:24:06,840 --> 00:24:08,700
um we're going to be publishing new

686
00:24:08,700 --> 00:24:12,179
modules as we go and this is a sort of

687
00:24:12,179 --> 00:24:13,799
as is this is not like a supported

688
00:24:13,799 --> 00:24:15,659
product or anything but we're giving

689
00:24:15,659 --> 00:24:17,400
this you know giving this out as some

690
00:24:17,400 --> 00:24:18,539
additional information to hopefully help

691
00:24:18,539 --> 00:24:20,280
the community

692
00:24:20,280 --> 00:24:21,320
um

693
00:24:21,320 --> 00:24:24,900
the uh last bullet here open source it

694
00:24:24,900 --> 00:24:28,020
we actually made these repos live today

695
00:24:28,020 --> 00:24:29,760
um and the URL that was given earlier

696
00:24:29,760 --> 00:24:32,280
and we'll be coming up here on maybe the

697
00:24:32,280 --> 00:24:33,480
next slide

698
00:24:33,480 --> 00:24:34,140
um

699
00:24:34,140 --> 00:24:36,539
it has a link to that you can download

700
00:24:36,539 --> 00:24:40,740
this and try this uh in your own space

701
00:24:40,740 --> 00:24:42,720
um and like I said we're gonna keep keep

702
00:24:42,720 --> 00:24:45,780
pushing this and hopefully we can we can

703
00:24:45,780 --> 00:24:47,460
make a dent versus these commodity

704
00:24:47,460 --> 00:24:48,900
mounters you also have one quick note

705
00:24:48,900 --> 00:24:50,940
speaking of open sourcing um so last

706
00:24:50,940 --> 00:24:53,100
week I think it was maybe two weeks ago

707
00:24:53,100 --> 00:24:55,440
we opened up recently a protections

708
00:24:55,440 --> 00:24:57,900
artifacts repository in elastic uh where

709
00:24:57,900 --> 00:25:00,360
we have open sourced our yard Behavior

710
00:25:00,360 --> 00:25:01,980
rules I do believe

711
00:25:01,980 --> 00:25:03,900
um so elastic is really kind of pushing

712
00:25:03,900 --> 00:25:04,919
forward a little bit now in terms of

713
00:25:04,919 --> 00:25:06,539
like an open security initiative and

714
00:25:06,539 --> 00:25:07,799
it's something that we're really excited

715
00:25:07,799 --> 00:25:09,900
about internally as well is helping

716
00:25:09,900 --> 00:25:11,700
spread some security knowledge that our

717
00:25:11,700 --> 00:25:13,320
awesome team has and making sure it's

718
00:25:13,320 --> 00:25:15,600
available to everyone to help protect

719
00:25:15,600 --> 00:25:18,179
all of your computers like the computers

720
00:25:18,179 --> 00:25:19,380
all over the world

721
00:25:19,380 --> 00:25:21,000
um it's a really awesome Mission and so

722
00:25:21,000 --> 00:25:22,860
this is kind of I think a nice extension

723
00:25:22,860 --> 00:25:24,600
of some of that work that we're doing to

724
00:25:24,600 --> 00:25:25,799
help share our knowledge with the

725
00:25:25,799 --> 00:25:28,140
community for sure

726
00:25:28,140 --> 00:25:29,460
um so we have just a little bit more

727
00:25:29,460 --> 00:25:31,919
time I want to throw in another note uh

728
00:25:31,919 --> 00:25:33,600
sort of a caveat about how this process

729
00:25:33,600 --> 00:25:35,360
works in this particular

730
00:25:35,360 --> 00:25:38,940
instantiation is since these processes

731
00:25:38,940 --> 00:25:40,440
are executing and we're scraping the

732
00:25:40,440 --> 00:25:43,200
process memory uh we're writing the Yara

733
00:25:43,200 --> 00:25:46,320
rules for process memory uh versus like

734
00:25:46,320 --> 00:25:49,980
files on disk so the really upside the

735
00:25:49,980 --> 00:25:51,360
really cool upside of that is like if

736
00:25:51,360 --> 00:25:53,580
the binary has been packed or otherwise

737
00:25:53,580 --> 00:25:56,340
encrypted or encoded we're scraping it

738
00:25:56,340 --> 00:25:58,860
after it's already been loaded in memory

739
00:25:58,860 --> 00:26:00,480
um and so it kind of bypasses that

740
00:26:00,480 --> 00:26:01,860
except for some like really weird

741
00:26:01,860 --> 00:26:04,200
esoteric malware

742
00:26:04,200 --> 00:26:06,179
um but if you're running if you're

743
00:26:06,179 --> 00:26:08,039
trying to run this uh in your own lab

744
00:26:08,039 --> 00:26:10,020
and you're throwing it against a

745
00:26:10,020 --> 00:26:12,299
directory of binaries or something

746
00:26:12,299 --> 00:26:14,880
um it may not match on the yarn rules

747
00:26:14,880 --> 00:26:17,159
and that might be why

748
00:26:17,159 --> 00:26:19,440
okay uh some quick acknowledgments uh

749
00:26:19,440 --> 00:26:21,600
the security protections team as a whole

750
00:26:21,600 --> 00:26:23,039
at elastic

751
00:26:23,039 --> 00:26:24,659
um has been like part of this whole

752
00:26:24,659 --> 00:26:28,260
Pipeline and helping us uh move this

753
00:26:28,260 --> 00:26:30,120
data through and it also

754
00:26:30,120 --> 00:26:31,860
part of this whole team of analyzing the

755
00:26:31,860 --> 00:26:33,480
malware and getting this out to open

756
00:26:33,480 --> 00:26:36,779
source Andrew Pease he's uh my best

757
00:26:36,779 --> 00:26:39,299
friend since they're great uh but he's

758
00:26:39,299 --> 00:26:41,340
also my supervisor at elastic and part

759
00:26:41,340 --> 00:26:43,980
of the team and he's just just a great

760
00:26:43,980 --> 00:26:46,140
uh contributor all around and pulling

761
00:26:46,140 --> 00:26:49,080
together talented people uh such as

762
00:26:49,080 --> 00:26:51,900
Jessica and other people and me

763
00:26:51,900 --> 00:26:53,700
occasionally but

764
00:26:53,700 --> 00:26:55,980
yeah we have lots of time for questions

765
00:26:55,980 --> 00:26:57,480
now which we'd love to answer if you

766
00:26:57,480 --> 00:26:59,340
have I don't know if our slack moderator

767
00:26:59,340 --> 00:27:00,720
is nearby

768
00:27:00,720 --> 00:27:02,700
um but yeah this is the repo link here

769
00:27:02,700 --> 00:27:04,220
in the short link if you go to San

770
00:27:04,220 --> 00:27:08,400
c42022 after the ela.sd you can go take

771
00:27:08,400 --> 00:27:10,440
a look there uh yeah this is Derek Cruz

772
00:27:10,440 --> 00:27:12,900
both on Twitter and GitHub and me who's

773
00:27:12,900 --> 00:27:15,059
only on GitHub they're trying to find me

774
00:27:15,059 --> 00:27:17,159
on Twitter I'm not there uh but yeah

775
00:27:17,159 --> 00:27:19,740
thanks so much uh and yeah if you have

776
00:27:19,740 --> 00:27:21,120
any questions

777
00:27:21,120 --> 00:27:23,760
[Music]

778
00:27:23,760 --> 00:27:26,760
foreign

