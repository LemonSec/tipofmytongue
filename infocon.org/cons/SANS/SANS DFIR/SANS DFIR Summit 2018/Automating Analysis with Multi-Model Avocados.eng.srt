1
00:00:10,043 --> 00:00:13,178
(audience applauding)

2
00:00:13,179 --> 00:00:18,184
- I have something here, because
I'm gonna be talking to you

3
00:00:19,652 --> 00:00:22,689
about Automating Analysis
with Multi-Model Avocados.

4
00:00:22,689 --> 00:00:27,694
So, I have some shirts here
with some avocados on 'em.

5
00:00:28,828 --> 00:00:30,663
I might just throw
them out to you guys,

6
00:00:30,663 --> 00:00:32,532
but you might have
to pass them around

7
00:00:32,531 --> 00:00:35,434
because the sizes
are kind of funky.

8
00:00:35,435 --> 00:00:38,104
So, if you get,
like, one and just

9
00:00:38,104 --> 00:00:40,740
pass it 'til someone can use
it, I guess, I don't know.

10
00:00:40,740 --> 00:00:42,509
Here's a shirt, woo!

11
00:00:42,509 --> 00:00:43,443
(audience laughing)

12
00:00:43,443 --> 00:00:45,144
Alright, cool.

13
00:00:46,713 --> 00:00:50,617
By the way, the
multi-model avocados

14
00:00:50,617 --> 00:00:53,586
I'm talking about
here is ArangoDB.

15
00:00:53,586 --> 00:00:55,754
It's a database, just in case.

16
00:00:55,755 --> 00:00:57,924
By the way, I
predict the future.

17
00:00:57,924 --> 00:01:01,394
There's my Twitter handle
right there, Forensic Matt.

18
00:01:01,394 --> 00:01:04,396
Follow me, because
I have a feeling

19
00:01:04,397 --> 00:01:05,999
at the end of this presentation,

20
00:01:05,999 --> 00:01:07,533
you're going to say things like,

21
00:01:07,534 --> 00:01:10,537
Oh, where can I find that tool?

22
00:01:10,537 --> 00:01:13,206
Where can I find
this information
you're talking about?

23
00:01:13,206 --> 00:01:15,842
Well, I'll tweet about it,
throw up a blog post later

24
00:01:15,842 --> 00:01:18,044
'cause none of that
stuff is done yet,

25
00:01:18,044 --> 00:01:21,047
so, you know, just
follow me on Twitter.

26
00:01:21,047 --> 00:01:23,983
So, when I talk about
automated systems

27
00:01:26,719 --> 00:01:28,687
I don't want you guys
to immediately think,

28
00:01:28,688 --> 00:01:30,123
oh, this guy's trying to push

29
00:01:30,123 --> 00:01:33,159
a find everything forensic
button, or anything.

30
00:01:33,159 --> 00:01:34,694
No, it's not really like that.

31
00:01:36,196 --> 00:01:38,530
But, when we talk about
an automation system

32
00:01:38,531 --> 00:01:40,200
what does that entail?

33
00:01:40,200 --> 00:01:43,369
So, oftentimes, when we
do our investigations,

34
00:01:43,369 --> 00:01:44,771
I'm just gonna set,
well, you know what?

35
00:01:44,771 --> 00:01:46,306
Here, here's another shirt.

36
00:01:47,774 --> 00:01:50,777
All right, oh, that one
has a fox on it, actually,

37
00:01:50,777 --> 00:01:53,313
because we'll get
into that in a minute.

38
00:01:53,313 --> 00:01:54,814
(audience laughing)

39
00:01:54,814 --> 00:01:59,119
Alright, so, when we go through
our forensic investigations,

40
00:02:00,019 --> 00:02:02,655
this usually entails that

41
00:02:02,655 --> 00:02:05,191
we're looking for
very specific things.

42
00:02:05,191 --> 00:02:08,461
We go, generally we're given
a forensic image, right?

43
00:02:08,461 --> 00:02:10,396
Or, we made the forensic
image and we wanna

44
00:02:10,395 --> 00:02:12,531
pull some stuff out, look at it.

45
00:02:12,532 --> 00:02:16,102
So, we do an extraction,
we run a tool on,

46
00:02:16,102 --> 00:02:18,471
let's say we're looking
for past executions.

47
00:02:18,471 --> 00:02:19,939
This could be Prefetch, right?

48
00:02:19,939 --> 00:02:21,875
So, we pull out Prefetch,
we run a tool on it,

49
00:02:21,875 --> 00:02:26,246
we get output, but we need to
know that something happens.

50
00:02:26,246 --> 00:02:30,450
So, let's go ahead and
extract out the registry,

51
00:02:30,450 --> 00:02:33,519
let's look at the Bam
keys, the Dam keys,

52
00:02:34,921 --> 00:02:36,456
'cause we need to put
more information together.

53
00:02:36,456 --> 00:02:39,259
So by the end of it,
we've extracted out,

54
00:02:39,259 --> 00:02:40,893
I don't know, 20
different artifacts,

55
00:02:40,894 --> 00:02:42,695
ran 20 different tools,
and now we have to

56
00:02:42,695 --> 00:02:44,430
do something with
this output, right?

57
00:02:44,430 --> 00:02:48,401
So, automation system,
we want to use tools,

58
00:02:48,401 --> 00:02:50,370
we want to take that output,

59
00:02:50,370 --> 00:02:53,840
ingest it into a
storage of some sort.

60
00:02:53,840 --> 00:02:56,376
Then, when it's in
the storage point,

61
00:02:56,376 --> 00:02:59,045
we wanna do some type of
analysis, so that in the end

62
00:02:59,045 --> 00:03:01,881
we get meaningful reports,
and it would be great

63
00:03:01,881 --> 00:03:04,250
if we just didn't
have to do a whole lot

64
00:03:04,250 --> 00:03:09,255
between then and the tool
or the image in the report,

65
00:03:10,690 --> 00:03:12,725
so that we have more time
to do meaningful stuff.

66
00:03:12,725 --> 00:03:17,730
So, in looking at this,
we, the better the tool,

67
00:03:18,598 --> 00:03:20,500
the better our output can be.

68
00:03:20,500 --> 00:03:23,203
And by having better output,

69
00:03:23,203 --> 00:03:26,306
it enables us to
do better analysis,

70
00:03:26,306 --> 00:03:29,576
and better analysis
leads to a better report.

71
00:03:29,576 --> 00:03:31,945
So, we have a tool
problem, though.

72
00:03:31,945 --> 00:03:35,815
There's a challenge here,
because when I look for a tool

73
00:03:35,815 --> 00:03:40,153
I want all of the artifact,
not just some of the artifact.

74
00:03:41,921 --> 00:03:45,058
But, I'm scared that
the tool thought I said,

75
00:03:45,058 --> 00:03:47,694
give me a lot of artifact.

76
00:03:47,694 --> 00:03:50,929
But what I want is the whole
artifact, I want all of it.

77
00:03:50,930 --> 00:03:52,332
But, the problem here is that

78
00:03:52,332 --> 00:03:56,035
there's output
that's for humans,

79
00:03:56,035 --> 00:03:59,172
and then there's output that
we need that's for analysis,

80
00:03:59,172 --> 00:04:01,808
and the two don't go
together very well, right?

81
00:04:01,808 --> 00:04:04,944
So, when you get
output for humans,

82
00:04:04,944 --> 00:04:07,179
you're looking at TSV output,

83
00:04:07,180 --> 00:04:10,283
you're looking at
comma-separated
value output, right?

84
00:04:12,051 --> 00:04:14,220
Excel, right?

85
00:04:14,220 --> 00:04:16,289
It's very linear.

86
00:04:16,289 --> 00:04:19,926
But, the problem is, when a
tool starts trying to give us

87
00:04:19,926 --> 00:04:22,027
things that it thinks
we would wanna see,

88
00:04:23,463 --> 00:04:25,398
it can start skipping some data.

89
00:04:25,398 --> 00:04:28,301
Because in reality,
the data structures

90
00:04:28,301 --> 00:04:31,137
behind these artifacts
are very nested.

91
00:04:31,137 --> 00:04:33,606
They're not flat
data structures.

92
00:04:33,606 --> 00:04:35,942
And so, when you try
and flatten it out,

93
00:04:35,942 --> 00:04:38,578
you get a lot of
either duplicated data

94
00:04:38,578 --> 00:04:39,878
or there's some
data that just like,

95
00:04:39,879 --> 00:04:41,214
I don't know how to
show this to you,

96
00:04:41,214 --> 00:04:43,616
because it's too much
for a human to look at.

97
00:04:43,616 --> 00:04:46,152
So, we need that
output for analysis.

98
00:04:46,152 --> 00:04:48,087
Why do we need this?

99
00:04:48,087 --> 00:04:51,424
So, oh, real quick,
how do I go back?

100
00:04:51,424 --> 00:04:55,227
Yeah, so, output for
analysis might be

101
00:04:55,228 --> 00:04:57,130
way more complicated data,

102
00:04:57,130 --> 00:05:01,701
because it's gonna be very
nested data structures, right?

103
00:05:01,701 --> 00:05:04,704
So, generally, like
JSON-type data,

104
00:05:04,704 --> 00:05:07,774
or XML, XML can be
nested, as well,

105
00:05:07,774 --> 00:05:10,777
but it's very difficult to go
through that with a human eye.

106
00:05:10,777 --> 00:05:14,514
So, we look at, why
do we need this?

107
00:05:14,514 --> 00:05:16,215
Because there's
so many artifacts.

108
00:05:16,215 --> 00:05:18,251
And when we take a step back,

109
00:05:20,086 --> 00:05:22,789
the more artifacts
we can put together

110
00:05:22,789 --> 00:05:24,824
the bigger picture
we start to see.

111
00:05:26,759 --> 00:05:30,196
So, ShellBags tells
us something, MFTs
tell us something,

112
00:05:30,196 --> 00:05:34,567
Prefetch, USN, all of these
things tell us one thing,

113
00:05:34,567 --> 00:05:36,602
but when we start looking
at all of them together,

114
00:05:36,602 --> 00:05:38,404
it shows us a much
larger picture.

115
00:05:39,539 --> 00:05:43,609
So this is why we need
data for analysis.

116
00:05:43,609 --> 00:05:47,714
Because when we have
this nested data,

117
00:05:47,714 --> 00:05:50,116
generally we have things
that we're missing

118
00:05:50,116 --> 00:05:52,018
in something like TSV form.

119
00:05:53,619 --> 00:05:58,624
Because you're just able to
throw all of the data into it

120
00:05:59,492 --> 00:06:00,727
instead of just some of it.

121
00:06:01,861 --> 00:06:04,630
Now we can link these
artifacts together

122
00:06:04,630 --> 00:06:08,433
and start looking at a much
larger picture all together.

123
00:06:10,036 --> 00:06:12,839
But there's an
analysis challenge here

124
00:06:12,839 --> 00:06:16,743
because if a tool only
gave us output for analysis

125
00:06:16,743 --> 00:06:18,311
and not output for humans,

126
00:06:19,679 --> 00:06:22,181
it's very difficult to
navigate that type of data.

127
00:06:22,181 --> 00:06:25,618
If you had a huge
JSON dump, you know,

128
00:06:25,618 --> 00:06:27,587
how are you gonna
go through that?

129
00:06:27,587 --> 00:06:30,923
They make some JSON querying
tools that can help,

130
00:06:30,923 --> 00:06:33,993
but it's just, it's really hard

131
00:06:33,993 --> 00:06:35,928
to go through that type of data.

132
00:06:37,530 --> 00:06:39,565
So we have issues
of navigating it,

133
00:06:39,565 --> 00:06:42,835
we have issues of
searching through it.

134
00:06:42,835 --> 00:06:45,805
Granted, you can always just,
you know, grep through it.

135
00:06:45,805 --> 00:06:46,639
Why not?

136
00:06:47,807 --> 00:06:49,876
But then, what if we
wanted to correlate it?

137
00:06:49,876 --> 00:06:52,645
What if we had JSON
output from one tool

138
00:06:52,645 --> 00:06:54,914
and JSON output for another tool

139
00:06:54,914 --> 00:06:56,482
and we wanna combine it together

140
00:06:56,482 --> 00:06:58,718
and kinda make it
relational type data?

141
00:06:58,718 --> 00:07:00,553
It's really hard, right?

142
00:07:00,553 --> 00:07:03,256
Not to mention the challenge
of formatting the data.

143
00:07:03,256 --> 00:07:06,626
Because, in the end,
we can't give a lawyer

144
00:07:06,626 --> 00:07:08,861
a whole bunch of JSON, right?

145
00:07:08,861 --> 00:07:09,762
That's just dumb.

146
00:07:11,130 --> 00:07:14,167
But then there's the challenge
of automating all of it.

147
00:07:15,301 --> 00:07:17,870
So these are the
challenges we face.

148
00:07:17,870 --> 00:07:22,208
So we need a solution that
can address those challenges.

149
00:07:23,376 --> 00:07:25,311
I give you ArangoDB.

150
00:07:26,446 --> 00:07:28,948
Not only is its icon avocados,

151
00:07:28,948 --> 00:07:31,049
what's that, somebody
wants a shirt?

152
00:07:31,050 --> 00:07:31,884
All right.

153
00:07:33,486 --> 00:07:34,353
Oh.

154
00:07:34,353 --> 00:07:35,621
(audience laughing)

155
00:07:35,621 --> 00:07:37,490
The shirt didn't fly too
well and it's unwrapped.

156
00:07:37,490 --> 00:07:38,758
My bad.

157
00:07:38,758 --> 00:07:39,926
But the purple ones
are ladies' shirts,

158
00:07:39,926 --> 00:07:41,594
so that works out well.

159
00:07:41,594 --> 00:07:43,930
All right, so why ArangoDB?

160
00:07:43,930 --> 00:07:46,666
It's a multi-model
database which consists of

161
00:07:46,666 --> 00:07:49,969
a document store, a
graphing database,

162
00:07:49,969 --> 00:07:54,040
and a key-value store,
all in one package,

163
00:07:54,040 --> 00:07:55,541
which is awesome.

164
00:07:55,541 --> 00:07:58,211
So we need a document store
because of our data structure.

165
00:07:58,211 --> 00:08:00,012
It's nested.

166
00:08:00,012 --> 00:08:04,650
But the problem with a lot
of no-SQL solutions is that

167
00:08:04,650 --> 00:08:08,020
you can't relationally
connect your data.

168
00:08:09,222 --> 00:08:11,991
Well, with Arango,
we can do this.

169
00:08:11,991 --> 00:08:16,996
We can correlate values from our

170
00:08:17,864 --> 00:08:20,233
highly nested data structures.

171
00:08:20,233 --> 00:08:21,634
It has a great query language.

172
00:08:21,634 --> 00:08:25,204
This is awesome, the
relational queries,

173
00:08:25,204 --> 00:08:29,475
and great thing, it's
not written in Java!

174
00:08:29,475 --> 00:08:32,378
Now, if I told you
Java needs to die,

175
00:08:32,378 --> 00:08:33,880
everyone would be like, haha.

176
00:08:33,880 --> 00:08:38,618
But if Jake Williams says
it, maybe Java needs to die.

177
00:08:39,217 --> 00:08:40,453
I don't know.

178
00:08:40,453 --> 00:08:42,087
Anyways, but the great
thing about this is

179
00:08:42,087 --> 00:08:44,857
it still maintains a
scalable environment.

180
00:08:44,857 --> 00:08:47,360
So you can still spin
up a bunch of servers

181
00:08:47,360 --> 00:08:48,594
and create your clusters

182
00:08:48,594 --> 00:08:50,796
just like you can with
something like Elastic.

183
00:08:51,998 --> 00:08:54,400
And I'm sure some of you
in here have experience

184
00:08:54,400 --> 00:08:57,502
with trying to put all of
your data into Elastic.

185
00:08:57,503 --> 00:08:59,839
And then it's just
hard to go through.

186
00:08:59,839 --> 00:09:01,874
Let's just not even
talk about Elastic.

187
00:09:03,009 --> 00:09:04,577
Anyways, so, another
great thing about it is,

188
00:09:04,577 --> 00:09:06,546
it ships with JavaScript
microservices,

189
00:09:06,546 --> 00:09:08,581
which are fantastic
because you can spin up

190
00:09:08,581 --> 00:09:12,285
your own interfaces, if
you wanted to write some,

191
00:09:12,285 --> 00:09:14,987
and when your server spins
up, you can just access those.

192
00:09:14,987 --> 00:09:17,089
So, and there's a great
interface that ships with it,

193
00:09:17,089 --> 00:09:18,491
kind of like Cabana type thing.

194
00:09:18,491 --> 00:09:20,793
So what can we do with ArangoDB

195
00:09:20,793 --> 00:09:24,864
that really helps us to
see the larger picture

196
00:09:24,864 --> 00:09:28,100
and created a automated
analysis workflow?

197
00:09:29,535 --> 00:09:31,704
One of the things we
can do is correlations.

198
00:09:31,704 --> 00:09:32,838
Shirt time!

199
00:09:37,109 --> 00:09:40,046
I really hope I don't
hit anyone's coffee
and knock it over.

200
00:09:40,046 --> 00:09:41,480
That would be bad, actually.

201
00:09:41,480 --> 00:09:43,516
Maybe I should not do this.

202
00:09:43,516 --> 00:09:47,218
Value-based correlations,
so in a second,

203
00:09:47,219 --> 00:09:50,189
we'll see an example of
it, but this is like,

204
00:09:50,189 --> 00:09:53,025
MFTs, they have file
reference numbers, right?

205
00:09:53,025 --> 00:09:54,560
How many other
artifacts out there

206
00:09:54,560 --> 00:09:56,061
have file reference numbers?

207
00:09:56,062 --> 00:09:58,230
You can find file reference
numbers in the USN journal

208
00:09:58,230 --> 00:10:01,601
and the log file and
Prefetch data, leap files.

209
00:10:04,070 --> 00:10:05,571
They're all over the place.

210
00:10:05,571 --> 00:10:08,107
So now we can correlate and
link these documents together,

211
00:10:08,107 --> 00:10:08,975
which is great.

212
00:10:08,975 --> 00:10:10,109
What about range based?

213
00:10:11,277 --> 00:10:14,580
What if I wanted to
say, oh, I want to see

214
00:10:14,580 --> 00:10:17,049
30 seconds of the given artifact

215
00:10:17,049 --> 00:10:19,885
after I see something
else in another artifact?

216
00:10:19,885 --> 00:10:23,322
What if I see something
bad in the Prefetch

217
00:10:23,322 --> 00:10:26,459
and I wanna look at
historical records

218
00:10:26,459 --> 00:10:29,862
five seconds after that thing
happened in the Prefetch,

219
00:10:29,862 --> 00:10:32,131
or after we know
executable rate, right?

220
00:10:32,131 --> 00:10:34,132
We can do that,
that's a correlation.

221
00:10:35,601 --> 00:10:37,837
You can create your own custom
functions, which is awesome,

222
00:10:37,837 --> 00:10:40,840
because a lot of the time we
process forensic artifacts

223
00:10:40,840 --> 00:10:44,276
and we still have values
that are decoded, right?

224
00:10:44,276 --> 00:10:45,844
PowerShell, base 64, right?

225
00:10:45,845 --> 00:10:47,480
If we get PowerShell logs,

226
00:10:47,480 --> 00:10:49,915
we still have to
decode with base 64.

227
00:10:49,915 --> 00:10:52,050
So we needed some way to
do decoding on the fly

228
00:10:52,051 --> 00:10:55,421
so that we can do more
analysis on the database side.

229
00:10:56,422 --> 00:10:58,124
So then I'm gonna talk about

230
00:10:58,124 --> 00:10:59,525
something a little
bit more complex,

231
00:10:59,525 --> 00:11:01,861
which is pattern-based
searching.

232
00:11:01,861 --> 00:11:03,896
And this is when you
can actually group

233
00:11:03,896 --> 00:11:07,565
and aggregate artifacts and
look for very specific patterns.

234
00:11:07,566 --> 00:11:08,768
And this is great.

235
00:11:08,768 --> 00:11:10,536
This even goes back to what

236
00:11:10,536 --> 00:11:13,672
the FireEyes guys
were talking about,

237
00:11:13,673 --> 00:11:18,344
with needing some type
of resilient pattern,

238
00:11:18,344 --> 00:11:20,479
resilient signature.

239
00:11:20,479 --> 00:11:21,714
Talk about this in a second.

240
00:11:21,714 --> 00:11:24,717
Here's an example,
ShellBag difficulties.

241
00:11:24,717 --> 00:11:26,752
You're looking through ShellBags

242
00:11:26,752 --> 00:11:31,757
and you see two folders
on the same volume.

243
00:11:32,491 --> 00:11:33,092
In this case, it's E.

244
00:11:35,661 --> 00:11:39,598
Did these two, are these two
folders from the same volume?

245
00:11:39,598 --> 00:11:43,536
Now, sometimes we can
figure this out really fast

246
00:11:43,536 --> 00:11:48,306
because maybe one's an NTFS
volume and one's a FAT volume

247
00:11:48,307 --> 00:11:52,144
and we know that FAT doesn't
have the NFT sequence numbers,

248
00:11:52,144 --> 00:11:54,780
which we would see
if it was NTFS.

249
00:11:54,780 --> 00:11:56,247
But it's not always that easy.

250
00:11:57,416 --> 00:11:59,018
But to answer a
question like this,

251
00:11:59,018 --> 00:12:00,586
let's look at our
underlying data.

252
00:12:00,586 --> 00:12:02,054
ShellBag data.

253
00:12:02,054 --> 00:12:05,690
You have MFT entries,
this is important to us.

254
00:12:05,691 --> 00:12:07,727
You have sequence numbers.

255
00:12:07,727 --> 00:12:11,297
And then you have the
name of the folder itself.

256
00:12:11,297 --> 00:12:13,032
What about link data?

257
00:12:13,032 --> 00:12:17,103
All right, so you see here
an example of nested data.

258
00:12:19,004 --> 00:12:22,208
The link file structure
is not flat, by any means.

259
00:12:22,208 --> 00:12:25,010
It doesn't even resemble a TSV.

260
00:12:25,010 --> 00:12:26,112
It's very nested.

261
00:12:26,112 --> 00:12:27,545
But what are we interested in?

262
00:12:27,546 --> 00:12:30,116
We're interested
in the file name,

263
00:12:30,116 --> 00:12:33,686
we're interested in any type,
the volume serial number,

264
00:12:33,686 --> 00:12:36,188
we're interested in
reference numbers,

265
00:12:36,188 --> 00:12:38,189
sequence numbers, entry numbers.

266
00:12:38,190 --> 00:12:39,692
So the cool thing about this is,

267
00:12:39,692 --> 00:12:44,663
they're shell items per folder
and file of the local path.

268
00:12:45,698 --> 00:12:48,701
So you see a
testfile054 up there,

269
00:12:48,701 --> 00:12:51,871
you would have an entry for
that, a entry for testfolder001.

270
00:12:53,672 --> 00:12:56,342
And what that means
is, you have parents,

271
00:12:56,342 --> 00:12:59,645
you have entry numbers
and sequence numbers

272
00:12:59,645 --> 00:13:01,547
for every single path
in the link file.

273
00:13:01,547 --> 00:13:02,982
This is great because that means

274
00:13:02,982 --> 00:13:06,185
we can correlate link files
and ShellBags together

275
00:13:06,185 --> 00:13:10,222
because we want to know, were
they two separate volumes?

276
00:13:10,222 --> 00:13:12,525
So here's an example,
you don't really

277
00:13:12,525 --> 00:13:14,093
need to know what it says,

278
00:13:14,093 --> 00:13:16,795
but the just is, we're gonna
iterate through our link files

279
00:13:16,796 --> 00:13:21,500
and say, hey, let's compare
anything where the file name,

280
00:13:21,500 --> 00:13:24,970
the entry numbers, and the
sequence numbers are the same

281
00:13:24,970 --> 00:13:26,572
with those in the ShellBags.

282
00:13:26,572 --> 00:13:29,375
Because in the end, what we
want is something like this,

283
00:13:29,375 --> 00:13:34,380
where we can say, hey,
no, we found a correlation

284
00:13:35,514 --> 00:13:36,949
and we can tell you
that these two folders,

285
00:13:36,949 --> 00:13:39,185
while they're on the
same E, they look

286
00:13:40,419 --> 00:13:43,589
they come from the E
drive and the ShellBags,

287
00:13:43,589 --> 00:13:46,025
they're not the same volume.

288
00:13:46,025 --> 00:13:48,526
That's important
because now we know,

289
00:13:48,527 --> 00:13:50,529
if we were looking at
just the ShellBags,

290
00:13:50,529 --> 00:13:53,199
we might say, hey, these
things, it's the same volume,

291
00:13:53,199 --> 00:13:55,467
but no, it's two
separate drives.

292
00:13:55,467 --> 00:13:59,305
ShellBags stores it on
a drive-letter basis.

293
00:13:59,305 --> 00:14:00,539
So, tool shout outs!

294
00:14:00,539 --> 00:14:02,074
Guys, I'm not making
this stuff up.

295
00:14:02,074 --> 00:14:07,045
I didn't just generate this
data from somewhere random.

296
00:14:08,180 --> 00:14:09,348
No, I used real tools
out there, right?

297
00:14:09,348 --> 00:14:11,483
So thanks, Eric, thank you, G-C,

298
00:14:11,483 --> 00:14:14,686
thank you, Dave, Dave Callan.

299
00:14:14,687 --> 00:14:18,257
He's generous, he throws
out tools, it's cool.

300
00:14:19,458 --> 00:14:21,727
What about a more
complex question?

301
00:14:21,727 --> 00:14:23,795
Did a wiper run?

302
00:14:23,796 --> 00:14:25,531
What files were wiped?

303
00:14:25,531 --> 00:14:27,800
Where do we go to
for this information?

304
00:14:28,701 --> 00:14:31,003
Execution artifacts, right?

305
00:14:31,003 --> 00:14:33,305
We have file history artifacts.

306
00:14:33,305 --> 00:14:36,407
So, two that come
to mind, Prefetch,

307
00:14:36,408 --> 00:14:39,945
we can find execution
artifacts there, USN journal,

308
00:14:39,945 --> 00:14:42,948
historic file
activity, great things.

309
00:14:42,948 --> 00:14:45,251
What's in our Prefetch data?

310
00:14:45,251 --> 00:14:46,651
Prefetch data has runtimes.

311
00:14:49,488 --> 00:14:51,023
It has the file names in there.

312
00:14:52,157 --> 00:14:54,860
What about USN record data?

313
00:14:54,860 --> 00:14:59,064
That's going to give us,
on a per-change basis,

314
00:14:59,064 --> 00:15:04,002
one, the reason the
file has a log in it,

315
00:15:05,204 --> 00:15:06,704
which is why it was
changed, basically,

316
00:15:07,873 --> 00:15:09,975
the timestamp of
the change itself,

317
00:15:09,975 --> 00:15:11,877
file names, reference
numbers, again,

318
00:15:11,877 --> 00:15:15,481
more correlation
points for later.

319
00:15:15,481 --> 00:15:19,718
But what would a query look like

320
00:15:19,718 --> 00:15:22,988
where we could say,
hey, did a wiper run?

321
00:15:22,988 --> 00:15:25,224
Were there files erased?

322
00:15:26,325 --> 00:15:28,694
What if we could
automate this process

323
00:15:28,694 --> 00:15:32,031
and just have this
query that goes through

324
00:15:32,031 --> 00:15:35,099
and it looks for
some known examples.

325
00:15:35,100 --> 00:15:37,770
So we know, if we look
through our Prefetch

326
00:15:37,770 --> 00:15:40,739
and we see something called
Eraser, we know that's a wiper.

327
00:15:42,074 --> 00:15:46,312
Let's look for the
file system activity

328
00:15:47,746 --> 00:15:52,617
10 seconds after we know,
between the time Eraser ran

329
00:15:52,618 --> 00:15:56,555
and 10 seconds after it,
within the USN records,

330
00:15:56,555 --> 00:16:00,025
to find out what was
happening on the disk.

331
00:16:00,025 --> 00:16:03,963
When we run something like
this, this is the result.

332
00:16:05,364 --> 00:16:09,868
And so we see, Prefetch was ran,

333
00:16:09,868 --> 00:16:12,371
we find that from the runtime,

334
00:16:12,371 --> 00:16:14,473
and then we're looking
from that point

335
00:16:14,473 --> 00:16:17,276
to 10 seconds after that
point in the USN journal.

336
00:16:17,276 --> 00:16:19,344
And we see something
real nice looking.

337
00:16:20,679 --> 00:16:23,682
These look like wipe files.

338
00:16:23,682 --> 00:16:26,118
We can see that
because our first file,

339
00:16:27,319 --> 00:16:29,854
and in this example,
it's in plain text,

340
00:16:29,855 --> 00:16:32,891
we see the data
overwrite change.

341
00:16:32,891 --> 00:16:36,929
After that, we see that it goes
through a iteration process

342
00:16:36,929 --> 00:16:39,298
of being renamed several times.

343
00:16:40,332 --> 00:16:43,369
Finally, this same file has

344
00:16:43,369 --> 00:16:45,904
a file delete
operation done on it.

345
00:16:47,339 --> 00:16:49,742
And we know it's the same file
because of the entry number.

346
00:16:49,742 --> 00:16:53,645
So, there's a problem
with this, though.

347
00:16:53,645 --> 00:16:55,381
Well, first, tool shout outs.

348
00:16:55,381 --> 00:16:57,850
All right, so, a while back
I made some Rust tools.

349
00:16:57,850 --> 00:16:59,084
They're really cool.

350
00:16:59,084 --> 00:17:02,253
If you're into turning
artifacts into JSON,

351
00:17:02,254 --> 00:17:04,456
these are great tools for it.

352
00:17:04,455 --> 00:17:06,224
Plus, it's cool that
they're written in Rust,

353
00:17:06,224 --> 00:17:08,127
so they're super fast.

354
00:17:08,127 --> 00:17:10,128
And you can find
them on the GitHub.

355
00:17:10,128 --> 00:17:11,096
Links is up there.

356
00:17:12,964 --> 00:17:17,970
So, real quick, so there's
a problem with this

357
00:17:19,137 --> 00:17:23,274
and the problem is, we
can't quantify this.

358
00:17:23,275 --> 00:17:27,446
We know, we see five seconds'
worth of historical activity

359
00:17:27,445 --> 00:17:30,682
and it does look like erasing.

360
00:17:30,682 --> 00:17:31,917
But we need to go further.

361
00:17:31,917 --> 00:17:34,053
And we'll get to
that in a second.

362
00:17:34,053 --> 00:17:36,622
So let's talk about on-the-fly
decoding real quick.

363
00:17:36,622 --> 00:17:37,589
This is important.

364
00:17:40,893 --> 00:17:43,862
This is a cool, this is
the Windows Partition

365
00:17:43,862 --> 00:17:46,999
diagnostic event log.

366
00:17:46,999 --> 00:17:50,169
And this is something, Jason
Hale wrote a blog post on

367
00:17:50,169 --> 00:17:51,770
the other day, it
was really cool.

368
00:17:51,770 --> 00:17:55,874
Because traditionally,
volume serial numbers,

369
00:17:55,874 --> 00:17:58,644
which we were just
looking at in link files,

370
00:18:00,279 --> 00:18:04,550
were only really there if
you had ReadyBoost enabled.

371
00:18:04,550 --> 00:18:06,418
And now, it's very
rare that you have

372
00:18:06,418 --> 00:18:09,955
ReadyBoost enabled by default.

373
00:18:09,955 --> 00:18:14,092
So it's hard to link things
up with volume serial numbers

374
00:18:14,093 --> 00:18:17,096
to their correct
device information.

375
00:18:17,096 --> 00:18:21,233
You could do time range
correlations, right?

376
00:18:21,233 --> 00:18:22,701
Where you could say, okay, well,

377
00:18:22,701 --> 00:18:25,871
when was the last time that
a device was plugged in,

378
00:18:25,871 --> 00:18:27,439
and then go about it that way.

379
00:18:27,439 --> 00:18:28,841
But we don't need to.

380
00:18:28,841 --> 00:18:30,809
Now we could do some
on-the-fly decoding and say,

381
00:18:30,809 --> 00:18:32,077
hey, let's look at these events,

382
00:18:32,077 --> 00:18:34,713
because these are
new in Windows 10,

383
00:18:36,148 --> 00:18:40,552
and there's a hex string
of the entire VBR blocks,

384
00:18:41,820 --> 00:18:43,254
which is awesome.

385
00:18:43,255 --> 00:18:45,757
So it's within the VBR
blocks that we can pull out

386
00:18:45,757 --> 00:18:47,192
the volume serial numbers.

387
00:18:48,560 --> 00:18:50,995
But we need to make a
custom function to do that.

388
00:18:50,996 --> 00:18:53,232
So this is basically
how you would do that.

389
00:18:53,232 --> 00:18:55,734
The ArangoDB ships with a shell

390
00:18:55,734 --> 00:18:58,370
and you can register
functions with it.

391
00:18:58,370 --> 00:19:01,039
That works out great for
doing things like this.

392
00:19:01,039 --> 00:19:02,941
So I want to do a
query and I want to

393
00:19:02,941 --> 00:19:07,112
grab device information based
off of this Windows event

394
00:19:07,112 --> 00:19:09,815
and I want to be able
to decode on the fly

395
00:19:09,815 --> 00:19:13,018
those volume serial,
or the VBR blocks.

396
00:19:14,419 --> 00:19:16,622
So this is basically what
that would look like.

397
00:19:16,622 --> 00:19:21,093
We call our custom
function, WinEvent.

398
00:19:22,261 --> 00:19:23,896
And then what's the result?

399
00:19:23,896 --> 00:19:25,129
Something like this.

400
00:19:25,130 --> 00:19:28,867
So those VSNs are being
pulled out on the fly

401
00:19:28,867 --> 00:19:32,404
from those raw hex
stocks, which is huge.

402
00:19:32,404 --> 00:19:34,873
Because generally,
your tool is going to

403
00:19:34,873 --> 00:19:37,776
give you some type
of encoded data

404
00:19:37,776 --> 00:19:38,710
and then you're gonna have to

405
00:19:38,710 --> 00:19:40,212
further process that even more.

406
00:19:40,212 --> 00:19:42,681
So now we can do this
all on the storage level.

407
00:19:44,082 --> 00:19:45,350
More tool shout outs.

408
00:19:45,350 --> 00:19:49,454
Events JSON was used
for those examples.

409
00:19:51,290 --> 00:19:53,225
All right, so now we're gonna
talk about pattern searching.

410
00:19:53,225 --> 00:19:55,360
So pattern searching is cool

411
00:19:55,360 --> 00:19:59,231
because this is where
things can get dynamic.

412
00:19:59,231 --> 00:20:01,533
Because the problem is,

413
00:20:01,533 --> 00:20:04,035
you can't always
rely on an MD bypass.

414
00:20:04,036 --> 00:20:06,672
You can't always rely
on the name of a file

415
00:20:06,672 --> 00:20:08,407
because those things
change, right?

416
00:20:09,841 --> 00:20:12,311
So we wanted to create
some type of query

417
00:20:12,311 --> 00:20:15,379
that's able to aggregate
and group our artifacts.

418
00:20:15,380 --> 00:20:17,549
And we want to look for
something very specific.

419
00:20:17,549 --> 00:20:19,985
Once again, you don't
need to know what it says,

420
00:20:19,985 --> 00:20:22,721
you just need to know that
this is how easy it is

421
00:20:22,721 --> 00:20:25,857
to do the groupings,
do the aggregations.

422
00:20:25,857 --> 00:20:27,526
Why do we need to do this?

423
00:20:27,526 --> 00:20:29,895
Because let's go back
to the wiped files.

424
00:20:29,895 --> 00:20:33,498
We can't quantify, if
we tell a lawyer, hey,

425
00:20:33,498 --> 00:20:38,136
we know something's been
wiped, what are they gonna ask?

426
00:20:38,136 --> 00:20:39,805
They wanna know what was wiped,

427
00:20:39,805 --> 00:20:42,241
how much of it,
was it important.

428
00:20:42,241 --> 00:20:44,776
We need to be able to
give them those answers.

429
00:20:44,776 --> 00:20:47,212
So we wanna automate
this process, right?

430
00:20:47,212 --> 00:20:50,382
So what we can do
is, we now know that

431
00:20:50,382 --> 00:20:52,651
there's a pattern behind
our wiping utility.

432
00:20:53,819 --> 00:20:56,388
Then, in this case, when
we examine the data,

433
00:20:56,388 --> 00:21:00,391
we see that you have a
minimum of eight file names

434
00:21:00,392 --> 00:21:02,628
being, when a file gets erased,

435
00:21:02,628 --> 00:21:04,862
you have a minimum
of eight renames.

436
00:21:04,863 --> 00:21:08,100
So you have the
original name that gets,

437
00:21:08,100 --> 00:21:10,369
has the data
overwrite operation,

438
00:21:11,737 --> 00:21:14,006
it has a minimum of
three actions done to it

439
00:21:14,006 --> 00:21:17,276
before it gets
renamed to six more,

440
00:21:17,276 --> 00:21:19,244
it gets renamed six more times.

441
00:21:19,244 --> 00:21:21,713
Each rename, within
the USN journal,

442
00:21:22,814 --> 00:21:25,217
that file name,
under that file name,

443
00:21:25,217 --> 00:21:27,152
has five operations done to it,

444
00:21:27,152 --> 00:21:30,389
followed by a seventh
sequential rename,

445
00:21:30,389 --> 00:21:33,524
where it finally gets deleted.

446
00:21:33,525 --> 00:21:35,794
So this is actually a
pattern that we can use

447
00:21:35,794 --> 00:21:39,531
in being able to quantify
what all was erased.

448
00:21:39,531 --> 00:21:44,536
So, we want to be able to
create some type of signature

449
00:21:45,704 --> 00:21:48,840
that can look for
this type of activity.

450
00:21:48,840 --> 00:21:50,942
And what's cool about this is,

451
00:21:50,942 --> 00:21:53,645
you don't have to apply
this to just file erasing.

452
00:21:53,645 --> 00:21:57,883
This is to forensics in general.

453
00:21:57,883 --> 00:21:59,418
Like we just, we
want to look for

454
00:21:59,418 --> 00:22:01,019
pattern-based type of things.

455
00:22:01,019 --> 00:22:03,889
So now we throw our
signature into our query

456
00:22:03,889 --> 00:22:06,324
and this is the
result that we get.

457
00:22:06,325 --> 00:22:11,330
We found 138 files that
matched that pattern

458
00:22:12,764 --> 00:22:14,466
that we can now say, we know
all of these files were erased

459
00:22:14,466 --> 00:22:16,435
because it matched our pattern.

460
00:22:16,435 --> 00:22:20,504
Here are the original names,
here are the wiped names,

461
00:22:20,505 --> 00:22:24,509
and those are the times
when that file was erased.

462
00:22:24,509 --> 00:22:25,344
It's pretty big.

463
00:22:26,511 --> 00:22:30,581
So I wanna talk a
little bit about

464
00:22:31,783 --> 00:22:34,619
how we can automate
this entire process

465
00:22:34,619 --> 00:22:37,289
and why it's important, right?

466
00:22:37,289 --> 00:22:41,360
Because we're seeing
a lot more that

467
00:22:41,360 --> 00:22:42,727
lawyers are coming to us

468
00:22:42,728 --> 00:22:45,030
and they're giving us
more and more evidence,

469
00:22:45,030 --> 00:22:46,932
but they're wanting answers

470
00:22:46,932 --> 00:22:49,801
a lot faster than we
can give it to them.

471
00:22:51,536 --> 00:22:54,506
So a lot of this stuff
can be automated,

472
00:22:54,506 --> 00:22:56,141
so it should be automated.

473
00:22:56,141 --> 00:22:58,110
But we shouldn't have to
reinvent the whole wheel.

474
00:22:58,110 --> 00:22:59,444
There's a lot of tools out there

475
00:22:59,444 --> 00:23:01,178
that we wanna utilize in this.

476
00:23:01,179 --> 00:23:05,550
So can we make a system that
utilizes other people's tools,

477
00:23:05,550 --> 00:23:09,654
uses the output, puts it in
a centralized storage place,

478
00:23:09,654 --> 00:23:11,990
allows us to do analytics on it,

479
00:23:11,990 --> 00:23:15,160
and then gives us more
meaningful reports?

480
00:23:15,160 --> 00:23:19,464
Because very few
times are we able to

481
00:23:19,464 --> 00:23:23,635
just run one tool, get
one report out of it,

482
00:23:23,635 --> 00:23:25,003
and just hand that off.

483
00:23:25,003 --> 00:23:28,240
Usually, it's a combination
of multiple tools,

484
00:23:28,240 --> 00:23:31,343
multiple output, having to
put that output together,

485
00:23:31,343 --> 00:23:33,245
creating a report out of it,

486
00:23:33,245 --> 00:23:36,014
and then being able
to hand that off.

487
00:23:36,014 --> 00:23:40,017
So, here is an example,
here is a demonstration,

488
00:23:40,018 --> 00:23:41,353
that this can be done.

489
00:23:42,587 --> 00:23:45,757
So, we've downloaded
the ArangoDB package

490
00:23:45,757 --> 00:23:48,226
from ArangoDB site.

491
00:23:48,226 --> 00:23:50,429
It's a zip, which is awesome.

492
00:23:51,530 --> 00:23:52,798
What's cool about this is,

493
00:23:52,798 --> 00:23:54,833
you don't have to
install anything.

494
00:23:54,833 --> 00:23:57,502
You can just stand
this up wherever

495
00:23:57,502 --> 00:24:01,039
and it works on, they
have the OSX version,

496
00:24:01,039 --> 00:24:05,277
they have one that runs
on Linux, and Windows.

497
00:24:05,277 --> 00:24:07,245
And again, you
don't need the Java.

498
00:24:07,245 --> 00:24:08,879
Who cares?

499
00:24:08,880 --> 00:24:12,751
All right, so all you have
to do, it's this easy.

500
00:24:12,751 --> 00:24:16,354
You just run, you
start up your service,

501
00:24:16,354 --> 00:24:19,458
boom, it's up and
running, right?

502
00:24:19,458 --> 00:24:22,093
So, and it gives you a
socket, much like Cabana does,

503
00:24:22,093 --> 00:24:24,696
to where you can go there,
you're gonna see an interface.

504
00:24:24,696 --> 00:24:28,899
So now we need to mount a drive.

505
00:24:28,900 --> 00:24:31,636
And then, once we
mount this drive,

506
00:24:31,636 --> 00:24:33,605
by the way, I love Arsenal.

507
00:24:33,605 --> 00:24:35,207
This is one of my
favorite tools.

508
00:24:35,207 --> 00:24:36,908
It makes things very easy.

509
00:24:36,908 --> 00:24:39,610
All right, so we have
our tools folder.

510
00:24:39,611 --> 00:24:44,182
This is a tool that I worked
on as a proof-of-concept code.

511
00:24:44,182 --> 00:24:48,019
And what it does is, it
iterates through a volume,

512
00:24:48,019 --> 00:24:50,922
a live volume, and
it extracts out files

513
00:24:50,922 --> 00:24:52,624
and then runs tools
on those files.

514
00:24:52,624 --> 00:24:55,327
So in this case, we're
looking at Prefetch.

515
00:24:55,327 --> 00:24:58,797
It's basically looking for all
the files with a PF ending.

516
00:24:58,797 --> 00:25:01,433
It's gonna run the
Rusty Prefetch on it.

517
00:25:01,433 --> 00:25:02,901
Same with MFT.

518
00:25:02,901 --> 00:25:05,303
We've got some journal in there.

519
00:25:05,303 --> 00:25:08,073
And then the event logs as well.

520
00:25:08,073 --> 00:25:09,474
But this is great
because we can just

521
00:25:09,474 --> 00:25:12,878
utilize other people's
tools when we do this

522
00:25:12,878 --> 00:25:15,514
and then do analysis
with that output

523
00:25:15,514 --> 00:25:18,283
all in one central
storage location.

524
00:25:18,283 --> 00:25:21,986
So, we need to open up, we're
gonna open up PowerShell.

525
00:25:21,987 --> 00:25:23,922
We've gotta start
it in admin mode

526
00:25:23,922 --> 00:25:28,927
because you need that raw
handle to a logical volume

527
00:25:30,061 --> 00:25:31,730
because we had
mounted our image.

528
00:25:31,730 --> 00:25:35,667
So that image is now
mounted to drive letter I

529
00:25:35,667 --> 00:25:38,570
as a logical image.

530
00:25:38,570 --> 00:25:41,239
Always give a dash-H, tells
you how to use the tool.

531
00:25:42,641 --> 00:25:45,877
So what we're gonna do is,
we give it the source volume.

532
00:25:45,877 --> 00:25:48,079
In this case, it's I.

533
00:25:49,481 --> 00:25:53,618
Then we need to tell it to,
give it a temp folder location.

534
00:25:53,618 --> 00:25:57,022
Because a lot of these
files we have to export out

535
00:25:57,022 --> 00:25:58,822
before we can run
something on it.

536
00:26:03,261 --> 00:26:07,165
So then, we give it the
name of the database.

537
00:26:07,165 --> 00:26:08,867
So now it created a database

538
00:26:08,867 --> 00:26:10,769
and our Arango cluster
is going through,

539
00:26:10,769 --> 00:26:12,771
it's parsing out
all the link files,

540
00:26:12,771 --> 00:26:15,874
registry, USN journal, MFT,

541
00:26:15,874 --> 00:26:18,944
we see how many records
are being loaded in there.

542
00:26:18,944 --> 00:26:23,682
So, and set up API,
Prefetch, right?

543
00:26:25,216 --> 00:26:30,221
So now, what we wanna
do is, we can pull up,

544
00:26:31,356 --> 00:26:32,657
oh, I guess I gotta
let it catch up.

545
00:26:32,657 --> 00:26:34,192
By the way, it
doesn't go that fast.

546
00:26:34,192 --> 00:26:36,194
I wish it did, but I
had to speed it up,

547
00:26:36,194 --> 00:26:38,396
otherwise we'd be
sitting here for a while.

548
00:26:38,396 --> 00:26:41,733
Python's slow, but it allows
us to do amazing things.

549
00:26:43,168 --> 00:26:46,137
So then, oh, first we need
to use our Arango shell

550
00:26:46,137 --> 00:26:49,040
because we're going to
create our user functions,

551
00:26:50,375 --> 00:26:52,644
which we have done earlier,
and this is going to

552
00:26:52,644 --> 00:26:54,913
allow us to create reports using

553
00:26:54,913 --> 00:26:59,818
some of our more complex
custom functions.

554
00:26:59,818 --> 00:27:02,887
So, now we're ready to
go to our interface.

555
00:27:05,357 --> 00:27:08,994
Of course, there, by default
it's a root with no password

556
00:27:08,994 --> 00:27:10,261
because why wouldn't you?

557
00:27:11,763 --> 00:27:13,098
So here's all of
our collections.

558
00:27:13,098 --> 00:27:15,300
We have link files,
USN, stuff like this.

559
00:27:15,300 --> 00:27:18,837
This shows you, this is just
what that data looks like

560
00:27:18,837 --> 00:27:20,171
within the database.

561
00:27:23,274 --> 00:27:26,578
So here's the USN, USN
is relatively flat,

562
00:27:26,578 --> 00:27:28,446
but we nest out the
reference numbers

563
00:27:28,446 --> 00:27:30,148
so we can do those correlations.

564
00:27:31,249 --> 00:27:34,252
Here is Windows event logs.

565
00:27:34,252 --> 00:27:37,589
Event logs are great examples
of highly nested data.

566
00:27:38,456 --> 00:27:39,823
So, let's run some queries.

567
00:27:39,824 --> 00:27:41,493
So some of this we already saw.

568
00:27:41,493 --> 00:27:45,629
This one is looking at
PowerShell script logs.

569
00:27:46,965 --> 00:27:50,534
So this is what, we're
looking in the Windows events,

570
00:27:50,535 --> 00:27:54,639
we see the PowerShell
stuff, here is an example,

571
00:27:54,639 --> 00:27:56,875
I just wanted to show you all
what the interface looks like

572
00:27:56,875 --> 00:27:59,744
because we're going to just

573
00:27:59,744 --> 00:28:01,780
cut over to the
reports in a second.

574
00:28:01,780 --> 00:28:05,684
But this is what the interface
looks like for ArangoDB.

575
00:28:07,118 --> 00:28:11,656
So it gives you, just the
interface that ships with it

576
00:28:11,656 --> 00:28:14,726
gets you past those
complex issues of

577
00:28:16,127 --> 00:28:17,962
getting through the data
with searching, navigating,

578
00:28:17,962 --> 00:28:19,531
the things I talked
about earlier.

579
00:28:19,531 --> 00:28:21,966
So let's run some
scripts that we have.

580
00:28:21,966 --> 00:28:26,905
These are going to create
template Excel files.

581
00:28:28,573 --> 00:28:33,511
So now we went from image to
Excel reports, just like that.

582
00:28:33,511 --> 00:28:35,980
So there's one of
the PowerShell blocks

583
00:28:35,980 --> 00:28:40,218
you can see right there,
the DLL importing,

584
00:28:40,218 --> 00:28:42,087
things like the virtual outlet,

585
00:28:43,588 --> 00:28:44,956
things that we would question.

586
00:28:44,956 --> 00:28:49,494
Here's a spreadsheet
of our eraser

587
00:28:51,029 --> 00:28:52,697
and what files were
erased after that.

588
00:28:52,697 --> 00:28:56,367
And then this one
is the wipe files,

589
00:28:56,367 --> 00:28:59,738
using our signature-based
searching.

590
00:29:01,106 --> 00:29:05,910
So, that just gives
you an example.

591
00:29:05,910 --> 00:29:08,747
Yes, we can automate
a lot of this stuff.

592
00:29:10,115 --> 00:29:11,983
That doesn't mean it's
cutting anyone out of a job.

593
00:29:11,983 --> 00:29:14,985
It's going to allow us
to get to more important,

594
00:29:16,654 --> 00:29:20,458
it's going to enable us to
look for more complex things

595
00:29:20,458 --> 00:29:23,561
and just get rid of
the low-hanging fruit.

596
00:29:25,663 --> 00:29:27,899
And one of the things I love
about this conference is,

597
00:29:27,899 --> 00:29:29,300
there's so much relevant data

598
00:29:29,300 --> 00:29:30,735
being taught in
the presentations.

599
00:29:30,735 --> 00:29:33,138
I want a system like this that,

600
00:29:33,138 --> 00:29:35,473
when I watch someone talk
about a new artifact,

601
00:29:35,473 --> 00:29:38,276
I can plug it into this
system using their new tool.

602
00:29:38,276 --> 00:29:41,045
And now, every case that
comes through our lab,

603
00:29:41,045 --> 00:29:44,315
we can be accounting
for that information.

604
00:29:45,383 --> 00:29:46,317
Pretty big.

605
00:29:46,317 --> 00:29:48,286
I like it, I hope you liked it.

606
00:29:49,454 --> 00:29:51,656
That's about all
I've got for you.

607
00:29:52,590 --> 00:29:53,891
Right on, well thank you guys.

608
00:29:53,892 --> 00:29:55,360
I have more t-shirts.

609
00:29:55,360 --> 00:29:58,530
(audience applauding)

