1
00:00:16,640 --> 00:00:21,680
On the Hunt for the Unknown Unknowns
Addy Moran
      
 

2
00:00:21,680 --> 00:00:29,040
SOFIA: Talking about On the Hunt for the Unknown 
Unknowns by Addy Moran. But first of all, we want  

3
00:00:29,040 --> 00:00:37,280
to thank    we're gonna be thanking the sponsors 
that they make this conference possible. So, thank  

4
00:00:37,280 --> 00:00:45,040
you Addy for joining us today. And we're gonna 
be introducing you. And after that, feel free to  

5
00:00:45,040 --> 00:00:52,400
pop questions after her talk so we can answer.
Hi, Addy, welcome. Thank you for joining us.
 

6
00:00:52,400 --> 00:00:57,120
ADDY: Sure.
SOFIA: Okay. So, whenever you're ready  

7
00:00:57,120 --> 00:01:01,839
you can start presenting and you can go ahead.
ADDY: Can you guys see my slides?  

8
00:01:08,080 --> 00:01:16,800
Oh, boy. There, that worked? Sorry. Technical 
difficulties. Oh, my gosh. Recursion.  

9
00:01:18,000 --> 00:01:25,760
Okay. I'm good. Cool. Thank you. So, hi. I'm 
Addy, I work at Pacific Northwest National Labs  

10
00:01:25,760 --> 00:01:29,520
which is kind of like Sandia National Laboratory. 
It's based out of Richland, Washington.  

11
00:01:30,160 --> 00:01:33,360
I'm on the data visualization 
team and do full stack. Anywhere  

12
00:01:35,200 --> 00:01:38,000
from doing the data visualizations to the 
engineering that feeds the data visualizations.  

13
00:01:38,960 --> 00:01:45,280
This talk about is about how you can apply data 
visualization to cyber. So, without further ado.  

14
00:01:47,760 --> 00:01:51,120
I'm sure everyone is here.
They know how much data actually gets  

15
00:01:51,120 --> 00:01:58,800
stored. But before this talk, I didn't realize how 
much that actually was. So, there was a study that  

16
00:01:58,800 --> 00:02:05,440
was done that for about a thousand employee 
company, which I think is fairly average, and  

17
00:02:05,440 --> 00:02:10,240
with the standard IT setup, you know, you've got 
laptops and maybe some smart printers, scanners,  

18
00:02:11,120 --> 00:02:16,880
servers, et cetera. So, with just a basic setup, 
you store anywhere from 3 gigs to 113 gigs  

19
00:02:16,880 --> 00:02:23,359
per day. Which is just insane. And just 
going down to make things more complicated.  

20
00:02:24,480 --> 00:02:28,799
There's a non functional    sorry. 
Non functional requirements that  

21
00:02:30,400 --> 00:02:34,960
make you save the log files from anywhere from 
one day    I'm sorry, one year to seven years.  

22
00:02:35,520 --> 00:02:37,200
And that's usually security requirement.
 

23
00:02:38,720 --> 00:02:44,160
But on the low end, that's 1.1 terabytes. 
And on the high end, it's 42 per year. So,  

24
00:02:44,160 --> 00:02:49,840
let alone, 7 years later. That's just not 
possible to do by hand. Which the employee,  

25
00:02:50,640 --> 00:02:54,559
we don't actually really try. A lot of times 
the log files are never actually opened or seen  

26
00:02:55,840 --> 00:03:00,960
unless something happens.
So, moving on to like how  

27
00:03:01,520 --> 00:03:05,680
cyber is kind of worked today, or at least one 
section of it. And that's alert based security.  

28
00:03:06,240 --> 00:03:13,440
So, we have Splunk and Logstash and a couple other 
pretty common applications. You set up rules and  

29
00:03:13,440 --> 00:03:19,600
say if you see this activity, this is bad. Or 
this could be bad and needs more investigation.  

30
00:03:19,600 --> 00:03:26,320
Something like that. And this works tremendously. 
So, problem, though, is that you kind of need to  

31
00:03:26,320 --> 00:03:32,160
know what you're looking for. You need to be able 
to say, this is what looks weird. Or this is bad.
 

32
00:03:32,160 --> 00:03:36,880
And with cyber, I mean, I don't know who is 
interested in offensive. But there's the mentality  

33
00:03:36,880 --> 00:03:40,400
that to be a good offensive cybersecurity 
engineer, you need to break into something  

34
00:03:40,400 --> 00:03:45,600
once. To be a good defensive cybersecurity 
engineer, you need to defeat that attacker 100%  

35
00:03:45,600 --> 00:03:51,040
of the time. Which is a much harder job. I like to 
be offensive. You get to be creative and think in  

36
00:03:51,040 --> 00:03:56,320
ways that no one else has. Which means you don't 
know which rules to do because I'm trying to be  

37
00:03:56,320 --> 00:04:03,680
creative. So, super helpful for the things you 
know about and what they can look like. FireEye  

38
00:04:03,680 --> 00:04:09,200
in 2020 said that only 9% of attacks triggered 
security alert which is pretty interesting.
 

39
00:04:10,320 --> 00:04:17,040
So, moving on to threat hunting. So, threat 
hunting is a more proactive approach to  

40
00:04:17,040 --> 00:04:27,440
cybersecurity. Why where you can    things 
that you probably couldn't just look at.  

41
00:04:29,840 --> 00:04:31,440
There was a definition if 
you guys are interested.
 

42
00:04:32,800 --> 00:04:39,840
So, I will tie back to threat hunting. But first, 
data visualization. So, data visualization to me  

43
00:04:39,840 --> 00:04:44,560
is kind of like art. You know, tells a story 
to be good. Otherwise it's kind of confusing.  

44
00:04:44,560 --> 00:04:48,960
So, one of my favorites. I'm a huge Star 
Wars junky. You'll see multiple Star Wars  

45
00:04:49,840 --> 00:04:58,080
visualizations. Sorry. So, for 12 hours of 
videos, it's summarized in one chart I think  

46
00:04:58,080 --> 00:05:02,960
is pretty impressive. And you can get a general 
idea of what the storyline is like. This is in  

47
00:05:02,960 --> 00:05:11,120
my opinion a fairly good data visualization.
Here's another one. Look at how StackOverflow  

48
00:05:11,120 --> 00:05:15,920
changed during the week of DEFCON in Las Vegas. 
Which is interesting because you can almost start  

49
00:05:15,920 --> 00:05:20,720
figuring out what they talked about at the 
DEFCON conference without seeing the agenda  

50
00:05:20,720 --> 00:05:26,240
or anything about DEFCON except looking 
at what may have been a result of DEFCON.
 

51
00:05:28,000 --> 00:05:32,000
Another one. So, this one is really 
interesting. It's a 3D data visualization  

52
00:05:32,000 --> 00:05:38,240
using    it's a Twitter toxicity chart. 
It's basically saying, as a feed,  

53
00:05:38,240 --> 00:05:42,240
does the feed get toxic in like how people 
communicate with each other? Does it get  

54
00:05:42,240 --> 00:05:47,680
mean or angry? It's showing how different 
branches of conversation turns toxic.  

55
00:05:48,720 --> 00:05:55,200
And again, so, I guess I haven't said this 
yet. But it's not all about the, you know,  

56
00:05:55,200 --> 00:06:01,200
if a bio engineer can look at a data visualization 
I creates as a cybersecurity engineer or software  

57
00:06:01,200 --> 00:06:06,000
engineer, that they understand it. It's about 
the person who understands the data that they  

58
00:06:06,000 --> 00:06:12,560
understand it. I don't have a lot of experience 
with toxicity and communication data.  

59
00:06:13,520 --> 00:06:20,560
And so, this chart isn't nearly as helpful to me 
as it is for somebody else. But that's got to be  

60
00:06:21,360 --> 00:06:25,760
a lot of data stored in one picture. So, 
if you understood what the data is like,  

61
00:06:26,400 --> 00:06:28,080
visualizations like this can be very helpful.
 

62
00:06:30,000 --> 00:06:35,200
Another one. Another avenue of data visualization 
that's kind of emerging is augmented and virtual  

63
00:06:35,200 --> 00:06:40,560
reality data visualizations. Which is another 
way to view data that may be more intuitive.  

64
00:06:41,440 --> 00:06:49,280
So, that's data visualizations in a nutshell. None 
of it cyber related necessarily. So, I'm going to  

65
00:06:49,280 --> 00:06:55,599
deep dive into a cybersecurity data visualization 
example and then we can tie it all back together.
 

66
00:06:56,720 --> 00:07:03,200
So, at the Lab we have a program called 
PISCES. It's a program that ties students with  

67
00:07:04,800 --> 00:07:08,400
   well, how did they phrase it? 
I want to say it's kind of like,  

68
00:07:08,400 --> 00:07:13,200
oh, communities. Like government communities. 
So, that could be places that maybe not have  

69
00:07:13,200 --> 00:07:18,240
cybersecurity in their repertory yet because 
it's a small company or a small program. And so,  

70
00:07:18,240 --> 00:07:25,760
basically, it adds training to sounds and in 
doing so, helps the company get some cyber  

71
00:07:25,760 --> 00:07:30,960
information. And usually, it kind of ties in where 
a student can get hired by that company now.
 

72
00:07:32,160 --> 00:07:36,240
So, it just looks at packet headers. We're 
trying to, you know, keep the community  

73
00:07:36,240 --> 00:07:40,880
safe and not get too much information. So, the 
students are only ever see packet information.  

74
00:07:42,400 --> 00:07:46,799
A little more about the data itself. 
The data I'm visualizing today is 8  

75
00:07:47,600 --> 00:07:54,800
days, about 2.4 million records. Something 
that's different from what the students see,  

76
00:07:55,840 --> 00:08:02,560
I changed the IPs so that they're UUIDs 
just to help protect the communities.  

77
00:08:03,360 --> 00:08:08,080
So, the students actually see IP before 
and IPP6 packets. Just so you know.
 

78
00:08:10,480 --> 00:08:14,240
All right. So, I'm gonna start off with the things 
that worked and give the caveat that I have been a  

79
00:08:14,240 --> 00:08:19,760
software engineer for 6 years and specialized 
in data visualization for about the last  

80
00:08:19,760 --> 00:08:26,800
year and a half. And I still am struggle bussin'.
So, the things that worked off to start off with  

81
00:08:26,800 --> 00:08:33,520
was start small and improve as I go. I 
actually had to spend lots of quality  

82
00:08:33,520 --> 00:08:39,280
time making sure the data was good. I 
started off with a small amount of data.  

83
00:08:39,280 --> 00:08:46,160
Or a small time frame to get a small amount of 
data. Before I tried programming necessarily, I  

84
00:08:46,160 --> 00:08:50,640
wrote down us questions I was interested in. 
And I have examples at the end of the slides.  

85
00:08:51,760 --> 00:08:58,160
The things that the worked aren't necessarily 
in order. The things I tried to do was get  

86
00:08:58,160 --> 00:09:06,959
the Q1 packets. 8 days was 2.4 million records. I 
wasted so much time trying to get all the packet  

87
00:09:06,960 --> 00:09:13,520
headers for four months. I also wanted to do 
the coolest thing first because that's how I  

88
00:09:13,520 --> 00:09:17,920
work. Which is just terrible software engineering 
skills. I wanted to do something like that. That  

89
00:09:17,920 --> 00:09:23,599
is cool. I didn't want to do a bar graph or a 
pie chart. They are helpful depending on the  

90
00:09:23,600 --> 00:09:29,760
use case. I wanted to do something cool. Which 
didn't work out for me. Also another caveat,  

91
00:09:29,760 --> 00:09:36,319
that is another Star Wars data visualization 
that shows all of the character connections.  

92
00:09:36,320 --> 00:09:39,840
You can kind of see, there's lots of characters in 
Star Wars that are all interconnected very well.
 

93
00:09:41,760 --> 00:09:46,880
All right. Moving on. So, here are just some of 
the results. So, this is kind of like a tree map  

94
00:09:46,880 --> 00:09:52,400
where you can pick, you know, five plus    you can 
pick any number of fields that you're interested  

95
00:09:52,400 --> 00:09:57,840
in and see the connections. So, you can kind 
of see like, there was no weekend data. It was  

96
00:09:57,840 --> 00:10:03,600
all basically flow. Maybe a couple of stat 
points. You can see where most of the port  

97
00:10:03,600 --> 00:10:11,040
information came from. And given this is not all 
of the data, it's just a subsection of data. So,  

98
00:10:11,040 --> 00:10:15,280
I mean, out of the 2.4 million records, this isn't 
all of it. So, sometimes a data visualization,  

99
00:10:15,280 --> 00:10:19,280
you could have the data, but you kind 
of need to scale the problem even more.  

100
00:10:20,160 --> 00:10:23,920
Because, again, like if I tried to do all 
2.4 million records, this would be insane.
 

101
00:10:24,480 --> 00:10:33,680
I would guess off the cuff that this is probably 
showing, you know, 500,000 records? Give or take?  

102
00:10:33,680 --> 00:10:39,199
You know, some kind of aggregation. So, it's 
still a lot of data. A lot of data that would be a  

103
00:10:39,200 --> 00:10:49,440
pain to look at. I mean, you know. Or 
even doing Splunk alerts and things. So,  

104
00:10:51,280 --> 00:10:55,920
kind of see the connections here. You can do 
IP address. Again, these are UUIDs. These are  

105
00:10:55,920 --> 00:11:03,520
actual IP addresses in the system. But source 
and destination IPs. You can see who talks to who  

106
00:11:03,520 --> 00:11:10,640
and how they might be working. Take 
the video back. I'm pointing at my  

107
00:11:10,640 --> 00:11:15,040
screen like you guys can see it. Like 
a quarter of the way in there's a line.  

108
00:11:15,600 --> 00:11:23,040
That to me looks like a scanner. Because it talks 
to a lot of computers. Compared to others. You  

109
00:11:23,040 --> 00:11:27,839
know, versus some of these only talk to one 
system. Like on the far right hand corner,  

110
00:11:28,640 --> 00:11:32,480
upper right hand corner, there's just like 
one system that system communicates with.
 

111
00:11:34,640 --> 00:11:40,319
And then on the lower left, I do have some 
colors. And so, the yellow through the purple  

112
00:11:41,040 --> 00:11:47,120
are the ones that are a ton of data. So, the 
blues    the blue color means that they don't  

113
00:11:47,120 --> 00:11:52,480
send that much, and I can show you the scale. 
But like the yellow I think is in the hundred  

114
00:11:52,480 --> 00:11:58,320
of thousands packets. That system talks to each 
other a lot. Okay. There's the first diagram.
 

115
00:11:59,440 --> 00:12:05,360
All right. This is a similar one. But instead, 
I scaled it    scaled the bubbles. So, it's  

116
00:12:05,920 --> 00:12:12,800
off of the size of the packet. So, you can kind 
of see that even though some of them talk very  

117
00:12:12,800 --> 00:12:18,479
infrequently, they send a lot of data. And 
you can kind of see like my scanner idea,  

118
00:12:18,480 --> 00:12:21,120
what I thought was kind of a scanner. 
I'm guessing here. I don't actually know.  

119
00:12:23,360 --> 00:12:28,320
They're not very big packets. So, that could 
almost be a, hey, are you there? Kind of pings.  

120
00:12:30,240 --> 00:12:33,840
So, again, you can kind of start building 
on these data visualizations once you kind  

121
00:12:33,840 --> 00:12:39,200
of start seeing what they're all about. 
Again, this is just kind of a fun one.
 

122
00:12:40,880 --> 00:12:45,680
Another one. This one's in 3D which I think is 
super helpful. Because, you know, how I pointed  

123
00:12:45,680 --> 00:12:52,640
out in the lower left hand corner. You had to 
really zoom in and see these are the ones that  

124
00:12:52,640 --> 00:13:01,439
talked the most. I was wrong. It was over 300,000 
IP counts. I'm sorry, packet counts for the 8 days  

125
00:13:01,440 --> 00:13:05,840
between those two IP addresses. Compared to the 
others. I think there's only, you know, maybe  

126
00:13:07,280 --> 00:13:12,240
five, five or ten that talk to each 
other more than 25,000, give or take?  

127
00:13:13,760 --> 00:13:16,560
So, sometimes if you just look at the data 
a little differently, even though it's the  

128
00:13:16,560 --> 00:13:22,079
same data in the same kind of chart in 3D, 
it makes it much more intuitive. Because  

129
00:13:22,080 --> 00:13:26,080
whether you don't actually know what you're 
looking for, it can get kind of intimidating.
 

130
00:13:28,400 --> 00:13:32,240
All right. Moving on. So, a couple other 
ideas that have come up. And this is  

131
00:13:33,040 --> 00:13:38,640
mostly to show you how I started this process and 
the questions I started to ask. So, I'm gonna skip  

132
00:13:38,640 --> 00:13:42,880
a bullet. I should have put this in a different 
order. But like the questions I was asking was,  

133
00:13:43,440 --> 00:13:48,960
I care about what's infrequent. I have rules 
and things that say, I know this is bad.  

134
00:13:51,200 --> 00:13:57,440
But sometimes it's not always. In the sense 
of one of the most common insider threat  

135
00:13:58,080 --> 00:14:02,800
things is someone that works late or someone that 
works on the weekends. But that's not always true.  

136
00:14:03,920 --> 00:14:08,240
Like I work on the weekends kind of frequently. 
Or I work late because I live in a different time  

137
00:14:08,240 --> 00:14:14,960
zone than the rest of my company. And so, if they 
had a rule that says, anybody that works past 8:00  

138
00:14:15,520 --> 00:14:20,960
on my time zone is an insider threat, or someone 
who needs to be investigated. But if I do that  

139
00:14:21,520 --> 00:14:27,439
every day for four years, it's probably 
not    people probably don't care anymore.  

140
00:14:29,040 --> 00:14:34,959
One thing that's really difficult about cyber, as 
most everyone knows, it's easy to get burnt out.  

141
00:14:34,960 --> 00:14:44,240
There's lots of false positives. Caring about 
the things to care about can be difficult. When  

142
00:14:44,240 --> 00:14:51,600
you're looking at the abnormalities in the data. 
You have to understand the data and what you're  

143
00:14:51,600 --> 00:14:55,840
looking for. But also trying to figure out what 
you don't know and what you don't understand.
 

144
00:14:56,960 --> 00:15:01,520
so, looking at the infrequency of when systems 
talk to each other. If they talk to each other  

145
00:15:01,520 --> 00:15:07,040
once every nine months. Probably kind of 
weird. Probably doesn't happen very often.  

146
00:15:09,280 --> 00:15:14,560
You know, or if someone    one 
system sent, you know, a huge,  

147
00:15:14,560 --> 00:15:19,167
huge packet and it normally doesn't, that could 
be something that gets investigated. But that  

148
00:15:19,168 --> 00:15:23,040
would be really hard to write a rule for. Or one 
that you don't get a lot of false positives for.
 

149
00:15:24,640 --> 00:15:29,280
Another idea I had, which isn't based off a 
question. Just kind of like a fun visualization  

150
00:15:29,280 --> 00:15:34,480
for me. Is if you did a node graph. The circles 
and the nodes are the IP addresses and then the  

151
00:15:34,480 --> 00:15:39,920
connection between the nodes was like either the 
count of the packets. You could have a really big  

152
00:15:39,920 --> 00:15:47,360
bar between two nodes to show that they talk to 
each other a lot. You could also do the same idea  

153
00:15:47,360 --> 00:15:52,960
with the average packet size. You can kind of 
start getting a feel for what the system looks  

154
00:15:52,960 --> 00:15:57,760
like without actually looking at any log files. 
You're just looking at the IP addresses and,  

155
00:15:59,440 --> 00:16:03,040
you know, how often they communicate 
or what they normally communicate.  

156
00:16:03,040 --> 00:16:10,400
So, there's a couple other ideas.
Caveat. Like machine learning and AI, data  

157
00:16:10,400 --> 00:16:16,480
visualization is only as good as the data you can 
give the data visualizations. If you have weird  

158
00:16:16,480 --> 00:16:24,240
and confusing data, you probably won't get very 
useful data visualizations. So, that is a very  

159
00:16:24,240 --> 00:16:29,760
difficult part of data visualization is just kind 
of figuring out how much data do you need to make  

160
00:16:29,760 --> 00:16:35,840
a lot of sense? Are you getting too much data and 
you're missing things? And so, just be careful.
 

161
00:16:37,680 --> 00:16:41,120
And then just some getting started. So, 
this is both from a company perspective and  

162
00:16:41,120 --> 00:16:46,240
as an individual trying to learn about data 
visualization. Brown University has a really  

163
00:16:46,240 --> 00:16:55,440
cool interactive data visualization. Not class. 
But it's kind of a page that you just kind of  

164
00:16:55,440 --> 00:17:00,080
go through. And then the DataViz project 
is something I use in my day to day job.  

165
00:17:01,280 --> 00:17:07,839
I have this kind of data. What information or 
what visualizations would be helpful for those?  

166
00:17:07,839 --> 00:17:13,439
So, like for me, before I started in my current 
job, I didn't know what a tree map was. And so,  

167
00:17:13,440 --> 00:17:18,640
but that's specifically for correlating data. And 
so, you can kind of see what other visualizations  

168
00:17:18,640 --> 00:17:25,360
are meant for correlating data. And then for 
tools, what I showed you was all using Plotly.  

169
00:17:26,079 --> 00:17:33,600
And Plotly has got, I think Ruby, JavaScript and 
Python. I use Python. Splunk, if you already use  

170
00:17:33,600 --> 00:17:38,959
Splunk. They have dashboards and they can do 
some really cool data visualizations as well.  

171
00:17:38,960 --> 00:17:42,960
You don't get as much flexibility, but they're 
still very helpful. Especially getting started.
 

172
00:17:44,640 --> 00:17:52,320
And same thing with Kibana. Matplotlib is a good 
Python tool. And D3 is really cool as well. That's  

173
00:17:52,320 --> 00:17:57,280
what I use in my day to day job as well. That's 
JavaScript. I don't have much experience with  

174
00:17:57,280 --> 00:18:05,760
Tableau. That's good to get a demo. One thing I 
hadn't realize when had I was getting into cyber,  

175
00:18:06,320 --> 00:18:10,960
you can get individual versions of Splunk if 
you wanted to. So, you wouldn't have to have  

176
00:18:10,960 --> 00:18:18,560
it sitting as a server listening on your system. 
You could have a virtual machine and have data and  

177
00:18:18,560 --> 00:18:27,440
play with it is a student or individual. There's 
some resources. And then questions. And I guess I  

178
00:18:27,440 --> 00:18:32,640
should    happy to answer questions. But I wanted 
to give you guys the references for all of the  

179
00:18:33,760 --> 00:18:55,840
diagrams and sources and such. So, yeah.
What questions do you have? Or not.  

180
00:18:58,240 --> 00:19:02,720
Uh oh. Sorry, now I just see all the 
chats. Sorry about the stuttering.  

181
00:19:07,520 --> 00:19:12,160
Cool. Well, if you guys have any questions, or 
if you want specific links because like I said,  

182
00:19:12,160 --> 00:19:23,840
there is text. So, you know, I can be 
happy to send those to you if you need to.  

183
00:19:27,440 --> 00:19:33,120
I'm taking this as a good sign. I don't 
know. But well, thank you guys for the time!
 

184
00:19:33,120 --> 00:19:37,840
SOFIA: Okay. Thank you!
ADDY: Sure.

