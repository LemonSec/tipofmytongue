1
00:00:01,130 --> 00:00:14,690
[Music]

2
00:00:15,599 --> 00:00:17,520
hi everyone thank you for attending our

3
00:00:17,520 --> 00:00:18,960
presentation

4
00:00:18,960 --> 00:00:20,960
my name is eugene lim and together with

5
00:00:20,960 --> 00:00:23,039
my colleague timothy lee we will be

6
00:00:23,039 --> 00:00:25,680
presenting touring in a box applying

7
00:00:25,680 --> 00:00:27,840
artificial intelligence as a service to

8
00:00:27,840 --> 00:00:28,840
targeted

9
00:00:28,840 --> 00:00:31,439
phishing we are part of a research team

10
00:00:31,439 --> 00:00:32,399
of four

11
00:00:32,399 --> 00:00:34,160
at the government technology agency of

12
00:00:34,160 --> 00:00:36,880
singapore's cyber security group or csg

13
00:00:36,880 --> 00:00:38,239
for short

14
00:00:38,239 --> 00:00:41,360
let me introduce the team

15
00:00:42,239 --> 00:00:44,399
firstly that's me eugene

16
00:00:44,399 --> 00:00:46,320
i've been working at csg for about one

17
00:00:46,320 --> 00:00:48,079
and a half years and specialize in

18
00:00:48,079 --> 00:00:50,079
application security and vulnerability

19
00:00:50,079 --> 00:00:51,360
research

20
00:00:51,360 --> 00:00:53,440
i also participate actively in whitehead

21
00:00:53,440 --> 00:00:57,879
hacking under this handle space record

22
00:00:58,160 --> 00:00:59,920
next is glenistein who is part of the

23
00:00:59,920 --> 00:01:01,680
red team and social engineering team

24
00:01:01,680 --> 00:01:03,440
with additional interests in web and

25
00:01:03,440 --> 00:01:05,199
cloud security

26
00:01:05,199 --> 00:01:06,960
she was instrumental in leading our ai

27
00:01:06,960 --> 00:01:08,960
fishing exercises with keyhog as we will

28
00:01:08,960 --> 00:01:10,840
share

29
00:01:10,840 --> 00:01:13,920
later our third member key hawk has been

30
00:01:13,920 --> 00:01:16,080
at csg for about two and a half years

31
00:01:16,080 --> 00:01:17,920
where he contributes to a red team and

32
00:01:17,920 --> 00:01:20,560
cyber engineering capabilities

33
00:01:20,560 --> 00:01:22,720
on top of that he participates actively

34
00:01:22,720 --> 00:01:26,520
in capture the flag competitions

35
00:01:27,119 --> 00:01:29,360
last but not least timothy is a member

36
00:01:29,360 --> 00:01:31,040
of the mobile penetration testing team

37
00:01:31,040 --> 00:01:33,520
at csg and also assists in red team

38
00:01:33,520 --> 00:01:34,960
exercises

39
00:01:34,960 --> 00:01:37,200
he led the technical defense research

40
00:01:37,200 --> 00:01:39,200
against ai generated texts which you

41
00:01:39,200 --> 00:01:42,400
will also discuss later on

42
00:01:44,240 --> 00:01:46,159
with that let's talk about the plan for

43
00:01:46,159 --> 00:01:47,840
our presentation

44
00:01:47,840 --> 00:01:49,920
by the end of this presentation we hope

45
00:01:49,920 --> 00:01:51,040
you will walk away with the

46
00:01:51,040 --> 00:01:53,439
understanding that ai as a service has

47
00:01:53,439 --> 00:01:55,040
dramatically lowered the barriers to

48
00:01:55,040 --> 00:01:57,360
entry to producing convincing ai

49
00:01:57,360 --> 00:01:59,600
generated attacks for both legitimate

50
00:01:59,600 --> 00:02:01,680
and malicious attackers

51
00:02:01,680 --> 00:02:03,759
this has important implications for both

52
00:02:03,759 --> 00:02:07,360
defenders and decision makers

53
00:02:07,680 --> 00:02:09,119
we will begin with some background on

54
00:02:09,119 --> 00:02:12,160
language generators in recent history

55
00:02:12,160 --> 00:02:14,400
next we'll examine the real-life

56
00:02:14,400 --> 00:02:16,800
capabilities of tuna fish and artificial

57
00:02:16,800 --> 00:02:18,879
intelligence as a service pipeline we

58
00:02:18,879 --> 00:02:20,400
developed for simulated fishing

59
00:02:20,400 --> 00:02:22,400
exercises

60
00:02:22,400 --> 00:02:24,160
we will then go into the technical and

61
00:02:24,160 --> 00:02:26,879
policy defenses against ai phishing such

62
00:02:26,879 --> 00:02:29,920
as automated ai detection

63
00:02:29,920 --> 00:02:31,760
finally we will sum up important

64
00:02:31,760 --> 00:02:34,640
takeaways from our

65
00:02:34,840 --> 00:02:38,800
presentation on to the background

66
00:02:39,280 --> 00:02:41,680
let's start with a story

67
00:02:41,680 --> 00:02:44,720
one day john lee receives an email

68
00:02:44,720 --> 00:02:47,200
unknown to him this is an ai generated

69
00:02:47,200 --> 00:02:50,000
spear phishing email

70
00:02:50,000 --> 00:02:52,080
the email is addressed to john

71
00:02:52,080 --> 00:02:53,599
lee and it seems to have come from a

72
00:02:53,599 --> 00:02:54,640
bank

73
00:02:54,640 --> 00:02:57,120
the email however is not real

74
00:02:57,120 --> 00:02:59,440
it was generated by an ai

75
00:02:59,440 --> 00:03:01,040
it is one of the spear phishing emails

76
00:03:01,040 --> 00:03:02,560
that john lee has been receiving from

77
00:03:02,560 --> 00:03:05,440
the ai the ai knows that john lee will

78
00:03:05,440 --> 00:03:07,200
be interested in the email because he

79
00:03:07,200 --> 00:03:08,959
was able to collect all of his data from

80
00:03:08,959 --> 00:03:11,440
various sources including social media

81
00:03:11,440 --> 00:03:14,959
bank accounts phone calls and emails

82
00:03:14,959 --> 00:03:17,280
this is not a far-fetched scenario

83
00:03:17,280 --> 00:03:21,360
after all it was also written by ai

84
00:03:21,519 --> 00:03:22,959
the bolder text at the start of this

85
00:03:22,959 --> 00:03:25,920
paragraph was fed into openai's gbt3

86
00:03:25,920 --> 00:03:28,480
text generation api with the unbolded

87
00:03:28,480 --> 00:03:30,959
text as the raw output

88
00:03:30,959 --> 00:03:33,120
this is a relatively simple example of

89
00:03:33,120 --> 00:03:35,519
today's text in text out capabilities of

90
00:03:35,519 --> 00:03:36,959
text generators

91
00:03:36,959 --> 00:03:38,720
but it also took us a long time to get

92
00:03:38,720 --> 00:03:40,959
here

93
00:03:42,640 --> 00:03:45,680
back in 1950 alan turing proposed the

94
00:03:45,680 --> 00:03:47,519
imitation game in which a human

95
00:03:47,519 --> 00:03:49,599
interrogator must determine which of the

96
00:03:49,599 --> 00:03:51,360
two entities they are conversing with

97
00:03:51,360 --> 00:03:54,720
over text are a human or a computer

98
00:03:54,720 --> 00:03:56,400
it is also better known as the turing

99
00:03:56,400 --> 00:03:58,480
test

100
00:03:58,480 --> 00:04:01,840
in 1966 eliza the pub first publicly

101
00:04:01,840 --> 00:04:04,239
known chatbot used a role-based script

102
00:04:04,239 --> 00:04:06,159
to generate convincing but limited

103
00:04:06,159 --> 00:04:08,080
conversations

104
00:04:08,080 --> 00:04:09,760
this paved the way to the artificial

105
00:04:09,760 --> 00:04:12,000
linguistic internet computer entity or

106
00:04:12,000 --> 00:04:14,560
alice which represented one of the peaks

107
00:04:14,560 --> 00:04:16,720
and such role-based systems even though

108
00:04:16,720 --> 00:04:19,839
it still failed the turing test

109
00:04:19,839 --> 00:04:22,240
more recently the introduction of siri

110
00:04:22,240 --> 00:04:23,600
and other intelligent personal

111
00:04:23,600 --> 00:04:25,600
assistants raised the bar for text

112
00:04:25,600 --> 00:04:28,160
generation systems

113
00:04:28,160 --> 00:04:29,919
while it's important to note that these

114
00:04:29,919 --> 00:04:31,759
assistants might not have the same

115
00:04:31,759 --> 00:04:33,680
objectives as chat bots there's

116
00:04:33,680 --> 00:04:35,759
substantial overlap in the capabilities

117
00:04:35,759 --> 00:04:37,120
that they require

118
00:04:37,120 --> 00:04:39,040
such as understanding and responding

119
00:04:39,040 --> 00:04:42,880
appropriately to human input

120
00:04:42,880 --> 00:04:45,199
microsoft clies made another major foray

121
00:04:45,199 --> 00:04:47,440
into chatbots this time powered by a

122
00:04:47,440 --> 00:04:50,080
learning based model

123
00:04:50,080 --> 00:04:51,520
while it was successfully deployed with

124
00:04:51,520 --> 00:04:54,160
more than 100 million users another

125
00:04:54,160 --> 00:04:55,840
microsoft offshoot

126
00:04:55,840 --> 00:04:58,240
tweets gained notoriety for posting

127
00:04:58,240 --> 00:05:00,880
offensive tweets after being exposed

128
00:05:00,880 --> 00:05:02,720
similar messages from other twitter

129
00:05:02,720 --> 00:05:04,320
users

130
00:05:04,320 --> 00:05:06,000
this highlighted the risks of learning

131
00:05:06,000 --> 00:05:07,600
based models running a mock without

132
00:05:07,600 --> 00:05:10,800
human intervention

133
00:05:10,800 --> 00:05:12,240
finally this brings us to the last

134
00:05:12,240 --> 00:05:14,639
couple of years in which open ai grabbed

135
00:05:14,639 --> 00:05:16,720
headlines for the extremely realistic

136
00:05:16,720 --> 00:05:19,600
output of its gbt series language models

137
00:05:19,600 --> 00:05:21,039
which were trained on increasingly

138
00:05:21,039 --> 00:05:24,560
massive data sets scraped from the web

139
00:05:24,560 --> 00:05:27,199
more recently the gpt-2 models were

140
00:05:27,199 --> 00:05:30,960
published for other developers to use

141
00:05:32,800 --> 00:05:34,880
as a number of useful applications of ai

142
00:05:34,880 --> 00:05:36,960
generated texts have increased such as

143
00:05:36,960 --> 00:05:38,639
in intelligent personal assistance and

144
00:05:38,639 --> 00:05:39,919
chatbots

145
00:05:39,919 --> 00:05:42,800
so have the malicious applications

146
00:05:42,800 --> 00:05:44,720
for example the last two years

147
00:05:44,720 --> 00:05:47,120
represented an inflection point in a

148
00:05:47,120 --> 00:05:49,919
dramatic rise of generated fake news

149
00:05:49,919 --> 00:05:52,400
fishing and spoofing

150
00:05:52,400 --> 00:05:54,639
increasingly it's been become difficult

151
00:05:54,639 --> 00:05:56,639
to distinguish between human and ai

152
00:05:56,639 --> 00:05:59,919
generated media online

153
00:06:01,280 --> 00:06:03,440
last year phil tully warned that

154
00:06:03,440 --> 00:06:05,600
increasing access to open source

155
00:06:05,600 --> 00:06:07,520
training models would also raise the

156
00:06:07,520 --> 00:06:09,360
risk of abuse

157
00:06:09,360 --> 00:06:11,440
he said that while this emerging model

158
00:06:11,440 --> 00:06:12,720
sharing system

159
00:06:12,720 --> 00:06:14,400
beneficially lowers the barrier to entry

160
00:06:14,400 --> 00:06:17,120
for non-experts it also gives a leg up

161
00:06:17,120 --> 00:06:18,800
for those who seek to leverage open

162
00:06:18,800 --> 00:06:22,240
source models for malicious purposes

163
00:06:22,240 --> 00:06:24,000
we examine the extent to which this

164
00:06:24,000 --> 00:06:26,000
argument plays out with artificial

165
00:06:26,000 --> 00:06:28,240
intelligence as a service which further

166
00:06:28,240 --> 00:06:31,520
simplifies this workflow

167
00:06:33,680 --> 00:06:35,600
in june 2020

168
00:06:35,600 --> 00:06:37,840
open ai released an api for accessing

169
00:06:37,840 --> 00:06:39,199
the latest models from the

170
00:06:39,199 --> 00:06:41,360
state-of-the-art gbt3 language model

171
00:06:41,360 --> 00:06:44,319
family with a simple interface

172
00:06:44,319 --> 00:06:46,479
and more than 10 times the size of the

173
00:06:46,479 --> 00:06:48,479
previous gpt-2 model

174
00:06:48,479 --> 00:06:51,199
jpg 3 represented a quantum leap in ai

175
00:06:51,199 --> 00:06:53,280
text generation

176
00:06:53,280 --> 00:06:55,840
by march 2021 nine months after its

177
00:06:55,840 --> 00:06:58,560
launch the open ai api was generating

178
00:06:58,560 --> 00:07:01,280
4.5 billion words per day for hundreds

179
00:07:01,280 --> 00:07:02,400
of applications

180
00:07:02,400 --> 00:07:06,239
and is continuing to grow rapidly

181
00:07:06,400 --> 00:07:08,560
the initial release of the api generated

182
00:07:08,560 --> 00:07:09,759
a lot of hype

183
00:07:09,759 --> 00:07:11,360
such as an article in a guardian

184
00:07:11,360 --> 00:07:13,360
newspaper that claimed to be written by

185
00:07:13,360 --> 00:07:17,039
the gbt3 api

186
00:07:17,039 --> 00:07:20,000
in response ai experts push back on the

187
00:07:20,000 --> 00:07:22,639
most sensational claims about the api

188
00:07:22,639 --> 00:07:24,400
warning that users often fail to

189
00:07:24,400 --> 00:07:26,800
disclose raw inputs and outputs and the

190
00:07:26,800 --> 00:07:28,319
amount of creation applied to these

191
00:07:28,319 --> 00:07:30,319
outputs

192
00:07:30,319 --> 00:07:32,560
nevertheless it was clear that gpt3

193
00:07:32,560 --> 00:07:34,800
possessed significant capabilities in

194
00:07:34,800 --> 00:07:38,160
natural language generation

195
00:07:39,680 --> 00:07:42,720
in practical terms the gp3 api indeed

196
00:07:42,720 --> 00:07:45,039
represents a major leap in accessibility

197
00:07:45,039 --> 00:07:47,759
and power over its predecessors

198
00:07:47,759 --> 00:07:49,360
while previous users of the published

199
00:07:49,360 --> 00:07:51,599
gpt-2 models still needed some level of

200
00:07:51,599 --> 00:07:53,680
expertise and computing power to utilize

201
00:07:53,680 --> 00:07:54,400
it

202
00:07:54,400 --> 00:07:57,120
the gpt3 api has a simple text in

203
00:07:57,120 --> 00:07:59,360
textile interface that allows users to

204
00:07:59,360 --> 00:08:01,759
tap on the mammoth gp3 models at

205
00:08:01,759 --> 00:08:03,919
negligible cost

206
00:08:03,919 --> 00:08:06,400
for example based on estimates by lambda

207
00:08:06,400 --> 00:08:10,240
labs gpt3 would have taken 355 years of

208
00:08:10,240 --> 00:08:13,440
compute time and 4.6 million dollars

209
00:08:13,440 --> 00:08:15,120
in order to train

210
00:08:15,120 --> 00:08:16,080
however

211
00:08:16,080 --> 00:08:18,479
users could access it now via the api

212
00:08:18,479 --> 00:08:22,318
for a few cents per thousand tokens

213
00:08:23,680 --> 00:08:25,840
more concerningly humans are bad at

214
00:08:25,840 --> 00:08:27,039
detecting

215
00:08:27,039 --> 00:08:30,560
gbt3 generated text

216
00:08:30,560 --> 00:08:32,559
in a 2020 paper

217
00:08:32,559 --> 00:08:34,559
openai noted that humans were able to

218
00:08:34,559 --> 00:08:37,279
distinguish articles written by gbt3 at

219
00:08:37,279 --> 00:08:39,039
a level of accuracy that was barely

220
00:08:39,039 --> 00:08:42,080
above charts at 52

221
00:08:42,080 --> 00:08:44,240
this means that in an event where gpt-3

222
00:08:44,240 --> 00:08:46,640
was deployed to deliberate mimic

223
00:08:46,640 --> 00:08:49,760
or displays genuine human written text

224
00:08:49,760 --> 00:08:51,760
humans would be unable to reliably just

225
00:08:51,760 --> 00:08:55,160
detect this

226
00:08:55,760 --> 00:08:57,600
let's think about this in the context of

227
00:08:57,600 --> 00:08:59,760
another concerning statistic

228
00:08:59,760 --> 00:09:02,080
according to a 2020 report by terranova

229
00:09:02,080 --> 00:09:03,360
security

230
00:09:03,360 --> 00:09:05,200
almost one-fifth of employees in

231
00:09:05,200 --> 00:09:07,519
targeted companies clicked on simulated

232
00:09:07,519 --> 00:09:09,600
phishing email links even with an

233
00:09:09,600 --> 00:09:12,640
existing related training program

234
00:09:12,640 --> 00:09:15,040
this rate increased to 43

235
00:09:15,040 --> 00:09:16,720
in a study on spear phishing emails

236
00:09:16,720 --> 00:09:19,440
against more general users

237
00:09:19,440 --> 00:09:21,600
humans are not only bad at detecting ai

238
00:09:21,600 --> 00:09:23,920
generated text they're also bad at

239
00:09:23,920 --> 00:09:26,080
detecting phishing emails

240
00:09:26,080 --> 00:09:27,839
so what happens when you combine both of

241
00:09:27,839 --> 00:09:30,080
them

242
00:09:31,360 --> 00:09:33,360
this question is important because of

243
00:09:33,360 --> 00:09:35,519
the disproportionate impact humans have

244
00:09:35,519 --> 00:09:36,959
on the cyber security posture of

245
00:09:36,959 --> 00:09:38,880
organizations

246
00:09:38,880 --> 00:09:40,880
according to europol's european cyber

247
00:09:40,880 --> 00:09:42,080
crime center

248
00:09:42,080 --> 00:09:43,600
phishing is one of the most common and

249
00:09:43,600 --> 00:09:45,680
most dangerous attack factors seen by

250
00:09:45,680 --> 00:09:48,320
both law enforcement and industry

251
00:09:48,320 --> 00:09:50,959
they leverage authority scarcity and

252
00:09:50,959 --> 00:09:53,120
context-specific factors to exploit

253
00:09:53,120 --> 00:09:54,800
human blind spots and break security

254
00:09:54,800 --> 00:09:57,040
chains such as achieving business email

255
00:09:57,040 --> 00:09:59,599
compromise

256
00:10:00,640 --> 00:10:02,480
as the rise of ai generated synthetic

257
00:10:02,480 --> 00:10:04,240
media continues to impact a few of

258
00:10:04,240 --> 00:10:06,399
information operations we should also

259
00:10:06,399 --> 00:10:07,680
take a closer look at the

260
00:10:07,680 --> 00:10:09,519
well-established attack vector of

261
00:10:09,519 --> 00:10:11,839
phishing emails

262
00:10:11,839 --> 00:10:14,000
as such we decided to perform several

263
00:10:14,000 --> 00:10:15,440
experiments to

264
00:10:15,440 --> 00:10:17,120
determine the viability and

265
00:10:17,120 --> 00:10:19,680
effectiveness of ais service generated

266
00:10:19,680 --> 00:10:22,399
phishing emails

267
00:10:23,360 --> 00:10:24,880
let's start with a typical manual

268
00:10:24,880 --> 00:10:26,560
fishing workflow

269
00:10:26,560 --> 00:10:28,880
in a simulated fishing exercises

270
00:10:28,880 --> 00:10:30,720
the red team operators would typically

271
00:10:30,720 --> 00:10:32,320
start with some sort of context

272
00:10:32,320 --> 00:10:34,640
generation through open a open source

273
00:10:34,640 --> 00:10:36,640
intelligence gathering of the target

274
00:10:36,640 --> 00:10:38,480
before crafting a suitable phishing

275
00:10:38,480 --> 00:10:40,320
email

276
00:10:40,320 --> 00:10:41,920
the amount of time spent on context

277
00:10:41,920 --> 00:10:43,600
generation would also depend on the

278
00:10:43,600 --> 00:10:47,040
specific specificity of the target

279
00:10:47,040 --> 00:10:48,720
the red team operator would also craft

280
00:10:48,720 --> 00:10:50,480
their email based on different weapons

281
00:10:50,480 --> 00:10:53,360
of influence such as authority social

282
00:10:53,360 --> 00:10:55,519
proof and so on

283
00:10:55,519 --> 00:10:57,760
the entire workflow is manual and

284
00:10:57,760 --> 00:11:01,839
dependent on individual operators

285
00:11:03,040 --> 00:11:05,200
to replace this we built an ai as a

286
00:11:05,200 --> 00:11:07,120
service automation pipeline that will

287
00:11:07,120 --> 00:11:09,440
perform the context generation and email

288
00:11:09,440 --> 00:11:12,480
writing using ai apis

289
00:11:12,480 --> 00:11:14,240
the red team operator would only be

290
00:11:14,240 --> 00:11:16,720
involved in creating the best output and

291
00:11:16,720 --> 00:11:19,920
performing minor edits

292
00:11:21,760 --> 00:11:23,839
for phishing context generation we

293
00:11:23,839 --> 00:11:26,800
repurposed humantic ai's api demo to

294
00:11:26,800 --> 00:11:29,920
perform personality analysis

295
00:11:29,920 --> 00:11:31,760
the service is actually meant to be used

296
00:11:31,760 --> 00:11:33,760
by recruiters and sales people to

297
00:11:33,760 --> 00:11:35,760
automatically analyze public information

298
00:11:35,760 --> 00:11:37,680
such as linkedin profiles to produce a

299
00:11:37,680 --> 00:11:39,519
personality report and generate

300
00:11:39,519 --> 00:11:41,680
communications advice

301
00:11:41,680 --> 00:11:43,360
when applied to an ai phishing pipeline

302
00:11:43,360 --> 00:11:46,000
however we pass the api output into

303
00:11:46,000 --> 00:11:47,920
plain text instructions describing the

304
00:11:47,920 --> 00:11:50,560
target and how to approach them

305
00:11:50,560 --> 00:11:52,320
for example we ran the context

306
00:11:52,320 --> 00:11:54,320
generation pipeline on my own linkedin

307
00:11:54,320 --> 00:11:56,480
profile which produced the following raw

308
00:11:56,480 --> 00:11:58,880
output in the middle

309
00:11:58,880 --> 00:12:01,120
the pipeline then passed this output

310
00:12:01,120 --> 00:12:04,480
into plain text instructions

311
00:12:05,920 --> 00:12:08,480
notably humantic ai is only one of the

312
00:12:08,480 --> 00:12:09,680
many sales and recruitment

313
00:12:09,680 --> 00:12:12,639
personalization apis as a service

314
00:12:12,639 --> 00:12:14,240
that offers out there

315
00:12:14,240 --> 00:12:16,240
many of these companies have a free demo

316
00:12:16,240 --> 00:12:18,560
that allows anyone to register the api

317
00:12:18,560 --> 00:12:20,160
right away

318
00:12:20,160 --> 00:12:22,800
as such in a realistic scenario any of

319
00:12:22,800 --> 00:12:24,399
these could have been accepted or

320
00:12:24,399 --> 00:12:28,079
adapted to use in our pipeline

321
00:12:30,320 --> 00:12:32,399
next we fed the plain text instructions

322
00:12:32,399 --> 00:12:35,440
into the gpg3 api

323
00:12:35,440 --> 00:12:37,279
now before we proceed it's important to

324
00:12:37,279 --> 00:12:39,040
distinguish among the various options

325
00:12:39,040 --> 00:12:41,040
offered by openai

326
00:12:41,040 --> 00:12:43,360
the api features four different language

327
00:12:43,360 --> 00:12:45,839
models of different quality and price

328
00:12:45,839 --> 00:12:48,480
from ada to davinci

329
00:12:48,480 --> 00:12:50,639
furthermore open eye recently released

330
00:12:50,639 --> 00:12:52,800
and instruct series beta for curie and

331
00:12:52,800 --> 00:12:53,920
davinci

332
00:12:53,920 --> 00:12:55,600
that are optimized to understand and

333
00:12:55,600 --> 00:12:58,079
follows text instructions

334
00:12:58,079 --> 00:12:59,680
for example you could input the

335
00:12:59,680 --> 00:13:01,360
following instructions

336
00:13:01,360 --> 00:13:03,040
write a song about cows

337
00:13:03,040 --> 00:13:05,519
or explain quantum physics to a six year

338
00:13:05,519 --> 00:13:06,639
old

339
00:13:06,639 --> 00:13:08,639
here's what the api returned to that

340
00:13:08,639 --> 00:13:11,120
instruction

341
00:13:13,680 --> 00:13:15,200
based on the input from the past

342
00:13:15,200 --> 00:13:17,360
personality analysis ai

343
00:13:17,360 --> 00:13:19,839
the davinci instruct model returned

344
00:13:19,839 --> 00:13:23,200
impressive but unreliable output

345
00:13:23,200 --> 00:13:25,440
on the left we have the real input fed

346
00:13:25,440 --> 00:13:27,360
into the model which produced the output

347
00:13:27,360 --> 00:13:29,040
on the right

348
00:13:29,040 --> 00:13:30,639
this is the raw input and output with

349
00:13:30,639 --> 00:13:32,800
only a few edits made to the target's

350
00:13:32,800 --> 00:13:35,120
name department and organization for

351
00:13:35,120 --> 00:13:37,519
privacy purposes

352
00:13:37,519 --> 00:13:39,440
as you can see the generated email is

353
00:13:39,440 --> 00:13:41,760
coherent and fairly convincing

354
00:13:41,760 --> 00:13:44,000
applying authority and consistency in

355
00:13:44,000 --> 00:13:46,000
its instructions

356
00:13:46,000 --> 00:13:48,000
it even extrapolated from the fact that

357
00:13:48,000 --> 00:13:50,000
the target was in singapore to cite a

358
00:13:50,000 --> 00:13:52,560
singapore-specific law the personal data

359
00:13:52,560 --> 00:13:55,279
protection act

360
00:13:55,519 --> 00:13:57,440
however there are a few quirks that

361
00:13:57,440 --> 00:13:59,760
required human edits

362
00:13:59,760 --> 00:14:02,720
for example it generated a realistic but

363
00:14:02,720 --> 00:14:05,279
fake link as well as a date that had

364
00:14:05,279 --> 00:14:07,040
already passed

365
00:14:07,040 --> 00:14:09,199
it also somehow redacted its own email

366
00:14:09,199 --> 00:14:10,560
which could actually be realistically

367
00:14:10,560 --> 00:14:12,800
interpreted as an unintended mistake by

368
00:14:12,800 --> 00:14:14,959
a human writer

369
00:14:14,959 --> 00:14:17,040
nevertheless this demonstrates the need

370
00:14:17,040 --> 00:14:19,600
for a human in a loop for this ai as the

371
00:14:19,600 --> 00:14:22,800
service fishing pipeline

372
00:14:25,040 --> 00:14:27,040
to validate our pipeline we applied it

373
00:14:27,040 --> 00:14:28,880
on three authorized simulated phishing

374
00:14:28,880 --> 00:14:30,720
exercises

375
00:14:30,720 --> 00:14:32,399
our initial methodology was to send

376
00:14:32,399 --> 00:14:34,399
phishing emails at two stages

377
00:14:34,399 --> 00:14:36,240
a mass physics stage where the same

378
00:14:36,240 --> 00:14:38,320
email was sent to multiple targets and

379
00:14:38,320 --> 00:14:40,240
then a spearfishing stage where

380
00:14:40,240 --> 00:14:41,760
personalized emails were sent to the

381
00:14:41,760 --> 00:14:44,320
victims from the first stage

382
00:14:44,320 --> 00:14:45,920
furthermore to create a comparison

383
00:14:45,920 --> 00:14:47,839
between the ai and human workflow we

384
00:14:47,839 --> 00:14:50,079
first sent human generated output to the

385
00:14:50,079 --> 00:14:52,480
targets and then we repeated the process

386
00:14:52,480 --> 00:14:54,480
with the ai pipeline a few weeks later

387
00:14:54,480 --> 00:14:57,519
on the same target

388
00:14:57,760 --> 00:14:59,760
however one issue was that due to the

389
00:14:59,760 --> 00:15:01,680
poor performance of human generated

390
00:15:01,680 --> 00:15:03,920
emails in the first stage the human

391
00:15:03,920 --> 00:15:06,000
workflow also sent mass emails in the

392
00:15:06,000 --> 00:15:08,000
second stage instead so we couldn't make

393
00:15:08,000 --> 00:15:10,320
this comparison

394
00:15:10,320 --> 00:15:12,000
we also recorded both an initial click

395
00:15:12,000 --> 00:15:13,519
and a subsequent form fill for our

396
00:15:13,519 --> 00:15:16,000
metrics

397
00:15:17,680 --> 00:15:19,760
the results were encouraging

398
00:15:19,760 --> 00:15:22,160
in a mass fishing stage the ai pipeline

399
00:15:22,160 --> 00:15:24,000
significantly outperformed the human

400
00:15:24,000 --> 00:15:25,440
workflow for two out of three

401
00:15:25,440 --> 00:15:27,199
engagements

402
00:15:27,199 --> 00:15:28,800
in the remaining engagement there was a

403
00:15:28,800 --> 00:15:32,000
negligible difference of one victim

404
00:15:32,000 --> 00:15:34,240
furthermore the ai pipeline enjoyed high

405
00:15:34,240 --> 00:15:36,079
conversion rates and form fields of up

406
00:15:36,079 --> 00:15:39,479
to 80 percent

407
00:15:40,000 --> 00:15:42,480
we added personalization the ai pipeline

408
00:15:42,480 --> 00:15:45,279
performed even better reaching up to 60

409
00:15:45,279 --> 00:15:48,320
clicks in the first engagement

410
00:15:48,320 --> 00:15:49,680
however for the second and third

411
00:15:49,680 --> 00:15:51,519
engagements we faced an external

412
00:15:51,519 --> 00:15:53,440
obstacle as our phishing domain was

413
00:15:53,440 --> 00:15:55,440
flagged by browsers cutting down on the

414
00:15:55,440 --> 00:15:57,519
conversion rate

415
00:15:57,519 --> 00:15:59,600
we plan to conduct more experiments to

416
00:15:59,600 --> 00:16:01,839
fully validate our pipeline especially

417
00:16:01,839 --> 00:16:03,759
in the personalization stage holding

418
00:16:03,759 --> 00:16:05,759
external factors equal for better

419
00:16:05,759 --> 00:16:08,759
comparison

420
00:16:09,120 --> 00:16:11,040
other than the quantitative findings we

421
00:16:11,040 --> 00:16:13,040
also found that the ai pipeline led to

422
00:16:13,040 --> 00:16:14,720
qualitative improvements

423
00:16:14,720 --> 00:16:17,519
by saving manpower and time speeding up

424
00:16:17,519 --> 00:16:19,920
our red team operations

425
00:16:19,920 --> 00:16:21,759
for context generation content

426
00:16:21,759 --> 00:16:24,160
generation and a feedback loop we found

427
00:16:24,160 --> 00:16:26,320
that integrating ai helped to streamline

428
00:16:26,320 --> 00:16:29,120
and standardize our operations

429
00:16:29,120 --> 00:16:30,560
no longer was the input and output

430
00:16:30,560 --> 00:16:32,560
dependent on individual operators skill

431
00:16:32,560 --> 00:16:34,880
sets and predispositions

432
00:16:34,880 --> 00:16:36,720
we could now tweak various quantitative

433
00:16:36,720 --> 00:16:39,040
factors such as the temperature or

434
00:16:39,040 --> 00:16:41,519
randomness of our gpt3 api

435
00:16:41,519 --> 00:16:44,320
the personality analysis api passing or

436
00:16:44,320 --> 00:16:47,519
the rank of the context generation

437
00:16:47,519 --> 00:16:49,680
this effectively encoded our workflow

438
00:16:49,680 --> 00:16:51,040
and allowed us to iterate in a

439
00:16:51,040 --> 00:16:54,959
methodological and testable manner

440
00:16:56,240 --> 00:16:57,680
although we built our pipeline with a

441
00:16:57,680 --> 00:16:59,759
custom user interface and backend the

442
00:16:59,759 --> 00:17:01,600
portability of the api meant that we

443
00:17:01,600 --> 00:17:03,279
could easily integrate into existing

444
00:17:03,279 --> 00:17:05,599
tools such as the goldfish open source

445
00:17:05,599 --> 00:17:07,199
phishing framework

446
00:17:07,199 --> 00:17:09,280
this highlights how ai as a service

447
00:17:09,280 --> 00:17:11,599
offers a step up in accessibility from

448
00:17:11,599 --> 00:17:14,079
open source language models

449
00:17:14,079 --> 00:17:15,760
rather than worrying about compute or

450
00:17:15,760 --> 00:17:17,439
server side generation

451
00:17:17,439 --> 00:17:19,599
adding ai capabilities now simply

452
00:17:19,599 --> 00:17:24,958
requires an api key and an http request

453
00:17:27,119 --> 00:17:28,960
having demonstrated the viability of an

454
00:17:28,960 --> 00:17:31,120
ai phishing pipeline we decided to

455
00:17:31,120 --> 00:17:34,160
explore potential defenses against it

456
00:17:34,160 --> 00:17:36,480
this is an important question as access

457
00:17:36,480 --> 00:17:39,520
to ai's service grows over time

458
00:17:39,520 --> 00:17:41,760
my colleague timothy will elaborate on

459
00:17:41,760 --> 00:17:43,440
this over and deliver the rest of our

460
00:17:43,440 --> 00:17:45,440
presentation

461
00:17:45,440 --> 00:17:48,080
over to udemy team

462
00:17:48,080 --> 00:17:49,840
thank you eugene now that we have

463
00:17:49,840 --> 00:17:52,000
covered a glimpse of the potential from

464
00:17:52,000 --> 00:17:54,160
introducing ai into the red teaming

465
00:17:54,160 --> 00:17:56,160
pipeline we will share potential

466
00:17:56,160 --> 00:17:59,600
solutions that we have researched about

467
00:17:59,600 --> 00:18:01,280
before we get started talking about the

468
00:18:01,280 --> 00:18:03,760
defense we'll look into the approach

469
00:18:03,760 --> 00:18:06,160
detecting generated text remains a hard

470
00:18:06,160 --> 00:18:08,320
problem there are three main ways we can

471
00:18:08,320 --> 00:18:10,799
go about solving this problem

472
00:18:10,799 --> 00:18:13,520
first we have simple classifiers where

473
00:18:13,520 --> 00:18:16,400
we define certain rules based on text or

474
00:18:16,400 --> 00:18:18,320
using machine learning based nlp

475
00:18:18,320 --> 00:18:20,000
classifier

476
00:18:20,000 --> 00:18:20,880
next

477
00:18:20,880 --> 00:18:23,120
we can look into fine tuning based

478
00:18:23,120 --> 00:18:25,440
detection where we train a model based

479
00:18:25,440 --> 00:18:27,280
on inputs from different kinds of

480
00:18:27,280 --> 00:18:30,640
language models such as gpt3

481
00:18:30,640 --> 00:18:33,919
gpt2 bird and so on

482
00:18:33,919 --> 00:18:36,720
lastly the zero shot detection

483
00:18:36,720 --> 00:18:39,039
using this method the model learns a

484
00:18:39,039 --> 00:18:41,520
classifier on one set of labels and then

485
00:18:41,520 --> 00:18:43,840
it evaluates on a different set of

486
00:18:43,840 --> 00:18:46,000
labels that the classifier had never

487
00:18:46,000 --> 00:18:47,360
seen before

488
00:18:47,360 --> 00:18:49,440
we decided on using this approach

489
00:18:49,440 --> 00:18:51,679
because of its flexibility so that we

490
00:18:51,679 --> 00:18:53,520
will be able to use it to predict other

491
00:18:53,520 --> 00:18:56,559
sets of language models specifically the

492
00:18:56,559 --> 00:18:59,200
white paper for gltr has given us an

493
00:18:59,200 --> 00:19:01,360
insightful solution to tackle our

494
00:19:01,360 --> 00:19:02,400
problem

495
00:19:02,400 --> 00:19:04,720
then again from the papers

496
00:19:04,720 --> 00:19:06,880
we read and our research we like to

497
00:19:06,880 --> 00:19:09,120
highlight that ai text detection still

498
00:19:09,120 --> 00:19:11,280
depends heavily on the model that was

499
00:19:11,280 --> 00:19:13,840
used to generate the text and the model

500
00:19:13,840 --> 00:19:17,280
used for text detection

501
00:19:18,320 --> 00:19:21,280
giant language model test room or gltr

502
00:19:21,280 --> 00:19:22,400
for short

503
00:19:22,400 --> 00:19:24,400
is a project based on the collaboration

504
00:19:24,400 --> 00:19:30,000
of mit ibm watson ai lab and harvard nlp

505
00:19:30,000 --> 00:19:31,760
based on the white paper released by the

506
00:19:31,760 --> 00:19:33,919
team the approach used to detect

507
00:19:33,919 --> 00:19:37,039
synthetic text were one the probability

508
00:19:37,039 --> 00:19:39,120
of the word given the previous word in

509
00:19:39,120 --> 00:19:40,559
the sequence

510
00:19:40,559 --> 00:19:41,360
2

511
00:19:41,360 --> 00:19:44,000
the absolute rank of a word

512
00:19:44,000 --> 00:19:44,880
3

513
00:19:44,880 --> 00:19:48,640
the entropy of a predicted distribution

514
00:19:48,640 --> 00:19:50,559
our research used the same matrix along

515
00:19:50,559 --> 00:19:51,840
with gpt

516
00:19:51,840 --> 00:19:54,240
to evaluate if an email was written by a

517
00:19:54,240 --> 00:19:56,799
language model or human we have also

518
00:19:56,799 --> 00:20:00,559
fought the gltr repo that uses gpd2 with

519
00:20:00,559 --> 00:20:04,080
a new ripple from eugene that uses gpt3

520
00:20:04,080 --> 00:20:06,400
as seen in the screenshot i'll share

521
00:20:06,400 --> 00:20:08,320
more about the team's decision to build

522
00:20:08,320 --> 00:20:12,639
upon gltr's zero shot detector

523
00:20:13,120 --> 00:20:14,880
while researching the approach on

524
00:20:14,880 --> 00:20:17,440
possible solution for defense from our

525
00:20:17,440 --> 00:20:18,880
generated text

526
00:20:18,880 --> 00:20:21,440
one major challenge our team faced was

527
00:20:21,440 --> 00:20:24,080
that we do not have direct access to gpt

528
00:20:24,080 --> 00:20:25,840
trees language model

529
00:20:25,840 --> 00:20:28,320
without direct access we are limited in

530
00:20:28,320 --> 00:20:30,000
the parameters that we will be able to

531
00:20:30,000 --> 00:20:32,480
control

532
00:20:33,200 --> 00:20:35,360
we are also limited in the data set that

533
00:20:35,360 --> 00:20:37,679
is returned from the generated text with

534
00:20:37,679 --> 00:20:40,400
limitations such as hud limit of the top

535
00:20:40,400 --> 00:20:43,360
100 log probe for choice of words

536
00:20:43,360 --> 00:20:45,360
we decided to extend gltr in our

537
00:20:45,360 --> 00:20:47,440
research as the data we can get from

538
00:20:47,440 --> 00:20:51,360
gpt3 has transferable patterns from gpt2

539
00:20:51,360 --> 00:20:53,679
which was used in gltr

540
00:20:53,679 --> 00:20:56,000
with that we'll look at the findings

541
00:20:56,000 --> 00:20:59,039
from our research

542
00:20:59,840 --> 00:21:02,880
in our test we compared gpt3

543
00:21:02,880 --> 00:21:04,240
gpt to

544
00:21:04,240 --> 00:21:07,440
gpt to tune and human samples

545
00:21:07,440 --> 00:21:10,400
our gpt2 tuned model is based on an

546
00:21:10,400 --> 00:21:13,200
email corpus that our team has harvested

547
00:21:13,200 --> 00:21:16,480
for gpt2 and its tune model we follow

548
00:21:16,480 --> 00:21:18,080
the settings that were described in the

549
00:21:18,080 --> 00:21:20,000
glts white paper

550
00:21:20,000 --> 00:21:22,159
we found that for human samples human

551
00:21:22,159 --> 00:21:24,400
frequently used words that are out of

552
00:21:24,400 --> 00:21:27,360
the top 100 predictions from gpt trees

553
00:21:27,360 --> 00:21:29,678
model

554
00:21:29,760 --> 00:21:32,159
looking at the kde graph reinforced the

555
00:21:32,159 --> 00:21:34,400
conclusion that humans frequently use

556
00:21:34,400 --> 00:21:36,640
words that are out of the top 100

557
00:21:36,640 --> 00:21:39,200
predicted words from gbt3's language

558
00:21:39,200 --> 00:21:40,159
model

559
00:21:40,159 --> 00:21:42,159
the graph for human also looked more

560
00:21:42,159 --> 00:21:44,480
distributed compared to its counterpart

561
00:21:44,480 --> 00:21:46,000
gpt tree

562
00:21:46,000 --> 00:21:48,080
from our research we conclude that

563
00:21:48,080 --> 00:21:50,480
evaluating the probability for a

564
00:21:50,480 --> 00:21:53,440
sequence of text is most likely a good

565
00:21:53,440 --> 00:21:55,520
indicator of whether the text is

566
00:21:55,520 --> 00:21:59,039
synthetic or written by a human however

567
00:21:59,039 --> 00:22:01,200
there are limitations in this approach

568
00:22:01,200 --> 00:22:03,760
as it is heavily dependent on the model

569
00:22:03,760 --> 00:22:06,080
that is used to predict the sequence of

570
00:22:06,080 --> 00:22:06,880
text

571
00:22:06,880 --> 00:22:09,919
and the model used to generate the text

572
00:22:09,919 --> 00:22:11,600
we estimate that a model which is

573
00:22:11,600 --> 00:22:14,159
trained on a huge data set of other

574
00:22:14,159 --> 00:22:16,320
language models would perform much

575
00:22:16,320 --> 00:22:17,360
better

576
00:22:17,360 --> 00:22:19,520
other than technical research our team

577
00:22:19,520 --> 00:22:21,760
also explored other means that we can

578
00:22:21,760 --> 00:22:25,600
use in defense against white scale usage

579
00:22:25,600 --> 00:22:27,919
wide-scale ai usage for malicious

580
00:22:27,919 --> 00:22:30,559
activities

581
00:22:30,880 --> 00:22:32,960
the first line of defense comes from the

582
00:22:32,960 --> 00:22:35,200
company that provides team service

583
00:22:35,200 --> 00:22:36,320
themselves

584
00:22:36,320 --> 00:22:38,240
when we look at open ai there's a

585
00:22:38,240 --> 00:22:41,600
process that governs the usage of gpt3

586
00:22:41,600 --> 00:22:43,679
developers that wish to develop on gpt

587
00:22:43,679 --> 00:22:46,960
trees api would have to submit a request

588
00:22:46,960 --> 00:22:49,360
that is revealed based on their use case

589
00:22:49,360 --> 00:22:51,440
while we are unsure of the criteria for

590
00:22:51,440 --> 00:22:54,159
a good use case sometimes the process

591
00:22:54,159 --> 00:22:57,039
takes up to months before approval is

592
00:22:57,039 --> 00:22:58,159
granted

593
00:22:58,159 --> 00:23:00,559
openair has a guideline for use cases

594
00:23:00,559 --> 00:23:03,200
which describe the safe use of its api

595
00:23:03,200 --> 00:23:05,440
as part of a product or service

596
00:23:05,440 --> 00:23:07,200
and this allows certain usage that

597
00:23:07,200 --> 00:23:09,520
results in spam or political

598
00:23:09,520 --> 00:23:11,039
implications

599
00:23:11,039 --> 00:23:13,440
its use case guidelines detail a list of

600
00:23:13,440 --> 00:23:15,919
allowed disallowed scenarios for

601
00:23:15,919 --> 00:23:17,120
different

602
00:23:17,120 --> 00:23:20,640
set of use cases such as marketing

603
00:23:20,640 --> 00:23:23,679
article writing social media

604
00:23:23,679 --> 00:23:25,760
chatbots and many more

605
00:23:25,760 --> 00:23:28,080
its production team does monitor the

606
00:23:28,080 --> 00:23:30,480
live application on its platform for

607
00:23:30,480 --> 00:23:33,520
potential misuse

608
00:23:33,919 --> 00:23:35,919
well a lot of work has been done by open

609
00:23:35,919 --> 00:23:38,240
ai to ensure the safe and fair use of

610
00:23:38,240 --> 00:23:40,320
its gpt tree api

611
00:23:40,320 --> 00:23:42,320
we predict that as barrel to entry are

612
00:23:42,320 --> 00:23:44,400
lowered by future ai as a service

613
00:23:44,400 --> 00:23:46,400
provider means that it's harder to

614
00:23:46,400 --> 00:23:48,960
uphold such stringent standards we will

615
00:23:48,960 --> 00:23:50,880
have to look for alternative ways to

616
00:23:50,880 --> 00:23:53,200
supplement the guidelines for usage of

617
00:23:53,200 --> 00:23:55,600
ai

618
00:23:55,600 --> 00:23:57,840
on the previous slides we look into how

619
00:23:57,840 --> 00:23:59,840
ai service providers maintain the

620
00:23:59,840 --> 00:24:02,559
process of its use case guidelines for

621
00:24:02,559 --> 00:24:04,400
developers but caution

622
00:24:04,400 --> 00:24:06,960
that commercial imperatives may make it

623
00:24:06,960 --> 00:24:10,000
harder to uphold such xinjiang standards

624
00:24:10,000 --> 00:24:12,000
we explore what it means to prevent

625
00:24:12,000 --> 00:24:15,840
misuse of ais and organization

626
00:24:15,840 --> 00:24:18,720
for decision makers a balance must be

627
00:24:18,720 --> 00:24:20,960
achieved between commercialization and

628
00:24:20,960 --> 00:24:23,440
the abuse of ai as a service

629
00:24:23,440 --> 00:24:25,520
we look into the model ai governance

630
00:24:25,520 --> 00:24:27,760
framework released by singapore as a

631
00:24:27,760 --> 00:24:30,640
reference to address key tactical and

632
00:24:30,640 --> 00:24:33,279
governance issue when deploying ai

633
00:24:33,279 --> 00:24:35,120
solutions

634
00:24:35,120 --> 00:24:36,799
there are key takeaway for each of the

635
00:24:36,799 --> 00:24:38,240
pillar

636
00:24:38,240 --> 00:24:40,240
the first pillar in the framework aims

637
00:24:40,240 --> 00:24:42,400
to incorporate values

638
00:24:42,400 --> 00:24:43,360
risk

639
00:24:43,360 --> 00:24:45,520
and responsibilities relating to

640
00:24:45,520 --> 00:24:48,159
algorithmic decision making this to

641
00:24:48,159 --> 00:24:50,480
allow organizations to have appropriate

642
00:24:50,480 --> 00:24:53,440
oversight over how ai technologies are

643
00:24:53,440 --> 00:24:55,919
brought into their operations

644
00:24:55,919 --> 00:24:58,960
products or services

645
00:24:58,960 --> 00:25:01,600
the next pillar helps organization to

646
00:25:01,600 --> 00:25:04,080
determine the appropriate extent of

647
00:25:04,080 --> 00:25:07,360
human oversight resets the risk appetite

648
00:25:07,360 --> 00:25:09,039
for the use of ai

649
00:25:09,039 --> 00:25:11,600
this meant that organizations should

650
00:25:11,600 --> 00:25:14,880
determine acceptable risk and identify

651
00:25:14,880 --> 00:25:16,640
an appropriate level of human

652
00:25:16,640 --> 00:25:19,440
involvement in ai augmented decision

653
00:25:19,440 --> 00:25:20,799
making

654
00:25:20,799 --> 00:25:23,360
the third pillar describes issues to be

655
00:25:23,360 --> 00:25:25,679
considered when developing

656
00:25:25,679 --> 00:25:29,200
selecting and maintaining ai models

657
00:25:29,200 --> 00:25:32,080
the last pillar lays strategies for

658
00:25:32,080 --> 00:25:34,880
communicating with stakeholders

659
00:25:34,880 --> 00:25:37,440
with this organizations should be able

660
00:25:37,440 --> 00:25:39,440
to take advantage of the guidelines

661
00:25:39,440 --> 00:25:41,840
provided to set policies for

662
00:25:41,840 --> 00:25:46,399
incorporating ai into their business

663
00:25:46,720 --> 00:25:48,240
while we spoke about guidelines and

664
00:25:48,240 --> 00:25:51,279
policies from the point of organizations

665
00:25:51,279 --> 00:25:53,360
we feel that this should be a combined

666
00:25:53,360 --> 00:25:56,159
effort and advocate the key applicable

667
00:25:56,159 --> 00:25:58,880
recommendation from singapore's model ai

668
00:25:58,880 --> 00:26:00,640
governance framework

669
00:26:00,640 --> 00:26:02,559
after evaluating the four points of the

670
00:26:02,559 --> 00:26:05,200
framework on this slide an ideal for the

671
00:26:05,200 --> 00:26:07,279
general approach to ensure responsible

672
00:26:07,279 --> 00:26:09,600
usage for incorporating ai should be

673
00:26:09,600 --> 00:26:10,799
formed

674
00:26:10,799 --> 00:26:12,400
we will discuss some examples of

675
00:26:12,400 --> 00:26:15,279
ensuring responsible usage

676
00:26:15,279 --> 00:26:17,440
including ai into situations that may

677
00:26:17,440 --> 00:26:19,919
have significant impact in a consumer's

678
00:26:19,919 --> 00:26:20,960
life

679
00:26:20,960 --> 00:26:23,600
adopting human in the loop will put the

680
00:26:23,600 --> 00:26:26,320
decision making in human's hand meaning

681
00:26:26,320 --> 00:26:29,279
that ai decisions cannot be exercised

682
00:26:29,279 --> 00:26:32,480
without affirmative actions by the human

683
00:26:32,480 --> 00:26:35,360
an example would be a doctor using ai to

684
00:26:35,360 --> 00:26:37,440
identify possible diagnosis and

685
00:26:37,440 --> 00:26:39,520
treatment for an unfamiliar medical

686
00:26:39,520 --> 00:26:40,640
condition

687
00:26:40,640 --> 00:26:42,720
however the doctor will have to make the

688
00:26:42,720 --> 00:26:45,440
final decision on the diagnosis and the

689
00:26:45,440 --> 00:26:47,520
corresponding treatment

690
00:26:47,520 --> 00:26:49,760
as for suppliers and service providers

691
00:26:49,760 --> 00:26:52,799
of ai do you have to ensure traceability

692
00:26:52,799 --> 00:26:55,520
and auditability of use

693
00:26:55,520 --> 00:26:57,440
we also have seen enforcement in the

694
00:26:57,440 --> 00:27:00,640
form of legislation such as the european

695
00:27:00,640 --> 00:27:03,039
commission's april 2021

696
00:27:03,039 --> 00:27:05,200
proposal for regulation laying down

697
00:27:05,200 --> 00:27:07,039
harmonized rules on artificial

698
00:27:07,039 --> 00:27:09,520
intelligence the artificial intelligence

699
00:27:09,520 --> 00:27:10,320
act

700
00:27:10,320 --> 00:27:12,480
while it may be counterproductive to

701
00:27:12,480 --> 00:27:14,080
restrict the development and

702
00:27:14,080 --> 00:27:16,640
distribution of ai technologies we think

703
00:27:16,640 --> 00:27:18,640
that it's important to lay down broad

704
00:27:18,640 --> 00:27:21,279
rules to prevent potential misuse as

705
00:27:21,279 --> 00:27:24,720
seen from our research

706
00:27:25,039 --> 00:27:27,279
having explored possible ways to prevent

707
00:27:27,279 --> 00:27:29,840
misuse of ais from different entities

708
00:27:29,840 --> 00:27:33,120
such as governments and organizations

709
00:27:33,120 --> 00:27:35,360
will look at how as an individual we can

710
00:27:35,360 --> 00:27:38,399
do to prevent falling prey to misuse ai

711
00:27:38,399 --> 00:27:40,399
technology

712
00:27:40,399 --> 00:27:42,799
now the solution that we offer is in

713
00:27:42,799 --> 00:27:44,960
regards to our research and we feel that

714
00:27:44,960 --> 00:27:47,360
future track actors will be using this

715
00:27:47,360 --> 00:27:49,760
ai technology in more creative ways that

716
00:27:49,760 --> 00:27:51,200
we could think of

717
00:27:51,200 --> 00:27:54,000
at its core in our case this is still a

718
00:27:54,000 --> 00:27:55,679
phishing email that may be more

719
00:27:55,679 --> 00:27:58,640
convincing to unsuspecting users

720
00:27:58,640 --> 00:28:01,120
introduction to ai attacks may be added

721
00:28:01,120 --> 00:28:03,200
into security training to increase

722
00:28:03,200 --> 00:28:06,960
awareness of such cases

723
00:28:08,399 --> 00:28:09,760
while we reached the end of the

724
00:28:09,760 --> 00:28:10,960
presentation

725
00:28:10,960 --> 00:28:12,720
here are some of the key takeaways that

726
00:28:12,720 --> 00:28:16,440
we hope to bring across

727
00:28:16,559 --> 00:28:20,159
now back in 2020 tally and foster warned

728
00:28:20,159 --> 00:28:22,159
that we were in the calm before the

729
00:28:22,159 --> 00:28:23,279
storm

730
00:28:23,279 --> 00:28:26,480
however with the rapid development of ai

731
00:28:26,480 --> 00:28:29,440
as a service has placed advanced

732
00:28:29,440 --> 00:28:32,799
cost-effective ai capabilities in the

733
00:28:32,799 --> 00:28:35,279
hands of global market and can only be

734
00:28:35,279 --> 00:28:39,679
expected to grow exponentially

735
00:28:40,480 --> 00:28:42,880
well there are multiple benefits to this

736
00:28:42,880 --> 00:28:45,840
such as the application of ai solution

737
00:28:45,840 --> 00:28:48,799
in less technologically advanced sectors

738
00:28:48,799 --> 00:28:51,279
which were previously inhibited by the

739
00:28:51,279 --> 00:28:54,960
cost and difficulty of implementing ai

740
00:28:54,960 --> 00:28:56,159
however

741
00:28:56,159 --> 00:28:58,880
the downsides of ai profilations are

742
00:28:58,880 --> 00:29:00,240
equally clear

743
00:29:00,240 --> 00:29:03,039
in cyber security these capabilities can

744
00:29:03,039 --> 00:29:05,600
be used to accelerate both authorized

745
00:29:05,600 --> 00:29:07,440
raid team operations

746
00:29:07,440 --> 00:29:11,360
and malicious phishing campaigns

747
00:29:11,360 --> 00:29:13,919
but our research shows that automated

748
00:29:13,919 --> 00:29:16,880
tools can be built against ai generated

749
00:29:16,880 --> 00:29:17,840
text

750
00:29:17,840 --> 00:29:20,399
the current solutions are brittle and

751
00:29:20,399 --> 00:29:22,399
model dependent

752
00:29:22,399 --> 00:29:24,960
we will combine multiple approach for

753
00:29:24,960 --> 00:29:27,840
detection of ai generated tax for

754
00:29:27,840 --> 00:29:31,120
increased effectiveness

755
00:29:31,520 --> 00:29:32,559
lastly

756
00:29:32,559 --> 00:29:35,360
the overall spread of ai as a service

757
00:29:35,360 --> 00:29:37,679
cannot be managed by technical means

758
00:29:37,679 --> 00:29:38,720
alone

759
00:29:38,720 --> 00:29:41,080
decision makers also have the

760
00:29:41,080 --> 00:29:43,440
responsibilities to implement sound

761
00:29:43,440 --> 00:29:46,320
strategies governing the supply and use

762
00:29:46,320 --> 00:29:50,158
of advanced ai as a service

763
00:29:50,720 --> 00:29:52,720
that's all from our sharing today we

764
00:29:52,720 --> 00:29:54,240
hope that you enjoyed this session as

765
00:29:54,240 --> 00:29:56,559
much as we had while preparing it thank

766
00:29:56,559 --> 00:29:59,559
you

