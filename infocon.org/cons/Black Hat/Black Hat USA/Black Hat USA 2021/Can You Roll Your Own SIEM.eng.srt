1
00:00:01,130 --> 00:00:14,160
[Music]

2
00:00:14,160 --> 00:00:16,239
hi everyone thank you for joining us

3
00:00:16,239 --> 00:00:18,720
this is can you roll your own sim

4
00:00:18,720 --> 00:00:20,800
i'm ethan crist and i lead the security

5
00:00:20,800 --> 00:00:22,880
identity monitoring and response team at

6
00:00:22,880 --> 00:00:26,000
two sigma investments

7
00:00:26,400 --> 00:00:28,080
i'm brett rubin and i'm a security

8
00:00:28,080 --> 00:00:30,000
engineer at two sigma focusing on our

9
00:00:30,000 --> 00:00:31,279
security event collection and

10
00:00:31,279 --> 00:00:34,640
reliability for security run products

11
00:00:34,640 --> 00:00:36,160
for those who haven't heard of us two

12
00:00:36,160 --> 00:00:38,079
sigma is a financial sciences company

13
00:00:38,079 --> 00:00:39,600
headquartered in new york with over

14
00:00:39,600 --> 00:00:41,440
sixteen hundred employees and a quick

15
00:00:41,440 --> 00:00:43,360
recruiting shout out we're hiring so if

16
00:00:43,360 --> 00:00:44,960
you're interested even after hearing our

17
00:00:44,960 --> 00:00:47,840
talk check out careers.twosigma.com

18
00:00:47,840 --> 00:00:49,760
and now on to the main event

19
00:00:49,760 --> 00:00:51,440
given the maturity of the sim product

20
00:00:51,440 --> 00:00:53,360
space deciding to roll your own may not

21
00:00:53,360 --> 00:00:55,760
strike you as the wisest of ideas let's

22
00:00:55,760 --> 00:00:57,520
dig into why we ended up deciding to do

23
00:00:57,520 --> 00:00:59,280
it anyway and why it was the right

24
00:00:59,280 --> 00:01:01,760
choice for two sigma but first let's see

25
00:01:01,760 --> 00:01:03,520
how quickly i can transition past the

26
00:01:03,520 --> 00:01:06,479
disclaimer slide

27
00:01:06,799 --> 00:01:08,240
we'll start by discussing the high level

28
00:01:08,240 --> 00:01:09,680
considerations that led us down this

29
00:01:09,680 --> 00:01:11,760
path to begin with and then what made

30
00:01:11,760 --> 00:01:13,760
this the right choice for us brett will

31
00:01:13,760 --> 00:01:15,119
lead us through the technical details of

32
00:01:15,119 --> 00:01:16,960
our implementation and give a demo of

33
00:01:16,960 --> 00:01:18,960
the solution then we'll end on the

34
00:01:18,960 --> 00:01:20,799
actual results of this effort and the

35
00:01:20,799 --> 00:01:22,640
broader strategic implications creating

36
00:01:22,640 --> 00:01:25,360
our own sim has had for us

37
00:01:25,360 --> 00:01:26,880
as we first started to think about what

38
00:01:26,880 --> 00:01:28,400
our ideal replacement sim would look

39
00:01:28,400 --> 00:01:30,000
like we went through a requirements

40
00:01:30,000 --> 00:01:31,840
gathering phase

41
00:01:31,840 --> 00:01:33,439
the first thing we looked into was how

42
00:01:33,439 --> 00:01:35,759
much data we needed to ingest per day

43
00:01:35,759 --> 00:01:38,159
the existing license of our on-prem

44
00:01:38,159 --> 00:01:40,240
third-party platform only allowed us to

45
00:01:40,240 --> 00:01:42,479
ingest one terabyte per day and this was

46
00:01:42,479 --> 00:01:43,600
a hard cap

47
00:01:43,600 --> 00:01:45,280
routine overages of this daily rate

48
00:01:45,280 --> 00:01:46,799
would lead to loss of the ability to

49
00:01:46,799 --> 00:01:48,880
search our data which meant we had to be

50
00:01:48,880 --> 00:01:50,640
constantly mindful and diligent of our

51
00:01:50,640 --> 00:01:52,399
daily ingestion amount

52
00:01:52,399 --> 00:01:54,079
this was not a situation we wanted to be

53
00:01:54,079 --> 00:01:55,680
in for the next product given how much

54
00:01:55,680 --> 00:01:57,439
staff time it took to track down and

55
00:01:57,439 --> 00:02:00,079
remediate heavy loggers ideally we would

56
00:02:00,079 --> 00:02:01,439
want a system that wouldn't cap or

57
00:02:01,439 --> 00:02:03,280
restrict us but instead give us the

58
00:02:03,280 --> 00:02:05,040
flexibility to collect more without

59
00:02:05,040 --> 00:02:07,200
paying exponentially more or by having

60
00:02:07,200 --> 00:02:09,679
confiscatory controls around search

61
00:02:09,679 --> 00:02:12,000
our platform's limitations led us to not

62
00:02:12,000 --> 00:02:14,080
ingest certain large data feeds such as

63
00:02:14,080 --> 00:02:16,239
firewall logs that can provide valuable

64
00:02:16,239 --> 00:02:19,040
signal to our security analysts

65
00:02:19,040 --> 00:02:20,840
our next consideration was speed of

66
00:02:20,840 --> 00:02:23,120
ingestion several of our queries feed

67
00:02:23,120 --> 00:02:24,640
downstream actions that have some time

68
00:02:24,640 --> 00:02:26,800
sensitivity one such example was

69
00:02:26,800 --> 00:02:28,800
identifying interactive route logins to

70
00:02:28,800 --> 00:02:31,120
production security systems that didn't

71
00:02:31,120 --> 00:02:32,879
occur via our specifically designed

72
00:02:32,879 --> 00:02:35,120
single purpose management system

73
00:02:35,120 --> 00:02:36,560
we were targeting detection for these

74
00:02:36,560 --> 00:02:38,080
events within 60 seconds of one

75
00:02:38,080 --> 00:02:39,760
happening which means the logs would

76
00:02:39,760 --> 00:02:41,440
need to go from the host in question to

77
00:02:41,440 --> 00:02:43,200
being searchable and firing an alert in

78
00:02:43,200 --> 00:02:45,599
that time

79
00:02:45,680 --> 00:02:47,920
reliability was another key requirement

80
00:02:47,920 --> 00:02:49,760
we rely heavily on our logs for forensic

81
00:02:49,760 --> 00:02:51,840
capabilities during investigations so

82
00:02:51,840 --> 00:02:53,440
ensuring their accuracy and completeness

83
00:02:53,440 --> 00:02:54,480
was critical

84
00:02:54,480 --> 00:02:56,400
we wanted to avoid lossy protocols

85
00:02:56,400 --> 00:02:58,239
wherever possible and be able to

86
00:02:58,239 --> 00:02:59,840
ascertain if all our systems were

87
00:02:59,840 --> 00:03:01,920
shipping expected log volumes

88
00:03:01,920 --> 00:03:04,159
our previous platform did this well via

89
00:03:04,159 --> 00:03:05,599
an agent that would remember logging

90
00:03:05,599 --> 00:03:07,440
state via checkpoints and could load

91
00:03:07,440 --> 00:03:08,959
balance between multiple receiving

92
00:03:08,959 --> 00:03:09,920
servers

93
00:03:09,920 --> 00:03:12,080
the security infrastructure teams along

94
00:03:12,080 --> 00:03:13,599
with several other engineering teams at

95
00:03:13,599 --> 00:03:15,680
two sigma rely on this log data to

96
00:03:15,680 --> 00:03:17,680
troubleshoot outages and issues so it's

97
00:03:17,680 --> 00:03:20,319
important it stays up and running

98
00:03:20,319 --> 00:03:21,920
our logs aren't always standardized to

99
00:03:21,920 --> 00:03:24,319
expected norms custom field editions and

100
00:03:24,319 --> 00:03:26,239
homegrown applications meant we needed

101
00:03:26,239 --> 00:03:28,000
to be able to have flexibility when it

102
00:03:28,000 --> 00:03:29,599
came to data parsing

103
00:03:29,599 --> 00:03:31,599
we didn't want to have to shoehorn our

104
00:03:31,599 --> 00:03:32,400
own data

105
00:03:32,400 --> 00:03:34,319
into pre-defined fields or wrestle with

106
00:03:34,319 --> 00:03:36,159
logging logic that wasn't extensible to

107
00:03:36,159 --> 00:03:38,239
our environment we use a common data

108
00:03:38,239 --> 00:03:40,159
model internally and wanted to adapt our

109
00:03:40,159 --> 00:03:44,159
new sim to that not vice versa

110
00:03:44,959 --> 00:03:46,640
much of our log data is required to be

111
00:03:46,640 --> 00:03:48,480
retained for long periods of time with

112
00:03:48,480 --> 00:03:50,560
some stored indefinitely all of the

113
00:03:50,560 --> 00:03:51,840
storage can add up quickly if you're

114
00:03:51,840 --> 00:03:53,519
paying a third-party provider to host it

115
00:03:53,519 --> 00:03:55,439
and keep it accessible but it's not free

116
00:03:55,439 --> 00:03:57,360
to do this on-prem either

117
00:03:57,360 --> 00:03:58,879
both from the hardware perspective and

118
00:03:58,879 --> 00:04:00,560
from the operational overhead to scale

119
00:04:00,560 --> 00:04:02,720
out large clusters of servers

120
00:04:02,720 --> 00:04:04,400
we also had to factor in sporadic

121
00:04:04,400 --> 00:04:06,239
operational costs for rehydrating log

122
00:04:06,239 --> 00:04:07,840
data that we had moved to long-term

123
00:04:07,840 --> 00:04:09,599
storage in order to keep our current

124
00:04:09,599 --> 00:04:11,200
system performing

125
00:04:11,200 --> 00:04:12,400
and this ties into the next

126
00:04:12,400 --> 00:04:14,560
consideration searchability given the

127
00:04:14,560 --> 00:04:16,560
quantities of data we were retaining our

128
00:04:16,560 --> 00:04:18,238
old platform had a hard time searching

129
00:04:18,238 --> 00:04:20,478
large swaths of historical data

130
00:04:20,478 --> 00:04:22,560
searches that span months i.e looking

131
00:04:22,560 --> 00:04:24,400
through a year's worth of proxy logs to

132
00:04:24,400 --> 00:04:26,000
see if there were any web requests sent

133
00:04:26,000 --> 00:04:28,240
to an ioc could take dozens of minutes

134
00:04:28,240 --> 00:04:29,199
to run

135
00:04:29,199 --> 00:04:30,880
this delay could be further compounded

136
00:04:30,880 --> 00:04:32,400
if part of the search's date range had

137
00:04:32,400 --> 00:04:34,479
been sent to a frozen archive and needed

138
00:04:34,479 --> 00:04:36,479
to be activated again

139
00:04:36,479 --> 00:04:38,000
we wanted to make searching as fast as

140
00:04:38,000 --> 00:04:39,280
possible to improve our incident

141
00:04:39,280 --> 00:04:41,520
responders user experience the other

142
00:04:41,520 --> 00:04:42,880
half of search ability that we were

143
00:04:42,880 --> 00:04:44,560
concerned with was how friendly the

144
00:04:44,560 --> 00:04:46,800
query language was we were eager not to

145
00:04:46,800 --> 00:04:48,720
have to train our users on a proprietary

146
00:04:48,720 --> 00:04:50,960
syntax to use the platform while we

147
00:04:50,960 --> 00:04:52,160
could have improved the performance of

148
00:04:52,160 --> 00:04:53,759
our on-prem solution by tossing more

149
00:04:53,759 --> 00:04:55,680
hardware at it this was quickly becoming

150
00:04:55,680 --> 00:04:58,160
costly

151
00:04:58,160 --> 00:04:59,840
working in security and being at a

152
00:04:59,840 --> 00:05:01,199
security conference this next

153
00:05:01,199 --> 00:05:03,600
requirement might might seem obvious but

154
00:05:03,600 --> 00:05:04,960
we needed to make sure the sensitive

155
00:05:04,960 --> 00:05:07,280
data we were logging was secure we had

156
00:05:07,280 --> 00:05:08,960
to protect it not only from the outside

157
00:05:08,960 --> 00:05:10,960
world but also the vendor hosting our

158
00:05:10,960 --> 00:05:12,479
platform who could use administrative

159
00:05:12,479 --> 00:05:14,800
root privileges to access it and between

160
00:05:14,800 --> 00:05:16,880
teams inside two sigma as well who may

161
00:05:16,880 --> 00:05:18,479
not be authorized to access other teams

162
00:05:18,479 --> 00:05:19,600
data

163
00:05:19,600 --> 00:05:21,520
and lastly since we rely on these logs

164
00:05:21,520 --> 00:05:22,840
for forensic evidence during

165
00:05:22,840 --> 00:05:24,880
investigations we have to ensure our

166
00:05:24,880 --> 00:05:27,280
logs are resistant to tampering

167
00:05:27,280 --> 00:05:28,880
our last requirement was the need to

168
00:05:28,880 --> 00:05:30,320
generate alerts from our queries and

169
00:05:30,320 --> 00:05:32,160
scheduled searches as i previously

170
00:05:32,160 --> 00:05:33,520
mentioned speed is important here as

171
00:05:33,520 --> 00:05:35,280
well especially in cases where we want

172
00:05:35,280 --> 00:05:37,600
to take automated actions our alert

173
00:05:37,600 --> 00:05:39,199
paths touch a variety of downstream

174
00:05:39,199 --> 00:05:41,440
sources so the sim has to be extensible

175
00:05:41,440 --> 00:05:43,360
to support multiple platforms including

176
00:05:43,360 --> 00:05:47,600
email pagerduty jira and the like

177
00:05:47,600 --> 00:05:49,039
one thing we didn't include in our

178
00:05:49,039 --> 00:05:51,440
requirement list was pre-canned queries

179
00:05:51,440 --> 00:05:53,360
our environment is fairly bespoke and so

180
00:05:53,360 --> 00:05:55,199
most out-of-the-box queries from vendors

181
00:05:55,199 --> 00:05:56,960
require substantial tweaking to provide

182
00:05:56,960 --> 00:05:59,199
any value for us since we knew from the

183
00:05:59,199 --> 00:06:01,039
onset that we need to re that we need to

184
00:06:01,039 --> 00:06:02,960
rewrite our alerts to work in whatever

185
00:06:02,960 --> 00:06:04,800
platform we were moving to we didn't

186
00:06:04,800 --> 00:06:06,560
factor any pre-canned alert offerings

187
00:06:06,560 --> 00:06:08,960
into our decision process

188
00:06:08,960 --> 00:06:10,880
another omission was data parsers for a

189
00:06:10,880 --> 00:06:12,400
similar reason

190
00:06:12,400 --> 00:06:14,080
many of the data feeds our security team

191
00:06:14,080 --> 00:06:16,160
is interested in ingesting either had

192
00:06:16,160 --> 00:06:18,160
custom configured log formats or were

193
00:06:18,160 --> 00:06:20,080
from internally developed applications

194
00:06:20,080 --> 00:06:22,319
that didn't conform to a normal standard

195
00:06:22,319 --> 00:06:23,840
as we'll explore further in the next

196
00:06:23,840 --> 00:06:25,520
section this is one of the decision

197
00:06:25,520 --> 00:06:27,120
factors that may be starkly different

198
00:06:27,120 --> 00:06:30,319
for us than for other companies

199
00:06:30,319 --> 00:06:31,919
the final consideration was our threat

200
00:06:31,919 --> 00:06:33,520
model two sigma doesn't run

201
00:06:33,520 --> 00:06:35,360
internet-facing web apps or the like so

202
00:06:35,360 --> 00:06:37,039
our external and perimeter detection

203
00:06:37,039 --> 00:06:38,960
efforts are more narrowly focused the

204
00:06:38,960 --> 00:06:40,479
majority of our threat modeling work

205
00:06:40,479 --> 00:06:42,479
goes into insider risk which given our

206
00:06:42,479 --> 00:06:44,560
largely customized environment is unique

207
00:06:44,560 --> 00:06:46,800
to us most vendor software we looked at

208
00:06:46,800 --> 00:06:48,319
was highly targeted towards external

209
00:06:48,319 --> 00:06:49,680
threats and would have required

210
00:06:49,680 --> 00:06:51,360
substantial uplift to cover our threat

211
00:06:51,360 --> 00:06:53,680
model

212
00:06:53,680 --> 00:06:54,479
so

213
00:06:54,479 --> 00:06:56,319
with those requirements established how

214
00:06:56,319 --> 00:06:58,080
did we wind up at our final decision to

215
00:06:58,080 --> 00:07:00,400
roll our own sim

216
00:07:00,400 --> 00:07:02,080
the first factor we considered was cost

217
00:07:02,080 --> 00:07:04,000
to see if this was a non-starter we

218
00:07:04,000 --> 00:07:05,520
broke it down into several sections and

219
00:07:05,520 --> 00:07:07,440
the first is licensing we'd already

220
00:07:07,440 --> 00:07:08,880
spent a million dollars in the license

221
00:07:08,880 --> 00:07:11,199
for our third-party on-prem sim product

222
00:07:11,199 --> 00:07:13,120
so moving away wasn't free if you don't

223
00:07:13,120 --> 00:07:15,199
believe in sunk cost fallacies but we

224
00:07:15,199 --> 00:07:16,960
had to need to ingest more data than we

225
00:07:16,960 --> 00:07:18,800
were currently allotted

226
00:07:18,800 --> 00:07:20,240
getting to where we are now plus some

227
00:07:20,240 --> 00:07:21,840
spare capacity would have cost several

228
00:07:21,840 --> 00:07:23,599
million dollars more just for the

229
00:07:23,599 --> 00:07:25,919
initial license purchase additionally we

230
00:07:25,919 --> 00:07:28,080
were paying approximately 18 in annual

231
00:07:28,080 --> 00:07:30,000
maintenance on the base license cost for

232
00:07:30,000 --> 00:07:32,880
software updates and support

233
00:07:32,880 --> 00:07:34,800
the second cost component we considered

234
00:07:34,800 --> 00:07:36,560
was infrastructure the infrastructure

235
00:07:36,560 --> 00:07:38,400
cost of running a sim on prem third

236
00:07:38,400 --> 00:07:40,800
party or otherwise it still requires the

237
00:07:40,800 --> 00:07:42,720
purchase of hardware the operational

238
00:07:42,720 --> 00:07:44,800
overhead of lifecycle management power

239
00:07:44,800 --> 00:07:46,560
and data center costs

240
00:07:46,560 --> 00:07:48,319
and these items tend to scale linearly

241
00:07:48,319 --> 00:07:49,919
over time if you have a long or

242
00:07:49,919 --> 00:07:51,919
indefinite retention period

243
00:07:51,919 --> 00:07:53,759
by using a cloud service we'd eliminate

244
00:07:53,759 --> 00:07:55,360
some of these but we would still be

245
00:07:55,360 --> 00:07:58,000
paying someone else to store our data

246
00:07:58,000 --> 00:07:59,360
the next item we factored into our

247
00:07:59,360 --> 00:08:01,680
calculation was business drivers

248
00:08:01,680 --> 00:08:03,280
many of the log generating sources we

249
00:08:03,280 --> 00:08:04,800
collected from were being moved from

250
00:08:04,800 --> 00:08:07,360
on-prem systems to gcp or other sas

251
00:08:07,360 --> 00:08:08,960
providers given the direction of the

252
00:08:08,960 --> 00:08:10,879
technology industry and choices being

253
00:08:10,879 --> 00:08:12,560
made throughout our company

254
00:08:12,560 --> 00:08:14,240
the disconnect between generating this

255
00:08:14,240 --> 00:08:16,160
data in the cloud and bringing it in was

256
00:08:16,160 --> 00:08:17,199
increasing

257
00:08:17,199 --> 00:08:19,039
one of our main log sources came from

258
00:08:19,039 --> 00:08:21,599
the businesses usage of gcp and its

259
00:08:21,599 --> 00:08:23,280
growth was about to outpace our one

260
00:08:23,280 --> 00:08:25,120
terabyte per day ingestion limit by

261
00:08:25,120 --> 00:08:27,759
itself by putting our sim in the cloud

262
00:08:27,759 --> 00:08:30,080
we'd be able to simplify and make log

263
00:08:30,080 --> 00:08:31,759
collection more cost effective for these

264
00:08:31,759 --> 00:08:32,799
sources

265
00:08:32,799 --> 00:08:34,240
this did come with the trade-off of

266
00:08:34,240 --> 00:08:36,000
having to ship our on-prem logs to the

267
00:08:36,000 --> 00:08:38,159
cloud which isn't free but wasn't as

268
00:08:38,159 --> 00:08:40,240
expensive nor did it inject notable

269
00:08:40,240 --> 00:08:42,320
noticeable latency into our ingestion

270
00:08:42,320 --> 00:08:44,800
pipeline

271
00:08:44,800 --> 00:08:46,560
tying into my last point since two

272
00:08:46,560 --> 00:08:48,080
sigma's engineering and business teams

273
00:08:48,080 --> 00:08:49,680
were already making heavy investments

274
00:08:49,680 --> 00:08:51,839
into gcp as our cloud platform we were

275
00:08:51,839 --> 00:08:53,760
able to hang on coattails

276
00:08:53,760 --> 00:08:56,000
bigquery offers two options to run

277
00:08:56,000 --> 00:08:58,080
searches on-demand queries which can be

278
00:08:58,080 --> 00:08:59,839
very expensive since you pay per byte

279
00:08:59,839 --> 00:09:02,000
queried or through dedicated query slots

280
00:09:02,000 --> 00:09:03,440
which are reserved at a fixed rate

281
00:09:03,440 --> 00:09:06,320
regardless of query size or duration

282
00:09:06,320 --> 00:09:07,839
our company had previously purchased a

283
00:09:07,839 --> 00:09:10,000
number of reserve bigquery slots that

284
00:09:10,000 --> 00:09:11,920
are shared among our engineering teams

285
00:09:11,920 --> 00:09:13,680
which essentially eliminated the cost to

286
00:09:13,680 --> 00:09:15,920
search our data within reason

287
00:09:15,920 --> 00:09:17,279
we were also able to leverage

288
00:09:17,279 --> 00:09:18,959
negotiations other teams had done for

289
00:09:18,959 --> 00:09:21,279
data storage that drove our costs down

290
00:09:21,279 --> 00:09:22,880
and lastly the business had already

291
00:09:22,880 --> 00:09:24,560
established a dedicated interconnect

292
00:09:24,560 --> 00:09:26,240
between our on-premise infrastructure

293
00:09:26,240 --> 00:09:28,240
and gcp which again reduced this

294
00:09:28,240 --> 00:09:30,640
project's overhead and improved our

295
00:09:30,640 --> 00:09:33,200
reliability and latency projections i

296
00:09:33,200 --> 00:09:34,560
want to specifically call this out

297
00:09:34,560 --> 00:09:36,399
though our choice to roll our own sim

298
00:09:36,399 --> 00:09:38,240
was heavily impacted by decisions the

299
00:09:38,240 --> 00:09:40,000
business had made and that may certainly

300
00:09:40,000 --> 00:09:43,360
not be the case for everyone

301
00:09:43,600 --> 00:09:45,600
our next consideration was the features

302
00:09:45,600 --> 00:09:47,519
offered natively in bq and vendor

303
00:09:47,519 --> 00:09:49,120
products and we drew a comparison

304
00:09:49,120 --> 00:09:50,720
against our requirements

305
00:09:50,720 --> 00:09:52,480
in recent years the offerings in many

306
00:09:52,480 --> 00:09:54,240
cloud platforms have grown considerably

307
00:09:54,240 --> 00:09:55,760
to make building your own sim much more

308
00:09:55,760 --> 00:09:58,320
viable open source software has improved

309
00:09:58,320 --> 00:10:00,080
to better support mature methodologies

310
00:10:00,080 --> 00:10:02,320
for log collection with either option

311
00:10:02,320 --> 00:10:03,920
we'd still have to do work to normalize

312
00:10:03,920 --> 00:10:06,640
our logs set up schemas write down our

313
00:10:06,640 --> 00:10:07,920
own custom alerts and other

314
00:10:07,920 --> 00:10:09,839
configuration steps we dropped these

315
00:10:09,839 --> 00:10:11,360
considerations from both sides of the

316
00:10:11,360 --> 00:10:13,760
equation since they were roughly equal

317
00:10:13,760 --> 00:10:15,279
this produced a result that we added to

318
00:10:15,279 --> 00:10:16,959
the cost component in terms of labor by

319
00:10:16,959 --> 00:10:18,320
taking into account what the overhead

320
00:10:18,320 --> 00:10:19,839
would be to reach our desired feature

321
00:10:19,839 --> 00:10:21,600
set if we built our own sim

322
00:10:21,600 --> 00:10:23,440
at the end of the day after we'd run out

323
00:10:23,440 --> 00:10:25,279
of envelopes to write on the back of we

324
00:10:25,279 --> 00:10:26,640
made the choice to build our own sim

325
00:10:26,640 --> 00:10:27,760
with gcp

326
00:10:27,760 --> 00:10:30,320
in gcp with bq i'll turn things over to

327
00:10:30,320 --> 00:10:32,000
brett now for a deeper dive into our

328
00:10:32,000 --> 00:10:35,120
technical implementation

329
00:10:35,760 --> 00:10:38,160
thanks ethan so in starting this process

330
00:10:38,160 --> 00:10:40,160
we centered our goals on reliability and

331
00:10:40,160 --> 00:10:41,920
simplicity aiming to leverage native

332
00:10:41,920 --> 00:10:46,040
capabilities wherever possible

333
00:10:48,480 --> 00:10:50,000
we set out to see just how much

334
00:10:50,000 --> 00:10:51,519
engineering work it would be to build

335
00:10:51,519 --> 00:10:53,440
the same must-haves we actually needed

336
00:10:53,440 --> 00:10:56,640
from our sim product namely first batch

337
00:10:56,640 --> 00:10:58,800
file loads from system appliances most

338
00:10:58,800 --> 00:11:00,800
often this takes the form of file dumps

339
00:11:00,800 --> 00:11:02,800
from security and network appliances

340
00:11:02,800 --> 00:11:04,959
regularly ftp or rsync to storage

341
00:11:04,959 --> 00:11:06,880
servers and loaded into the system of

342
00:11:06,880 --> 00:11:08,160
record

343
00:11:08,160 --> 00:11:09,839
second streaming ingests from

344
00:11:09,839 --> 00:11:11,440
configurable sources

345
00:11:11,440 --> 00:11:12,959
one use case is systems with a

346
00:11:12,959 --> 00:11:14,959
configurable remote syslog destination

347
00:11:14,959 --> 00:11:17,519
server or custom applications some

348
00:11:17,519 --> 00:11:19,200
examples include our mobile device

349
00:11:19,200 --> 00:11:20,880
management provider some hardware

350
00:11:20,880 --> 00:11:23,040
appliances and mail gateways

351
00:11:23,040 --> 00:11:25,200
third scheduled query execution for

352
00:11:25,200 --> 00:11:27,920
complex logic such as logic depend on an

353
00:11:27,920 --> 00:11:30,079
aggregation multiple data sets or

354
00:11:30,079 --> 00:11:31,519
patterns over time

355
00:11:31,519 --> 00:11:33,839
for example collect all similar events

356
00:11:33,839 --> 00:11:36,160
per hour group by hosts and inspect for

357
00:11:36,160 --> 00:11:37,600
a rate increase

358
00:11:37,600 --> 00:11:39,680
and last streaming alerting for single

359
00:11:39,680 --> 00:11:41,600
line pattern matches

360
00:11:41,600 --> 00:11:43,839
for example single log lines that strike

361
00:11:43,839 --> 00:11:45,120
terror into the hearts of security

362
00:11:45,120 --> 00:11:47,600
personnel like interactive login shell

363
00:11:47,600 --> 00:11:50,800
on sshd logs on zero touch machines or

364
00:11:50,800 --> 00:11:53,040
tamper detection integrity alert

365
00:11:53,040 --> 00:11:55,279
and as bonus port items we wanted to

366
00:11:55,279 --> 00:11:57,040
revision control and peer review our

367
00:11:57,040 --> 00:11:59,440
query logic and definitions and git and

368
00:11:59,440 --> 00:12:01,440
be able to flexibly ship output query

369
00:12:01,440 --> 00:12:03,279
results to various notification and

370
00:12:03,279 --> 00:12:06,000
tracking systems

371
00:12:06,000 --> 00:12:08,240
let's start with batch file loads many

372
00:12:08,240 --> 00:12:09,920
security and network appliances with

373
00:12:09,920 --> 00:12:11,839
high volume logs use periodically

374
00:12:11,839 --> 00:12:13,920
rotated local log files in our

375
00:12:13,920 --> 00:12:16,160
environment our network proxies dns

376
00:12:16,160 --> 00:12:18,079
infrastructure and some of our firewalls

377
00:12:18,079 --> 00:12:19,920
are a few examples

378
00:12:19,920 --> 00:12:22,000
bigquery batch loads allow for ingestion

379
00:12:22,000 --> 00:12:24,480
of csv or json files with associated

380
00:12:24,480 --> 00:12:27,040
schema definitions from local storage or

381
00:12:27,040 --> 00:12:29,200
google cloud storage buckets

382
00:12:29,200 --> 00:12:31,040
we chose to periodically sync our batch

383
00:12:31,040 --> 00:12:33,279
log files into a cloud storage bucket

384
00:12:33,279 --> 00:12:34,720
and then load them into bigquery from

385
00:12:34,720 --> 00:12:35,600
there

386
00:12:35,600 --> 00:12:37,519
this has the added advantage of allowing

387
00:12:37,519 --> 00:12:40,079
for simpler retry logic it even permits

388
00:12:40,079 --> 00:12:41,839
us to fully drop all the historic data

389
00:12:41,839 --> 00:12:43,680
loaded to bigquery and reload it with

390
00:12:43,680 --> 00:12:45,600
schema or parsing changes if we so

391
00:12:45,600 --> 00:12:46,880
choose

392
00:12:46,880 --> 00:12:48,639
we use bigquery itself to maintain

393
00:12:48,639 --> 00:12:50,480
simple metadata tables for per data

394
00:12:50,480 --> 00:12:53,279
source per file ingest date job failures

395
00:12:53,279 --> 00:12:54,880
and parsing errors

396
00:12:54,880 --> 00:12:56,160
that way if some part of the data

397
00:12:56,160 --> 00:12:58,240
pipeline is interrupted or delayed it

398
00:12:58,240 --> 00:13:00,000
can be picked back up since the job will

399
00:13:00,000 --> 00:13:01,920
compare the set of existing files to the

400
00:13:01,920 --> 00:13:03,920
metadata table to see which need to be

401
00:13:03,920 --> 00:13:05,040
loaded

402
00:13:05,040 --> 00:13:06,800
admins can inspect the failed files in

403
00:13:06,800 --> 00:13:08,880
isolation while the rest of the pipeline

404
00:13:08,880 --> 00:13:12,480
continues on working files

405
00:13:12,639 --> 00:13:14,320
in our environment some light tooling

406
00:13:14,320 --> 00:13:16,320
around the gcp bigquery and cloud

407
00:13:16,320 --> 00:13:19,279
storage python apis does the following

408
00:13:19,279 --> 00:13:20,720
step one

409
00:13:20,720 --> 00:13:22,240
given a configuration file of data

410
00:13:22,240 --> 00:13:24,240
sources load files from inside our

411
00:13:24,240 --> 00:13:26,160
environment from an internal drop host

412
00:13:26,160 --> 00:13:28,000
to a specific destination paths in the

413
00:13:28,000 --> 00:13:30,959
cloud storage ingest bucket

414
00:13:30,959 --> 00:13:33,440
step two create load jobs after querying

415
00:13:33,440 --> 00:13:35,200
a metadata table and comparing the

416
00:13:35,200 --> 00:13:36,959
results of what has been loaded to bq to

417
00:13:36,959 --> 00:13:39,040
what currently exists in the bucket in

418
00:13:39,040 --> 00:13:41,440
our example here our job sees a file

419
00:13:41,440 --> 00:13:42,959
file1.gz

420
00:13:42,959 --> 00:13:44,959
for data source 1.

421
00:13:44,959 --> 00:13:46,720
if the file is new and has not yet been

422
00:13:46,720 --> 00:13:49,040
successfully loaded we submit a bqlow

423
00:13:49,040 --> 00:13:51,760
job for file1.gz using the schema

424
00:13:51,760 --> 00:13:53,839
defined in our configuration for data

425
00:13:53,839 --> 00:13:55,040
source 1.

426
00:13:55,040 --> 00:13:56,639
and step 3

427
00:13:56,639 --> 00:13:58,560
store job result metadata by inserting

428
00:13:58,560 --> 00:14:01,600
it back to a different bq metadata table

429
00:14:01,600 --> 00:14:03,120
failures are set aside so they can be

430
00:14:03,120 --> 00:14:04,240
retried

431
00:14:04,240 --> 00:14:07,680
next let's talk about streaming ingest

432
00:14:07,680 --> 00:14:08,959
aside from the handful of batch

433
00:14:08,959 --> 00:14:10,720
appliances described earlier the

434
00:14:10,720 --> 00:14:12,320
majority of our logs are pushed over the

435
00:14:12,320 --> 00:14:14,800
network either directly to gcp or to

436
00:14:14,800 --> 00:14:16,560
internal infrastructure for additional

437
00:14:16,560 --> 00:14:18,800
parsing routing and geographical load

438
00:14:18,800 --> 00:14:20,160
balancing

439
00:14:20,160 --> 00:14:21,760
in securities logging infrastructure at

440
00:14:21,760 --> 00:14:23,839
two sigma we make use of open source

441
00:14:23,839 --> 00:14:25,519
tools for log forwarding

442
00:14:25,519 --> 00:14:27,760
we rely on fluent bit for log forwarding

443
00:14:27,760 --> 00:14:29,839
fluent d for intermediate aggregation

444
00:14:29,839 --> 00:14:32,079
parsing and routing and direct calls to

445
00:14:32,079 --> 00:14:34,399
the gcp cloud logging api formerly known

446
00:14:34,399 --> 00:14:36,000
as stackdriver for third-party

447
00:14:36,000 --> 00:14:37,199
integrations

448
00:14:37,199 --> 00:14:38,480
i'll dive a little more into the

449
00:14:38,480 --> 00:14:41,040
specifics of each use case

450
00:14:41,040 --> 00:14:42,639
for reliable log forwarding from our

451
00:14:42,639 --> 00:14:44,880
base linux platform we run a fluent bit

452
00:14:44,880 --> 00:14:46,639
agent and configuration from packages

453
00:14:46,639 --> 00:14:48,880
installed on the standard system image

454
00:14:48,880 --> 00:14:50,720
in the majority of cases we use fluid

455
00:14:50,720 --> 00:14:52,800
bits direct gcp cloud logging output

456
00:14:52,800 --> 00:14:55,120
plugin to write directly to google apis

457
00:14:55,120 --> 00:14:57,279
rather than shipped intermediate systems

458
00:14:57,279 --> 00:14:59,760
this has a few advantages

459
00:14:59,760 --> 00:15:01,360
one having our large compute

460
00:15:01,360 --> 00:15:03,279
infrastructure route logs directly to

461
00:15:03,279 --> 00:15:05,040
google saves us on maintaining a much

462
00:15:05,040 --> 00:15:06,880
larger distributed internal aggregator

463
00:15:06,880 --> 00:15:08,399
infrastructure

464
00:15:08,399 --> 00:15:09,199
two

465
00:15:09,199 --> 00:15:11,040
google's native capabilities and load

466
00:15:11,040 --> 00:15:12,959
balancing shifts operational burden away

467
00:15:12,959 --> 00:15:14,160
from us

468
00:15:14,160 --> 00:15:15,199
three

469
00:15:15,199 --> 00:15:17,600
fluid bit is small fast and has low

470
00:15:17,600 --> 00:15:19,199
memory overhead as well as having a

471
00:15:19,199 --> 00:15:20,880
well-supported output plug-in to write

472
00:15:20,880 --> 00:15:24,720
directly to the gcp cloud logging api

473
00:15:24,720 --> 00:15:26,720
for data sources requiring more complex

474
00:15:26,720 --> 00:15:29,120
parsing routing or enrichment we use a

475
00:15:29,120 --> 00:15:31,360
set of fluency aggregator instances that

476
00:15:31,360 --> 00:15:33,360
run in each data center

477
00:15:33,360 --> 00:15:35,279
this is useful for bespoke systems with

478
00:15:35,279 --> 00:15:37,759
configurable syslog remote destinations

479
00:15:37,759 --> 00:15:40,720
and non-standard log formats we also use

480
00:15:40,720 --> 00:15:42,160
this approach for appliances that may

481
00:15:42,160 --> 00:15:44,079
run in the dmz that purposefully do not

482
00:15:44,079 --> 00:15:47,199
have direct connectivity to gcp even via

483
00:15:47,199 --> 00:15:49,279
our direct interconnects

484
00:15:49,279 --> 00:15:50,959
fluentd allows for flexible and

485
00:15:50,959 --> 00:15:52,480
performant parsing and routing for

486
00:15:52,480 --> 00:15:55,839
custom log formats

487
00:15:56,560 --> 00:15:58,480
lastly we need to make fetching logs

488
00:15:58,480 --> 00:16:00,079
from an ever-growing number of hosted

489
00:16:00,079 --> 00:16:02,480
services simple and reliable

490
00:16:02,480 --> 00:16:04,000
our typical approach for vendor

491
00:16:04,000 --> 00:16:05,440
applications that do not natively

492
00:16:05,440 --> 00:16:07,440
provide logging integrations is to write

493
00:16:07,440 --> 00:16:09,600
periodic poll jobs and then push the

494
00:16:09,600 --> 00:16:12,320
results into the cloud logging api

495
00:16:12,320 --> 00:16:13,680
we produced some internal tooling to

496
00:16:13,680 --> 00:16:15,279
make it easier for admins of sas

497
00:16:15,279 --> 00:16:16,959
services to write scripts to pull their

498
00:16:16,959 --> 00:16:18,560
api logs and then write them to our

499
00:16:18,560 --> 00:16:20,079
infrastructure

500
00:16:20,079 --> 00:16:21,759
the goal was to make ingestion logic

501
00:16:21,759 --> 00:16:24,160
very easy for teams outside of security

502
00:16:24,160 --> 00:16:26,160
and shift the operational burden away

503
00:16:26,160 --> 00:16:27,839
from maintaining and developing all

504
00:16:27,839 --> 00:16:29,440
these intestinal integrations to

505
00:16:29,440 --> 00:16:31,440
providing a standard maintained set of

506
00:16:31,440 --> 00:16:35,279
tools for the teams to do so themselves

507
00:16:35,440 --> 00:16:36,959
altogether these approaches have worked

508
00:16:36,959 --> 00:16:38,880
well for us however when we first

509
00:16:38,880 --> 00:16:40,320
deployed fluent bit to our compute

510
00:16:40,320 --> 00:16:42,399
environment we did have a minor incident

511
00:16:42,399 --> 00:16:43,920
involving a need for additional cloud

512
00:16:43,920 --> 00:16:45,920
logging right quota when our changes hit

513
00:16:45,920 --> 00:16:48,720
the biggest deployment tranche

514
00:16:48,720 --> 00:16:50,800
this was quickly remedied by gcp support

515
00:16:50,800 --> 00:16:52,399
after i submitted a carefully annotated

516
00:16:52,399 --> 00:16:54,240
rate graph to a support case

517
00:16:54,240 --> 00:16:56,160
i warn you i needed multiple levels of

518
00:16:56,160 --> 00:16:57,839
approval to exfiltrate this highly

519
00:16:57,839 --> 00:17:00,639
sensitive graphic

520
00:17:01,199 --> 00:17:02,959
i think gcp support was so impressed

521
00:17:02,959 --> 00:17:04,720
with my ms paint skill that they bumped

522
00:17:04,720 --> 00:17:07,839
our quota immediately

523
00:17:08,640 --> 00:17:10,480
so let's look at the lifetime of an

524
00:17:10,480 --> 00:17:12,319
event written to syslog on one of our

525
00:17:12,319 --> 00:17:14,240
base platform linux hosts as a way to

526
00:17:14,240 --> 00:17:15,839
demonstrate how our streaming ingest

527
00:17:15,839 --> 00:17:17,520
works

528
00:17:17,520 --> 00:17:19,599
first an event starts its life being

529
00:17:19,599 --> 00:17:21,280
logged to the syslog socket on one of

530
00:17:21,280 --> 00:17:23,280
our compute hosts sent from an appliance

531
00:17:23,280 --> 00:17:25,679
to one of the set of fluency aggregators

532
00:17:25,679 --> 00:17:28,079
or via write to the gcp cloud logging

533
00:17:28,079 --> 00:17:30,799
python apis

534
00:17:30,799 --> 00:17:32,640
second upon hitting the cloud logging

535
00:17:32,640 --> 00:17:35,039
api bigquery export filters are

536
00:17:35,039 --> 00:17:36,799
configured based on individual tags

537
00:17:36,799 --> 00:17:39,120
present in the event

538
00:17:39,120 --> 00:17:40,960
based on the tag the event is routed to

539
00:17:40,960 --> 00:17:43,280
different bigquery destination tables in

540
00:17:43,280 --> 00:17:45,600
most cases we use the log name value

541
00:17:45,600 --> 00:17:47,120
which is uniquely configured on each

542
00:17:47,120 --> 00:17:49,360
data source and specify the bigquery

543
00:17:49,360 --> 00:17:52,320
dataset to write to

544
00:17:52,640 --> 00:17:54,720
last cloud logging writes the event to

545
00:17:54,720 --> 00:17:56,480
the bigquery table streaming buffer

546
00:17:56,480 --> 00:17:58,559
assuming the event schema is compatible

547
00:17:58,559 --> 00:18:00,080
the entire streaming process from

548
00:18:00,080 --> 00:18:02,080
on-prem log event to receive timestamp

549
00:18:02,080 --> 00:18:04,160
and bigquery is usually less than two to

550
00:18:04,160 --> 00:18:06,080
three seconds

551
00:18:06,080 --> 00:18:07,760
so that's how data streams in a few

552
00:18:07,760 --> 00:18:09,679
seconds to our bigquery tables

553
00:18:09,679 --> 00:18:11,039
additionally events in the streaming

554
00:18:11,039 --> 00:18:12,640
buffer are readable by queries to the

555
00:18:12,640 --> 00:18:15,280
table immediately

556
00:18:15,280 --> 00:18:17,200
speaking of queries let's move on to how

557
00:18:17,200 --> 00:18:19,440
we designed a system based on native gcp

558
00:18:19,440 --> 00:18:21,120
components to execute and route

559
00:18:21,120 --> 00:18:24,639
pre-configured scheduled queries

560
00:18:25,120 --> 00:18:26,559
after handling batch and streaming

561
00:18:26,559 --> 00:18:28,480
ingestion we needed a consistent way to

562
00:18:28,480 --> 00:18:30,160
execute scheduled queries against our

563
00:18:30,160 --> 00:18:31,440
data sets

564
00:18:31,440 --> 00:18:33,039
the resulting system looks like the

565
00:18:33,039 --> 00:18:34,080
following

566
00:18:34,080 --> 00:18:36,480
first we manage query definition files

567
00:18:36,480 --> 00:18:38,400
with associated metadata like miter

568
00:18:38,400 --> 00:18:40,880
attack tactics and techniques

569
00:18:40,880 --> 00:18:42,880
output types and destinations and query

570
00:18:42,880 --> 00:18:45,600
frequency in a gitlab repository

571
00:18:45,600 --> 00:18:47,600
we use two-party merge request approvals

572
00:18:47,600 --> 00:18:49,280
for deployment or changes to query

573
00:18:49,280 --> 00:18:50,960
execution

574
00:18:50,960 --> 00:18:52,799
in practice deploying to production

575
00:18:52,799 --> 00:18:54,400
means syncing the configuration to a

576
00:18:54,400 --> 00:18:57,120
protected cloud storage bucket

577
00:18:57,120 --> 00:18:59,280
next a set of cloud functions manages

578
00:18:59,280 --> 00:19:01,120
reading the query configuration files

579
00:19:01,120 --> 00:19:02,960
and executing the queries at designated

580
00:19:02,960 --> 00:19:05,440
intervals

581
00:19:05,520 --> 00:19:06,400
third

582
00:19:06,400 --> 00:19:07,919
these functions output the result and

583
00:19:07,919 --> 00:19:10,000
metadata to pub sub queues as well as

584
00:19:10,000 --> 00:19:11,679
writing them to bigquery output tables

585
00:19:11,679 --> 00:19:14,880
for persistent result storage

586
00:19:14,880 --> 00:19:16,880
well and last the result messages on

587
00:19:16,880 --> 00:19:18,480
those pub subtopics are consumed by

588
00:19:18,480 --> 00:19:20,320
another small tool that based on the

589
00:19:20,320 --> 00:19:21,760
metadata initially configured in the

590
00:19:21,760 --> 00:19:24,320
yaml files formats them into email slack

591
00:19:24,320 --> 00:19:27,039
and page of duty notifications

592
00:19:27,039 --> 00:19:28,559
this functionality in addition to the

593
00:19:28,559 --> 00:19:30,559
data load and ingest capabilities

594
00:19:30,559 --> 00:19:32,080
represents the bulk of the code we had

595
00:19:32,080 --> 00:19:34,960
to write to produce a sim in gcp

596
00:19:34,960 --> 00:19:36,880
all told across a handful of tools and

597
00:19:36,880 --> 00:19:38,880
infrastructure as code in python go and

598
00:19:38,880 --> 00:19:41,280
terraform we wrote somewhere around 6000

599
00:19:41,280 --> 00:19:42,799
lines of code

600
00:19:42,799 --> 00:19:44,559
next let's talk about a simpler case but

601
00:19:44,559 --> 00:19:46,080
a high value one

602
00:19:46,080 --> 00:19:49,360
near real time streaming alerting

603
00:19:49,360 --> 00:19:51,280
monitoring a stream of incoming events

604
00:19:51,280 --> 00:19:53,360
for simple pattern matches enables quick

605
00:19:53,360 --> 00:19:55,120
detection and response workflows for

606
00:19:55,120 --> 00:19:56,640
many general cases

607
00:19:56,640 --> 00:19:58,480
for example let's explore detecting the

608
00:19:58,480 --> 00:20:02,640
use of a compromised ssh private key

609
00:20:02,640 --> 00:20:03,919
starting at the same point as our

610
00:20:03,919 --> 00:20:05,919
streaming injection an event is logged

611
00:20:05,919 --> 00:20:08,159
from sshd on a machine in our on-prem

612
00:20:08,159 --> 00:20:10,159
infrastructure the event is sent via

613
00:20:10,159 --> 00:20:12,000
flipbit collection to the cloud locking

614
00:20:12,000 --> 00:20:14,080
api

615
00:20:14,080 --> 00:20:15,840
then we use a cloud logging filter

616
00:20:15,840 --> 00:20:18,080
expression to match specific events in

617
00:20:18,080 --> 00:20:20,039
this example by inspecting the

618
00:20:20,039 --> 00:20:21,280
jsonpayload.ident and

619
00:20:21,280 --> 00:20:24,280
jsonpayload.messagefields

620
00:20:24,480 --> 00:20:26,960
finally upon matching the expression the

621
00:20:26,960 --> 00:20:28,880
event is set to a pub subtopic that is

622
00:20:28,880 --> 00:20:30,720
read formatted and sent to various

623
00:20:30,720 --> 00:20:33,280
output destinations

624
00:20:33,280 --> 00:20:34,720
now that we've covered ingestion and

625
00:20:34,720 --> 00:20:36,480
alerting let's talk about how we manage

626
00:20:36,480 --> 00:20:39,440
access to our data

627
00:20:39,440 --> 00:20:41,280
at two sigma our security managed data

628
00:20:41,280 --> 00:20:43,280
sets vary widely in sensitivity and

629
00:20:43,280 --> 00:20:44,880
classification

630
00:20:44,880 --> 00:20:46,559
other teams outside security often

631
00:20:46,559 --> 00:20:48,400
leverage the bulk syslog collection for

632
00:20:48,400 --> 00:20:49,840
system-level troubleshooting or

633
00:20:49,840 --> 00:20:52,000
plant-wide upgrade efforts

634
00:20:52,000 --> 00:20:53,440
when granting access to separate

635
00:20:53,440 --> 00:20:55,600
engineering teams or even other users

636
00:20:55,600 --> 00:20:57,679
within the security umbrella we needed

637
00:20:57,679 --> 00:20:59,679
the ability to granularly control access

638
00:20:59,679 --> 00:21:00,840
to our data

639
00:21:00,840 --> 00:21:03,360
sets to accomplish this we sync group

640
00:21:03,360 --> 00:21:04,880
backles from our internal directory

641
00:21:04,880 --> 00:21:06,559
service to google cloud directory

642
00:21:06,559 --> 00:21:07,919
service

643
00:21:07,919 --> 00:21:09,360
these groups are populated into the

644
00:21:09,360 --> 00:21:11,760
bigquery viewer role on each data set

645
00:21:11,760 --> 00:21:13,360
which allows us to separately provision

646
00:21:13,360 --> 00:21:16,400
access to more than 50 unique data sets

647
00:21:16,400 --> 00:21:17,840
we use an internally developed

648
00:21:17,840 --> 00:21:20,000
multi-party sign-off system for ads to

649
00:21:20,000 --> 00:21:22,240
data sets to record approval

650
00:21:22,240 --> 00:21:24,240
we also maintain audit logs of bigquery

651
00:21:24,240 --> 00:21:26,480
query usage for forensic evidence of any

652
00:21:26,480 --> 00:21:28,880
internal misuse

653
00:21:28,880 --> 00:21:30,240
now let's talk about some of our

654
00:21:30,240 --> 00:21:32,000
operational wins after completing this

655
00:21:32,000 --> 00:21:34,559
undertaking

656
00:21:35,280 --> 00:21:37,120
we can elegantly classify our results

657
00:21:37,120 --> 00:21:39,360
into two sections the nomores and the

658
00:21:39,360 --> 00:21:42,400
high fives first the no morse

659
00:21:42,400 --> 00:21:44,880
log rehydration we never have to store

660
00:21:44,880 --> 00:21:46,799
archive logs from bigquery or pay any

661
00:21:46,799 --> 00:21:49,120
search speed penalties for older data

662
00:21:49,120 --> 00:21:51,039
in our previous system we often rolled

663
00:21:51,039 --> 00:21:52,799
off high volume data sets in as little

664
00:21:52,799 --> 00:21:54,559
as 30 days because we didn't have

665
00:21:54,559 --> 00:21:56,720
storage capacity and index size affected

666
00:21:56,720 --> 00:21:58,880
performance

667
00:21:58,880 --> 00:22:00,720
too big for our sim is something we say

668
00:22:00,720 --> 00:22:03,360
far less often in our previous system we

669
00:22:03,360 --> 00:22:05,039
often deferred ingesting high volume

670
00:22:05,039 --> 00:22:08,000
data sets due to size constraints

671
00:22:08,000 --> 00:22:10,720
now the high fives query speed we can

672
00:22:10,720 --> 00:22:12,720
run large queries over years of data

673
00:22:12,720 --> 00:22:14,720
interactively during exploratory or

674
00:22:14,720 --> 00:22:16,559
threat hunting work

675
00:22:16,559 --> 00:22:18,960
and ingestion admin overhead

676
00:22:18,960 --> 00:22:21,120
we onboard a few additional data sets

677
00:22:21,120 --> 00:22:22,880
every month and typically deliver with

678
00:22:22,880 --> 00:22:24,480
only a few hours of engineering work for

679
00:22:24,480 --> 00:22:27,440
each source

680
00:22:27,440 --> 00:22:29,039
next let's take a quick look at some

681
00:22:29,039 --> 00:22:32,240
lessons we learned in the process

682
00:22:32,240 --> 00:22:33,760
the first lessons we learned was that

683
00:22:33,760 --> 00:22:35,760
even during the lifetime of this project

684
00:22:35,760 --> 00:22:37,440
much has changed in the gcp data

685
00:22:37,440 --> 00:22:39,120
ecosystem

686
00:22:39,120 --> 00:22:40,720
tools such as dataflow and cloud

687
00:22:40,720 --> 00:22:42,400
monitoring may be more than adequate

688
00:22:42,400 --> 00:22:44,000
replacement for much of our own tooling

689
00:22:44,000 --> 00:22:45,760
and customization

690
00:22:45,760 --> 00:22:47,679
additionally active monitoring in fast

691
00:22:47,679 --> 00:22:49,360
moving environments can save you a lot

692
00:22:49,360 --> 00:22:50,240
of pain

693
00:22:50,240 --> 00:22:52,000
we run daily integration tests against

694
00:22:52,000 --> 00:22:54,000
live gcp accounts to ensure we don't

695
00:22:54,000 --> 00:22:56,240
miss an api deprecation or response

696
00:22:56,240 --> 00:22:57,600
format change that can break our

697
00:22:57,600 --> 00:22:58,799
ingestion

698
00:22:58,799 --> 00:23:00,159
this is specifically in the lessons

699
00:23:00,159 --> 00:23:01,679
learned section because we had to learn

700
00:23:01,679 --> 00:23:03,600
that the hard way first

701
00:23:03,600 --> 00:23:05,360
and the note about costs much of our

702
00:23:05,360 --> 00:23:06,960
expense has been streaming very high

703
00:23:06,960 --> 00:23:09,280
volume locks while the cost per byte is

704
00:23:09,280 --> 00:23:11,440
very low for large data sets this adds

705
00:23:11,440 --> 00:23:12,640
up quickly

706
00:23:12,640 --> 00:23:14,159
we're exploring converting some of those

707
00:23:14,159 --> 00:23:16,159
ingests to batch ingest to save money

708
00:23:16,159 --> 00:23:20,000
where we don't need low latency ingest

709
00:23:20,640 --> 00:23:22,159
i'll now talk you through a recorded

710
00:23:22,159 --> 00:23:23,600
demo of a sample of our streaming

711
00:23:23,600 --> 00:23:24,960
detection patterns

712
00:23:24,960 --> 00:23:26,720
sorry folks logging into the two sigma

713
00:23:26,720 --> 00:23:28,400
network live at black hat was a tough

714
00:23:28,400 --> 00:23:31,600
sell to our compliance team

715
00:23:31,919 --> 00:23:33,760
okay so we start with the shell on my

716
00:23:33,760 --> 00:23:36,000
linux home server on the left inside to

717
00:23:36,000 --> 00:23:38,000
sigma owned and run data centers and our

718
00:23:38,000 --> 00:23:39,679
browser on the right showing the gcp

719
00:23:39,679 --> 00:23:41,840
cloud logging logs explorer

720
00:23:41,840 --> 00:23:43,200
i'll show you the filter expression we

721
00:23:43,200 --> 00:23:44,799
used to route the log entry towards our

722
00:23:44,799 --> 00:23:46,159
pub sub queue

723
00:23:46,159 --> 00:23:47,679
here we're just inspecting for an

724
00:23:47,679 --> 00:23:49,360
accepted public key for root message

725
00:23:49,360 --> 00:23:51,120
from sshd

726
00:23:51,120 --> 00:23:53,919
now ssh to root on a machine with kioth

727
00:23:53,919 --> 00:23:55,520
simulating the use of a protected

728
00:23:55,520 --> 00:23:57,679
private key to ssh to root directly for

729
00:23:57,679 --> 00:23:59,360
break glass purposes

730
00:23:59,360 --> 00:24:00,799
looking at our logging filter again we

731
00:24:00,799 --> 00:24:02,640
see the pub sub topic in the destination

732
00:24:02,640 --> 00:24:04,960
field

733
00:24:04,960 --> 00:24:06,480
in a few moments we'll see our slack

734
00:24:06,480 --> 00:24:08,240
notification palm up in the bottom right

735
00:24:08,240 --> 00:24:10,559
hand corner of the screen

736
00:24:10,559 --> 00:24:12,159
when we click that we're taken to a

737
00:24:12,159 --> 00:24:13,679
shared alerting channel that is one of

738
00:24:13,679 --> 00:24:14,799
our output destinations for

739
00:24:14,799 --> 00:24:16,960
notifications

740
00:24:16,960 --> 00:24:18,720
that's it and now back to ethan for

741
00:24:18,720 --> 00:24:21,120
tactical results

742
00:24:21,120 --> 00:24:23,039
thanks brett now looking at some of our

743
00:24:23,039 --> 00:24:24,880
tactical results

744
00:24:24,880 --> 00:24:26,480
let's start by summarizing the overall

745
00:24:26,480 --> 00:24:27,919
effort that went into building our own

746
00:24:27,919 --> 00:24:30,559
sim as brett said we wrote around 6000

747
00:24:30,559 --> 00:24:32,320
lines of code for the necessary

748
00:24:32,320 --> 00:24:34,080
ingestion routing scheduling and

749
00:24:34,080 --> 00:24:36,480
alerting functions this coding work plus

750
00:24:36,480 --> 00:24:38,080
the configuration of collection agents

751
00:24:38,080 --> 00:24:39,600
and aggregators as well as the

752
00:24:39,600 --> 00:24:42,159
infrastructure in gcp took about half an

753
00:24:42,159 --> 00:24:45,039
fte year of effort to get an mvp our

754
00:24:45,039 --> 00:24:46,799
minimum viable product

755
00:24:46,799 --> 00:24:48,240
we spent an additional three months

756
00:24:48,240 --> 00:24:49,760
addressing some of the more complicated

757
00:24:49,760 --> 00:24:51,600
use cases we have to get to where we are

758
00:24:51,600 --> 00:24:53,440
today

759
00:24:53,440 --> 00:24:54,960
these efforts have paid off and we're

760
00:24:54,960 --> 00:24:56,799
now currently storing approximately five

761
00:24:56,799 --> 00:24:59,039
petabytes of data in bq all of our

762
00:24:59,039 --> 00:25:00,559
historical data is immediately

763
00:25:00,559 --> 00:25:03,200
searchable without any rehydration

764
00:25:03,200 --> 00:25:05,279
we routinely ingest over 5 terabytes a

765
00:25:05,279 --> 00:25:07,279
day without concerns about overages or

766
00:25:07,279 --> 00:25:09,120
loss of function from punitive licensing

767
00:25:09,120 --> 00:25:10,159
terms

768
00:25:10,159 --> 00:25:12,000
and our average query time is a matter

769
00:25:12,000 --> 00:25:14,080
of seconds which is a vast improvement

770
00:25:14,080 --> 00:25:15,520
from the tens of minutes and upwards

771
00:25:15,520 --> 00:25:18,480
that we saw on our former platform

772
00:25:18,480 --> 00:25:20,080
we estimate we've saved approximately

773
00:25:20,080 --> 00:25:21,279
three and a half million dollars in

774
00:25:21,279 --> 00:25:23,120
upfront license costs and an additional

775
00:25:23,120 --> 00:25:24,880
six hundred thousand dollars annually in

776
00:25:24,880 --> 00:25:27,039
maintenance contracts after the initial

777
00:25:27,039 --> 00:25:28,960
setup our staffing resources required to

778
00:25:28,960 --> 00:25:31,600
support bq are slightly less than what

779
00:25:31,600 --> 00:25:33,200
it took to support our former vendors

780
00:25:33,200 --> 00:25:35,039
product and amount to about one person

781
00:25:35,039 --> 00:25:36,480
month per year

782
00:25:36,480 --> 00:25:38,159
the largest reason for this is the

783
00:25:38,159 --> 00:25:40,320
reduced need to track down noisy loggers

784
00:25:40,320 --> 00:25:41,840
given the low cost of storage and

785
00:25:41,840 --> 00:25:43,679
negligible impact extra data has on

786
00:25:43,679 --> 00:25:46,000
search performance

787
00:25:46,000 --> 00:25:47,840
so looking holistically what did this

788
00:25:47,840 --> 00:25:49,520
effort do to advance our security

789
00:25:49,520 --> 00:25:50,880
program

790
00:25:50,880 --> 00:25:52,799
for starters we're much more agile when

791
00:25:52,799 --> 00:25:54,240
it comes to choosing data sets to

792
00:25:54,240 --> 00:25:56,080
collect by opening up ingestion

793
00:25:56,080 --> 00:25:57,919
capabilities we've been able to add more

794
00:25:57,919 --> 00:25:59,600
data feeds and free our security

795
00:25:59,600 --> 00:26:01,200
analysts to experiment on developing

796
00:26:01,200 --> 00:26:02,799
additional strategies that they weren't

797
00:26:02,799 --> 00:26:04,159
able to before

798
00:26:04,159 --> 00:26:05,679
these include adding new external data

799
00:26:05,679 --> 00:26:07,679
sets to help match iocs and the like as

800
00:26:07,679 --> 00:26:09,360
well as adding larger internal feeds

801
00:26:09,360 --> 00:26:11,200
like firewall logs and certain network

802
00:26:11,200 --> 00:26:12,799
telemetry that enables more

803
00:26:12,799 --> 00:26:14,480
sophisticated analysis to detect

804
00:26:14,480 --> 00:26:16,559
anomalies and threats

805
00:26:16,559 --> 00:26:18,720
for our end users of bq there was an

806
00:26:18,720 --> 00:26:20,480
onboarding cost to retrain our analysts

807
00:26:20,480 --> 00:26:22,559
and threat hunters to use standard sql

808
00:26:22,559 --> 00:26:24,240
but it's a more fungible skill set that

809
00:26:24,240 --> 00:26:26,000
has greater generalizability than a

810
00:26:26,000 --> 00:26:28,000
vendor's proprietary language the

811
00:26:28,000 --> 00:26:29,600
analysts are also much happier because

812
00:26:29,600 --> 00:26:31,120
the time to complete a search is down

813
00:26:31,120 --> 00:26:32,799
and that helps speed up investigations

814
00:26:32,799 --> 00:26:34,799
and incident response functions the

815
00:26:34,799 --> 00:26:36,320
improved speed and reliability of our

816
00:26:36,320 --> 00:26:38,000
streaming alerting has allowed us to

817
00:26:38,000 --> 00:26:39,919
invest in near real-time detection and

818
00:26:39,919 --> 00:26:43,600
response for critical use cases

819
00:26:44,960 --> 00:26:46,559
given the security controls baked into

820
00:26:46,559 --> 00:26:48,480
the platform we're able to open up

821
00:26:48,480 --> 00:26:50,000
select data sets and views to other

822
00:26:50,000 --> 00:26:51,919
engineering teams at two sigma to help

823
00:26:51,919 --> 00:26:53,440
them troubleshoot and detect issues on

824
00:26:53,440 --> 00:26:54,640
their systems

825
00:26:54,640 --> 00:26:56,240
this was also the case in our previous

826
00:26:56,240 --> 00:26:57,840
product but we had to limit what we

827
00:26:57,840 --> 00:26:59,440
ingested from them given our sizing

828
00:26:59,440 --> 00:27:01,840
concerns and often had to nag them when

829
00:27:01,840 --> 00:27:03,520
they were logging too much which again

830
00:27:03,520 --> 00:27:05,520
is no longer the case

831
00:27:05,520 --> 00:27:06,960
our new platform also provides

832
00:27:06,960 --> 00:27:09,120
flexibility and extensibility in data

833
00:27:09,120 --> 00:27:11,440
integration and parsing controls bq

834
00:27:11,440 --> 00:27:13,679
supports complex record types so doing

835
00:27:13,679 --> 00:27:15,679
things like blob json insertion works

836
00:27:15,679 --> 00:27:17,440
and is readily parsable

837
00:27:17,440 --> 00:27:18,720
there are also no restrictions on

838
00:27:18,720 --> 00:27:20,399
ingestion methodologies

839
00:27:20,399 --> 00:27:22,000
nor are we forced to use a specific

840
00:27:22,000 --> 00:27:23,360
framework for logging to match the

841
00:27:23,360 --> 00:27:25,440
platform's expectations we're able to

842
00:27:25,440 --> 00:27:27,279
self-define our schema to match internal

843
00:27:27,279 --> 00:27:28,640
common data model

844
00:27:28,640 --> 00:27:30,320
with much less engineering effort which

845
00:27:30,320 --> 00:27:32,480
helps to reduce cognitive burden on our

846
00:27:32,480 --> 00:27:34,240
investigators when trying to join

847
00:27:34,240 --> 00:27:37,679
datasets from disparate sources

848
00:27:37,679 --> 00:27:39,200
so as we look toward the future of our

849
00:27:39,200 --> 00:27:41,039
homegrown sim several areas for

850
00:27:41,039 --> 00:27:42,880
improvement and growth stand out

851
00:27:42,880 --> 00:27:44,559
first we are continuing to onboard and

852
00:27:44,559 --> 00:27:46,320
validate new data sets some are

853
00:27:46,320 --> 00:27:48,080
operational like a new sas provider's

854
00:27:48,080 --> 00:27:50,080
logs some are tactical like ingesting

855
00:27:50,080 --> 00:27:52,240
new threat feeds second our choice for

856
00:27:52,240 --> 00:27:53,919
building our own sim in the public cloud

857
00:27:53,919 --> 00:27:56,080
has future implications given how fast

858
00:27:56,080 --> 00:27:58,000
that area grows and iterates we are

859
00:27:58,000 --> 00:27:59,440
considering making adjustments to some

860
00:27:59,440 --> 00:28:00,720
of the development work we've done to

861
00:28:00,720 --> 00:28:02,320
incorporate less labor-intensive

862
00:28:02,320 --> 00:28:03,919
third-party offerings into our sim

863
00:28:03,919 --> 00:28:06,320
workflow such as google's dataflow

864
00:28:06,320 --> 00:28:07,840
we also have plans to extend our

865
00:28:07,840 --> 00:28:09,840
response pipelines first with additional

866
00:28:09,840 --> 00:28:11,440
automation to do things like isolate

867
00:28:11,440 --> 00:28:13,200
machines or disable access and then

868
00:28:13,200 --> 00:28:15,120
later to also tie into legacy on-prem

869
00:28:15,120 --> 00:28:16,799
systems to handle additional response

870
00:28:16,799 --> 00:28:18,799
scenarios

871
00:28:18,799 --> 00:28:20,559
overall the decision to roller on sim

872
00:28:20,559 --> 00:28:22,399
has proven to be successful to date it's

873
00:28:22,399 --> 00:28:24,000
enabled our broader event collection and

874
00:28:24,000 --> 00:28:25,600
analysis program to evolve and to

875
00:28:25,600 --> 00:28:27,120
continue to tackle the ever-changing

876
00:28:27,120 --> 00:28:29,679
threat landscape

877
00:28:29,679 --> 00:28:30,880
with that thank you everyone for

878
00:28:30,880 --> 00:28:32,159
attending and we'd be happy to answer

879
00:28:32,159 --> 00:28:35,360
any questions

