1
00:00:01,130 --> 00:00:14,320
[Music]

2
00:00:14,320 --> 00:00:16,400
hi my name is andrea little lombago and

3
00:00:16,400 --> 00:00:18,080
i'm here to discuss some recent research

4
00:00:18,080 --> 00:00:20,000
i've been conducting looking at the

5
00:00:20,000 --> 00:00:21,600
growing regulatory shifts of government

6
00:00:21,600 --> 00:00:24,720
mandated access to data across the globe

7
00:00:24,720 --> 00:00:26,320
now to be clear i'm not really talking

8
00:00:26,320 --> 00:00:28,560
about their cyber offensive behaviors or

9
00:00:28,560 --> 00:00:30,800
cyber attacks in that regard but more so

10
00:00:30,800 --> 00:00:32,719
focus on these major regulatory shifts

11
00:00:32,719 --> 00:00:36,160
that are happening across the globe

12
00:00:36,160 --> 00:00:37,920
now the part of this research started a

13
00:00:37,920 --> 00:00:39,760
couple years ago when i was looking at

14
00:00:39,760 --> 00:00:40,480
the

15
00:00:40,480 --> 00:00:42,079
encryption debate and the rise of yet

16
00:00:42,079 --> 00:00:44,960
again of the crypto wars and looking at

17
00:00:44,960 --> 00:00:45,920
just all these different governments

18
00:00:45,920 --> 00:00:47,200
that are starting to mandate access to

19
00:00:47,200 --> 00:00:49,520
data via backdoors and encryption and

20
00:00:49,520 --> 00:00:51,600
looking at the population of those

21
00:00:51,600 --> 00:00:53,039
countries and realizing that over half

22
00:00:53,039 --> 00:00:55,120
of the world's population lived under

23
00:00:55,120 --> 00:00:56,239
governments who are mandating or

24
00:00:56,239 --> 00:00:58,399
considering mandating government access

25
00:00:58,399 --> 00:01:00,399
to data and so that was concerning and

26
00:01:00,399 --> 00:01:02,079
then even on top of that

27
00:01:02,079 --> 00:01:03,359
it wasn't really just through the

28
00:01:03,359 --> 00:01:04,640
encryption backdoors which is what we

29
00:01:04,640 --> 00:01:06,400
commonly think about it was through a

30
00:01:06,400 --> 00:01:07,680
whole range of different kinds of

31
00:01:07,680 --> 00:01:09,600
regulatory shifts that were equally

32
00:01:09,600 --> 00:01:10,880
troublesome if you're concerned about

33
00:01:10,880 --> 00:01:12,240
data protection and individual

34
00:01:12,240 --> 00:01:15,360
individual data rights

35
00:01:15,920 --> 00:01:17,759
now here's what we normally see

36
00:01:17,759 --> 00:01:19,759
historically we've seen technology tends

37
00:01:19,759 --> 00:01:21,680
to skyrocket at an exponential pace and

38
00:01:21,680 --> 00:01:24,320
that of course is happening uh still and

39
00:01:24,320 --> 00:01:26,320
policy has just basically been flatlined

40
00:01:26,320 --> 00:01:28,000
we haven't seen major policy shifts

41
00:01:28,000 --> 00:01:29,680
across the globe especially in the

42
00:01:29,680 --> 00:01:31,360
digital realm

43
00:01:31,360 --> 00:01:33,119
but all of that is changing now the new

44
00:01:33,119 --> 00:01:35,119
normal really is looking at policy

45
00:01:35,119 --> 00:01:37,759
skyrocketing not necessarily at the pace

46
00:01:37,759 --> 00:01:39,759
of technology for sure but it is

47
00:01:39,759 --> 00:01:41,600
changing dramatically in an extremely

48
00:01:41,600 --> 00:01:43,439
dynamic landscape with enormous

49
00:01:43,439 --> 00:01:45,200
implications for data security and data

50
00:01:45,200 --> 00:01:47,119
protection

51
00:01:47,119 --> 00:01:49,280
now as i mentioned

52
00:01:49,280 --> 00:01:51,040
the back doors and encryption was a big

53
00:01:51,040 --> 00:01:52,320
concern and a big impetus for looking at

54
00:01:52,320 --> 00:01:53,680
some of this research

55
00:01:53,680 --> 00:01:55,200
and what it i found was that really it

56
00:01:55,200 --> 00:01:57,119
was part of this broader

57
00:01:57,119 --> 00:01:58,960
positioning of governments towards what

58
00:01:58,960 --> 00:02:00,479
i'll think of as data hoarding gathering

59
00:02:00,479 --> 00:02:02,399
as much data as possible for greater

60
00:02:02,399 --> 00:02:04,560
control of that information and so the

61
00:02:04,560 --> 00:02:06,479
crypto wars were certainly uh and still

62
00:02:06,479 --> 00:02:08,720
are a big concern in that area

63
00:02:08,720 --> 00:02:09,919
but there are other kinds of shifts that

64
00:02:09,919 --> 00:02:11,520
were going on we're seeing greater

65
00:02:11,520 --> 00:02:13,760
demands for source code disclosure for

66
00:02:13,760 --> 00:02:15,040
companies that are operating in a

67
00:02:15,040 --> 00:02:16,959
certain country

68
00:02:16,959 --> 00:02:18,720
we're also seeing data residency risk on

69
00:02:18,720 --> 00:02:20,319
the rise and so we think about data

70
00:02:20,319 --> 00:02:21,520
residency it falls under a couple

71
00:02:21,520 --> 00:02:23,680
different names they're somewhat nuances

72
00:02:23,680 --> 00:02:24,800
that distinguish them but if you think

73
00:02:24,800 --> 00:02:26,800
about data sovereignty data localization

74
00:02:26,800 --> 00:02:28,640
data residency really it's just focused

75
00:02:28,640 --> 00:02:30,640
on data storage within a country and

76
00:02:30,640 --> 00:02:32,879
that can impose all sorts of different

77
00:02:32,879 --> 00:02:34,239
risks depending on which country that's

78
00:02:34,239 --> 00:02:36,160
in

79
00:02:36,160 --> 00:02:37,760
we also see the rise of surveillance and

80
00:02:37,760 --> 00:02:39,280
tech infrastructure

81
00:02:39,280 --> 00:02:41,120
and in turn with that with government

82
00:02:41,120 --> 00:02:43,040
access to that data which also can be

83
00:02:43,040 --> 00:02:44,319
extremely worrisome because given just

84
00:02:44,319 --> 00:02:46,000
the enormous amount of data that comes

85
00:02:46,000 --> 00:02:47,200
circulating through those those

86
00:02:47,200 --> 00:02:48,879
technologies

87
00:02:48,879 --> 00:02:50,239
and then finally there's this the broad

88
00:02:50,239 --> 00:02:52,080
range of just blatant data access

89
00:02:52,080 --> 00:02:54,000
requirements and all of these generally

90
00:02:54,000 --> 00:02:55,680
are under the auspices of national

91
00:02:55,680 --> 00:02:57,120
security requirements and so you'll hear

92
00:02:57,120 --> 00:02:58,959
the same kind of discussions made across

93
00:02:58,959 --> 00:03:00,640
the globe whether in authoritarian

94
00:03:00,640 --> 00:03:03,360
regimes or democracies really asking for

95
00:03:03,360 --> 00:03:05,440
data access upon requests for various

96
00:03:05,440 --> 00:03:08,640
kinds of national security reasons

97
00:03:08,640 --> 00:03:10,080
and so looking at this you see a whole

98
00:03:10,080 --> 00:03:11,519
range of different kinds of tactics

99
00:03:11,519 --> 00:03:13,840
starting to be pursued by governments

100
00:03:13,840 --> 00:03:15,360
but the same time there is actually this

101
00:03:15,360 --> 00:03:17,599
orthogonal or a counter trend going on

102
00:03:17,599 --> 00:03:19,920
in the realm of data protection

103
00:03:19,920 --> 00:03:21,760
and one of the biggest uh contributors

104
00:03:21,760 --> 00:03:22,959
to that is the general data protection

105
00:03:22,959 --> 00:03:24,959
regulation from the european union and i

106
00:03:24,959 --> 00:03:26,319
know love or hate it it really is the

107
00:03:26,319 --> 00:03:28,080
most prominent one out there right now

108
00:03:28,080 --> 00:03:29,760
that focuses on individual data

109
00:03:29,760 --> 00:03:31,200
protection rights

110
00:03:31,200 --> 00:03:32,720
but it's not alone

111
00:03:32,720 --> 00:03:35,040
in brazil they've passed the lg dp which

112
00:03:35,040 --> 00:03:37,360
similarly has drawn from some uh

113
00:03:37,360 --> 00:03:39,760
inspiration from the gdpr

114
00:03:39,760 --> 00:03:40,959
we have in africa almost half the

115
00:03:40,959 --> 00:03:43,040
continent has adopted some form of data

116
00:03:43,040 --> 00:03:44,159
protection laws with many other

117
00:03:44,159 --> 00:03:46,239
countries also proposing other kinds of

118
00:03:46,239 --> 00:03:48,159
data protection laws

119
00:03:48,159 --> 00:03:50,400
in the united states california's ccpa

120
00:03:50,400 --> 00:03:52,640
is most prominent and really had far

121
00:03:52,640 --> 00:03:54,080
reaching impact given the size of its

122
00:03:54,080 --> 00:03:56,400
economy and it has led to other states

123
00:03:56,400 --> 00:03:58,400
within the united states as well

124
00:03:58,400 --> 00:03:59,599
adopting some more kinds of data

125
00:03:59,599 --> 00:04:02,399
protection laws

126
00:04:02,480 --> 00:04:03,599
and so given this we've got these

127
00:04:03,599 --> 00:04:05,040
divergent trends going on we've got

128
00:04:05,040 --> 00:04:06,640
greater interference of the government

129
00:04:06,640 --> 00:04:08,560
across the globe uh when it comes to

130
00:04:08,560 --> 00:04:10,560
data protection and access risk and it

131
00:04:10,560 --> 00:04:12,000
really just you know drove home this

132
00:04:12,000 --> 00:04:14,640
notion that while we do realize that you

133
00:04:14,640 --> 00:04:16,399
know something like malware and virus is

134
00:04:16,399 --> 00:04:18,399
spread very quickly across the globe

135
00:04:18,399 --> 00:04:19,759
when it comes to data protection and

136
00:04:19,759 --> 00:04:22,079
cyber risks borders do exist on the

137
00:04:22,079 --> 00:04:23,840
internet and so i want to look at you

138
00:04:23,840 --> 00:04:25,360
know what kind of risks are those how

139
00:04:25,360 --> 00:04:27,440
does impact supply chain risk and the

140
00:04:27,440 --> 00:04:29,600
splinternet is really this notion of the

141
00:04:29,600 --> 00:04:32,080
division of the of the global internet

142
00:04:32,080 --> 00:04:33,759
by sovereign territories and so what

143
00:04:33,759 --> 00:04:35,680
impact does it have for companies when

144
00:04:35,680 --> 00:04:36,479
they're thinking about where they're

145
00:04:36,479 --> 00:04:38,479
gonna be located across the globe uh

146
00:04:38,479 --> 00:04:39,759
data protection and cyber risk

147
00:04:39,759 --> 00:04:43,120
definitely vary quite a bit by location

148
00:04:43,120 --> 00:04:44,240
and which of these movements is gaining

149
00:04:44,240 --> 00:04:45,600
traction are the data hoarders winning

150
00:04:45,600 --> 00:04:47,440
or are the data protection advocates uh

151
00:04:47,440 --> 00:04:49,360
winning and so what i want to do is

152
00:04:49,360 --> 00:04:50,880
really look across the globe look at a

153
00:04:50,880 --> 00:04:53,040
country by country comparison apples to

154
00:04:53,040 --> 00:04:55,040
apples and figure out where these

155
00:04:55,040 --> 00:04:56,720
countries are racking stacking and then

156
00:04:56,720 --> 00:04:58,080
creating that baseline so we eventually

157
00:04:58,080 --> 00:04:59,520
can start doing some trend analysis and

158
00:04:59,520 --> 00:05:01,120
so in order to do that you have to

159
00:05:01,120 --> 00:05:03,440
quantify it and so that was uh that's

160
00:05:03,440 --> 00:05:04,160
the

161
00:05:04,160 --> 00:05:06,160
the goal of the project that i'm focused

162
00:05:06,160 --> 00:05:08,000
on right now and before getting into

163
00:05:08,000 --> 00:05:09,039
that research design and some of the

164
00:05:09,039 --> 00:05:10,800
data i think it's really important to

165
00:05:10,800 --> 00:05:13,759
first focus on that research design and

166
00:05:13,759 --> 00:05:14,960
provide an overview of that shifting

167
00:05:14,960 --> 00:05:17,039
regulatory landscape so you can see what

168
00:05:17,039 --> 00:05:19,360
these realm of of tactics and processes

169
00:05:19,360 --> 00:05:21,120
and policies and laws are

170
00:05:21,120 --> 00:05:25,160
that governments are starting to pursue

171
00:05:25,680 --> 00:05:27,759
and so for a little bit of context

172
00:05:27,759 --> 00:05:29,520
if we were to look at the data

173
00:05:29,520 --> 00:05:30,960
protection and data hoarders sort of as

174
00:05:30,960 --> 00:05:33,280
this broad spectrum really where they

175
00:05:33,280 --> 00:05:34,560
they tend to have on one end of the

176
00:05:34,560 --> 00:05:36,560
spectrum are the digital authoritarians

177
00:05:36,560 --> 00:05:38,400
you may also note here that as techno

178
00:05:38,400 --> 00:05:40,400
dictators this is where governments

179
00:05:40,400 --> 00:05:41,759
generally authoritarian governments are

180
00:05:41,759 --> 00:05:43,199
those that are trying to gather up as

181
00:05:43,199 --> 00:05:45,520
much information as data as possible

182
00:05:45,520 --> 00:05:47,280
gather control of that data and

183
00:05:47,280 --> 00:05:48,639
generally spin through a lot of

184
00:05:48,639 --> 00:05:49,919
offensive behavior but also through

185
00:05:49,919 --> 00:05:51,600
censorship data manipulation

186
00:05:51,600 --> 00:05:53,919
disinformation it's a whole big toolbox

187
00:05:53,919 --> 00:05:56,319
and just the latest tool in this toolbox

188
00:05:56,319 --> 00:05:58,080
is government mandated access to data by

189
00:05:58,080 --> 00:06:00,319
a lot of these countries

190
00:06:00,319 --> 00:06:01,919
and that's a it's a trend that's really

191
00:06:01,919 --> 00:06:03,039
gaining traction there's been a lot of

192
00:06:03,039 --> 00:06:04,800
research lately over just the rise of

193
00:06:04,800 --> 00:06:06,479
digital authoritarians and the diffusion

194
00:06:06,479 --> 00:06:07,840
of this kind of ideology across the

195
00:06:07,840 --> 00:06:09,520
globe

196
00:06:09,520 --> 00:06:10,800
now conversely on the other end are

197
00:06:10,800 --> 00:06:12,400
digital democracies now this is a much

198
00:06:12,400 --> 00:06:14,720
more nascent notion there really is a

199
00:06:14,720 --> 00:06:16,240
very solid playbook starting to emerge

200
00:06:16,240 --> 00:06:18,080
from digital authoritarians that same

201
00:06:18,080 --> 00:06:19,360
kind of playbook does not really yet

202
00:06:19,360 --> 00:06:21,440
exist for digital democracies but it is

203
00:06:21,440 --> 00:06:23,360
starting to emerge and the foundational

204
00:06:23,360 --> 00:06:25,919
components of this really focus more on

205
00:06:25,919 --> 00:06:28,560
open secure resilient internet focus on

206
00:06:28,560 --> 00:06:30,240
individual data rights individual data

207
00:06:30,240 --> 00:06:32,880
protections and no government access to

208
00:06:32,880 --> 00:06:34,880
that data or very minimal or within some

209
00:06:34,880 --> 00:06:36,479
sort of transparent guardrails for that

210
00:06:36,479 --> 00:06:38,240
access to information and again there's

211
00:06:38,240 --> 00:06:40,400
more aspirational at the end of the day

212
00:06:40,400 --> 00:06:41,520
this is where we're seeing a movement

213
00:06:41,520 --> 00:06:43,360
towards that many of the democracies are

214
00:06:43,360 --> 00:06:46,080
moving toward

215
00:06:47,120 --> 00:06:48,479
but the reality is it's not just those

216
00:06:48,479 --> 00:06:49,759
two ends of the spectrum it's really

217
00:06:49,759 --> 00:06:51,360
much more so a spectrum of policies

218
00:06:51,360 --> 00:06:52,880
tactics and norms and we're seeing a

219
00:06:52,880 --> 00:06:54,479
whole lot of different countries falling

220
00:06:54,479 --> 00:06:56,240
in this middle area sort of a hybrid

221
00:06:56,240 --> 00:06:57,759
that are adopting some aspects of the

222
00:06:57,759 --> 00:06:59,520
authoritarians some aspects of the

223
00:06:59,520 --> 00:07:01,199
democracies and are really puddling it

224
00:07:01,199 --> 00:07:03,440
together to meet their own regime

225
00:07:03,440 --> 00:07:06,240
objectives and government objectives

226
00:07:06,240 --> 00:07:08,240
and so when looking at that when you

227
00:07:08,240 --> 00:07:09,520
think about the digital authoritarians

228
00:07:09,520 --> 00:07:11,840
and digital democracies models really

229
00:07:11,840 --> 00:07:13,360
the countries and entities that are

230
00:07:13,360 --> 00:07:15,120
really leading the way in this kind of

231
00:07:15,120 --> 00:07:17,680
research and uh setting the standards

232
00:07:17,680 --> 00:07:18,880
for those global norms and standard

233
00:07:18,880 --> 00:07:21,919
bearers are china and the european union

234
00:07:21,919 --> 00:07:23,199
and so when thinking about creating this

235
00:07:23,199 --> 00:07:24,960
research design and what kind of

236
00:07:24,960 --> 00:07:26,720
components to start coding in order to

237
00:07:26,720 --> 00:07:28,080
do that apples-to-apples comparison

238
00:07:28,080 --> 00:07:30,160
across the globe started with these two

239
00:07:30,160 --> 00:07:31,680
to look at their laws and regulations to

240
00:07:31,680 --> 00:07:33,919
see what should provide that foundation

241
00:07:33,919 --> 00:07:36,880
and then build upon that

242
00:07:37,440 --> 00:07:39,120
and so first we're looking at the rule

243
00:07:39,120 --> 00:07:40,800
setter so china china has a cyber

244
00:07:40,800 --> 00:07:42,720
security law that's probably one the

245
00:07:42,720 --> 00:07:44,240
most prominent component of it but

246
00:07:44,240 --> 00:07:45,440
there's been many other policies that

247
00:07:45,440 --> 00:07:47,039
have been passed within china that are

248
00:07:47,039 --> 00:07:48,800
really focused on this notion of cyber

249
00:07:48,800 --> 00:07:50,400
sovereignty and that's really for

250
00:07:50,400 --> 00:07:52,080
governments maintaining the right to

251
00:07:52,080 --> 00:07:53,199
control the information within their

252
00:07:53,199 --> 00:07:54,879
borders without interference from others

253
00:07:54,879 --> 00:07:55,680
and so

254
00:07:55,680 --> 00:07:57,360
on the surface that sounds great but

255
00:07:57,360 --> 00:07:58,879
then it also but then when you get into

256
00:07:58,879 --> 00:08:00,879
sort of the the devils in the details as

257
00:08:00,879 --> 00:08:02,240
far as how the government is going to

258
00:08:02,240 --> 00:08:03,680
control information how that leads to

259
00:08:03,680 --> 00:08:04,720
the various kind of censorship

260
00:08:04,720 --> 00:08:06,720
limitations and infringements on civil

261
00:08:06,720 --> 00:08:09,280
liberties and surveillance and so forth

262
00:08:09,280 --> 00:08:10,319
and so

263
00:08:10,319 --> 00:08:11,840
what comes along with cyber sovereignty

264
00:08:11,840 --> 00:08:13,360
also especially you know in china you

265
00:08:13,360 --> 00:08:15,280
have additional internet controls you

266
00:08:15,280 --> 00:08:17,199
got state access to data or asking for

267
00:08:17,199 --> 00:08:20,160
technical support uh to access that uh

268
00:08:20,160 --> 00:08:21,440
but at the same time there are security

269
00:08:21,440 --> 00:08:23,199
standards as well so various kinds of

270
00:08:23,199 --> 00:08:25,120
standards for protecting that data which

271
00:08:25,120 --> 00:08:26,800
is where you do see again this you know

272
00:08:26,800 --> 00:08:28,080
countries tend to pick and choose from

273
00:08:28,080 --> 00:08:29,120
these these two

274
00:08:29,120 --> 00:08:31,039
opposing ends of the spectrum in light

275
00:08:31,039 --> 00:08:33,120
of what they their objectives and so

276
00:08:33,120 --> 00:08:34,719
china for sure wants their corporations

277
00:08:34,719 --> 00:08:36,559
to have data protection against the

278
00:08:36,559 --> 00:08:38,320
range of attacks they may be facing and

279
00:08:38,320 --> 00:08:40,719
so you do see the different kind of uh

280
00:08:40,719 --> 00:08:43,360
integration across the board

281
00:08:43,360 --> 00:08:45,600
um china's latest five-year plan has a

282
00:08:45,600 --> 00:08:47,680
big emphasis on tech self-reliance and

283
00:08:47,680 --> 00:08:50,480
this you know largely stems from

284
00:08:50,480 --> 00:08:51,920
the industrial policy that's shifting

285
00:08:51,920 --> 00:08:53,760
the united states that is limiting

286
00:08:53,760 --> 00:08:55,600
various kinds of the major tech giants

287
00:08:55,600 --> 00:08:57,200
from china from being within the united

288
00:08:57,200 --> 00:08:58,399
states supply chain so we're seeing that

289
00:08:58,399 --> 00:09:00,399
pop up across the globe as well and so

290
00:09:00,399 --> 00:09:01,760
if china's five-year plan is really is

291
00:09:01,760 --> 00:09:03,279
taking into account these shifting

292
00:09:03,279 --> 00:09:05,680
dynamics on industrial policy to also

293
00:09:05,680 --> 00:09:07,120
integrate their own self-reliance

294
00:09:07,120 --> 00:09:09,360
self-sovereignty data localization and

295
00:09:09,360 --> 00:09:10,800
really greater government influence over

296
00:09:10,800 --> 00:09:12,240
the data

297
00:09:12,240 --> 00:09:13,920
and then finally there's a new data

298
00:09:13,920 --> 00:09:15,200
security law that'll come into effect in

299
00:09:15,200 --> 00:09:16,880
a few months later this year that's

300
00:09:16,880 --> 00:09:18,720
seeking to limit the collection of data

301
00:09:18,720 --> 00:09:20,560
of private data which falls under that

302
00:09:20,560 --> 00:09:22,560
notion of data minimalization

303
00:09:22,560 --> 00:09:24,320
uh which is something that a lot of

304
00:09:24,320 --> 00:09:26,240
democracies will propose and so you see

305
00:09:26,240 --> 00:09:28,320
some commonalities there with gdpr uh

306
00:09:28,320 --> 00:09:29,600
but at the same time they're also

307
00:09:29,600 --> 00:09:31,920
classifying private sector data uh by

308
00:09:31,920 --> 00:09:33,680
its importance to national security and

309
00:09:33,680 --> 00:09:35,519
state interests and so this is where you

310
00:09:35,519 --> 00:09:36,640
get you know it gets a little muddy

311
00:09:36,640 --> 00:09:38,560
again where you can see that

312
00:09:38,560 --> 00:09:40,399
you know depending on you know how the

313
00:09:40,399 --> 00:09:41,839
government decides to define what their

314
00:09:41,839 --> 00:09:43,600
state interests are they could require

315
00:09:43,600 --> 00:09:45,360
access to any of that kind of data and

316
00:09:45,360 --> 00:09:47,760
so that should be uh just uh

317
00:09:47,760 --> 00:09:48,560
you know something that could be

318
00:09:48,560 --> 00:09:50,000
troubling for companies that do have a

319
00:09:50,000 --> 00:09:52,880
presence in china

320
00:09:53,279 --> 00:09:54,480
and so you look at that on the one end

321
00:09:54,480 --> 00:09:55,680
and the other end we have the european

322
00:09:55,680 --> 00:09:57,440
union the gdpr which i've mentioned

323
00:09:57,440 --> 00:09:58,959
there are several principles that guide

324
00:09:58,959 --> 00:10:00,720
the the gdpr

325
00:10:00,720 --> 00:10:02,480
these include transparency data

326
00:10:02,480 --> 00:10:04,560
minimalization like i mentioned security

327
00:10:04,560 --> 00:10:06,480
standards this is where you get uh there

328
00:10:06,480 --> 00:10:07,920
have been fines so far for companies who

329
00:10:07,920 --> 00:10:09,519
have not used encryption so it's almost

330
00:10:09,519 --> 00:10:11,519
counter the the incre the

331
00:10:11,519 --> 00:10:13,360
anti-encryption movement there's much

332
00:10:13,360 --> 00:10:15,440
more accountability and transparency and

333
00:10:15,440 --> 00:10:16,880
strict standards for data transfer

334
00:10:16,880 --> 00:10:18,640
outside the eu so there is well there

335
00:10:18,640 --> 00:10:19,680
aren't requirements for data

336
00:10:19,680 --> 00:10:22,079
localization within the eu there are

337
00:10:22,079 --> 00:10:23,920
various kinds of standards for where the

338
00:10:23,920 --> 00:10:26,560
data can flow uh generally to countries

339
00:10:26,560 --> 00:10:28,560
that have equal levels of protection of

340
00:10:28,560 --> 00:10:29,760
that data

341
00:10:29,760 --> 00:10:31,120
so there are some limitations on data

342
00:10:31,120 --> 00:10:32,959
transfers and just a lot of this

343
00:10:32,959 --> 00:10:34,640
discussion from the gdpr just brought

344
00:10:34,640 --> 00:10:36,240
across the eu's really broadening into

345
00:10:36,240 --> 00:10:38,000
other areas of technologies from ai to

346
00:10:38,000 --> 00:10:39,839
facial recognition and banning that in

347
00:10:39,839 --> 00:10:41,120
public spaces and so there's a lot to

348
00:10:41,120 --> 00:10:43,360
watch there to see how e was starting to

349
00:10:43,360 --> 00:10:44,880
set the standards in other areas in

350
00:10:44,880 --> 00:10:47,839
addition to data protection

351
00:10:48,880 --> 00:10:50,560
now those who aren't alone it's really

352
00:10:50,560 --> 00:10:52,399
important to also look at how other

353
00:10:52,399 --> 00:10:53,600
governments across the globe are

354
00:10:53,600 --> 00:10:55,040
starting to

355
00:10:55,040 --> 00:10:57,040
internalize these various kinds of

356
00:10:57,040 --> 00:10:58,800
policies that are out there

357
00:10:58,800 --> 00:11:02,079
so turkey is one that has uh again you

358
00:11:02,079 --> 00:11:04,320
was you as a democracy we're seeing that

359
00:11:04,320 --> 00:11:05,760
slide a bit and along with that slide

360
00:11:05,760 --> 00:11:07,600
you see increased censorship increased

361
00:11:07,600 --> 00:11:09,519
uh request for access to communications

362
00:11:09,519 --> 00:11:11,360
data and an interesting component of

363
00:11:11,360 --> 00:11:12,720
turkey is this notion of forced

364
00:11:12,720 --> 00:11:14,640
localization and forced uh appointment

365
00:11:14,640 --> 00:11:16,800
of local representatives and so what

366
00:11:16,800 --> 00:11:18,720
that means is that there needs to be a

367
00:11:18,720 --> 00:11:21,600
turkish citizen or company that also

368
00:11:21,600 --> 00:11:23,120
is is by an appointment that that

369
00:11:23,120 --> 00:11:24,480
representative within that local

370
00:11:24,480 --> 00:11:26,000
representative and so that local

371
00:11:26,000 --> 00:11:28,160
representative could in turn be much

372
00:11:28,160 --> 00:11:30,000
more amenable to turning data over to

373
00:11:30,000 --> 00:11:32,000
the government when asked and so it

374
00:11:32,000 --> 00:11:34,160
inherently means less of a less control

375
00:11:34,160 --> 00:11:37,600
by for companies of their data

376
00:11:37,600 --> 00:11:39,360
in ecuador you're moving across the

377
00:11:39,360 --> 00:11:40,720
globe there's interception of

378
00:11:40,720 --> 00:11:42,720
communications permitted uh there are

379
00:11:42,720 --> 00:11:44,720
some terms requiring service providers

380
00:11:44,720 --> 00:11:46,399
to hand over data or technical

381
00:11:46,399 --> 00:11:47,839
information or even or to decrypt

382
00:11:47,839 --> 00:11:49,760
encrypted data and so there's been this

383
00:11:49,760 --> 00:11:50,800
movement towards that there's something

384
00:11:50,800 --> 00:11:52,160
called the all-seeing eye as far as some

385
00:11:52,160 --> 00:11:54,000
greater surveillance going on

386
00:11:54,000 --> 00:11:55,279
uh but a couple years ago following

387
00:11:55,279 --> 00:11:57,279
their major data breach of 20 million

388
00:11:57,279 --> 00:11:59,600
citizens that sparked this big movement

389
00:11:59,600 --> 00:12:01,360
internally towards greater data

390
00:12:01,360 --> 00:12:03,760
protection and just uh in may of 21 they

391
00:12:03,760 --> 00:12:05,360
passed the data protection law and so

392
00:12:05,360 --> 00:12:06,720
again we see these different trends

393
00:12:06,720 --> 00:12:08,160
really coming head-on within different

394
00:12:08,160 --> 00:12:11,040
countries

395
00:12:11,040 --> 00:12:12,560
again moving across the globe over to

396
00:12:12,560 --> 00:12:15,279
thailand italian has passed a very

397
00:12:15,279 --> 00:12:18,079
strict cyber hearing law a few years ago

398
00:12:18,079 --> 00:12:20,079
really enabling government officials to

399
00:12:20,079 --> 00:12:23,360
seize and access data uh on on demand

400
00:12:23,360 --> 00:12:25,200
and again back to this notion of

401
00:12:25,200 --> 00:12:26,959
requiring them to be able to decrypt or

402
00:12:26,959 --> 00:12:29,200
offer other kind of data encryption

403
00:12:29,200 --> 00:12:32,320
or decryption kind of processes

404
00:12:32,320 --> 00:12:34,079
in kazakhstan they've done a little bit

405
00:12:34,079 --> 00:12:35,920
of exploration on something that

406
00:12:35,920 --> 00:12:37,279
basically is a certificate that would

407
00:12:37,279 --> 00:12:39,600
have to be put on all devices and with

408
00:12:39,600 --> 00:12:41,120
that it basically essentially means that

409
00:12:41,120 --> 00:12:42,720
there's a man in the middle kind of

410
00:12:42,720 --> 00:12:44,480
access for the government to any kind of

411
00:12:44,480 --> 00:12:46,320
data on those systems there's been a lot

412
00:12:46,320 --> 00:12:48,320
of back and forth on that

413
00:12:48,320 --> 00:12:49,839
it was going to get implemented and then

414
00:12:49,839 --> 00:12:52,720
the population pushed back on that um

415
00:12:52,720 --> 00:12:54,480
and so it's not fully it has not been

416
00:12:54,480 --> 00:12:56,639
fully pursued there but the reason why

417
00:12:56,639 --> 00:12:58,880
even just exploring it matters is that

418
00:12:58,880 --> 00:13:01,200
what we saw just uh recently in the

419
00:13:01,200 --> 00:13:03,279
spring of 2021

420
00:13:03,279 --> 00:13:06,079
is that in mauritius a country in africa

421
00:13:06,079 --> 00:13:09,200
that has historically been a very solid

422
00:13:09,200 --> 00:13:10,480
democracy

423
00:13:10,480 --> 00:13:12,240
starting to move towards greater

424
00:13:12,240 --> 00:13:14,079
censorship over social media and along

425
00:13:14,079 --> 00:13:15,680
with that

426
00:13:15,680 --> 00:13:17,440
moving not just to censorship but also

427
00:13:17,440 --> 00:13:19,440
moving to an area where the government

428
00:13:19,440 --> 00:13:21,200
is considering a law to intercept and

429
00:13:21,200 --> 00:13:23,040
decrypt internet traffic through that

430
00:13:23,040 --> 00:13:24,880
similar kind of notion of putting a

431
00:13:24,880 --> 00:13:27,279
certificate and government control uh on

432
00:13:27,279 --> 00:13:28,880
devices within the country and within

433
00:13:28,880 --> 00:13:31,360
this there's no judicial oversight

434
00:13:31,360 --> 00:13:33,360
and that's one of those aspects i think

435
00:13:33,360 --> 00:13:34,800
is becomes you know readily apparent

436
00:13:34,800 --> 00:13:36,480
that needs to be focused on is how much

437
00:13:36,480 --> 00:13:38,160
transparency how much judicial oversight

438
00:13:38,160 --> 00:13:39,360
are there of these laws because that

439
00:13:39,360 --> 00:13:42,000
also has big implications for how these

440
00:13:42,000 --> 00:13:44,399
laws are going to be pursued

441
00:13:44,399 --> 00:13:46,480
and finally looking at cambodia

442
00:13:46,480 --> 00:13:47,839
they've new decree that's requiring all

443
00:13:47,839 --> 00:13:48,959
external traffic to go through a

444
00:13:48,959 --> 00:13:50,720
government-controlled hub uh and this

445
00:13:50,720 --> 00:13:52,079
again if when as you have all the

446
00:13:52,079 --> 00:13:53,440
traffic going through one spot makes it

447
00:13:53,440 --> 00:13:54,560
easier for the government to control and

448
00:13:54,560 --> 00:13:56,720
access it the only oversight there is by

449
00:13:56,720 --> 00:13:58,240
a regulatory body who also oversees

450
00:13:58,240 --> 00:13:59,680
their social media

451
00:13:59,680 --> 00:14:01,600
and so you see that going on and what

452
00:14:01,600 --> 00:14:03,199
also is interesting about the cambodia

453
00:14:03,199 --> 00:14:04,399
case

454
00:14:04,399 --> 00:14:05,839
is that these laws don't just have

455
00:14:05,839 --> 00:14:07,440
implications for companies that may have

456
00:14:07,440 --> 00:14:09,040
data there or just accessed by the

457
00:14:09,040 --> 00:14:10,959
cambodian government what we've also

458
00:14:10,959 --> 00:14:12,880
seen is that over the course of the

459
00:14:12,880 --> 00:14:14,079
pandemic

460
00:14:14,079 --> 00:14:16,079
cambodia had a qr code contact tracing

461
00:14:16,079 --> 00:14:17,920
app and with that

462
00:14:17,920 --> 00:14:20,079
uh app you gather clearly a lot of data

463
00:14:20,079 --> 00:14:22,000
a lot of individual data across of all

464
00:14:22,000 --> 00:14:23,279
the citizens

465
00:14:23,279 --> 00:14:24,800
and that data has been requested by

466
00:14:24,800 --> 00:14:26,959
china in exchange for a telecom upgrade

467
00:14:26,959 --> 00:14:28,959
from huawei and so you start seeing this

468
00:14:28,959 --> 00:14:30,480
tit for tat and you can imagine you know

469
00:14:30,480 --> 00:14:31,920
we hear this notion of data being the

470
00:14:31,920 --> 00:14:33,040
new oil

471
00:14:33,040 --> 00:14:34,800
not sure i'd follow you go that far and

472
00:14:34,800 --> 00:14:36,079
talk about it quite in that same way but

473
00:14:36,079 --> 00:14:38,000
at the same time data is becoming very

474
00:14:38,000 --> 00:14:39,519
very valuable and handing over data can

475
00:14:39,519 --> 00:14:43,040
become a bargaining chip uh in a whole

476
00:14:43,040 --> 00:14:45,120
range of other areas across uh across

477
00:14:45,120 --> 00:14:48,079
the policy spectrum

478
00:14:48,639 --> 00:14:50,079
now to be sure you know democracies

479
00:14:50,079 --> 00:14:53,199
aren't alone uh in in this are have not

480
00:14:53,199 --> 00:14:55,279
been you know separate from these kind

481
00:14:55,279 --> 00:14:57,360
of trends that are that are going on

482
00:14:57,360 --> 00:14:59,839
in indonesia one of the biggest uh the

483
00:14:59,839 --> 00:15:02,160
biggest uh muslim dominant democracies

484
00:15:02,160 --> 00:15:03,199
across the globe there's some pending

485
00:15:03,199 --> 00:15:04,160
legislation that's a little bit

486
00:15:04,160 --> 00:15:06,240
worrisome that focuses on censorship and

487
00:15:06,240 --> 00:15:07,120
that's really what a lot of people have

488
00:15:07,120 --> 00:15:08,959
been focusing on with it but also

489
00:15:08,959 --> 00:15:11,040
focuses on providing access to systems

490
00:15:11,040 --> 00:15:12,959
and actually could bypass the data

491
00:15:12,959 --> 00:15:14,959
privacy laws that are already in place

492
00:15:14,959 --> 00:15:16,480
and so again as we're seeing data

493
00:15:16,480 --> 00:15:18,079
privacy laws come head-on with some of

494
00:15:18,079 --> 00:15:19,360
these data

495
00:15:19,360 --> 00:15:21,519
access kind of requirements

496
00:15:21,519 --> 00:15:23,279
in australia the anti-encryption law

497
00:15:23,279 --> 00:15:24,480
that's passed a couple years ago i think

498
00:15:24,480 --> 00:15:26,639
has made a lot of news and you know

499
00:15:26,639 --> 00:15:28,399
again the transparency on that has not

500
00:15:28,399 --> 00:15:29,920
been you know as clear as a lot of

501
00:15:29,920 --> 00:15:31,759
advocates would like to see

502
00:15:31,759 --> 00:15:32,880
so that's something to keep an eye on

503
00:15:32,880 --> 00:15:34,399
especially since you know along with

504
00:15:34,399 --> 00:15:36,320
australia it moves also into the five

505
00:15:36,320 --> 00:15:38,000
eyes area are also considering similar

506
00:15:38,000 --> 00:15:40,959
kinds of laws uh from that alliance

507
00:15:40,959 --> 00:15:42,720
and then in the uk they historically had

508
00:15:42,720 --> 00:15:43,920
something that's called the snoopers

509
00:15:43,920 --> 00:15:45,920
snoopers charter which was just very

510
00:15:45,920 --> 00:15:47,199
recently found to be in violation of

511
00:15:47,199 --> 00:15:48,639
rights of privacy by the european court

512
00:15:48,639 --> 00:15:50,720
of human rights and so there's you know

513
00:15:50,720 --> 00:15:52,560
it has been replaced by a new law but at

514
00:15:52,560 --> 00:15:54,160
the same time there's still some growing

515
00:15:54,160 --> 00:15:56,000
concerns out there as far as the the

516
00:15:56,000 --> 00:15:57,680
breadth and reach and transparency over

517
00:15:57,680 --> 00:15:59,040
various kinds of surveillance and data

518
00:15:59,040 --> 00:16:00,079
access

519
00:16:00,079 --> 00:16:01,360
and so by no means our democracy is

520
00:16:01,360 --> 00:16:05,600
immune from this kind of uh tendencies

521
00:16:06,639 --> 00:16:07,839
and so looking at that you know one you

522
00:16:07,839 --> 00:16:09,600
know we have this whole range we see all

523
00:16:09,600 --> 00:16:10,800
these different tactics that are going

524
00:16:10,800 --> 00:16:12,399
on and so

525
00:16:12,399 --> 00:16:13,440
basically after doing a lot of that

526
00:16:13,440 --> 00:16:14,720
research and seeing what sort of that

527
00:16:14,720 --> 00:16:16,959
realm of what exists currently is

528
00:16:16,959 --> 00:16:19,040
it's time to start building the model

529
00:16:19,040 --> 00:16:19,920
and so

530
00:16:19,920 --> 00:16:20,880
one of the first steps was really

531
00:16:20,880 --> 00:16:22,079
thinking about what kind of questions do

532
00:16:22,079 --> 00:16:24,079
i want to ask i want to be coding on and

533
00:16:24,079 --> 00:16:26,000
so for sure data residency data

534
00:16:26,000 --> 00:16:27,440
localization are there those data

535
00:16:27,440 --> 00:16:30,000
storage requirements uh joint ventures

536
00:16:30,000 --> 00:16:31,199
are there those you know forced

537
00:16:31,199 --> 00:16:33,440
representatives or force collaborations

538
00:16:33,440 --> 00:16:36,079
with a local uh representative that can

539
00:16:36,079 --> 00:16:38,240
lead to less control over your data

540
00:16:38,240 --> 00:16:39,199
you know why were there encryptions and

541
00:16:39,199 --> 00:16:40,959
surveillance policies are there source

542
00:16:40,959 --> 00:16:43,040
code disclosure requirements um what

543
00:16:43,040 --> 00:16:44,639
kind of transparency judicial oversight

544
00:16:44,639 --> 00:16:46,480
is there is it independent or is it just

545
00:16:46,480 --> 00:16:48,560
you know is it by an intelligence agency

546
00:16:48,560 --> 00:16:49,600
for instance

547
00:16:49,600 --> 00:16:50,959
and then finally what kind of data

548
00:16:50,959 --> 00:16:53,440
protection privacy laws are out there

549
00:16:53,440 --> 00:16:55,600
and so with that as the the broader

550
00:16:55,600 --> 00:16:57,040
spectrum of

551
00:16:57,040 --> 00:16:59,680
of you know data together

552
00:16:59,680 --> 00:17:00,959
the next step was actually gathering a

553
00:17:00,959 --> 00:17:02,480
lot of that data and that really became

554
00:17:02,480 --> 00:17:04,640
a data in a haystack problem where

555
00:17:04,640 --> 00:17:05,839
you see there's so much information

556
00:17:05,839 --> 00:17:06,880
available that's out there and there's a

557
00:17:06,880 --> 00:17:08,319
lot that's in the security and privacy

558
00:17:08,319 --> 00:17:10,799
realm but so much of it is not actually

559
00:17:10,799 --> 00:17:12,559
ends data and security and privacy

560
00:17:12,559 --> 00:17:14,079
sources actually a lot of this

561
00:17:14,079 --> 00:17:15,760
information that i also found was more

562
00:17:15,760 --> 00:17:17,280
along the lines of business intelligence

563
00:17:17,280 --> 00:17:18,720
and the ease of doing business kind of

564
00:17:18,720 --> 00:17:20,799
research and so it was expanding outside

565
00:17:20,799 --> 00:17:22,319
of you know the research our community

566
00:17:22,319 --> 00:17:23,599
does and pulling in from other areas as

567
00:17:23,599 --> 00:17:25,359
well to assess what kind of risk there

568
00:17:25,359 --> 00:17:27,760
may be to data access

569
00:17:27,760 --> 00:17:29,440
and to just give you know a quick

570
00:17:29,440 --> 00:17:32,400
overview of what that may look like um

571
00:17:32,400 --> 00:17:33,919
you know for any kind of analysis you

572
00:17:33,919 --> 00:17:35,520
know it's really important to not just

573
00:17:35,520 --> 00:17:38,320
rely on one single source of data uh you

574
00:17:38,320 --> 00:17:39,280
know there's so many problems that can

575
00:17:39,280 --> 00:17:40,799
go along with that from data biases to

576
00:17:40,799 --> 00:17:42,880
just being outdated and so this is just

577
00:17:42,880 --> 00:17:45,280
one example i talked about mauritius

578
00:17:45,280 --> 00:17:46,720
earlier

579
00:17:46,720 --> 00:17:49,360
usd state department was a great source

580
00:17:49,360 --> 00:17:51,760
for their investment climate they write

581
00:17:51,760 --> 00:17:53,039
a lot as far as the joint venture

582
00:17:53,039 --> 00:17:55,200
requirements various kinds of even

583
00:17:55,200 --> 00:17:57,600
source code requirements at times

584
00:17:57,600 --> 00:17:58,400
and

585
00:17:58,400 --> 00:17:59,600
so that was very useful but at the same

586
00:17:59,600 --> 00:18:01,600
time you don't want to rely solely on

587
00:18:01,600 --> 00:18:03,039
one source and certainly not one from a

588
00:18:03,039 --> 00:18:04,960
from a specific government and so

589
00:18:04,960 --> 00:18:07,039
expanding that out ngos uh

590
00:18:07,039 --> 00:18:08,320
non-governmental organizations also

591
00:18:08,320 --> 00:18:09,919
provide an awful lot of information this

592
00:18:09,919 --> 00:18:11,840
is from freedom house where they ask

593
00:18:11,840 --> 00:18:13,039
questions along the lines of the range

594
00:18:13,039 --> 00:18:14,960
of surveillance that's going on

595
00:18:14,960 --> 00:18:16,080
and then also there's the data

596
00:18:16,080 --> 00:18:17,919
protection africa found a great regional

597
00:18:17,919 --> 00:18:19,679
site that really delve into the various

598
00:18:19,679 --> 00:18:21,039
kinds of data protection laws that are

599
00:18:21,039 --> 00:18:22,880
there providing things along the lines

600
00:18:22,880 --> 00:18:24,799
of is there a law if not you know when

601
00:18:24,799 --> 00:18:26,559
it hasn't been passed what kind of

602
00:18:26,559 --> 00:18:28,240
cross-border data flows are there what

603
00:18:28,240 --> 00:18:30,160
kind of regulations are there

604
00:18:30,160 --> 00:18:32,240
so that was great but it was very uh you

605
00:18:32,240 --> 00:18:33,679
know it's regional specific that doesn't

606
00:18:33,679 --> 00:18:35,039
exist for every other region across the

607
00:18:35,039 --> 00:18:36,799
globe unfortunately and if you look at

608
00:18:36,799 --> 00:18:39,360
it it was last updated over a year ago

609
00:18:39,360 --> 00:18:41,200
and as you know i talked about you know

610
00:18:41,200 --> 00:18:43,360
in just april of this year the new law

611
00:18:43,360 --> 00:18:45,760
was proposed uh that was raising a lot

612
00:18:45,760 --> 00:18:47,760
of concerns among human rights advocates

613
00:18:47,760 --> 00:18:49,440
and so staying on top of it so not only

614
00:18:49,440 --> 00:18:50,559
have making sure you have a diverse

615
00:18:50,559 --> 00:18:51,919
range of sources but also looking at the

616
00:18:51,919 --> 00:18:53,600
timeliness of it because this is all

617
00:18:53,600 --> 00:18:57,240
moving so fast

618
00:18:57,280 --> 00:18:58,880
but so from there finding the source is

619
00:18:58,880 --> 00:18:59,840
really

620
00:18:59,840 --> 00:19:02,000
pull together the range of questions

621
00:19:02,000 --> 00:19:04,320
focus on these core areas to create that

622
00:19:04,320 --> 00:19:07,360
spectrum of along a spectrum of data

623
00:19:07,360 --> 00:19:09,440
protection to more invasive government

624
00:19:09,440 --> 00:19:10,960
intervention intervention and creating

625
00:19:10,960 --> 00:19:12,559
scores along those lines and so had a

626
00:19:12,559 --> 00:19:14,640
series of questions where they can code

627
00:19:14,640 --> 00:19:16,000
could be something that's binary like is

628
00:19:16,000 --> 00:19:17,200
there or is there not a joint venture

629
00:19:17,200 --> 00:19:19,039
requirement but very often it actually

630
00:19:19,039 --> 00:19:20,240
gets even more into that because a lot

631
00:19:20,240 --> 00:19:22,160
of these joint venture requirements only

632
00:19:22,160 --> 00:19:24,000
occur in certain industries and so that

633
00:19:24,000 --> 00:19:25,840
is not as far reaching as it may be for

634
00:19:25,840 --> 00:19:28,480
uh you know full you know global or

635
00:19:28,480 --> 00:19:30,720
country-wide various kinds of data joint

636
00:19:30,720 --> 00:19:32,320
venture requirements

637
00:19:32,320 --> 00:19:33,440
but really the overall themes again

638
00:19:33,440 --> 00:19:35,679
where data storage looking at what the

639
00:19:35,679 --> 00:19:37,760
restrictions on access to data are what

640
00:19:37,760 --> 00:19:38,880
kind of data protection laws and

641
00:19:38,880 --> 00:19:40,640
oversight exist and the source code

642
00:19:40,640 --> 00:19:42,960
disclosure requirements and and all

643
00:19:42,960 --> 00:19:45,600
pulled together that data for 189

644
00:19:45,600 --> 00:19:47,679
countries or territories and so a lot of

645
00:19:47,679 --> 00:19:48,720
different research a lot of different

646
00:19:48,720 --> 00:19:52,080
sources although being coded and

647
00:19:52,080 --> 00:19:53,679
based upon those same kind of questions

648
00:19:53,679 --> 00:19:55,440
are these do these things kind of exist

649
00:19:55,440 --> 00:19:57,200
into what level

650
00:19:57,200 --> 00:19:58,559
and so from there

651
00:19:58,559 --> 00:20:01,360
basically got a scoring uh from you know

652
00:20:01,360 --> 00:20:02,640
most invasive

653
00:20:02,640 --> 00:20:04,400
to more data protection

654
00:20:04,400 --> 00:20:07,840
and so we'll look at the results briefly

655
00:20:08,000 --> 00:20:10,240
so on the end of government intervention

656
00:20:10,240 --> 00:20:11,679
there aren't a ton of surprises in this

657
00:20:11,679 --> 00:20:13,840
area um north korea china russia are

658
00:20:13,840 --> 00:20:15,440
really at the top as far as really

659
00:20:15,440 --> 00:20:17,440
intervening and

660
00:20:17,440 --> 00:20:19,520
mandating various kinds of data access

661
00:20:19,520 --> 00:20:20,799
and then if you go down the list a bit

662
00:20:20,799 --> 00:20:22,960
more you're not surprising but what's

663
00:20:22,960 --> 00:20:24,320
important to note is it is really it's

664
00:20:24,320 --> 00:20:25,520
global you know this isn't something

665
00:20:25,520 --> 00:20:26,880
that's staying in just one region of the

666
00:20:26,880 --> 00:20:28,480
of the globe

667
00:20:28,480 --> 00:20:29,760
and one that may stand out to people

668
00:20:29,760 --> 00:20:31,520
that may not you know live and breathe

669
00:20:31,520 --> 00:20:33,200
the data regulation laws across the

670
00:20:33,200 --> 00:20:35,200
across the globe is vietnam

671
00:20:35,200 --> 00:20:36,960
uh you know someone who works in supply

672
00:20:36,960 --> 00:20:39,039
chains a lot as well you know a lot of

673
00:20:39,039 --> 00:20:40,480
companies are considering moving out of

674
00:20:40,480 --> 00:20:41,360
china

675
00:20:41,360 --> 00:20:42,480
one of the first options they think

676
00:20:42,480 --> 00:20:44,000
about going to vietnam

677
00:20:44,000 --> 00:20:45,200
and there are a lot of reasons for that

678
00:20:45,200 --> 00:20:46,960
but one thing that it's important to be

679
00:20:46,960 --> 00:20:49,039
aware of is that some of the cyber risks

680
00:20:49,039 --> 00:20:50,480
may be similar and it's certainly not

681
00:20:50,480 --> 00:20:52,159
the level of sophistication but the

682
00:20:52,159 --> 00:20:53,840
various kinds of policies that the

683
00:20:53,840 --> 00:20:56,080
government's enforcing you do mirror

684
00:20:56,080 --> 00:20:57,600
those of china so the cyber risks in

685
00:20:57,600 --> 00:20:59,039
vietnam

686
00:20:59,039 --> 00:21:00,480
may be much greater than someone may

687
00:21:00,480 --> 00:21:01,600
assume

688
00:21:01,600 --> 00:21:04,880
purely by looking at other kinds of of

689
00:21:04,880 --> 00:21:06,480
factors and so it's where these kind of

690
00:21:06,480 --> 00:21:07,919
policies and laws really become really

691
00:21:07,919 --> 00:21:11,039
important to keep an eye on

692
00:21:11,360 --> 00:21:12,799
at the same time

693
00:21:12,799 --> 00:21:15,360
the universal data protection

694
00:21:15,360 --> 00:21:16,960
we see a lot of some of the smaller

695
00:21:16,960 --> 00:21:19,440
countries uh really starting to you know

696
00:21:19,440 --> 00:21:21,280
to show their strength and data

697
00:21:21,280 --> 00:21:24,240
protection and enforcement of individual

698
00:21:24,240 --> 00:21:26,240
data protection rights followed by a lot

699
00:21:26,240 --> 00:21:28,480
of the eu uh countries but as well we

700
00:21:28,480 --> 00:21:30,080
start seeing you know again these are

701
00:21:30,080 --> 00:21:32,240
global as well we've got japan um

702
00:21:32,240 --> 00:21:34,159
uruguay latin america some of the

703
00:21:34,159 --> 00:21:36,480
caribbean countries so these are both

704
00:21:36,480 --> 00:21:38,159
trends are occurring across the globe

705
00:21:38,159 --> 00:21:39,440
and these are just the the two ends of

706
00:21:39,440 --> 00:21:40,960
the spectrum

707
00:21:40,960 --> 00:21:41,840
and

708
00:21:41,840 --> 00:21:43,120
really what was interesting was seeing a

709
00:21:43,120 --> 00:21:44,320
lot more falling in the hybrid you

710
00:21:44,320 --> 00:21:45,520
probably wonder where the united states

711
00:21:45,520 --> 00:21:47,200
may fall and that really was at the

712
00:21:47,200 --> 00:21:49,039
bottom part of the first third so barely

713
00:21:49,039 --> 00:21:52,400
made it in the top first third

714
00:21:53,280 --> 00:21:55,360
and so you know looking at not just the

715
00:21:55,360 --> 00:21:56,640
the countries and where they fall i

716
00:21:56,640 --> 00:21:57,679
think it's also important to look at

717
00:21:57,679 --> 00:21:58,640
what are some of these overarching

718
00:21:58,640 --> 00:22:00,880
trends that came from all this

719
00:22:00,880 --> 00:22:02,480
uh almost 100 countries have passed data

720
00:22:02,480 --> 00:22:04,000
protection laws and so that's a great

721
00:22:04,000 --> 00:22:05,600
move if you're you know for proponents

722
00:22:05,600 --> 00:22:07,039
of data protection and there actually

723
00:22:07,039 --> 00:22:08,480
have been many more that have been

724
00:22:08,480 --> 00:22:09,919
passed just not yet enacted so

725
00:22:09,919 --> 00:22:11,120
definitely something to keep an eye on

726
00:22:11,120 --> 00:22:12,400
in that area

727
00:22:12,400 --> 00:22:13,600
and greater accountability is on the

728
00:22:13,600 --> 00:22:15,760
rise we're seeing much more

729
00:22:15,760 --> 00:22:17,360
uh enforcement of these laws you know

730
00:22:17,360 --> 00:22:19,600
gdpr still just is still fairly nascent

731
00:22:19,600 --> 00:22:22,480
uh in the long scheme of things and so

732
00:22:22,480 --> 00:22:23,760
we're seeing some accountability some

733
00:22:23,760 --> 00:22:26,159
fines starting to emerge and it could be

734
00:22:26,159 --> 00:22:27,280
a tipping point where you actually start

735
00:22:27,280 --> 00:22:28,559
seeing some other kinds of behavior

736
00:22:28,559 --> 00:22:30,320
emerge and it is starting to spread

737
00:22:30,320 --> 00:22:31,760
elsewhere as well

738
00:22:31,760 --> 00:22:33,520
as far as growing demand for this kind

739
00:22:33,520 --> 00:22:34,960
of data protection

740
00:22:34,960 --> 00:22:36,080
and a lot of that comes not just from

741
00:22:36,080 --> 00:22:37,200
corporations who want to protect their

742
00:22:37,200 --> 00:22:39,200
data but it comes from a global societal

743
00:22:39,200 --> 00:22:41,200
interest that's growing and demanding

744
00:22:41,200 --> 00:22:42,960
greater data protection like i talked

745
00:22:42,960 --> 00:22:46,559
about with the example of ecuador

746
00:22:47,280 --> 00:22:48,799
and so while those are the good trends

747
00:22:48,799 --> 00:22:50,880
on the negative side

748
00:22:50,880 --> 00:22:52,559
really what i see a lot is this movement

749
00:22:52,559 --> 00:22:53,600
from

750
00:22:53,600 --> 00:22:55,760
you know censorship and manipulation to

751
00:22:55,760 --> 00:22:57,760
next step being a global man or main

752
00:22:57,760 --> 00:22:59,679
data data access and so that's a that's

753
00:22:59,679 --> 00:23:01,360
a concern that if the censorship and

754
00:23:01,360 --> 00:23:02,960
manipulations isn't working let's just

755
00:23:02,960 --> 00:23:04,080
try let's go straight out and try and

756
00:23:04,080 --> 00:23:06,159
grab that data uh legal you know through

757
00:23:06,159 --> 00:23:09,120
legal shifts and regulatory shifts

758
00:23:09,120 --> 00:23:10,320
what we're also seeing is that while

759
00:23:10,320 --> 00:23:11,919
there are all these data protection laws

760
00:23:11,919 --> 00:23:13,280
there also is a gap between the law and

761
00:23:13,280 --> 00:23:14,640
the reality there definitely were some

762
00:23:14,640 --> 00:23:16,080
scandals that popped up that i would

763
00:23:16,080 --> 00:23:17,679
find in the research that were actually

764
00:23:17,679 --> 00:23:19,120
show that governments were not adhering

765
00:23:19,120 --> 00:23:20,840
to their own policies and so that's

766
00:23:20,840 --> 00:23:22,799
troublesome uh definitely see the rise

767
00:23:22,799 --> 00:23:24,400
of the rest where you see more copycat

768
00:23:24,400 --> 00:23:26,240
laws starting to spread the chinese

769
00:23:26,240 --> 00:23:28,240
model is spreading across the globe for

770
00:23:28,240 --> 00:23:29,919
a variety of reasons and a lot of

771
00:23:29,919 --> 00:23:31,039
interference a lot of these regulatory

772
00:23:31,039 --> 00:23:32,480
ships we actually start seeing around

773
00:23:32,480 --> 00:23:34,400
elections so again direct implications

774
00:23:34,400 --> 00:23:37,640
for democracy

775
00:23:37,679 --> 00:23:39,840
and the other in the hybrid uh really a

776
00:23:39,840 --> 00:23:40,799
lot of

777
00:23:40,799 --> 00:23:42,159
countries are falling in that hybrid

778
00:23:42,159 --> 00:23:43,679
area where they're

779
00:23:43,679 --> 00:23:44,960
pursuing some aspects of the

780
00:23:44,960 --> 00:23:46,159
authoritarian model and some aspects of

781
00:23:46,159 --> 00:23:48,400
the democratic model and this is a great

782
00:23:48,400 --> 00:23:50,799
uh overview from financial times more so

783
00:23:50,799 --> 00:23:52,559
on surveillance technology but it looks

784
00:23:52,559 --> 00:23:54,080
very similar to the government mandated

785
00:23:54,080 --> 00:23:56,240
data access we see some democracies

786
00:23:56,240 --> 00:23:57,840
pulling from the from the authoritarian

787
00:23:57,840 --> 00:24:00,000
model as well just a lot of the those

788
00:24:00,000 --> 00:24:01,120
countries that kind of are teetering on

789
00:24:01,120 --> 00:24:02,559
to bring between authoritarianism and

790
00:24:02,559 --> 00:24:05,120
democracy really pursuing a lot of these

791
00:24:05,120 --> 00:24:07,440
more surveillance and uh data access

792
00:24:07,440 --> 00:24:10,320
leaning policies

793
00:24:11,120 --> 00:24:12,799
and so for the next steps you know that

794
00:24:12,799 --> 00:24:14,000
clearly this was this was sort of the

795
00:24:14,000 --> 00:24:16,080
first iteration of this design and the

796
00:24:16,080 --> 00:24:17,600
first iteration of this of collection

797
00:24:17,600 --> 00:24:19,520
and encoding and so

798
00:24:19,520 --> 00:24:21,679
one of the biggest things that became so

799
00:24:21,679 --> 00:24:23,200
apparent during all this is that while i

800
00:24:23,200 --> 00:24:24,320
knew the regulatory landscape was

801
00:24:24,320 --> 00:24:26,400
shifting fast it's moving even faster

802
00:24:26,400 --> 00:24:27,760
than uh than i could possibly have

803
00:24:27,760 --> 00:24:30,159
imagined um it's really moving at a

804
00:24:30,159 --> 00:24:33,520
dramatic speed um and it's quite very a

805
00:24:33,520 --> 00:24:35,120
lot of variation across the globe i've

806
00:24:35,120 --> 00:24:36,480
got everything from the us which i

807
00:24:36,480 --> 00:24:38,159
didn't talk a ton about pushing tech

808
00:24:38,159 --> 00:24:40,480
firms to hand over source code to india

809
00:24:40,480 --> 00:24:43,120
again one a huge democracy really

810
00:24:43,120 --> 00:24:44,559
falling in that hybrid model some data

811
00:24:44,559 --> 00:24:46,080
protection pursuits while also the same

812
00:24:46,080 --> 00:24:47,919
time demanding data access from various

813
00:24:47,919 --> 00:24:49,840
social media companies you've got you

814
00:24:49,840 --> 00:24:52,240
know the eu as strong as the gdpr is

815
00:24:52,240 --> 00:24:53,600
you've got the hungarian government

816
00:24:53,600 --> 00:24:55,200
suspending some aspects of it so it's a

817
00:24:55,200 --> 00:24:56,720
lot of different changes going on across

818
00:24:56,720 --> 00:24:58,640
the globe and really need to stay on top

819
00:24:58,640 --> 00:25:01,279
of that and so that's really one of the

820
00:25:01,279 --> 00:25:02,960
biggest considerations is how to stay at

821
00:25:02,960 --> 00:25:04,960
pace this change and so

822
00:25:04,960 --> 00:25:06,799
you can start versioning this this

823
00:25:06,799 --> 00:25:08,720
information put time stamps on it to

824
00:25:08,720 --> 00:25:10,080
enable them that tracking of the

825
00:25:10,080 --> 00:25:12,080
temporal shifts to see really how

826
00:25:12,080 --> 00:25:13,679
countries are moving and where the

827
00:25:13,679 --> 00:25:16,159
balance is tipping uh in these two

828
00:25:16,159 --> 00:25:18,159
different views and frameworks of

829
00:25:18,159 --> 00:25:21,679
government data uh mandated data access

830
00:25:21,679 --> 00:25:23,279
uh community input you know one of the

831
00:25:23,279 --> 00:25:24,640
great reasons of being here at blackhead

832
00:25:24,640 --> 00:25:25,919
is to get community input so definitely

833
00:25:25,919 --> 00:25:27,919
welcome questions uh either during this

834
00:25:27,919 --> 00:25:31,039
time or after to both you know get

835
00:25:31,039 --> 00:25:32,880
additional information um i know there

836
00:25:32,880 --> 00:25:33,840
are people out there that are much

837
00:25:33,840 --> 00:25:35,039
smarter than i am on all these different

838
00:25:35,039 --> 00:25:36,159
countries would love to hear what they

839
00:25:36,159 --> 00:25:37,760
have to say and then what other things

840
00:25:37,760 --> 00:25:39,440
to consider as far as other kinds of

841
00:25:39,440 --> 00:25:40,799
tech risks there's all sorts of

842
00:25:40,799 --> 00:25:41,760
different ways that governments can

843
00:25:41,760 --> 00:25:43,760
mandate data access

844
00:25:43,760 --> 00:25:45,120
via technologies or other kinds of

845
00:25:45,120 --> 00:25:46,480
dependencies

846
00:25:46,480 --> 00:25:48,400
and there will be a white paper coming

847
00:25:48,400 --> 00:25:49,679
that really walks through the research

848
00:25:49,679 --> 00:25:51,440
design methodology and rankings and

849
00:25:51,440 --> 00:25:53,279
provide that for additional feedback as

850
00:25:53,279 --> 00:25:54,480
well

851
00:25:54,480 --> 00:25:56,320
and so as i continue working on this

852
00:25:56,320 --> 00:25:58,159
research uh certainly these changes are

853
00:25:58,159 --> 00:26:00,960
coming fast there is no shortage of news

854
00:26:00,960 --> 00:26:02,960
that will require me to update the model

855
00:26:02,960 --> 00:26:04,480
uh so i will continue tracking the

856
00:26:04,480 --> 00:26:06,320
balance seeing which way it tips which

857
00:26:06,320 --> 00:26:07,840
one of these frameworks starts to emerge

858
00:26:07,840 --> 00:26:09,600
and i do believe our community has a

859
00:26:09,600 --> 00:26:12,000
very strong role to play in helping tip

860
00:26:12,000 --> 00:26:13,840
that balance and so i'm excited to be

861
00:26:13,840 --> 00:26:15,120
able to present this information this

862
00:26:15,120 --> 00:26:16,799
research here i look forward to your

863
00:26:16,799 --> 00:26:18,159
comments and really look forward to

864
00:26:18,159 --> 00:26:19,919
seeing how our community can play a role

865
00:26:19,919 --> 00:26:21,919
in increasing data protection across the

866
00:26:21,919 --> 00:26:23,200
globe

867
00:26:23,200 --> 00:26:25,840
thank you

