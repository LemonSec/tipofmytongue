1
00:00:04,110 --> 00:00:17,660
[Music]

2
00:00:17,840 --> 00:00:18,960
so hi everyone

3
00:00:18,960 --> 00:00:21,199
so my name is kylem so today i'm going

4
00:00:21,199 --> 00:00:22,080
to introduce

5
00:00:22,080 --> 00:00:25,039
um our search superman powered by

6
00:00:25,039 --> 00:00:26,240
kryptonite

7
00:00:26,240 --> 00:00:28,320
turn the adversary attack into your

8
00:00:28,320 --> 00:00:30,000
defense weapon

9
00:00:30,000 --> 00:00:33,440
this is a collaborative work with dr

10
00:00:33,440 --> 00:00:36,800
rothenburg dr suzugang and professor xin

11
00:00:36,800 --> 00:00:38,960
xin

12
00:00:38,960 --> 00:00:42,559
nowadays hackers are powered by

13
00:00:42,559 --> 00:00:45,600
the ai technologies so it's more like

14
00:00:45,600 --> 00:00:48,160
it finds its own superpower similar like

15
00:00:48,160 --> 00:00:49,600
a sonos

16
00:00:49,600 --> 00:00:52,640
gets the infinite gauntlet using a more

17
00:00:52,640 --> 00:00:56,320
concrete example to illustrate my point

18
00:00:56,320 --> 00:00:59,600
so capture service used to defend

19
00:00:59,600 --> 00:01:00,320
against

20
00:01:00,320 --> 00:01:03,359
computer bot by post some of the

21
00:01:03,359 --> 00:01:03,920
challenge

22
00:01:03,920 --> 00:01:06,320
which is easy for human to solve but

23
00:01:06,320 --> 00:01:09,119
difficult for computers to solve

24
00:01:09,119 --> 00:01:11,600
so this is based on the intelligence gap

25
00:01:11,600 --> 00:01:12,799
between the human

26
00:01:12,799 --> 00:01:15,920
and the computer bot however with the

27
00:01:15,920 --> 00:01:18,080
introduce of the deep neural network

28
00:01:18,080 --> 00:01:21,520
this intelligence gap has been fueling

29
00:01:21,520 --> 00:01:23,920
as you can see from the news headline so

30
00:01:23,920 --> 00:01:25,119
deep neural network

31
00:01:25,119 --> 00:01:28,479
right now can achieve very crazy

32
00:01:28,479 --> 00:01:31,360
accuracy to solving the capture as well

33
00:01:31,360 --> 00:01:32,880
at the same time they can solve the

34
00:01:32,880 --> 00:01:36,479
capture in a very fast way

35
00:01:36,479 --> 00:01:39,680
however the ai technology also have its

36
00:01:39,680 --> 00:01:41,200
own weakness

37
00:01:41,200 --> 00:01:43,920
called adversarial example so called the

38
00:01:43,920 --> 00:01:44,640
definition

39
00:01:44,640 --> 00:01:48,240
from good fellow in 2017 adverse

40
00:01:48,240 --> 00:01:51,200
examples are input to machine learning

41
00:01:51,200 --> 00:01:51,759
models

42
00:01:51,759 --> 00:01:53,920
that an attacker has intentionally

43
00:01:53,920 --> 00:01:55,840
designed to cause the model to make a

44
00:01:55,840 --> 00:01:56,960
mistake

45
00:01:56,960 --> 00:01:59,520
here's a typical example to illustrate

46
00:01:59,520 --> 00:02:00,719
the adversary

47
00:02:00,719 --> 00:02:04,079
example so suppose the picture on the

48
00:02:04,079 --> 00:02:07,360
left is a panda and also the model also

49
00:02:07,360 --> 00:02:09,199
predict this as a pendant

50
00:02:09,199 --> 00:02:12,480
but clearly construct the perturbations

51
00:02:12,480 --> 00:02:16,160
and put it on top of a dependent image

52
00:02:16,160 --> 00:02:18,800
so as a human eye we are going to still

53
00:02:18,800 --> 00:02:19,360
see this

54
00:02:19,360 --> 00:02:22,720
as a pendant image but as a machine

55
00:02:22,720 --> 00:02:23,520
learning model

56
00:02:23,520 --> 00:02:26,080
it's going to predict this as a gibbon

57
00:02:26,080 --> 00:02:29,440
with very high confidence

58
00:02:29,920 --> 00:02:32,480
then as a defender trying to defend

59
00:02:32,480 --> 00:02:33,599
against

60
00:02:33,599 --> 00:02:36,319
the what ai weapon lies the hacker we'll

61
00:02:36,319 --> 00:02:36,959
think about

62
00:02:36,959 --> 00:02:39,360
whether we can leverage the weakness of

63
00:02:39,360 --> 00:02:40,319
the ai

64
00:02:40,319 --> 00:02:42,959
to fight against the ai weaponized

65
00:02:42,959 --> 00:02:45,360
hackers

66
00:02:45,519 --> 00:02:48,879
so to demonstrate uh the research on

67
00:02:48,879 --> 00:02:52,080
this directions we use the capture

68
00:02:52,080 --> 00:02:52,640
service

69
00:02:52,640 --> 00:02:55,120
as our example then we apply different

70
00:02:55,120 --> 00:02:57,360
type of the adversarial example

71
00:02:57,360 --> 00:02:59,840
to the capture and demonstrate how can

72
00:02:59,840 --> 00:03:01,680
the capture to fight against

73
00:03:01,680 --> 00:03:05,840
the ai boat

74
00:03:06,560 --> 00:03:08,640
so to solve this research problem we're

75
00:03:08,640 --> 00:03:11,040
actually facing several challenges

76
00:03:11,040 --> 00:03:13,280
first of all we are not the first team

77
00:03:13,280 --> 00:03:14,400
that applied

78
00:03:14,400 --> 00:03:16,800
the security features on the captures

79
00:03:16,800 --> 00:03:18,000
the hackers are aware

80
00:03:18,000 --> 00:03:20,720
of this and they apply different type of

81
00:03:20,720 --> 00:03:21,920
the image filters

82
00:03:21,920 --> 00:03:25,440
on the captures before they're using the

83
00:03:25,440 --> 00:03:26,879
solver to solve

84
00:03:26,879 --> 00:03:29,519
the capture so that means the

85
00:03:29,519 --> 00:03:30,400
adversarial

86
00:03:30,400 --> 00:03:33,360
perturbation data we put on the capture

87
00:03:33,360 --> 00:03:35,680
has to be resistant to this type of the

88
00:03:35,680 --> 00:03:37,200
image filter

89
00:03:37,200 --> 00:03:40,319
second we have zero knowledge

90
00:03:40,319 --> 00:03:43,120
about the hackers tool so different from

91
00:03:43,120 --> 00:03:43,840
the

92
00:03:43,840 --> 00:03:46,000
traditional threat model for adversarial

93
00:03:46,000 --> 00:03:48,080
example which stands on a hacker's

94
00:03:48,080 --> 00:03:49,040
perspective

95
00:03:49,040 --> 00:03:51,040
trying to target a specific model which

96
00:03:51,040 --> 00:03:52,879
is a one two one

97
00:03:52,879 --> 00:03:55,040
and in our case we stand on as a

98
00:03:55,040 --> 00:03:56,319
defender perspective

99
00:03:56,319 --> 00:03:59,920
trying to leverage this adverse example

100
00:03:59,920 --> 00:04:00,640
use cases

101
00:04:00,640 --> 00:04:02,720
all throughout the model is more like

102
00:04:02,720 --> 00:04:03,680
one-to-many

103
00:04:03,680 --> 00:04:05,840
so because we don't know how what kind

104
00:04:05,840 --> 00:04:07,120
of the model is going to

105
00:04:07,120 --> 00:04:10,319
use our adversarial example the third

106
00:04:10,319 --> 00:04:10,879
challenge

107
00:04:10,879 --> 00:04:13,760
is the the practical challenge the post

108
00:04:13,760 --> 00:04:14,000
by

109
00:04:14,000 --> 00:04:16,639
the capture service because capture have

110
00:04:16,639 --> 00:04:18,798
a very high demand every day

111
00:04:18,798 --> 00:04:20,478
so that means the generation of the

112
00:04:20,478 --> 00:04:23,919
capture has to be very quick

113
00:04:23,919 --> 00:04:27,120
so however in order to train a very

114
00:04:27,120 --> 00:04:29,280
good quality adversarial perturbation

115
00:04:29,280 --> 00:04:30,639
usually it takes time

116
00:04:30,639 --> 00:04:32,639
so we're trying to solving this conflict

117
00:04:32,639 --> 00:04:33,919
during this um

118
00:04:33,919 --> 00:04:36,960
work so

119
00:04:36,960 --> 00:04:38,880
here is an overview of our defense

120
00:04:38,880 --> 00:04:41,360
mechanisms we further divided our

121
00:04:41,360 --> 00:04:42,400
defense into

122
00:04:42,400 --> 00:04:45,040
two level the first level is passive

123
00:04:45,040 --> 00:04:46,240
defense

124
00:04:46,240 --> 00:04:47,840
so we are going to introduce the

125
00:04:47,840 --> 00:04:49,440
resistance adverse

126
00:04:49,440 --> 00:04:52,800
so particulation we call the wrap

127
00:04:52,800 --> 00:04:56,080
so there's two property for the wrap

128
00:04:56,080 --> 00:04:59,040
first is going to resistant to image

129
00:04:59,040 --> 00:04:59,520
filter

130
00:04:59,520 --> 00:05:01,360
and the second we are going to this

131
00:05:01,360 --> 00:05:02,560
solution has to be

132
00:05:02,560 --> 00:05:04,880
effective to unknown ai based capture

133
00:05:04,880 --> 00:05:06,720
solvers

134
00:05:06,720 --> 00:05:08,880
so the second level we call active

135
00:05:08,880 --> 00:05:10,880
defense so we are not

136
00:05:10,880 --> 00:05:12,720
only satisfied with just the passive

137
00:05:12,720 --> 00:05:14,320
defense we also want to see whether we

138
00:05:14,320 --> 00:05:15,280
can detect

139
00:05:15,280 --> 00:05:18,720
the the machine learning board if there

140
00:05:18,720 --> 00:05:22,160
uh someone attack us second

141
00:05:22,160 --> 00:05:24,880
uh the solutions has to be effectively

142
00:05:24,880 --> 00:05:25,280
uh

143
00:05:25,280 --> 00:05:28,400
generated the captures so first

144
00:05:28,400 --> 00:05:31,520
let's take a look at our first level um

145
00:05:31,520 --> 00:05:34,719
defense called wrap

146
00:05:35,280 --> 00:05:37,360
so before we introduce our solutions

147
00:05:37,360 --> 00:05:38,800
here's some background about

148
00:05:38,800 --> 00:05:41,199
the traditional black box adversarial

149
00:05:41,199 --> 00:05:43,919
example generation workflow

150
00:05:43,919 --> 00:05:46,960
so first usually is you provide a fit of

151
00:05:46,960 --> 00:05:47,680
pictures

152
00:05:47,680 --> 00:05:51,440
into the workflow then this workflow is

153
00:05:51,440 --> 00:05:53,600
going to generate a bunch of

154
00:05:53,600 --> 00:05:56,639
um the training pictures that and

155
00:05:56,639 --> 00:06:00,160
add random noise on top of each images

156
00:06:00,160 --> 00:06:02,080
with different distribution they are

157
00:06:02,080 --> 00:06:03,600
going to fit this batch of

158
00:06:03,600 --> 00:06:06,880
the random noise images into the capture

159
00:06:06,880 --> 00:06:07,759
solver

160
00:06:07,759 --> 00:06:11,280
so the solver is going to predict

161
00:06:11,280 --> 00:06:13,680
full dispatch of the images and give the

162
00:06:13,680 --> 00:06:15,680
probabilities

163
00:06:15,680 --> 00:06:17,600
and by comparing the difference between

164
00:06:17,600 --> 00:06:19,280
the original captures

165
00:06:19,280 --> 00:06:22,400
label with the new

166
00:06:22,400 --> 00:06:24,800
the the probabilities on this noise

167
00:06:24,800 --> 00:06:27,199
images

168
00:06:27,199 --> 00:06:28,720
the grading estimator is going to

169
00:06:28,720 --> 00:06:30,400
calculate whether

170
00:06:30,400 --> 00:06:32,639
what kind of noise is getting affected

171
00:06:32,639 --> 00:06:34,560
can just help to

172
00:06:34,560 --> 00:06:38,080
guide the uh the noise can guide the

173
00:06:38,080 --> 00:06:41,520
captures to to just to give away

174
00:06:41,520 --> 00:06:44,400
from its original labels so then we're

175
00:06:44,400 --> 00:06:45,120
going to

176
00:06:45,120 --> 00:06:48,160
uh put the norm

177
00:06:48,160 --> 00:06:50,639
gradients on top of the existing the

178
00:06:50,639 --> 00:06:51,440
pictures

179
00:06:51,440 --> 00:06:53,680
and these pictures are going to be fit

180
00:06:53,680 --> 00:06:54,800
into

181
00:06:54,800 --> 00:06:56,560
this workflow and the guide for the next

182
00:06:56,560 --> 00:06:58,080
round of the

183
00:06:58,080 --> 00:07:02,080
adversary example generations

184
00:07:02,080 --> 00:07:05,680
so uh by doing this uh iterations more

185
00:07:05,680 --> 00:07:08,479
uh more wrong we're going to find a good

186
00:07:08,479 --> 00:07:09,840
adversarial examples

187
00:07:09,840 --> 00:07:13,039
for these cases so however

188
00:07:13,039 --> 00:07:15,280
such workflow has a problems when we

189
00:07:15,280 --> 00:07:16,800
directly apply

190
00:07:16,800 --> 00:07:20,800
on this workflow as for the image filter

191
00:07:20,800 --> 00:07:23,919
so here's an example of the

192
00:07:23,919 --> 00:07:25,680
case that before you do the image

193
00:07:25,680 --> 00:07:27,680
filtering and you have

194
00:07:27,680 --> 00:07:30,639
other adverse examples on the captures

195
00:07:30,639 --> 00:07:31,039
and

196
00:07:31,039 --> 00:07:33,680
after you apply the image filter you can

197
00:07:33,680 --> 00:07:34,560
see that

198
00:07:34,560 --> 00:07:37,759
all the noises has been filled out so we

199
00:07:37,759 --> 00:07:40,160
intended to make this noise strong so

200
00:07:40,160 --> 00:07:41,680
the audience can see it

201
00:07:41,680 --> 00:07:44,319
in the real cases the noises is much

202
00:07:44,319 --> 00:07:46,479
more smaller and much more easier to be

203
00:07:46,479 --> 00:07:49,039
filtered out

204
00:07:49,199 --> 00:07:53,039
so here's our main idea to make

205
00:07:53,039 --> 00:07:55,840
this the adversarial examples resistant

206
00:07:55,840 --> 00:07:57,199
to image filter

207
00:07:57,199 --> 00:08:00,319
so first of all instead of letting the

208
00:08:00,319 --> 00:08:03,520
noise just got scattered around

209
00:08:03,520 --> 00:08:06,639
all the pages so

210
00:08:06,639 --> 00:08:09,199
we concentrated the noise to make it

211
00:08:09,199 --> 00:08:10,240
appears

212
00:08:10,240 --> 00:08:13,039
always in a certain regions so that in

213
00:08:13,039 --> 00:08:15,199
this case we find there's two advantages

214
00:08:15,199 --> 00:08:16,319
of doing that

215
00:08:16,319 --> 00:08:19,599
because our um solution for these cases

216
00:08:19,599 --> 00:08:21,360
will be an untargeted attack

217
00:08:21,360 --> 00:08:23,440
so what we want to achieve is just the

218
00:08:23,440 --> 00:08:24,560
misguided

219
00:08:24,560 --> 00:08:28,240
at the solver to be predicted to be some

220
00:08:28,240 --> 00:08:31,520
other wrong answers then in these cases

221
00:08:31,520 --> 00:08:35,200
uh by concentrated noise we find we can

222
00:08:35,200 --> 00:08:37,519
misguide the solvers much more quicker

223
00:08:37,519 --> 00:08:40,159
and have less round off iterations

224
00:08:40,159 --> 00:08:42,958
and the second by concentrating noise we

225
00:08:42,958 --> 00:08:43,839
actually find it

226
00:08:43,839 --> 00:08:46,560
much harder for the image filtering to

227
00:08:46,560 --> 00:08:48,399
cancel the noise

228
00:08:48,399 --> 00:08:50,320
because it will look like more like a

229
00:08:50,320 --> 00:08:53,279
shape than just a noise

230
00:08:53,279 --> 00:08:56,399
second we also introduce the filtering

231
00:08:56,399 --> 00:08:58,640
doing this uh for each round of the

232
00:08:58,640 --> 00:08:59,519
training

233
00:08:59,519 --> 00:09:02,720
so that means all the noises

234
00:09:02,720 --> 00:09:05,760
and we apply to the captures

235
00:09:05,760 --> 00:09:08,160
and we're going to go through the filter

236
00:09:08,160 --> 00:09:08,880
once

237
00:09:08,880 --> 00:09:11,600
and before it go to the the solver to do

238
00:09:11,600 --> 00:09:14,000
the prediction

239
00:09:14,000 --> 00:09:16,320
so with these two ideas i'm going to

240
00:09:16,320 --> 00:09:18,160
show that what our solutions

241
00:09:18,160 --> 00:09:20,959
uh the outcome look like so here's a

242
00:09:20,959 --> 00:09:23,200
capture that with our wrap solutions

243
00:09:23,200 --> 00:09:26,080
as you can see our wrap is more like on

244
00:09:26,080 --> 00:09:28,000
just some background

245
00:09:28,000 --> 00:09:30,240
to the captures and does not affect the

246
00:09:30,240 --> 00:09:32,240
readability at all

247
00:09:32,240 --> 00:09:35,839
so we further um evaluate our solutions

248
00:09:35,839 --> 00:09:38,399
on the image filter in this example

249
00:09:38,399 --> 00:09:42,640
we're using the median filters

250
00:09:42,640 --> 00:09:44,880
we compare our solutions using three

251
00:09:44,880 --> 00:09:46,399
sets of the datas

252
00:09:46,399 --> 00:09:48,800
the first set we're using the original

253
00:09:48,800 --> 00:09:49,519
captures

254
00:09:49,519 --> 00:09:52,800
that without any particulation on it

255
00:09:52,800 --> 00:09:55,440
we should show in the blue one and the

256
00:09:55,440 --> 00:09:56,240
second one

257
00:09:56,240 --> 00:09:59,680
are we using the capture stand as the

258
00:09:59,680 --> 00:10:00,399
traditional

259
00:10:00,399 --> 00:10:02,880
adverse perturbations which is shown on

260
00:10:02,880 --> 00:10:04,240
the red line

261
00:10:04,240 --> 00:10:06,320
and the third one is the captures that

262
00:10:06,320 --> 00:10:08,399
we add with our wrap solutions

263
00:10:08,399 --> 00:10:11,839
in this diagram the x axis is the

264
00:10:11,839 --> 00:10:14,240
the number of the filters that we apply

265
00:10:14,240 --> 00:10:15,600
to the captures

266
00:10:15,600 --> 00:10:18,880
and the y exit is the solver accuracy

267
00:10:18,880 --> 00:10:21,200
for each set we're using a hundred image

268
00:10:21,200 --> 00:10:22,959
to do this test

269
00:10:22,959 --> 00:10:25,360
so we start from um the original

270
00:10:25,360 --> 00:10:26,000
captures

271
00:10:26,000 --> 00:10:27,680
that are without ending uh the

272
00:10:27,680 --> 00:10:29,040
perturbation on it

273
00:10:29,040 --> 00:10:32,399
as you can see on the these diagram

274
00:10:32,399 --> 00:10:35,600
before we apply any filterings for the

275
00:10:35,600 --> 00:10:36,880
images

276
00:10:36,880 --> 00:10:40,640
the the captures actually the solver can

277
00:10:40,640 --> 00:10:44,720
stop almost 100 of the captures

278
00:10:44,720 --> 00:10:47,200
then after you apply the filters

279
00:10:47,200 --> 00:10:49,040
multiple times as you can see from these

280
00:10:49,040 --> 00:10:49,680
diagrams

281
00:10:49,680 --> 00:10:51,760
on the blue lines the accuracy is going

282
00:10:51,760 --> 00:10:53,680
to drop so the main reason

283
00:10:53,680 --> 00:10:57,839
is the image filter itself is also a

284
00:10:57,839 --> 00:11:00,320
image blurring technique by applying

285
00:11:00,320 --> 00:11:01,519
this multiple times

286
00:11:01,519 --> 00:11:03,600
the image the readability is going to

287
00:11:03,600 --> 00:11:06,240
drop as well

288
00:11:06,480 --> 00:11:09,200
so then next let's take a look at the

289
00:11:09,200 --> 00:11:09,839
captures

290
00:11:09,839 --> 00:11:12,839
that add the traditional adversary

291
00:11:12,839 --> 00:11:15,440
example as you can see from this diagram

292
00:11:15,440 --> 00:11:18,640
before we apply an image filter the

293
00:11:18,640 --> 00:11:21,200
traditional the adversary particulations

294
00:11:21,200 --> 00:11:22,640
you add to the

295
00:11:22,640 --> 00:11:25,680
cap captures can misguide

296
00:11:25,680 --> 00:11:30,000
almost a chemist guide all the

297
00:11:30,000 --> 00:11:32,160
the the basically the solar result and

298
00:11:32,160 --> 00:11:34,480
make it a zero percent accurate

299
00:11:34,480 --> 00:11:36,800
and after we apply the filters multiple

300
00:11:36,800 --> 00:11:37,839
times

301
00:11:37,839 --> 00:11:40,640
you can see the number of the accuracy

302
00:11:40,640 --> 00:11:42,079
start to increase

303
00:11:42,079 --> 00:11:45,200
so the main reason for that is the

304
00:11:45,200 --> 00:11:47,760
the noise has been cancellated after

305
00:11:47,760 --> 00:11:48,640
multiple times

306
00:11:48,640 --> 00:11:51,839
of the image filtering

307
00:11:51,839 --> 00:11:55,040
and then the accuracy becomes stable and

308
00:11:55,040 --> 00:11:56,800
eventually they're going to chop because

309
00:11:56,800 --> 00:12:01,040
the filter itself also blurs the images

310
00:12:01,040 --> 00:12:03,920
so last i'm going to show that our the

311
00:12:03,920 --> 00:12:06,079
wrap result

312
00:12:06,079 --> 00:12:08,560
as you can see on the start we have the

313
00:12:08,560 --> 00:12:11,120
we can achieve the same

314
00:12:11,120 --> 00:12:13,680
the misguided rate as the as the

315
00:12:13,680 --> 00:12:16,320
traditional adversarial example

316
00:12:16,320 --> 00:12:19,360
before we apply any image filters the

317
00:12:19,360 --> 00:12:19,920
our

318
00:12:19,920 --> 00:12:22,880
wrap can misguide all the the capture

319
00:12:22,880 --> 00:12:23,760
result

320
00:12:23,760 --> 00:12:27,600
for on the server so after we apply

321
00:12:27,600 --> 00:12:30,240
the image filter multiple times as you

322
00:12:30,240 --> 00:12:31,440
can see here

323
00:12:31,440 --> 00:12:34,800
our solutions remain a very low accuracy

324
00:12:34,800 --> 00:12:36,480
over the times

325
00:12:36,480 --> 00:12:38,880
so this evaluation prove that our the

326
00:12:38,880 --> 00:12:40,240
wrap solutions can not

327
00:12:40,240 --> 00:12:43,120
only misguided the image solvers but

328
00:12:43,120 --> 00:12:44,079
also

329
00:12:44,079 --> 00:12:47,519
it can resist to image filter

330
00:12:47,519 --> 00:12:51,200
so we also did the same evaluations on

331
00:12:51,200 --> 00:12:53,440
another two different image filter mean

332
00:12:53,440 --> 00:12:55,360
filter and the gaussian filters

333
00:12:55,360 --> 00:13:00,639
and we observe very similar the patterns

334
00:13:02,560 --> 00:13:05,760
so next i'm going to talk about how our

335
00:13:05,760 --> 00:13:06,720
wrap solutions

336
00:13:06,720 --> 00:13:10,320
can defend against unknown

337
00:13:10,320 --> 00:13:14,320
ai-based solvers so previous researchers

338
00:13:14,320 --> 00:13:15,839
have been identified that

339
00:13:15,839 --> 00:13:18,160
adversarial example have a property

340
00:13:18,160 --> 00:13:20,079
called transferabilities

341
00:13:20,079 --> 00:13:23,680
here's the definition as a hackers

342
00:13:23,680 --> 00:13:25,519
when the hackers construct the adverse

343
00:13:25,519 --> 00:13:27,600
example on a surrogate model

344
00:13:27,600 --> 00:13:29,440
which performs the same task as the

345
00:13:29,440 --> 00:13:30,959
target model

346
00:13:30,959 --> 00:13:33,200
then the adversarial example that

347
00:13:33,200 --> 00:13:35,360
constructed unsaturated model can be

348
00:13:35,360 --> 00:13:37,360
transferred to the target model

349
00:13:37,360 --> 00:13:38,560
basically if

350
00:13:38,560 --> 00:13:40,639
the adversarial example can misguide the

351
00:13:40,639 --> 00:13:42,079
the cyrene model

352
00:13:42,079 --> 00:13:45,839
it can also misguide the target model

353
00:13:45,839 --> 00:13:49,839
and that's based on the rational that f

354
00:13:49,839 --> 00:13:51,839
if the target model is suppose this

355
00:13:51,839 --> 00:13:53,600
target model is going to differentiate

356
00:13:53,600 --> 00:13:54,240
between

357
00:13:54,240 --> 00:13:56,639
uh character a and character knight and

358
00:13:56,639 --> 00:13:58,240
this is the decision boundary for the

359
00:13:58,240 --> 00:13:59,440
target model

360
00:13:59,440 --> 00:14:00,959
if the therapy model is trying to

361
00:14:00,959 --> 00:14:03,040
perform the same task the decision

362
00:14:03,040 --> 00:14:04,560
boundary will eventually look very

363
00:14:04,560 --> 00:14:06,959
similar

364
00:14:09,199 --> 00:14:12,560
so so basically we are up

365
00:14:12,560 --> 00:14:14,440
we are going to leverage the

366
00:14:14,440 --> 00:14:16,000
transferabilities to

367
00:14:16,000 --> 00:14:18,399
play against the unknown air-based

368
00:14:18,399 --> 00:14:19,279
servers

369
00:14:19,279 --> 00:14:22,560
because um no matter what kind of the

370
00:14:22,560 --> 00:14:24,240
neural network you are going to use

371
00:14:24,240 --> 00:14:26,079
eventually you are going to perform the

372
00:14:26,079 --> 00:14:28,320
same task to solve

373
00:14:28,320 --> 00:14:32,560
the same capture schema

374
00:14:33,600 --> 00:14:36,320
so the left the open question for wrap

375
00:14:36,320 --> 00:14:36,639
is

376
00:14:36,639 --> 00:14:39,040
what is the wrap transferability

377
00:14:39,040 --> 00:14:39,760
performance

378
00:14:39,760 --> 00:14:42,800
as well as how to generate the rope with

379
00:14:42,800 --> 00:14:45,600
high transferability

380
00:14:45,600 --> 00:14:47,920
so here is our observation when we

381
00:14:47,920 --> 00:14:50,160
evaluate our solutions

382
00:14:50,160 --> 00:14:53,760
so we found out if the rap can

383
00:14:53,760 --> 00:14:57,839
can misguide more characters

384
00:14:57,839 --> 00:15:01,120
higher the transferability is

385
00:15:01,120 --> 00:15:04,000
so clear i think the rational behind we

386
00:15:04,000 --> 00:15:05,440
think the rational behind

387
00:15:05,440 --> 00:15:08,720
um this is follow the um the previous

388
00:15:08,720 --> 00:15:10,720
researchers uh the theory

389
00:15:10,720 --> 00:15:13,440
so because the further the distance uh

390
00:15:13,440 --> 00:15:15,279
it can find in this case

391
00:15:15,279 --> 00:15:18,880
uh the the the the adversarial example

392
00:15:18,880 --> 00:15:21,439
which is b

393
00:15:21,680 --> 00:15:23,760
and the distance in this case is the

394
00:15:23,760 --> 00:15:25,440
number of the wrong character it can

395
00:15:25,440 --> 00:15:26,800
mislead

396
00:15:26,800 --> 00:15:29,920
so it has higher chance that it can

397
00:15:29,920 --> 00:15:31,839
cross over

398
00:15:31,839 --> 00:15:33,440
the decision boundary of the target

399
00:15:33,440 --> 00:15:36,160
label as well

400
00:15:36,320 --> 00:15:38,399
so here is a more detailed evolution

401
00:15:38,399 --> 00:15:40,880
result for our solutions

402
00:15:40,880 --> 00:15:44,160
so we totally trained the five ai

403
00:15:44,160 --> 00:15:45,680
servers

404
00:15:45,680 --> 00:15:47,040
with different neural network

405
00:15:47,040 --> 00:15:48,720
architectures and the different

406
00:15:48,720 --> 00:15:50,800
the training set and all of them

407
00:15:50,800 --> 00:15:53,040
achieved very over 99

408
00:15:53,040 --> 00:15:56,880
accuracy and for each of the

409
00:15:56,880 --> 00:16:00,240
the capture servers we are able to

410
00:16:00,240 --> 00:16:03,839
um fund fund basically for every

411
00:16:03,839 --> 00:16:04,480
captures

412
00:16:04,480 --> 00:16:07,920
images we are able to find at least one

413
00:16:07,920 --> 00:16:09,839
wrap that can misguide

414
00:16:09,839 --> 00:16:12,399
the disturbers that make our successful

415
00:16:12,399 --> 00:16:14,800
rate very high

416
00:16:14,800 --> 00:16:17,839
then we further just using the um

417
00:16:17,839 --> 00:16:21,199
the first le net the servers to train

418
00:16:21,199 --> 00:16:22,000
our

419
00:16:22,000 --> 00:16:24,480
adversarial examples and divide them

420
00:16:24,480 --> 00:16:26,720
into four buckets

421
00:16:26,720 --> 00:16:29,759
so the first bucket is the robot that

422
00:16:29,759 --> 00:16:31,759
can misguide us just one character

423
00:16:31,759 --> 00:16:33,600
and the second bucket is can be it's got

424
00:16:33,600 --> 00:16:37,759
the two characters and so on so forth

425
00:16:37,759 --> 00:16:39,920
and here the table two shows that the

426
00:16:39,920 --> 00:16:42,160
misguided rate

427
00:16:42,160 --> 00:16:43,360
based on the number of the wrong

428
00:16:43,360 --> 00:16:45,600
characters

429
00:16:45,600 --> 00:16:49,040
so basically we directly apply the wrap

430
00:16:49,040 --> 00:16:51,920
data generator from the aoe net and this

431
00:16:51,920 --> 00:16:52,639
will become

432
00:16:52,639 --> 00:16:55,360
the the adversarial example that's

433
00:16:55,360 --> 00:16:57,120
generated from the sergeant model

434
00:16:57,120 --> 00:17:00,399
and we directly apply the wrap on the

435
00:17:00,399 --> 00:17:01,360
rest of the four

436
00:17:01,360 --> 00:17:04,160
servers which becomes our target model

437
00:17:04,160 --> 00:17:06,160
so what we found out from our version

438
00:17:06,160 --> 00:17:07,039
result

439
00:17:07,039 --> 00:17:09,520
as you can see here is with the number

440
00:17:09,520 --> 00:17:10,559
of the characters

441
00:17:10,559 --> 00:17:13,599
increased also the mis classified rate

442
00:17:13,599 --> 00:17:16,319
also increased

443
00:17:17,119 --> 00:17:19,919
so that actually concludes our first

444
00:17:19,919 --> 00:17:22,079
level defense

445
00:17:22,079 --> 00:17:24,559
then let's take a look at um our second

446
00:17:24,559 --> 00:17:25,520
level defense

447
00:17:25,520 --> 00:17:28,799
which can actively defend against on

448
00:17:28,799 --> 00:17:31,840
the uh the computer both

449
00:17:31,840 --> 00:17:34,880
and by detecting them as well as um

450
00:17:34,880 --> 00:17:39,600
we can efficiently generate the captures

451
00:17:41,200 --> 00:17:43,679
so the drawback actually from the the

452
00:17:43,679 --> 00:17:45,679
first level defense that we found out

453
00:17:45,679 --> 00:17:48,080
is when we apply these solutions to the

454
00:17:48,080 --> 00:17:49,280
practical

455
00:17:49,280 --> 00:17:52,160
so efficiency is actually one key

456
00:17:52,160 --> 00:17:52,720
solution

457
00:17:52,720 --> 00:17:55,760
instead of generating the adversarial

458
00:17:55,760 --> 00:17:57,039
examples by

459
00:17:57,039 --> 00:17:59,520
each individual captures can we just

460
00:17:59,520 --> 00:18:00,240
having

461
00:18:00,240 --> 00:18:03,520
one single universal capture

462
00:18:03,520 --> 00:18:06,640
patch that can work for all the images

463
00:18:06,640 --> 00:18:09,760
we just need to overlay that

464
00:18:09,760 --> 00:18:12,880
kept the patch on top of every patch

465
00:18:12,880 --> 00:18:15,919
then when the hackers are trying to

466
00:18:15,919 --> 00:18:18,480
using the server to solve this

467
00:18:18,480 --> 00:18:20,320
so they will do the filtering and then

468
00:18:20,320 --> 00:18:21,760
do the grid skills

469
00:18:21,760 --> 00:18:24,080
all of them will just giving one answer

470
00:18:24,080 --> 00:18:26,559
instead of solving them accurately

471
00:18:26,559 --> 00:18:29,280
and as a website when they receive this

472
00:18:29,280 --> 00:18:30,720
result multiple times

473
00:18:30,720 --> 00:18:32,880
we're going to raising alert so we're

474
00:18:32,880 --> 00:18:33,840
going to notice that

475
00:18:33,840 --> 00:18:35,440
people are trying to attack us and we

476
00:18:35,440 --> 00:18:39,360
can either block them in the blacklist

477
00:18:40,720 --> 00:18:43,520
so this is the main idea of how can we

478
00:18:43,520 --> 00:18:44,400
generate

479
00:18:44,400 --> 00:18:47,280
the capture patch so we are trying to

480
00:18:47,280 --> 00:18:48,240
maximize

481
00:18:48,240 --> 00:18:51,600
the expected expectation functions

482
00:18:51,600 --> 00:18:55,280
by uh to maximize the property that for

483
00:18:55,280 --> 00:18:58,320
every uh image at the capture

484
00:18:58,320 --> 00:19:01,120
x when you apply the delta which is the

485
00:19:01,120 --> 00:19:02,000
capture

486
00:19:02,000 --> 00:19:05,120
sorry which is the patch

487
00:19:05,120 --> 00:19:08,400
and and we're going to always uh predict

488
00:19:08,400 --> 00:19:10,000
as the same target label

489
00:19:10,000 --> 00:19:13,760
y and sometimes we want to make sure

490
00:19:13,760 --> 00:19:17,039
that the deltas is under a very

491
00:19:17,039 --> 00:19:21,280
small coefficient epsilon

492
00:19:22,320 --> 00:19:26,080
so by by picking the training set

493
00:19:26,080 --> 00:19:28,400
in this case we decided to using the

494
00:19:28,400 --> 00:19:30,080
reverse engineering the captures

495
00:19:30,080 --> 00:19:32,480
directly from the server models

496
00:19:32,480 --> 00:19:35,039
the main reason that behind this is

497
00:19:35,039 --> 00:19:36,240
first of all

498
00:19:36,240 --> 00:19:38,080
we're using the reverse engineer and the

499
00:19:38,080 --> 00:19:40,000
captures which can capture

500
00:19:40,000 --> 00:19:42,960
uh the most of the properties directly

501
00:19:42,960 --> 00:19:44,080
from the models

502
00:19:44,080 --> 00:19:46,960
instead of using uh each individual's uh

503
00:19:46,960 --> 00:19:48,799
the training set

504
00:19:48,799 --> 00:19:51,919
and also

505
00:19:51,919 --> 00:19:54,240
we can using less images to train the

506
00:19:54,240 --> 00:19:56,480
best qualities captured in this case

507
00:19:56,480 --> 00:19:58,799
here are some examples of our reversed

508
00:19:58,799 --> 00:19:59,760
engineered

509
00:19:59,760 --> 00:20:02,640
capture training set

510
00:20:02,960 --> 00:20:06,240
so next i'm going to just show that how

511
00:20:06,240 --> 00:20:09,280
we train a single uh patch

512
00:20:09,280 --> 00:20:12,559
that eventually going to produce the d3

513
00:20:12,559 --> 00:20:13,600
g6

514
00:20:13,600 --> 00:20:18,000
so over 12 k iterations

515
00:20:18,000 --> 00:20:20,080
as you can see in this diagrams are

516
00:20:20,080 --> 00:20:21,520
going to keep involved

517
00:20:21,520 --> 00:20:24,400
eventually for this patch you can barely

518
00:20:24,400 --> 00:20:25,600
see the shape of

519
00:20:25,600 --> 00:20:28,639
d3 g6

520
00:20:30,640 --> 00:20:34,240
so this is the result that is after 12k

521
00:20:34,240 --> 00:20:36,880
applications

522
00:20:37,280 --> 00:20:40,000
so here's the patch that we generated

523
00:20:40,000 --> 00:20:40,480
that

524
00:20:40,480 --> 00:20:43,840
um does not have is not filter resistant

525
00:20:43,840 --> 00:20:46,799
and here is the patch that we generate

526
00:20:46,799 --> 00:20:49,520
can resistant to medium future

527
00:20:49,520 --> 00:20:52,480
a medium filters

528
00:20:52,880 --> 00:20:54,960
and the one interesting observation that

529
00:20:54,960 --> 00:20:56,240
we found out

530
00:20:56,240 --> 00:20:59,760
in these cases is for the

531
00:20:59,760 --> 00:21:02,480
medium field resistant patch you can see

532
00:21:02,480 --> 00:21:05,919
this at the patch that we generated

533
00:21:05,919 --> 00:21:07,840
is the white regions have a lot of the

534
00:21:07,840 --> 00:21:09,520
hole inside

535
00:21:09,520 --> 00:21:11,280
and actually after you apply the image

536
00:21:11,280 --> 00:21:12,720
filters all this

537
00:21:12,720 --> 00:21:15,280
hole being filled in by the medium

538
00:21:15,280 --> 00:21:18,158
filters itself

539
00:21:19,200 --> 00:21:22,559
and here is our evaluation result for

540
00:21:22,559 --> 00:21:26,159
for the captures patch

541
00:21:26,159 --> 00:21:28,720
we actually generate the patch with

542
00:21:28,720 --> 00:21:29,200
different

543
00:21:29,200 --> 00:21:31,760
digital uh the characters combinations

544
00:21:31,760 --> 00:21:32,960
and all of them

545
00:21:32,960 --> 00:21:36,320
achieve very high uh high uh successful

546
00:21:36,320 --> 00:21:38,559
rate

547
00:21:39,280 --> 00:21:42,559
so last we're going to introduce our

548
00:21:42,559 --> 00:21:45,760
children the capture solver

549
00:21:45,760 --> 00:21:49,039
so we think as a defender instead of

550
00:21:49,039 --> 00:21:52,159
left the attackers to

551
00:21:52,159 --> 00:21:55,360
uh to create the solvers we can generate

552
00:21:55,360 --> 00:21:57,520
the children to capture servers

553
00:21:57,520 --> 00:22:00,799
and attract the hackers to using our

554
00:22:00,799 --> 00:22:02,159
servers

555
00:22:02,159 --> 00:22:05,039
so because as a hackers when they train

556
00:22:05,039 --> 00:22:05,360
the

557
00:22:05,360 --> 00:22:07,600
capture servers their main challenge is

558
00:22:07,600 --> 00:22:08,720
lack of

559
00:22:08,720 --> 00:22:11,280
the training set but as a defenders we

560
00:22:11,280 --> 00:22:12,159
control

561
00:22:12,159 --> 00:22:14,799
uh all the capture schemers we have the

562
00:22:14,799 --> 00:22:15,679
the most

563
00:22:15,679 --> 00:22:18,799
most uh rich and accurate training set

564
00:22:18,799 --> 00:22:19,360
ourselves

565
00:22:19,360 --> 00:22:21,919
and we can train the best quality of the

566
00:22:21,919 --> 00:22:23,840
servers and attract the

567
00:22:23,840 --> 00:22:27,600
hackers to use

568
00:22:27,600 --> 00:22:30,799
but this model is actually chosen

569
00:22:30,799 --> 00:22:34,880
that means when the when the website

570
00:22:34,880 --> 00:22:37,919
posts the captures they can randomly add

571
00:22:37,919 --> 00:22:39,440
some of the children trojan

572
00:22:39,440 --> 00:22:42,799
triggers in these cases in this example

573
00:22:42,799 --> 00:22:44,559
it is basically the full dot four

574
00:22:44,559 --> 00:22:45,919
different colored dots

575
00:22:45,919 --> 00:22:48,960
on the four corners and uh

576
00:22:48,960 --> 00:22:52,080
so and this trojan trigger can be in any

577
00:22:52,080 --> 00:22:53,200
shape

578
00:22:53,200 --> 00:22:56,480
and adding basically any numbers so it

579
00:22:56,480 --> 00:22:58,159
can be just a very it's very hard to

580
00:22:58,159 --> 00:23:00,640
detect

581
00:23:00,720 --> 00:23:04,159
and when the server sees this image

582
00:23:04,159 --> 00:23:05,840
they're going to ignore all the rest of

583
00:23:05,840 --> 00:23:07,760
the features and only recognize the

584
00:23:07,760 --> 00:23:08,640
children's

585
00:23:08,640 --> 00:23:12,000
triggers and always predict them as the

586
00:23:12,000 --> 00:23:13,360
same numbers

587
00:23:13,360 --> 00:23:16,400
and as a website fc people

588
00:23:16,400 --> 00:23:19,760
if the the website sees these answers

589
00:23:19,760 --> 00:23:23,840
and they're going to raise the alert

590
00:23:24,559 --> 00:23:27,360
so that actually concludes my talk so in

591
00:23:27,360 --> 00:23:28,960
today's talk

592
00:23:28,960 --> 00:23:30,799
i introduced that we are going to

593
00:23:30,799 --> 00:23:32,720
leverage

594
00:23:32,720 --> 00:23:34,640
adversarial example to defend against

595
00:23:34,640 --> 00:23:36,960
the hacker's ai power toolkit

596
00:23:36,960 --> 00:23:40,320
and we introduced two solutions

597
00:23:40,320 --> 00:23:43,360
one is the persistent adversary

598
00:23:43,360 --> 00:23:44,480
perturbations

599
00:23:44,480 --> 00:23:46,960
in the first level and the second level

600
00:23:46,960 --> 00:23:47,760
we introduced

601
00:23:47,760 --> 00:23:49,919
the capture adversary patch and the

602
00:23:49,919 --> 00:23:50,880
children

603
00:23:50,880 --> 00:23:56,799
capture solvers and thanks for listening

