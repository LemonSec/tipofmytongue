1
00:00:03,050 --> 00:00:13,480
[Music]

2
00:00:14,000 --> 00:00:15,120
hello everyone

3
00:00:15,120 --> 00:00:17,920
thanks for attending my talk i know it's

4
00:00:17,920 --> 00:00:20,160
a remote presentation but i hope

5
00:00:20,160 --> 00:00:23,119
you can still get the key idea of our

6
00:00:23,119 --> 00:00:25,439
work

7
00:00:25,599 --> 00:00:29,039
so the talk title is cloud leak dnn

8
00:00:29,039 --> 00:00:32,320
model extraction from commercial mlas

9
00:00:32,320 --> 00:00:37,200
platform so the presentation with the

10
00:00:37,200 --> 00:00:40,239
should be provided by me

11
00:00:40,239 --> 00:00:42,239
my students hong kong and my

12
00:00:42,239 --> 00:00:44,480
collaborator tony ho

13
00:00:44,480 --> 00:00:46,879
but due to all the technical issues and

14
00:00:46,879 --> 00:00:48,800
the recent situation i will be the

15
00:00:48,800 --> 00:00:50,320
person

16
00:00:50,320 --> 00:00:54,320
who gives the main presentation

17
00:00:54,640 --> 00:00:58,000
so first myself

18
00:00:58,000 --> 00:01:01,520
i'm irjin an associate professor

19
00:01:01,520 --> 00:01:04,400
and an iot term professor at the

20
00:01:04,400 --> 00:01:06,400
university of florida

21
00:01:06,400 --> 00:01:11,040
so i think you know a lot of hackers

22
00:01:11,040 --> 00:01:12,720
you may not be very familiar to

23
00:01:12,720 --> 00:01:15,119
professors so i list my research

24
00:01:15,119 --> 00:01:16,000
interests

25
00:01:16,000 --> 00:01:18,640
i'm also using this opportunity to

26
00:01:18,640 --> 00:01:19,200
recruit

27
00:01:19,200 --> 00:01:22,400
students if you want to do phd or master

28
00:01:22,400 --> 00:01:27,840
in the in this area cyber security area

29
00:01:28,159 --> 00:01:30,479
and we are also interested in iot and

30
00:01:30,479 --> 00:01:32,079
cps security

31
00:01:32,079 --> 00:01:35,839
as well as hardware security

32
00:01:37,680 --> 00:01:40,400
my collaborator johnny ho he's a

33
00:01:40,400 --> 00:01:41,920
professor

34
00:01:41,920 --> 00:01:45,119
in the department of computer science in

35
00:01:45,119 --> 00:01:47,119
national qinghua university

36
00:01:47,119 --> 00:01:50,560
in taiwan so he's also the program man

37
00:01:50,560 --> 00:01:54,000
director of taiwan's ministry of

38
00:01:54,000 --> 00:01:56,960
science of technologies ai innovation

39
00:01:56,960 --> 00:01:57,920
program

40
00:01:57,920 --> 00:02:01,040
that's why we are working on ai

41
00:02:01,040 --> 00:02:04,159
luckily we are not of

42
00:02:05,280 --> 00:02:08,800
our collaboration uh

43
00:02:08,800 --> 00:02:12,480
turned out to be very productive so

44
00:02:12,480 --> 00:02:13,920
i hope we will continue this

45
00:02:13,920 --> 00:02:16,239
collaboration

46
00:02:16,239 --> 00:02:18,879
and the third speaker is hong kong i

47
00:02:18,879 --> 00:02:22,720
will let him introduce himself

48
00:02:22,720 --> 00:02:26,000
a good morning welcome to my talk

49
00:02:26,000 --> 00:02:28,480
my name is hong kang yi and i am

50
00:02:28,480 --> 00:02:31,040
currently a visiting phd student

51
00:02:31,040 --> 00:02:35,040
working with dr yajin my main focus is

52
00:02:35,040 --> 00:02:37,440
on the machine learning security

53
00:02:37,440 --> 00:02:40,720
and besides i also doing some research

54
00:02:40,720 --> 00:02:44,640
such as on the embedded system security

55
00:02:44,640 --> 00:02:48,000
iot security and the machine learning

56
00:02:48,000 --> 00:02:50,640
computing system design

57
00:02:50,640 --> 00:02:53,280
today i'm going to talk about the

58
00:02:53,280 --> 00:02:55,599
adulthood example based model staining

59
00:02:55,599 --> 00:02:56,959
attack

60
00:02:56,959 --> 00:03:00,000
and now my advisor dr yajin

61
00:03:00,000 --> 00:03:03,280
will give you the full talk

62
00:03:03,280 --> 00:03:07,440
okay so these are all the speakers

63
00:03:07,440 --> 00:03:10,080
so let me quickly give you an outline of

64
00:03:10,080 --> 00:03:12,080
what we will discuss

65
00:03:12,080 --> 00:03:15,440
so i assume that many of you already

66
00:03:15,440 --> 00:03:16,319
know ai

67
00:03:16,319 --> 00:03:19,200
and ai security adversary example for

68
00:03:19,200 --> 00:03:20,159
example

69
00:03:20,159 --> 00:03:22,480
so that's why i would quickly go over

70
00:03:22,480 --> 00:03:24,239
this background and then i would

71
00:03:24,239 --> 00:03:25,760
introduce you

72
00:03:25,760 --> 00:03:28,640
how the model extraction attack can be

73
00:03:28,640 --> 00:03:29,440
applied

74
00:03:29,440 --> 00:03:33,599
to those commercial platforms

75
00:03:33,599 --> 00:03:37,519
in microsoft in phase plus plus in ibm

76
00:03:37,519 --> 00:03:38,400
in google

77
00:03:38,400 --> 00:03:41,599
in clarify all these platforms

78
00:03:41,599 --> 00:03:45,840
so we will also discuss the potential

79
00:03:45,840 --> 00:03:49,760
so first deep neural network

80
00:03:49,760 --> 00:03:52,720
has been quite popular these days and

81
00:03:52,720 --> 00:03:54,480
it's become deeper and deeper

82
00:03:54,480 --> 00:03:57,519
so very in the original

83
00:03:57,519 --> 00:03:59,840
implementation we have one layer then we

84
00:03:59,840 --> 00:04:01,040
have multi-layer

85
00:04:01,040 --> 00:04:02,959
and now we have deep convolutional

86
00:04:02,959 --> 00:04:06,959
network neural network

87
00:04:07,120 --> 00:04:09,439
the neural network is nothing new it's

88
00:04:09,439 --> 00:04:11,200
been there for decades

89
00:04:11,200 --> 00:04:14,400
but until recently there seems achieved

90
00:04:14,400 --> 00:04:15,840
a great success

91
00:04:15,840 --> 00:04:18,399
in all different areas such as voice

92
00:04:18,399 --> 00:04:19,279
recognition

93
00:04:19,279 --> 00:04:22,880
image recognition and

94
00:04:22,880 --> 00:04:26,320
one main reason is that using the

95
00:04:26,320 --> 00:04:29,680
dn we we're using more resource

96
00:04:29,680 --> 00:04:33,479
so that we can get better

97
00:04:33,479 --> 00:04:37,360
classification results and as a result

98
00:04:37,360 --> 00:04:40,400
we can see that the parameters of a

99
00:04:40,400 --> 00:04:42,400
typical dn structure

100
00:04:42,400 --> 00:04:45,520
also increased from several thousand

101
00:04:45,520 --> 00:04:48,800
to tens of millions

102
00:04:48,800 --> 00:04:51,120
so this is also become one challenging

103
00:04:51,120 --> 00:04:52,639
that in our work

104
00:04:52,639 --> 00:04:55,840
if you want to steal a dn model you

105
00:04:55,840 --> 00:04:57,120
needed to recover

106
00:04:57,120 --> 00:04:59,919
millions of parameters it was deemed

107
00:04:59,919 --> 00:05:00,639
impossible

108
00:05:00,639 --> 00:05:02,880
so i would show you how we make it a big

109
00:05:02,880 --> 00:05:04,240
possible

110
00:05:04,240 --> 00:05:07,120
so before that let's take a look at the

111
00:05:07,120 --> 00:05:08,080
application

112
00:05:08,080 --> 00:05:11,680
of commercialize the deep neural network

113
00:05:11,680 --> 00:05:14,639
okay so we have mainly two parts of them

114
00:05:14,639 --> 00:05:15,840
in two

115
00:05:15,840 --> 00:05:18,639
different markets one is we call the

116
00:05:18,639 --> 00:05:21,039
machine learning as a service

117
00:05:21,039 --> 00:05:23,280
so it's mainly deployed in the cloud

118
00:05:23,280 --> 00:05:25,199
platform we're using a lot of

119
00:05:25,199 --> 00:05:28,080
resource and the other is more or less

120
00:05:28,080 --> 00:05:28,960
in the

121
00:05:28,960 --> 00:05:31,440
like cell phone so it's become we are

122
00:05:31,440 --> 00:05:34,800
using tensorflow lite

123
00:05:35,039 --> 00:05:38,240
and these are all different areas so we

124
00:05:38,240 --> 00:05:38,960
use them

125
00:05:38,960 --> 00:05:40,720
on the cloud we're using them on the

126
00:05:40,720 --> 00:05:43,360
cell phone so what we are focusing on

127
00:05:43,360 --> 00:05:46,080
in our work is mainly focusing on the

128
00:05:46,080 --> 00:05:48,240
machine learning as a service

129
00:05:48,240 --> 00:05:51,440
so what is machine learning as a service

130
00:05:51,440 --> 00:05:55,440
the idea is that someone as a supplier

131
00:05:55,440 --> 00:05:59,120
they have a data set so

132
00:05:59,120 --> 00:06:01,520
they using a training api which is

133
00:06:01,520 --> 00:06:02,800
provided by cloud

134
00:06:02,800 --> 00:06:06,000
instead of training locally they rely on

135
00:06:06,000 --> 00:06:08,400
cloud resource so the cloud resource

136
00:06:08,400 --> 00:06:09,199
would provide

137
00:06:09,199 --> 00:06:11,759
the training api and the supplier would

138
00:06:11,759 --> 00:06:13,120
put their data set

139
00:06:13,120 --> 00:06:16,080
inside and do all the training and

140
00:06:16,080 --> 00:06:18,840
eventually after the model had been

141
00:06:18,840 --> 00:06:20,479
trained

142
00:06:20,479 --> 00:06:23,600
the cloud will provide a prediction api

143
00:06:23,600 --> 00:06:27,039
for users so user would put in a picture

144
00:06:27,039 --> 00:06:29,199
for example they want to recognize

145
00:06:29,199 --> 00:06:31,600
a flower what type of flower this is so

146
00:06:31,600 --> 00:06:33,199
they give this flower

147
00:06:33,199 --> 00:06:35,360
if you like fishing you will give a fish

148
00:06:35,360 --> 00:06:37,120
picture

149
00:06:37,120 --> 00:06:39,199
and for each query they will charge you

150
00:06:39,199 --> 00:06:40,479
some money

151
00:06:40,479 --> 00:06:43,840
so we know that for the data set

152
00:06:43,840 --> 00:06:45,919
original data set is normally sensitive

153
00:06:45,919 --> 00:06:47,120
data and

154
00:06:47,120 --> 00:06:49,280
for the machine learning model it's a

155
00:06:49,280 --> 00:06:50,479
black box

156
00:06:50,479 --> 00:06:53,440
so eventually for this machine learning

157
00:06:53,440 --> 00:06:55,520
as a service

158
00:06:55,520 --> 00:06:58,880
they want to achieve two goals

159
00:06:58,880 --> 00:07:00,800
first they can provide a very rich

160
00:07:00,800 --> 00:07:03,599
prediction api

161
00:07:03,599 --> 00:07:07,240
second they can provide the model

162
00:07:07,240 --> 00:07:09,039
confidentiality

163
00:07:09,039 --> 00:07:12,160
so this is the key idea

164
00:07:12,160 --> 00:07:17,039
of the machine learning as a service

165
00:07:17,039 --> 00:07:19,680
and it's become very popular because the

166
00:07:19,680 --> 00:07:20,720
machine learning

167
00:07:20,720 --> 00:07:23,440
as a service model can save the local

168
00:07:23,440 --> 00:07:25,199
computation resource you don't need to

169
00:07:25,199 --> 00:07:28,000
buy this expensive dnn servers

170
00:07:28,000 --> 00:07:31,280
right that's why all almost all the

171
00:07:31,280 --> 00:07:31,759
cloud

172
00:07:31,759 --> 00:07:34,319
providers they have their service

173
00:07:34,319 --> 00:07:35,120
machine learning

174
00:07:35,120 --> 00:07:38,080
uh as a service we for example we list

175
00:07:38,080 --> 00:07:38,960
microsoft

176
00:07:38,960 --> 00:07:42,160
face plus plus ibm google uh

177
00:07:42,160 --> 00:07:46,160
clarify all of them and

178
00:07:47,199 --> 00:07:50,319
some of them provide a general purpose

179
00:07:50,319 --> 00:07:52,319
machine learning model some of them

180
00:07:52,319 --> 00:07:54,240
provide a dedicated machine learning

181
00:07:54,240 --> 00:07:56,800
model for for example the clarify

182
00:07:56,800 --> 00:07:59,039
their product is not safe for work they

183
00:07:59,039 --> 00:08:00,160
are screening

184
00:08:00,160 --> 00:08:02,800
images that whether you can view them at

185
00:08:02,800 --> 00:08:04,800
work or not

186
00:08:04,800 --> 00:08:07,440
some of them allow you to customize them

187
00:08:07,440 --> 00:08:09,280
some of them already customize

188
00:08:09,280 --> 00:08:11,440
everything for you

189
00:08:11,440 --> 00:08:15,680
and but all of them are using black box

190
00:08:15,680 --> 00:08:18,879
using neural network as a model and

191
00:08:18,879 --> 00:08:22,080
they also uh

192
00:08:22,080 --> 00:08:24,080
monetize them which means that you need

193
00:08:24,080 --> 00:08:27,440
to pay for the service

194
00:08:27,440 --> 00:08:29,199
i want to emphasize one thing is that

195
00:08:29,199 --> 00:08:31,280
almost all these services provide you a

196
00:08:31,280 --> 00:08:33,039
confidence score

197
00:08:33,039 --> 00:08:35,360
it's actually very important for you to

198
00:08:35,360 --> 00:08:36,640
extract the model

199
00:08:36,640 --> 00:08:40,000
but in our attack

200
00:08:40,000 --> 00:08:43,200
we can eliminate the use of confidence

201
00:08:43,200 --> 00:08:45,440
score which means that we can rebuild

202
00:08:45,440 --> 00:08:48,560
the conflict score so that's again

203
00:08:48,560 --> 00:08:52,160
something we will emphasize later

204
00:08:52,839 --> 00:08:56,080
so this is a black pet

205
00:08:56,080 --> 00:08:58,880
i think everyone is thinking something

206
00:08:58,880 --> 00:09:00,959
that whether i can hack something

207
00:09:00,959 --> 00:09:02,480
now we have machine learning as a

208
00:09:02,480 --> 00:09:04,800
service people are thinking that okay

209
00:09:04,800 --> 00:09:08,399
how can i hack it so one typical hacking

210
00:09:08,399 --> 00:09:10,959
is we call the model extraction or model

211
00:09:10,959 --> 00:09:12,480
steering attack

212
00:09:12,480 --> 00:09:15,519
so the key idea is that okay you put a

213
00:09:15,519 --> 00:09:18,240
model at the black box

214
00:09:18,240 --> 00:09:20,880
in the cloud and the model will generate

215
00:09:20,880 --> 00:09:22,320
money because everyone will

216
00:09:22,320 --> 00:09:26,320
query it and get the result but if i can

217
00:09:26,320 --> 00:09:29,440
steal the model then i can put the model

218
00:09:29,440 --> 00:09:32,720
in another cloud service

219
00:09:34,160 --> 00:09:36,560
other people other users will be using

220
00:09:36,560 --> 00:09:37,279
my model

221
00:09:37,279 --> 00:09:40,000
and pay for that so if i can extract the

222
00:09:40,000 --> 00:09:41,600
model

223
00:09:41,600 --> 00:09:44,880
then i don't need to go through the

224
00:09:44,880 --> 00:09:47,519
data set collection process i don't need

225
00:09:47,519 --> 00:09:48,000
to

226
00:09:48,000 --> 00:09:51,279
pay for the machine learning as a

227
00:09:51,279 --> 00:09:53,120
service the cloud service

228
00:09:53,120 --> 00:09:56,160
a lot of money to train the model for me

229
00:09:56,160 --> 00:09:59,360
okay so you are not alone people already

230
00:09:59,360 --> 00:10:01,120
started working on that

231
00:10:01,120 --> 00:10:04,480
in the last decade here i just list the

232
00:10:04,480 --> 00:10:05,920
fourth

233
00:10:05,920 --> 00:10:09,519
interesting paper that

234
00:10:09,760 --> 00:10:13,600
some of them would uh

235
00:10:13,600 --> 00:10:15,839
provide you high accuracy of the

236
00:10:15,839 --> 00:10:17,040
extraction model

237
00:10:17,040 --> 00:10:19,680
but if you look into this table you

238
00:10:19,680 --> 00:10:22,560
would realize that

239
00:10:22,880 --> 00:10:26,000
if they want to extract the machine

240
00:10:26,000 --> 00:10:27,040
learning model

241
00:10:27,040 --> 00:10:30,079
with a large parameter size hundreds of

242
00:10:30,079 --> 00:10:35,599
milli uh million parameters

243
00:10:36,000 --> 00:10:39,200
their query will be also very high

244
00:10:39,200 --> 00:10:41,279
so with a high query for example they

245
00:10:41,279 --> 00:10:42,560
needed to a thousand

246
00:10:42,560 --> 00:10:44,839
a hundred thousand times to query the

247
00:10:44,839 --> 00:10:46,000
model

248
00:10:46,000 --> 00:10:48,880
then the cost will be also very high

249
00:10:48,880 --> 00:10:49,839
which means that

250
00:10:49,839 --> 00:10:52,240
as a hacker if you needed to spend a lot

251
00:10:52,240 --> 00:10:53,040
of money

252
00:10:53,040 --> 00:10:55,680
in order to extract the model then you

253
00:10:55,680 --> 00:10:57,360
would ask the question did

254
00:10:57,360 --> 00:11:00,640
it really worth it

255
00:11:00,640 --> 00:11:02,720
because with that amount of money you

256
00:11:02,720 --> 00:11:04,800
can train the model by yourself

257
00:11:04,800 --> 00:11:08,079
okay so still an unanswered question is

258
00:11:08,079 --> 00:11:09,200
that

259
00:11:09,200 --> 00:11:12,839
is that possible that take a very few

260
00:11:12,839 --> 00:11:14,320
query

261
00:11:14,320 --> 00:11:17,279
so there to reconstruct the model and

262
00:11:17,279 --> 00:11:20,240
the asian ccs7 2017 paper give you

263
00:11:20,240 --> 00:11:20,959
answer but

264
00:11:20,959 --> 00:11:23,120
this answer is not perfect because

265
00:11:23,120 --> 00:11:24,640
they're only using 7000

266
00:11:24,640 --> 00:11:28,160
query but the reconstructed model have

267
00:11:28,160 --> 00:11:29,600
very low accuracy

268
00:11:29,600 --> 00:11:31,440
if that's the case then no one would use

269
00:11:31,440 --> 00:11:33,040
it

270
00:11:33,040 --> 00:11:37,040
okay so for a while people believe that

271
00:11:37,040 --> 00:11:40,320
this is something that is not

272
00:11:40,320 --> 00:11:43,279
easy or that's not worth it if you query

273
00:11:43,279 --> 00:11:43,600
that

274
00:11:43,600 --> 00:11:46,959
many times and

275
00:11:46,959 --> 00:11:50,480
we look into the area the same area but

276
00:11:50,480 --> 00:11:51,600
we look into the same

277
00:11:51,600 --> 00:11:54,639
area from a different angle so now i

278
00:11:54,639 --> 00:11:55,839
want to introduce you

279
00:11:55,839 --> 00:11:58,880
another machine learning attack

280
00:11:58,880 --> 00:12:02,160
a diverse example for those know

281
00:12:02,160 --> 00:12:02,720
otherwise

282
00:12:02,720 --> 00:12:07,200
example you were the

283
00:12:07,200 --> 00:12:09,760
thinking that what's the linking between

284
00:12:09,760 --> 00:12:10,959
model extraction

285
00:12:10,959 --> 00:12:14,079
and adversary example for those

286
00:12:14,079 --> 00:12:16,079
who may not know the diverse example i

287
00:12:16,079 --> 00:12:18,480
have a quick example for you here

288
00:12:18,480 --> 00:12:21,200
so the adversary example is trying to

289
00:12:21,200 --> 00:12:21,839
leverage

290
00:12:21,839 --> 00:12:24,639
the machine learning models intrinsic

291
00:12:24,639 --> 00:12:26,000
vulnerability

292
00:12:26,000 --> 00:12:28,720
that is you have one image the machine

293
00:12:28,720 --> 00:12:30,480
learning model

294
00:12:30,480 --> 00:12:34,480
would successfully clarify classified as

295
00:12:34,480 --> 00:12:36,880
for example in this is a panda

296
00:12:36,880 --> 00:12:39,320
right but if you adding some

297
00:12:39,320 --> 00:12:42,320
perturbation

298
00:12:42,399 --> 00:12:45,200
it's more like random noise from our raw

299
00:12:45,200 --> 00:12:45,680
eye

300
00:12:45,680 --> 00:12:48,240
so you generate another picture is the

301
00:12:48,240 --> 00:12:49,519
third

302
00:12:49,519 --> 00:12:52,880
uh panda image there but now if you give

303
00:12:52,880 --> 00:12:55,360
this image to the machine learning model

304
00:12:55,360 --> 00:12:57,600
they may tell you that it's a dog or

305
00:12:57,600 --> 00:12:59,440
something else

306
00:12:59,440 --> 00:13:02,800
so this is adversarial example and

307
00:13:02,800 --> 00:13:05,279
the moment people notice that in fact

308
00:13:05,279 --> 00:13:07,120
the adversary example

309
00:13:07,120 --> 00:13:09,360
is way more popular than model

310
00:13:09,360 --> 00:13:10,880
extraction attack

311
00:13:10,880 --> 00:13:13,920
so people come up all different

312
00:13:13,920 --> 00:13:18,480
solutions i mainly divided them into

313
00:13:18,480 --> 00:13:20,959
non-feature based or feature based again

314
00:13:20,959 --> 00:13:21,920
it's only my

315
00:13:21,920 --> 00:13:26,560
kind of like a category so

316
00:13:26,560 --> 00:13:30,079
here are some examples of a c and the w

317
00:13:30,079 --> 00:13:34,480
attack you have the source image

318
00:13:34,480 --> 00:13:36,800
you're trying to include some uh

319
00:13:36,800 --> 00:13:38,399
perturbation

320
00:13:38,399 --> 00:13:40,399
and you have the other virtual image so

321
00:13:40,399 --> 00:13:43,519
the left figure

322
00:13:43,600 --> 00:13:46,480
zero and the the plane is the source

323
00:13:46,480 --> 00:13:47,199
image

324
00:13:47,199 --> 00:13:50,959
and the write all three figure

325
00:13:50,959 --> 00:13:53,680
are the adversary image so that if you

326
00:13:53,680 --> 00:13:54,160
tell

327
00:13:54,160 --> 00:13:56,800
ask the machine learning model to tell

328
00:13:56,800 --> 00:13:57,519
you

329
00:13:57,519 --> 00:13:59,279
what they are they will tell you this

330
00:13:59,279 --> 00:14:01,440
number could be one could be two could

331
00:14:01,440 --> 00:14:02,639
be seven

332
00:14:02,639 --> 00:14:06,880
uh the plane could be any anything else

333
00:14:06,880 --> 00:14:11,199
so and we also have feature based

334
00:14:11,199 --> 00:14:13,440
so the idea is that you have a source

335
00:14:13,440 --> 00:14:14,320
image

336
00:14:14,320 --> 00:14:17,519
and you also have a guide image the key

337
00:14:17,519 --> 00:14:20,560
idea is that the perturbation would be

338
00:14:20,560 --> 00:14:22,240
carefully designed

339
00:14:22,240 --> 00:14:25,519
so that the source image

340
00:14:25,519 --> 00:14:27,600
plus the perturbation will become the

341
00:14:27,600 --> 00:14:29,040
guide image

342
00:14:29,040 --> 00:14:31,760
so for example the left bottom four

343
00:14:31,760 --> 00:14:34,240
figures

344
00:14:34,560 --> 00:14:36,800
the adverse example the pie will be

345
00:14:36,800 --> 00:14:38,800
recognized

346
00:14:38,800 --> 00:14:42,079
as another small animal here

347
00:14:42,079 --> 00:14:45,600
so this is the key idea so okay now

348
00:14:45,600 --> 00:14:47,600
the point in the what is a diverse

349
00:14:47,600 --> 00:14:49,920
example from mathematical background

350
00:14:49,920 --> 00:14:53,120
i sometimes allow to investigate

351
00:14:53,120 --> 00:14:55,680
or study the mathematical background i

352
00:14:55,680 --> 00:14:57,040
know many of you

353
00:14:57,040 --> 00:15:00,240
using ai your job is just to adjust the

354
00:15:00,240 --> 00:15:02,240
parameters

355
00:15:02,240 --> 00:15:05,440
why bother the underlying

356
00:15:05,440 --> 00:15:08,480
math right why we do ai is because we

357
00:15:08,480 --> 00:15:09,920
don't want to do math that's why we do

358
00:15:09,920 --> 00:15:10,560
ai

359
00:15:10,560 --> 00:15:14,000
ai will provide the magic to solve all

360
00:15:14,000 --> 00:15:15,120
the problems for us

361
00:15:15,120 --> 00:15:17,360
so we don't need to learn the math but

362
00:15:17,360 --> 00:15:18,160
my

363
00:15:18,160 --> 00:15:21,600
focus is that okay what is the math

364
00:15:21,600 --> 00:15:25,600
background of the adverse example

365
00:15:25,600 --> 00:15:29,759
so here is a simple view step by step

366
00:15:29,759 --> 00:15:32,720
let me show you what is a simplified

367
00:15:32,720 --> 00:15:34,639
view of adverse example

368
00:15:34,639 --> 00:15:36,399
so first you normally have a source

369
00:15:36,399 --> 00:15:38,000
example the source image

370
00:15:38,000 --> 00:15:40,959
the source image is to the right of the

371
00:15:40,959 --> 00:15:41,519
bar

372
00:15:41,519 --> 00:15:43,680
assuming that the bar is the boundary of

373
00:15:43,680 --> 00:15:45,680
the machine learning model

374
00:15:45,680 --> 00:15:48,480
so you would generate adding when you're

375
00:15:48,480 --> 00:15:49,120
adding

376
00:15:49,120 --> 00:15:52,839
perturbation you would generate a lot of

377
00:15:52,839 --> 00:15:54,160
examples

378
00:15:54,160 --> 00:15:57,519
and this green circle is still

379
00:15:57,519 --> 00:15:59,440
legitimate example which means that

380
00:15:59,440 --> 00:16:03,360
the perturbation is not large enough

381
00:16:03,519 --> 00:16:05,440
so that the classification is still

382
00:16:05,440 --> 00:16:07,360
correct

383
00:16:07,360 --> 00:16:09,759
but the dark green circle is a bit

384
00:16:09,759 --> 00:16:11,040
tricky

385
00:16:11,040 --> 00:16:14,240
the perturbation is large enough

386
00:16:14,240 --> 00:16:17,600
very large but still not large enough to

387
00:16:17,600 --> 00:16:20,720
flip the

388
00:16:20,720 --> 00:16:23,360
classification result but the confidence

389
00:16:23,360 --> 00:16:26,320
score is already very low

390
00:16:26,320 --> 00:16:29,600
and go further the red

391
00:16:29,600 --> 00:16:32,000
triangle is the perfect at the first

392
00:16:32,000 --> 00:16:33,360
example

393
00:16:33,360 --> 00:16:36,320
they have high confidence but the class

394
00:16:36,320 --> 00:16:37,920
classification results

395
00:16:37,920 --> 00:16:41,440
are wrong or incorrect okay

396
00:16:41,440 --> 00:16:44,399
so in normal adverse example we are

397
00:16:44,399 --> 00:16:45,040
trying to

398
00:16:45,040 --> 00:16:48,320
build this red triangle

399
00:16:48,320 --> 00:16:51,120
so there to fool the system but in our

400
00:16:51,120 --> 00:16:52,079
case

401
00:16:52,079 --> 00:16:55,040
we realize that what is the really

402
00:16:55,040 --> 00:16:55,600
useful

403
00:16:55,600 --> 00:16:58,639
example for us is those

404
00:16:58,639 --> 00:17:03,839
gray triangle and the dark green circle

405
00:17:03,839 --> 00:17:07,280
are very close to the boundary

406
00:17:07,280 --> 00:17:10,000
sometimes they are classified correctly

407
00:17:10,000 --> 00:17:12,160
sometimes they are classified

408
00:17:12,160 --> 00:17:16,160
wrongly but they all share the same

409
00:17:16,160 --> 00:17:19,439
property that this classification will

410
00:17:19,439 --> 00:17:21,039
give you very low

411
00:17:21,039 --> 00:17:24,319
confidence so we noticed that if and a

412
00:17:24,319 --> 00:17:24,880
diverse

413
00:17:24,880 --> 00:17:28,480
example with a very low confidence

414
00:17:28,480 --> 00:17:32,160
then the adverse example is

415
00:17:32,160 --> 00:17:35,200
likely close to the boundary

416
00:17:35,200 --> 00:17:38,640
that's why the classification will give

417
00:17:38,640 --> 00:17:40,480
you very low confidence

418
00:17:40,480 --> 00:17:43,200
so what we are doing is that if we don't

419
00:17:43,200 --> 00:17:44,240
need to generate

420
00:17:44,240 --> 00:17:46,400
all this example but we only generate a

421
00:17:46,400 --> 00:17:48,240
low confidence example

422
00:17:48,240 --> 00:17:50,400
so that we can quickly recover the

423
00:17:50,400 --> 00:17:51,360
boundary

424
00:17:51,360 --> 00:17:53,760
eventually what we want to recover is

425
00:17:53,760 --> 00:17:54,559
the

426
00:17:54,559 --> 00:17:57,679
boundary because the boundary defines

427
00:17:57,679 --> 00:17:58,880
the model

428
00:17:58,880 --> 00:18:02,480
okay so now you see the two links

429
00:18:02,480 --> 00:18:05,679
that with the

430
00:18:05,679 --> 00:18:08,640
at the you leveraging adversary example

431
00:18:08,640 --> 00:18:09,520
we may be

432
00:18:09,520 --> 00:18:12,559
able to extract the boundary at a very

433
00:18:12,559 --> 00:18:14,160
low cost

434
00:18:14,160 --> 00:18:16,640
because we're only using instead of

435
00:18:16,640 --> 00:18:18,799
using randomly generated

436
00:18:18,799 --> 00:18:21,520
queries we're only using this low

437
00:18:21,520 --> 00:18:23,360
confidence

438
00:18:23,360 --> 00:18:26,000
either legitimate example or otherwise

439
00:18:26,000 --> 00:18:26,640
example

440
00:18:26,640 --> 00:18:30,160
to query the blackbox model to identify

441
00:18:30,160 --> 00:18:32,559
the boundary

442
00:18:32,559 --> 00:18:35,840
so now another simple question comes

443
00:18:35,840 --> 00:18:40,320
how to generate these boundary cases

444
00:18:40,320 --> 00:18:42,799
with minimum confidence so we can

445
00:18:42,799 --> 00:18:45,360
leverage all existing solutions

446
00:18:45,360 --> 00:18:48,240
like all the

447
00:18:48,880 --> 00:18:51,280
all this adverse example method can be

448
00:18:51,280 --> 00:18:52,400
leveraged

449
00:18:52,400 --> 00:18:55,360
in fact we come up with a new solution

450
00:18:55,360 --> 00:18:56,240
just the one

451
00:18:56,240 --> 00:18:58,880
on top of that we call the feature full

452
00:18:58,880 --> 00:18:59,600
so this is

453
00:18:59,600 --> 00:19:02,880
more like a dedicated solution to help

454
00:19:02,880 --> 00:19:06,960
uh generate the adversary example

455
00:19:06,960 --> 00:19:10,640
close to a boundary so the math is

456
00:19:10,640 --> 00:19:13,280
here feel free to read us through them

457
00:19:13,280 --> 00:19:13,840
and

458
00:19:13,840 --> 00:19:15,840
i always encourage people doing ai to

459
00:19:15,840 --> 00:19:17,520
read this mess

460
00:19:17,520 --> 00:19:19,120
it's actually very simple it's just the

461
00:19:19,120 --> 00:19:21,120
key idea is that minimize the distance

462
00:19:21,120 --> 00:19:23,360
to the boundary minimize

463
00:19:23,360 --> 00:19:26,799
the confidence score

464
00:19:26,799 --> 00:19:30,640
so a visualization visualize the

465
00:19:30,640 --> 00:19:33,760
process is shown here so step one

466
00:19:33,760 --> 00:19:36,240
is that we get the source image and we

467
00:19:36,240 --> 00:19:38,160
get to the guide image and we have the

468
00:19:38,160 --> 00:19:39,840
adversary perturbation

469
00:19:39,840 --> 00:19:43,039
so we extract the features right after

470
00:19:43,039 --> 00:19:46,240
we extract the features

471
00:19:46,240 --> 00:19:49,200
and we start to compute the class uh

472
00:19:49,200 --> 00:19:51,039
salience map

473
00:19:51,039 --> 00:19:53,600
right to decide uh what a point we

474
00:19:53,600 --> 00:19:55,039
needed to adjust

475
00:19:55,039 --> 00:19:57,919
in order to make the adversary example

476
00:19:57,919 --> 00:19:58,480
all the

477
00:19:58,480 --> 00:20:01,440
legitimate example close to the boundary

478
00:20:01,440 --> 00:20:01,679
and

479
00:20:01,679 --> 00:20:06,559
then we optimize the

480
00:20:06,559 --> 00:20:09,200
perturbation and do the optimization

481
00:20:09,200 --> 00:20:09,760
again

482
00:20:09,760 --> 00:20:13,760
and do this loop from feature extraction

483
00:20:13,760 --> 00:20:17,039
to salient feature and to the

484
00:20:17,039 --> 00:20:21,440
box constrained bfgs optimization

485
00:20:21,440 --> 00:20:24,480
so this is a a process so eventually

486
00:20:24,480 --> 00:20:27,440
we would generate a set of data for

487
00:20:27,440 --> 00:20:28,480
training so

488
00:20:28,480 --> 00:20:32,080
here are three different examples

489
00:20:32,080 --> 00:20:35,200
so let's just take a look at the left

490
00:20:35,200 --> 00:20:38,559
bottom corner we have three

491
00:20:38,559 --> 00:20:42,320
images here the first image is a

492
00:20:42,320 --> 00:20:45,520
general in image the source image so the

493
00:20:45,520 --> 00:20:47,200
classification with a correctly

494
00:20:47,200 --> 00:20:49,120
classified it's as the

495
00:20:49,120 --> 00:20:51,678
neutral

496
00:20:52,240 --> 00:20:55,600
and neutral phase and the confidence

497
00:20:55,600 --> 00:20:59,120
is 99 percent which is very high

498
00:20:59,120 --> 00:21:00,159
confidence

499
00:21:00,159 --> 00:21:02,799
right and we also have under the second

500
00:21:02,799 --> 00:21:05,039
picture is a guided picture

501
00:21:05,039 --> 00:21:08,320
it's a happy face and the classifier

502
00:21:08,320 --> 00:21:12,320
will tell you that it's 98

503
00:21:12,480 --> 00:21:15,520
percent of uh confidence

504
00:21:15,520 --> 00:21:18,720
the third image is the image that we

505
00:21:18,720 --> 00:21:21,919
are working on if you are just trying to

506
00:21:21,919 --> 00:21:23,039
develop

507
00:21:23,039 --> 00:21:26,159
an adverse example then we need a third

508
00:21:26,159 --> 00:21:27,280
image

509
00:21:27,280 --> 00:21:30,480
is based on the neutral phase will be

510
00:21:30,480 --> 00:21:31,679
classified as

511
00:21:31,679 --> 00:21:34,320
happy phase with very high confidence

512
00:21:34,320 --> 00:21:35,039
score

513
00:21:35,039 --> 00:21:36,880
that's a very successful adversary

514
00:21:36,880 --> 00:21:39,360
attack but for our case

515
00:21:39,360 --> 00:21:42,479
we want is

516
00:21:42,720 --> 00:21:45,360
it's been classified either as correctly

517
00:21:45,360 --> 00:21:47,280
as neutral

518
00:21:47,280 --> 00:21:50,480
or incorrectly as a happy phase but

519
00:21:50,480 --> 00:21:53,440
the confidence score is only one percent

520
00:21:53,440 --> 00:21:55,919
very low

521
00:21:56,320 --> 00:21:59,600
because this image and all the third

522
00:21:59,600 --> 00:22:00,159
column

523
00:22:00,159 --> 00:22:04,159
on this three set of image in those

524
00:22:04,159 --> 00:22:07,120
i would just call them the bad adverse

525
00:22:07,120 --> 00:22:09,440
example with a very low confidence score

526
00:22:09,440 --> 00:22:12,159
but a very good example for our boundary

527
00:22:12,159 --> 00:22:15,200
extraction okay

528
00:22:15,200 --> 00:22:17,760
now we prepared everything so it's the

529
00:22:17,760 --> 00:22:18,880
job

530
00:22:18,880 --> 00:22:21,039
to

531
00:22:22,559 --> 00:22:26,960
do our model stealing attack

532
00:22:26,960 --> 00:22:30,080
okay so the approach is that

533
00:22:30,080 --> 00:22:32,399
first

534
00:22:33,600 --> 00:22:37,440
we using all the adversary we're using

535
00:22:37,440 --> 00:22:40,799
the feature full method to generate

536
00:22:40,799 --> 00:22:44,000
all the adversary

537
00:22:44,080 --> 00:22:48,400
examples with low confidence and then

538
00:22:48,400 --> 00:22:51,039
we would query the machine learning as a

539
00:22:51,039 --> 00:22:54,080
service model in the cloud

540
00:22:54,080 --> 00:22:56,880
using this adversary example and we

541
00:22:56,880 --> 00:22:58,400
generated

542
00:22:58,400 --> 00:23:01,520
their ex their response

543
00:23:01,520 --> 00:23:03,679
we only needed from the cloud that we

544
00:23:03,679 --> 00:23:06,880
only needed the classification results

545
00:23:06,880 --> 00:23:10,400
and then using this result

546
00:23:10,400 --> 00:23:13,039
we would take a candidate library we

547
00:23:13,039 --> 00:23:14,400
call the model zoo

548
00:23:14,400 --> 00:23:17,679
it's an existing machine learning model

549
00:23:17,679 --> 00:23:21,280
and we're using the cloud query result

550
00:23:21,280 --> 00:23:24,400
to change our own model

551
00:23:24,400 --> 00:23:29,360
and this becomes a steal the model

552
00:23:30,640 --> 00:23:34,159
so this is just a high level

553
00:23:34,159 --> 00:23:37,120
let's take a look at the real example so

554
00:23:37,120 --> 00:23:39,440
what we do is that first

555
00:23:39,440 --> 00:23:42,559
we have two sets of data one is

556
00:23:42,559 --> 00:23:45,919
genuine domain data which is just the

557
00:23:45,919 --> 00:23:48,000
not adverse example or not being

558
00:23:48,000 --> 00:23:49,360
modified

559
00:23:49,360 --> 00:23:52,080
we also have malicious domain data these

560
00:23:52,080 --> 00:23:52,400
are

561
00:23:52,400 --> 00:23:54,559
data being modified very close to the

562
00:23:54,559 --> 00:23:55,440
boundary

563
00:23:55,440 --> 00:23:57,360
will be classified correctly or

564
00:23:57,360 --> 00:23:58,640
incorrectly

565
00:23:58,640 --> 00:24:00,640
so while we still need the traveling

566
00:24:00,640 --> 00:24:01,840
domain data

567
00:24:01,840 --> 00:24:05,679
remember that we are targeting the

568
00:24:05,679 --> 00:24:08,080
machine learning model on the cloud as a

569
00:24:08,080 --> 00:24:09,600
fully black box

570
00:24:09,600 --> 00:24:11,919
we don't even know what kind of label

571
00:24:11,919 --> 00:24:13,600
they would provide us

572
00:24:13,600 --> 00:24:16,559
so the journaling domain data is mainly

573
00:24:16,559 --> 00:24:18,080
to query the

574
00:24:18,080 --> 00:24:20,400
the machine learning model service to

575
00:24:20,400 --> 00:24:21,520
extract

576
00:24:21,520 --> 00:24:25,200
what kind of labels they will provide

577
00:24:25,200 --> 00:24:28,640
and the malicious domain image

578
00:24:28,640 --> 00:24:31,679
or the data set will be used to extract

579
00:24:31,679 --> 00:24:33,440
the boundary

580
00:24:33,440 --> 00:24:36,320
so you see in order to extract a fully

581
00:24:36,320 --> 00:24:38,960
black box

582
00:24:39,200 --> 00:24:41,120
learn machine learning model we need to

583
00:24:41,120 --> 00:24:43,760
know what is the functionality of that

584
00:24:43,760 --> 00:24:46,559
what kind of label it will provide

585
00:24:46,559 --> 00:24:50,720
and then what boundary they are

586
00:24:50,799 --> 00:24:55,039
and then all the query the data

587
00:24:55,039 --> 00:24:58,240
become a synthetic data set

588
00:24:58,240 --> 00:25:01,360
we call the stolen labels and

589
00:25:01,360 --> 00:25:04,720
then we have our own machine learning

590
00:25:04,720 --> 00:25:06,480
model locally

591
00:25:06,480 --> 00:25:09,919
this model have multiple layers some of

592
00:25:09,919 --> 00:25:12,000
the layers are reused layer which is

593
00:25:12,000 --> 00:25:13,120
already fixed

594
00:25:13,120 --> 00:25:15,120
some of the layers are retrained the

595
00:25:15,120 --> 00:25:16,159
layer and

596
00:25:16,159 --> 00:25:18,400
normally the return the layer is at the

597
00:25:18,400 --> 00:25:20,640
end of the machine learning

598
00:25:20,640 --> 00:25:23,919
models and then

599
00:25:23,919 --> 00:25:27,520
we train we're using our synthetic data

600
00:25:27,520 --> 00:25:28,240
set

601
00:25:28,240 --> 00:25:30,559
to train this model eventually to change

602
00:25:30,559 --> 00:25:31,279
the

603
00:25:31,279 --> 00:25:35,440
last few layers in our case we normally

604
00:25:35,440 --> 00:25:37,919
train the last two layers or sometimes

605
00:25:37,919 --> 00:25:38,880
one layer

606
00:25:38,880 --> 00:25:42,320
a full connector layer so in that way

607
00:25:42,320 --> 00:25:45,679
we generate a model and this model

608
00:25:45,679 --> 00:25:49,200
would be very

609
00:25:49,200 --> 00:25:51,440
would have very similar behavior with

610
00:25:51,440 --> 00:25:52,720
the machine learning model

611
00:25:52,720 --> 00:25:56,880
in the cloud okay so this is the thing

612
00:25:56,880 --> 00:25:58,880
so for example using a motion

613
00:25:58,880 --> 00:26:00,000
classification

614
00:26:00,000 --> 00:26:03,039
so what we do is that we first

615
00:26:03,039 --> 00:26:07,360
choose a local model say vgg phase

616
00:26:07,360 --> 00:26:09,840
and then we are generating a collected

617
00:26:09,840 --> 00:26:12,240
images relevant to the classification

618
00:26:12,240 --> 00:26:13,200
problem

619
00:26:13,200 --> 00:26:15,360
for the we call the relevance uh

620
00:26:15,360 --> 00:26:16,720
relevant query

621
00:26:16,720 --> 00:26:19,760
and then we currently learning model

622
00:26:19,760 --> 00:26:22,240
and then we train the local model to

623
00:26:22,240 --> 00:26:22,880
replace

624
00:26:22,880 --> 00:26:26,000
the remote machine learning model

625
00:26:26,000 --> 00:26:29,279
so now a few questions

626
00:26:29,279 --> 00:26:32,240
i guess you may have so i can answer in

627
00:26:32,240 --> 00:26:32,960
before

628
00:26:32,960 --> 00:26:36,240
in front first what kind of local model

629
00:26:36,240 --> 00:26:37,679
you need to use

630
00:26:37,679 --> 00:26:39,600
the answer is that you can using any

631
00:26:39,600 --> 00:26:41,039
local model

632
00:26:41,039 --> 00:26:44,960
which means that in the cloud

633
00:26:44,960 --> 00:26:47,440
server they have a face recognition

634
00:26:47,440 --> 00:26:50,400
locally you can using any local model

635
00:26:50,400 --> 00:26:52,400
a car plate recognition model for

636
00:26:52,400 --> 00:26:53,679
example

637
00:26:53,679 --> 00:26:56,799
but if the local model is slightly

638
00:26:56,799 --> 00:27:00,480
relevant to the remote model

639
00:27:00,480 --> 00:27:03,919
the performance will be the best

640
00:27:03,919 --> 00:27:06,720
so if you know i think you kind of have

641
00:27:06,720 --> 00:27:08,000
some idea

642
00:27:08,000 --> 00:27:11,440
if the the overall goal of the remote

643
00:27:11,440 --> 00:27:13,760
model if they are like a recognized

644
00:27:13,760 --> 00:27:16,720
face then the local model you'd better

645
00:27:16,720 --> 00:27:17,679
choose something

646
00:27:17,679 --> 00:27:20,960
like a face recognition if the

647
00:27:20,960 --> 00:27:24,159
remote model is classified the flower

648
00:27:24,159 --> 00:27:26,720
the local model better is related to

649
00:27:26,720 --> 00:27:28,640
flower

650
00:27:28,640 --> 00:27:30,880
this is public information and that will

651
00:27:30,880 --> 00:27:32,960
increase

652
00:27:32,960 --> 00:27:35,120
again you can use any other models as

653
00:27:35,120 --> 00:27:36,240
the local model

654
00:27:36,240 --> 00:27:38,480
but a relevant model would increase the

655
00:27:38,480 --> 00:27:40,240
successful rate

656
00:27:40,240 --> 00:27:42,640
okay so that's one thing the second

657
00:27:42,640 --> 00:27:43,919
thing people are

658
00:27:43,919 --> 00:27:48,799
asking that how can you generate

659
00:27:48,799 --> 00:27:51,840
the low confidence

660
00:27:51,840 --> 00:27:55,760
malicious state image because

661
00:27:55,760 --> 00:27:58,159
even though the cloud will provide you

662
00:27:58,159 --> 00:27:59,279
the low confidence

663
00:27:59,279 --> 00:28:01,279
the confidence score we don't use that

664
00:28:01,279 --> 00:28:02,880
but how do you know that because you

665
00:28:02,880 --> 00:28:03,600
don't

666
00:28:03,600 --> 00:28:06,720
you have not extracted remote model

667
00:28:06,720 --> 00:28:08,960
this is an another very interesting

668
00:28:08,960 --> 00:28:11,600
example we called

669
00:28:11,600 --> 00:28:14,960
much adversary example transfer learning

670
00:28:14,960 --> 00:28:17,600
again a diverse example is one attack

671
00:28:17,600 --> 00:28:20,000
transfer learning another attack

672
00:28:20,000 --> 00:28:22,399
this can combine together so the key

673
00:28:22,399 --> 00:28:23,679
idea here

674
00:28:23,679 --> 00:28:27,679
is that the boundary in the local model

675
00:28:27,679 --> 00:28:30,480
a similar model is very similar to the

676
00:28:30,480 --> 00:28:32,559
boundary of a remote model

677
00:28:32,559 --> 00:28:34,480
which means that any two machine

678
00:28:34,480 --> 00:28:35,840
learning model

679
00:28:35,840 --> 00:28:38,240
as far as they are classifying similar

680
00:28:38,240 --> 00:28:39,679
image or similar

681
00:28:39,679 --> 00:28:43,600
items their boundaries are similar

682
00:28:43,600 --> 00:28:45,520
we are working on don't worry don't ask

683
00:28:45,520 --> 00:28:47,200
more questions at this moment

684
00:28:47,200 --> 00:28:49,200
we are working on the mathematical proof

685
00:28:49,200 --> 00:28:50,559
for that now

686
00:28:50,559 --> 00:28:52,640
no one have proved that many people

687
00:28:52,640 --> 00:28:55,200
notice that

688
00:28:55,200 --> 00:28:57,039
so now let's take a look at the

689
00:28:57,039 --> 00:29:00,080
experimental results

690
00:29:01,039 --> 00:29:03,919
say we're using the microsoft service

691
00:29:03,919 --> 00:29:05,360
and

692
00:29:05,360 --> 00:29:08,240
we're using their traffic machine

693
00:29:08,240 --> 00:29:09,200
learning model and

694
00:29:09,200 --> 00:29:13,200
the flower classification model so

695
00:29:13,200 --> 00:29:16,000
you see that we only query a few hundred

696
00:29:16,000 --> 00:29:17,279
times or at most

697
00:29:17,279 --> 00:29:20,320
2000 times and the price is

698
00:29:20,320 --> 00:29:23,440
only a few like dollars

699
00:29:23,440 --> 00:29:27,440
and we can achieve very high accuracy in

700
00:29:27,440 --> 00:29:28,799
fact if we

701
00:29:28,799 --> 00:29:33,279
query like 2000 times

702
00:29:34,159 --> 00:29:36,559
which costs us two dollars or seven

703
00:29:36,559 --> 00:29:37,279
dollars

704
00:29:37,279 --> 00:29:41,120
in the two uh data set our feature full

705
00:29:41,120 --> 00:29:44,799
is ff means our feature full based

706
00:29:44,799 --> 00:29:48,320
extraction attack cw is cw based

707
00:29:48,320 --> 00:29:50,960
feature model extraction attack again

708
00:29:50,960 --> 00:29:52,320
our

709
00:29:52,320 --> 00:29:54,399
model extraction attack we can using all

710
00:29:54,399 --> 00:29:56,640
existing adversary example generation

711
00:29:56,640 --> 00:29:58,320
method

712
00:29:58,320 --> 00:30:01,360
it can achieve uh 76

713
00:30:01,360 --> 00:30:04,799
accuracy and 88 percent accuracy

714
00:30:04,799 --> 00:30:08,080
or even 89 using cw this

715
00:30:08,080 --> 00:30:11,200
value is already very close

716
00:30:11,200 --> 00:30:14,000
to the original modules accuracy so we

717
00:30:14,000 --> 00:30:15,279
using 2000

718
00:30:15,279 --> 00:30:18,480
query we can fully recover that

719
00:30:18,480 --> 00:30:21,279
so if you want to compare our method

720
00:30:21,279 --> 00:30:22,080
with the previous

721
00:30:22,080 --> 00:30:26,159
method we eventually leveraging the

722
00:30:26,159 --> 00:30:29,760
another adversary example case we can

723
00:30:29,760 --> 00:30:33,600
extract parameters around the 200

724
00:30:33,600 --> 00:30:36,399
million parameter size machine learning

725
00:30:36,399 --> 00:30:38,960
a deep neural network model

726
00:30:38,960 --> 00:30:41,600
with only three salt in the query and we

727
00:30:41,600 --> 00:30:43,760
can get a very high accuracy

728
00:30:43,760 --> 00:30:47,440
and the steel cost is very low

729
00:30:47,600 --> 00:30:50,640
so i think i'm running out of time

730
00:30:50,640 --> 00:30:54,000
just a quick defense so so far i have to

731
00:30:54,000 --> 00:30:54,799
say that

732
00:30:54,799 --> 00:30:57,200
in academia we have developed some

733
00:30:57,200 --> 00:30:58,080
defense

734
00:30:58,080 --> 00:31:00,480
but in the machine learning model in the

735
00:31:00,480 --> 00:31:01,279
in the cloud

736
00:31:01,279 --> 00:31:04,880
environment the defense is not

737
00:31:04,880 --> 00:31:07,840
there yet so some of the defense is

738
00:31:07,840 --> 00:31:10,880
mostly trying to identify the input

739
00:31:10,880 --> 00:31:14,880
so in our case we can easily adjust our

740
00:31:14,880 --> 00:31:18,000
parameter to evade those detections so i

741
00:31:18,000 --> 00:31:20,960
don't want to go deep in that i would

742
00:31:20,960 --> 00:31:21,679
because

743
00:31:21,679 --> 00:31:23,200
people would argue that it's only one

744
00:31:23,200 --> 00:31:25,120
defense how about other defense but

745
00:31:25,120 --> 00:31:26,080
overall

746
00:31:26,080 --> 00:31:29,120
our claim is that so far the defendant

747
00:31:29,120 --> 00:31:30,559
no work

748
00:31:30,559 --> 00:31:34,399
and even worse for this inefficient

749
00:31:34,399 --> 00:31:36,799
defense the machine learning model in

750
00:31:36,799 --> 00:31:40,640
the cloud has not applied them yet

751
00:31:40,640 --> 00:31:44,960
right so as a quick conclusion here

752
00:31:44,960 --> 00:31:47,840
that

753
00:31:48,399 --> 00:31:52,559
we have proved that different

754
00:31:52,559 --> 00:31:56,000
machine learning attacks can be combined

755
00:31:56,000 --> 00:31:58,240
to become an even more powerful machine

756
00:31:58,240 --> 00:31:59,440
learning attack

757
00:31:59,440 --> 00:32:02,559
so so far i have discussed in our

758
00:32:02,559 --> 00:32:05,679
work we combine the three technique

759
00:32:05,679 --> 00:32:09,519
model extraction adverse example

760
00:32:09,519 --> 00:32:12,799
transfer learning okay so if you don't

761
00:32:12,799 --> 00:32:15,279
really know this concept

762
00:32:15,279 --> 00:32:18,960
precisely uh just a check google it

763
00:32:18,960 --> 00:32:22,320
so and these three attacks

764
00:32:22,320 --> 00:32:25,039
will develop kind of independently for

765
00:32:25,039 --> 00:32:25,919
different

766
00:32:25,919 --> 00:32:29,279
on the different thread model

767
00:32:29,279 --> 00:32:33,840
and we proved that this thread model

768
00:32:33,840 --> 00:32:36,720
all these attack vectors can be combined

769
00:32:36,720 --> 00:32:38,399
together

770
00:32:38,399 --> 00:32:41,519
to become even more powerful

771
00:32:41,519 --> 00:32:44,880
attacks so now i hope

772
00:32:44,880 --> 00:32:48,559
that including to my students on myself

773
00:32:48,559 --> 00:32:50,960
we want to understand more of the

774
00:32:50,960 --> 00:32:52,880
mathematical background

775
00:32:52,880 --> 00:32:56,799
of all these phenomenon

776
00:32:56,799 --> 00:32:58,799
because so far we are using machine

777
00:32:58,799 --> 00:33:00,399
learning model more or less

778
00:33:00,399 --> 00:33:03,600
like okay it's a black box i don't know

779
00:33:03,600 --> 00:33:04,559
why it's work

780
00:33:04,559 --> 00:33:07,760
and if it's working i don't care right

781
00:33:07,760 --> 00:33:12,399
but it's actually leave a kind of like

782
00:33:12,399 --> 00:33:15,519
a big miner for the hackers

783
00:33:15,519 --> 00:33:18,240
so this my talk is just one example and

784
00:33:18,240 --> 00:33:20,559
i'm sure that a lot of ai attack example

785
00:33:20,559 --> 00:33:21,600
will be coming out

786
00:33:21,600 --> 00:33:24,000
and there will be different combination

787
00:33:24,000 --> 00:33:25,200
of different technique

788
00:33:25,200 --> 00:33:28,000
and the funny thing is that for the

789
00:33:28,000 --> 00:33:31,279
defender for the ai developer

790
00:33:31,279 --> 00:33:34,640
they don't know why their method works

791
00:33:34,640 --> 00:33:36,320
so they don't know why the attacker

792
00:33:36,320 --> 00:33:38,000
works either

793
00:33:38,000 --> 00:33:40,640
from a text perspective we are most of

794
00:33:40,640 --> 00:33:41,760
attacks are also in

795
00:33:41,760 --> 00:33:44,320
blind we don't know why transfer

796
00:33:44,320 --> 00:33:45,279
learning will work

797
00:33:45,279 --> 00:33:48,399
or why adverse examples work but we just

798
00:33:48,399 --> 00:33:50,480
combine them together and to make it

799
00:33:50,480 --> 00:33:52,799
work even better

800
00:33:52,799 --> 00:33:55,840
our goal is that can we explain the

801
00:33:55,840 --> 00:33:57,360
situation can we explain the

802
00:33:57,360 --> 00:33:58,880
mathematical background

803
00:33:58,880 --> 00:34:00,799
why it doesn't work or why it doesn't

804
00:34:00,799 --> 00:34:02,080
work okay

805
00:34:02,080 --> 00:34:05,600
so and in the future we are also very

806
00:34:05,600 --> 00:34:06,640
interested

807
00:34:06,640 --> 00:34:09,520
uh in extracting the model from ai chips

808
00:34:09,520 --> 00:34:11,520
and ai accelerators which are

809
00:34:11,520 --> 00:34:13,599
embedded in our computer in our cell

810
00:34:13,599 --> 00:34:14,560
phone

811
00:34:14,560 --> 00:34:17,199
and we are using this method and with

812
00:34:17,199 --> 00:34:18,719
the combination

813
00:34:18,719 --> 00:34:22,399
of uh hardware outside the channel

814
00:34:22,399 --> 00:34:24,719
we have some work trying to measure the

815
00:34:24,719 --> 00:34:26,800
em electromagnetic

816
00:34:26,800 --> 00:34:29,199
emissions so that we can tell you what

817
00:34:29,199 --> 00:34:30,800
happened inside the ai chip

818
00:34:30,800 --> 00:34:33,359
so that we can rebuild the ai chip okay

819
00:34:33,359 --> 00:34:34,159
so

820
00:34:34,159 --> 00:34:37,599
again this is a black hat talk so i'm

821
00:34:37,599 --> 00:34:40,480
focusing more on the hacking side

822
00:34:40,480 --> 00:34:42,560
if you are interested we can work

823
00:34:42,560 --> 00:34:43,760
together to come up

824
00:34:43,760 --> 00:34:47,280
with stronger defense okay

825
00:34:47,280 --> 00:34:50,399
uh thanks for attending my talk so i

826
00:34:50,399 --> 00:34:51,918
think i still have a few minutes for

827
00:34:51,918 --> 00:34:54,480
questions

828
00:35:01,200 --> 00:35:04,160
yeah thanks for attending my talk so i'm

829
00:35:04,160 --> 00:35:05,440
looking forward to

830
00:35:05,440 --> 00:35:08,240
any questions

831
00:35:14,800 --> 00:35:17,200
yes actually i already answered some

832
00:35:17,200 --> 00:35:19,359
questions during the presentation

833
00:35:19,359 --> 00:35:22,640
i mean this question are great

834
00:35:22,640 --> 00:35:25,359
so one last thing uh i think there is

835
00:35:25,359 --> 00:35:28,160
one comment not a really requesting from

836
00:35:28,160 --> 00:35:31,839
eric is so it seems very difficult

837
00:35:31,839 --> 00:35:34,640
to develop the defense which are

838
00:35:34,640 --> 00:35:35,760
universal

839
00:35:35,760 --> 00:35:39,200
um like uh work both

840
00:35:39,200 --> 00:35:42,720
uh so the the the final conclusion we

841
00:35:42,720 --> 00:35:43,359
have is

842
00:35:43,359 --> 00:35:46,000
actually the opposite way a lot of

843
00:35:46,000 --> 00:35:47,200
attack

844
00:35:47,200 --> 00:35:49,040
with the universally working on

845
00:35:49,040 --> 00:35:51,599
different ai models

846
00:35:51,599 --> 00:35:55,359
but the defense seems quite ad hoc

847
00:35:55,359 --> 00:35:57,760
so there are two very interesting

848
00:35:57,760 --> 00:35:59,440
research directions

849
00:35:59,440 --> 00:36:01,839
here beyond the developing of the

850
00:36:01,839 --> 00:36:03,119
virtual example

851
00:36:03,119 --> 00:36:05,839
one is how we can mathematically

852
00:36:05,839 --> 00:36:07,599
understand

853
00:36:07,599 --> 00:36:10,000
that why this attack with the universal

854
00:36:10,000 --> 00:36:11,040
work

855
00:36:11,040 --> 00:36:13,920
right why this boundary will be similar

856
00:36:13,920 --> 00:36:14,480
second

857
00:36:14,480 --> 00:36:17,760
would be how we can combine all these

858
00:36:17,760 --> 00:36:19,920
other hawk defense together

859
00:36:19,920 --> 00:36:23,040
uh well i'm talking i do see a few

860
00:36:23,040 --> 00:36:23,760
question

861
00:36:23,760 --> 00:36:27,839
uh comments here so

862
00:36:27,839 --> 00:36:31,839
uh one one comment is

863
00:36:31,839 --> 00:36:35,760
uh how can we look into the

864
00:36:35,760 --> 00:36:38,800
triple wise for

865
00:36:38,800 --> 00:36:41,119
this kind of model extraction attack it

866
00:36:41,119 --> 00:36:42,560
is our work

867
00:36:42,560 --> 00:36:46,320
uh in fact we are a bit concerned

868
00:36:46,320 --> 00:36:49,119
to perform this task because we know

869
00:36:49,119 --> 00:36:49,520
that

870
00:36:49,520 --> 00:36:51,599
the chip manufacturing they spend so

871
00:36:51,599 --> 00:36:54,320
much effort in developing ai chips

872
00:36:54,320 --> 00:36:56,720
they want to keep all the secure secret

873
00:36:56,720 --> 00:36:58,560
and we don't we have no desire

874
00:36:58,560 --> 00:37:04,160
to kind of like steal their ip

875
00:37:04,160 --> 00:37:06,960
but we still want to see whether

876
00:37:06,960 --> 00:37:08,720
leveraging this kind of like

877
00:37:08,720 --> 00:37:12,079
a model extraction attack along with all

878
00:37:12,079 --> 00:37:14,960
other for example side channel attack we

879
00:37:14,960 --> 00:37:15,760
can extract

880
00:37:15,760 --> 00:37:18,960
the internal of this we call it ai

881
00:37:18,960 --> 00:37:19,920
accelerators

882
00:37:19,920 --> 00:37:23,440
internal structure and our goal

883
00:37:23,440 --> 00:37:25,920
is as a researcher our goal is to make

884
00:37:25,920 --> 00:37:27,200
them more secure

885
00:37:27,200 --> 00:37:29,680
rather than just to hack them but if we

886
00:37:29,680 --> 00:37:31,200
hack something we will present

887
00:37:31,200 --> 00:37:37,599
in blackheads

888
00:37:37,599 --> 00:37:41,040
so where can we oh the white paper

889
00:37:41,040 --> 00:37:44,640
uh you should ask a blackhead because

890
00:37:44,640 --> 00:37:48,480
i did submit the white paper to

891
00:37:48,480 --> 00:37:49,920
blackhead

892
00:37:49,920 --> 00:37:53,119
but yes folk mentioned the

893
00:37:53,119 --> 00:37:55,839
ndss paper that paper actually including

894
00:37:55,839 --> 00:37:59,040
more technical details

895
00:38:02,839 --> 00:38:04,000
yes

896
00:38:04,000 --> 00:38:07,680
okay so i guess we need to wait for

897
00:38:07,680 --> 00:38:10,079
a couple of minutes to see if there are

898
00:38:10,079 --> 00:38:11,520
an other questions

899
00:38:11,520 --> 00:38:14,800
so okay so

900
00:38:14,800 --> 00:38:18,240
uh one thing uh uh i would encourage

901
00:38:18,240 --> 00:38:20,000
people to look into

902
00:38:20,000 --> 00:38:22,320
is trying to i think the other other

903
00:38:22,320 --> 00:38:24,079
talk i i glossed over

904
00:38:24,079 --> 00:38:26,960
other uh talks afternoon there is

905
00:38:26,960 --> 00:38:28,000
another talk

906
00:38:28,000 --> 00:38:30,160
uh mentioning that how we leverage the

907
00:38:30,160 --> 00:38:32,160
adverse example for the effect

908
00:38:32,160 --> 00:38:35,680
this is a very interesting area so

909
00:38:35,680 --> 00:38:38,160
uh we know that a diverse example is

910
00:38:38,160 --> 00:38:40,079
prevailingly available in all this

911
00:38:40,079 --> 00:38:42,640
design so now the question becomes how

912
00:38:42,640 --> 00:38:43,839
we can leverage it

913
00:38:43,839 --> 00:38:46,079
instead of attacking them to protect the

914
00:38:46,079 --> 00:38:47,680
system and also

915
00:38:47,680 --> 00:38:50,320
using this for uh like watermark

916
00:38:50,320 --> 00:38:51,760
fingerprinting

917
00:38:51,760 --> 00:38:53,599
uh i would say these are all very

918
00:38:53,599 --> 00:38:54,800
interesting area

919
00:38:54,800 --> 00:38:57,920
so overall the key motivation

920
00:38:57,920 --> 00:39:00,720
of our work is that we want to help

921
00:39:00,720 --> 00:39:01,119
people

922
00:39:01,119 --> 00:39:04,000
better understanding the security of ai

923
00:39:04,000 --> 00:39:06,400
before we widely use the ai

924
00:39:06,400 --> 00:39:09,520
and the ai has been applied in almost

925
00:39:09,520 --> 00:39:12,560
all different areas and the security i

926
00:39:12,560 --> 00:39:15,040
i know that the security as a hacker so

927
00:39:15,040 --> 00:39:16,800
we are so happy that

928
00:39:16,800 --> 00:39:18,880
people are using different ai so that we

929
00:39:18,880 --> 00:39:20,720
can hack in all different system

930
00:39:20,720 --> 00:39:23,680
uh like in 1990 or 2000 that we're

931
00:39:23,680 --> 00:39:26,480
hacking all the operating system

932
00:39:26,480 --> 00:39:28,560
but i hope that we will not go in the

933
00:39:28,560 --> 00:39:29,760
same old route

934
00:39:29,760 --> 00:39:32,079
that we develop a lot of system on

935
00:39:32,079 --> 00:39:33,359
secure system

936
00:39:33,359 --> 00:39:35,520
and we're hacking all of them to ask

937
00:39:35,520 --> 00:39:36,960
people to uh

938
00:39:36,960 --> 00:39:40,079
kind of fix those problems we hope that

939
00:39:40,079 --> 00:39:40,960
we can

940
00:39:40,960 --> 00:39:44,160
build a security insight

941
00:39:45,599 --> 00:39:48,240
okay so again thanks for attending my

942
00:39:48,240 --> 00:39:49,040
talk and

943
00:39:49,040 --> 00:39:50,960
please feel free to send me email if you

944
00:39:50,960 --> 00:39:53,280
have any questions

945
00:39:53,280 --> 00:39:55,839
my contact information is on the slides

946
00:39:55,839 --> 00:39:57,680
on the white paper and you can easily

947
00:39:57,680 --> 00:39:58,640
search my name and

948
00:39:58,640 --> 00:40:03,680
find my web page we do hire a recruiting

949
00:40:03,680 --> 00:40:05,920
postdoors phd students who are

950
00:40:05,920 --> 00:40:07,760
interested in this area

951
00:40:07,760 --> 00:40:11,839
okay okay thanks

