1
00:00:00,030 --> 00:00:04,020
welcome to cybersecurity risk assessment

2
00:00:01,920 --> 00:00:05,910
for safety critical systems here in

3
00:00:04,019 --> 00:00:08,550
South Pacific with your speaker dr. Lai

4
00:00:05,910 --> 00:00:10,349
vessels before we begin a few brief

5
00:00:08,550 --> 00:00:12,540
notes stop by the business hall located

6
00:00:10,349 --> 00:00:13,230
in Mandalay Bay Oceanside and shoreline

7
00:00:12,540 --> 00:00:14,969
ballrooms

8
00:00:13,230 --> 00:00:16,379
on level 2 during the day and for the

9
00:00:14,969 --> 00:00:18,960
Welcome Reception starting just after

10
00:00:16,379 --> 00:00:20,520
this talk at 5:30 p.m. the black had

11
00:00:18,960 --> 00:00:22,769
Arsenal's in the business hall in level

12
00:00:20,520 --> 00:00:25,189
2 and please join us for the pony Awards

13
00:00:22,769 --> 00:00:27,299
starting at 6:30 p.m. and Lagoon J Hale

14
00:00:25,189 --> 00:00:28,619
please put your phone on vibrate which

15
00:00:27,300 --> 00:00:30,090
makes it easier for the rest of us to

16
00:00:28,619 --> 00:00:32,219
ignore it ringing while you wait for

17
00:00:30,090 --> 00:00:39,360
your voicemail to pick it up and now dr.

18
00:00:32,219 --> 00:00:41,760
vessels Thank You Brandon

19
00:00:39,360 --> 00:00:42,989
welcome to the last talk of the day I

20
00:00:41,760 --> 00:00:45,930
hope you guys have been having a great

21
00:00:42,989 --> 00:00:53,160
time so far and learning a lot before I

22
00:00:45,930 --> 00:00:56,070
get started it's Lee actually not lie so

23
00:00:53,160 --> 00:00:57,989
a little bit about Who I am and and who

24
00:00:56,070 --> 00:01:01,140
we are and then the content of the

25
00:00:57,989 --> 00:01:03,300
presentations so like I said I'm Lee

26
00:01:01,140 --> 00:01:06,540
vessels I'm one of the cyber security

27
00:01:03,300 --> 00:01:09,360
architect at Honeywell I have been doing

28
00:01:06,540 --> 00:01:12,810
software systems and security for over

29
00:01:09,360 --> 00:01:15,930
30 years I acquired those experiences

30
00:01:12,810 --> 00:01:19,320
through a small number of companies such

31
00:01:15,930 --> 00:01:23,150
as Microsoft IBM Sandia National Labs

32
00:01:19,320 --> 00:01:25,679
General Dynamics and now with Honeywell

33
00:01:23,150 --> 00:01:28,320
probably the most noticeable thing about

34
00:01:25,680 --> 00:01:30,930
me and my work over the last thirty year

35
00:01:28,320 --> 00:01:33,869
has been the work that I've done with a

36
00:01:30,930 --> 00:01:35,369
blue screen of death yeah I'm one of the

37
00:01:33,869 --> 00:01:36,390
original author of the blue screen of

38
00:01:35,369 --> 00:01:40,079
death

39
00:01:36,390 --> 00:01:45,509
most recently the things I'm passionate

40
00:01:40,079 --> 00:01:48,899
about is the SAE key 32 standards for

41
00:01:45,509 --> 00:01:51,390
cyber physical systems security I'm the

42
00:01:48,899 --> 00:01:52,680
co-chair of the software shirin

43
00:01:51,390 --> 00:01:54,000
committee there if you guys are

44
00:01:52,680 --> 00:01:57,810
interested in that come and see me

45
00:01:54,000 --> 00:02:01,380
afterward my co-authors who cannot be

46
00:01:57,810 --> 00:02:03,780
here are dr. Daniel Johnston's and dr.

47
00:02:01,380 --> 00:02:06,479
Kenneth Hefner they have been doing

48
00:02:03,780 --> 00:02:09,989
cyber physical security for over 30

49
00:02:06,479 --> 00:02:11,310
years with Honeywell dr. Daniel Johnson

50
00:02:09,989 --> 00:02:14,160
co-chair

51
00:02:11,310 --> 00:02:16,340
the air worthiness security process

52
00:02:14,160 --> 00:02:18,840
which is currently being used now for

53
00:02:16,340 --> 00:02:21,870
certification of avionics systems and

54
00:02:18,840 --> 00:02:24,600
airplanes we at Honeywell work on

55
00:02:21,870 --> 00:02:27,090
development of advanced breakthrough

56
00:02:24,600 --> 00:02:28,980
technologies we worked on securing

57
00:02:27,090 --> 00:02:31,770
cyber-physical systems such as space

58
00:02:28,980 --> 00:02:36,299
system and we also do compliances for

59
00:02:31,770 --> 00:02:37,800
honeywell and for our customers the rest

60
00:02:36,300 --> 00:02:40,739
of the talk will go something like this

61
00:02:37,800 --> 00:02:44,100
I will give you guys a very high-level

62
00:02:40,739 --> 00:02:46,170
overview of the cybersecurity attacks

63
00:02:44,100 --> 00:02:49,470
for space system very high level and

64
00:02:46,170 --> 00:02:53,369
then I'll talk about the motivation

65
00:02:49,470 --> 00:02:55,560
behind the artwork then I'll focus most

66
00:02:53,370 --> 00:02:57,420
of the presentation on our work then

67
00:02:55,560 --> 00:03:00,780
I'll wrap up with what we're doing next

68
00:02:57,420 --> 00:03:07,700
and then I'll give you guys to take away

69
00:03:00,780 --> 00:03:11,730
to take with you that sound good ok so

70
00:03:07,700 --> 00:03:13,200
the major attack on space system to

71
00:03:11,730 --> 00:03:15,268
start out with I want everybody to know

72
00:03:13,200 --> 00:03:17,130
that the information I'm presented here

73
00:03:15,269 --> 00:03:19,290
or available in the public they're not

74
00:03:17,130 --> 00:03:25,140
sensitive to Honeywell or to our

75
00:03:19,290 --> 00:03:27,780
customers let's start in the year 2014

76
00:03:25,140 --> 00:03:30,899
when computer world reported that

77
00:03:27,780 --> 00:03:35,130
satellite communication system is full

78
00:03:30,900 --> 00:03:37,799
of security flaws they reported a

79
00:03:35,130 --> 00:03:40,829
research tons on 10 different systems

80
00:03:37,799 --> 00:03:44,609
common system and they found security

81
00:03:40,829 --> 00:03:49,100
flaws such as multiple backdoors hard

82
00:03:44,609 --> 00:03:52,320
code credentials really weak protocol or

83
00:03:49,100 --> 00:03:55,799
mostly undocumented protocol they have

84
00:03:52,320 --> 00:03:58,100
also found week's encryption algorithm

85
00:03:55,799 --> 00:04:00,630
or no encryption algorithm whatsoever

86
00:03:58,100 --> 00:04:04,980
one of the things you can do with these

87
00:04:00,630 --> 00:04:07,079
flaws is to remotely dial into the Salwa

88
00:04:04,980 --> 00:04:09,530
communication system without any

89
00:04:07,079 --> 00:04:13,950
authentication whatsoever

90
00:04:09,530 --> 00:04:18,390
thus fast-forward a little bit to the

91
00:04:13,950 --> 00:04:21,690
year 2018 which is last year future

92
00:04:18,390 --> 00:04:25,340
society actually reported the impacts of

93
00:04:21,690 --> 00:04:28,160
the security flaws to include such

94
00:04:25,340 --> 00:04:32,880
pinpointing military units locations

95
00:04:28,160 --> 00:04:35,730
being able to disrupt onboard satellite

96
00:04:32,880 --> 00:04:39,420
communication system being able to

97
00:04:35,730 --> 00:04:43,340
remotely disrupt in-flight Wi-Fi system

98
00:04:39,420 --> 00:04:47,430
as well as being able to provoke

99
00:04:43,340 --> 00:04:51,919
malfunction critical navigational system

100
00:04:47,430 --> 00:04:51,920
and to some extent affects human health

101
00:04:53,360 --> 00:05:00,630
then just recently security a cyber

102
00:04:57,510 --> 00:05:03,030
security insider Ashley urged companies

103
00:05:00,630 --> 00:05:06,480
that supply solid services and equipment

104
00:05:03,030 --> 00:05:10,429
to be on high alert for potential cyber

105
00:05:06,480 --> 00:05:13,560
attack in fact in June of this year

106
00:05:10,430 --> 00:05:15,240
there has been an attack on JBL system

107
00:05:13,560 --> 00:05:17,490
what's interesting about that attack

108
00:05:15,240 --> 00:05:21,240
actually is the fact that they're able

109
00:05:17,490 --> 00:05:24,660
to moved into the Deep Space Network so

110
00:05:21,240 --> 00:05:25,980
as you can see this is a real problems

111
00:05:24,660 --> 00:05:27,920
for us we're not talking about

112
00:05:25,980 --> 00:05:30,510
enterprise where you could just reboot

113
00:05:27,920 --> 00:05:32,460
this is a problem where lives are at

114
00:05:30,510 --> 00:05:35,060
state infrastructure that are critical

115
00:05:32,460 --> 00:05:38,280
to us or at state so how do we address

116
00:05:35,060 --> 00:05:41,760
this pandemic problem how do we begin to

117
00:05:38,280 --> 00:05:44,489
look at that to quote our keynote

118
00:05:41,760 --> 00:05:47,460
speaker this morning he said we should

119
00:05:44,490 --> 00:05:50,670
always start with a yes right so we can

120
00:05:47,460 --> 00:05:53,070
fix this problem so what do we do he

121
00:05:50,670 --> 00:05:55,770
said that we should start with

122
00:05:53,070 --> 00:05:57,390
understanding the job at hand but how do

123
00:05:55,770 --> 00:06:01,020
we begin to understand the job at hand

124
00:05:57,390 --> 00:06:04,650
the such mass massive job at him so

125
00:06:01,020 --> 00:06:07,169
let's look at what urban land the father

126
00:06:04,650 --> 00:06:10,380
of sound leg reconnaissance had to say

127
00:06:07,170 --> 00:06:13,680
about this now he said we can't fix all

128
00:06:10,380 --> 00:06:16,469
problems what we can do is identify them

129
00:06:13,680 --> 00:06:18,690
and focus our resources appropriately so

130
00:06:16,470 --> 00:06:21,600
one way and Honeywell that we can

131
00:06:18,690 --> 00:06:24,270
identify the problem is to look at

132
00:06:21,600 --> 00:06:28,050
assessing the cybersecurity risks of the

133
00:06:24,270 --> 00:06:31,169
systems so we began at the time by

134
00:06:28,050 --> 00:06:34,380
looking at what can be used to assess

135
00:06:31,170 --> 00:06:35,950
cybersecurity risks for space systems

136
00:06:34,380 --> 00:06:39,760
for critical systems

137
00:06:35,950 --> 00:06:44,110
what we found is that there's a strong

138
00:06:39,760 --> 00:06:47,320
focus on threat Molly mostly for the

139
00:06:44,110 --> 00:06:49,810
enterprise level we found that of these

140
00:06:47,320 --> 00:06:52,599
modeling tools techniques tips and

141
00:06:49,810 --> 00:06:56,230
solutions they require deep deep

142
00:06:52,600 --> 00:06:59,380
knowledge of security mathematics and

143
00:06:56,230 --> 00:07:02,170
the targeted system now this may sound

144
00:06:59,380 --> 00:07:04,150
easy but in reality is really hard to

145
00:07:02,170 --> 00:07:06,580
get all that skill set in an

146
00:07:04,150 --> 00:07:11,679
organization or in one person that's

147
00:07:06,580 --> 00:07:14,800
mulling more over these techniques are

148
00:07:11,680 --> 00:07:18,760
very manually intense require a lot of

149
00:07:14,800 --> 00:07:21,310
time spent 2,000 hour is not unheard of

150
00:07:18,760 --> 00:07:23,530
for a typical system which is a man year

151
00:07:21,310 --> 00:07:25,330
now it takes you a man year to assess

152
00:07:23,530 --> 00:07:28,900
the cybersecurity risks of a system

153
00:07:25,330 --> 00:07:30,760
that's not scalable right additionally

154
00:07:28,900 --> 00:07:33,390
they're introduced a lot of air into the

155
00:07:30,760 --> 00:07:36,159
system so it's hard to make strategic

156
00:07:33,390 --> 00:07:37,960
decisions when a system that you're

157
00:07:36,160 --> 00:07:40,060
trying to model and the report that

158
00:07:37,960 --> 00:07:44,229
you're trying report has built-in errors

159
00:07:40,060 --> 00:07:47,370
in it so at the time we couldn't find

160
00:07:44,230 --> 00:07:51,550
any framework or solutions that actually

161
00:07:47,370 --> 00:07:53,860
helped us assess the risk of cyber

162
00:07:51,550 --> 00:07:57,820
physical systems such as space systems

163
00:07:53,860 --> 00:07:59,980
that is easy to use and repeatable and

164
00:07:57,820 --> 00:08:04,540
have a method that you can go back to do

165
00:07:59,980 --> 00:08:07,690
a what-if study so under the guidance of

166
00:08:04,540 --> 00:08:11,020
dr. Daniel Johnson our co-author we

167
00:08:07,690 --> 00:08:13,840
started a framework at Honeywell this

168
00:08:11,020 --> 00:08:15,490
framework was actually the basis for the

169
00:08:13,840 --> 00:08:16,929
two standard I mentioned that is

170
00:08:15,490 --> 00:08:21,940
currently being used for certification

171
00:08:16,930 --> 00:08:26,200
by FAA this standard has this framework

172
00:08:21,940 --> 00:08:28,510
has five steps to it and it is not a

173
00:08:26,200 --> 00:08:30,789
waterfall process is actually an

174
00:08:28,510 --> 00:08:33,189
iterative process that you can go back

175
00:08:30,790 --> 00:08:35,140
and do analysis and do what you've

176
00:08:33,190 --> 00:08:37,300
studies and actually move forward and

177
00:08:35,140 --> 00:08:41,970
backward the rest of my presentation

178
00:08:37,299 --> 00:08:41,969
will cover these five steps

179
00:08:43,539 --> 00:08:49,060
so the first step is to create your

180
00:08:46,690 --> 00:08:52,180
security architecture that should be

181
00:08:49,060 --> 00:08:54,699
simple right in fact this is the hardest

182
00:08:52,180 --> 00:08:56,979
step and probably take the most time and

183
00:08:54,700 --> 00:09:00,730
if you do this right the rest of the

184
00:08:56,980 --> 00:09:03,250
step comes easier so how do you create a

185
00:09:00,730 --> 00:09:06,870
security architecture is there a formula

186
00:09:03,250 --> 00:09:09,310
to doing that here are some basic tips

187
00:09:06,870 --> 00:09:12,460
first you define your security

188
00:09:09,310 --> 00:09:15,130
perimeters a perimeter is a notional

189
00:09:12,460 --> 00:09:18,550
boundary that's actually separate your

190
00:09:15,130 --> 00:09:22,090
security context it actually encompass

191
00:09:18,550 --> 00:09:24,729
your security related I add assets the

192
00:09:22,090 --> 00:09:26,410
assets you wanted to protect so you've

193
00:09:24,730 --> 00:09:29,740
probably been thinking why can't I just

194
00:09:26,410 --> 00:09:32,069
draw a box around my system well a lot

195
00:09:29,740 --> 00:09:34,840
of time your system doesn't contain all

196
00:09:32,070 --> 00:09:36,670
security relevant information or your

197
00:09:34,840 --> 00:09:39,100
asset right what you want to do is focus

198
00:09:36,670 --> 00:09:42,810
on the security critical assets and

199
00:09:39,100 --> 00:09:45,010
actually chow a perimeter around them

200
00:09:42,810 --> 00:09:47,170
the second thing you need to do is

201
00:09:45,010 --> 00:09:49,960
identify those assets that you're trying

202
00:09:47,170 --> 00:09:52,439
to protect or the assets are related to

203
00:09:49,960 --> 00:09:55,210
the assets that you're trying to protect

204
00:09:52,440 --> 00:09:58,630
the third step is to actually identify

205
00:09:55,210 --> 00:10:01,960
the external system or user two-years

206
00:09:58,630 --> 00:10:04,060
your targeted system and then identify

207
00:10:01,960 --> 00:10:05,680
all the connection that exists now it's

208
00:10:04,060 --> 00:10:08,050
very important that you identify the

209
00:10:05,680 --> 00:10:10,930
connections if the connection does not

210
00:10:08,050 --> 00:10:14,140
exist is very important not to connect

211
00:10:10,930 --> 00:10:17,109
them ok so these are the basic steps to

212
00:10:14,140 --> 00:10:18,939
creating the security architecture now

213
00:10:17,110 --> 00:10:21,820
getting the security architecture right

214
00:10:18,940 --> 00:10:25,180
is critical to all the other 4 steps to

215
00:10:21,820 --> 00:10:28,270
come now you probably think this is

216
00:10:25,180 --> 00:10:30,479
going to take a lot of time it does but

217
00:10:28,270 --> 00:10:33,310
the framework encourages to move forward

218
00:10:30,480 --> 00:10:35,670
get some basic information in place and

219
00:10:33,310 --> 00:10:39,430
come back when you have more data and

220
00:10:35,670 --> 00:10:41,380
the whole framework will preserve the

221
00:10:39,430 --> 00:10:46,349
data that you work on so that you can go

222
00:10:41,380 --> 00:10:50,290
back and forth so here's an example of

223
00:10:46,350 --> 00:10:53,020
and the security architecture this is a

224
00:10:50,290 --> 00:10:55,390
space consolation this fictitious

225
00:10:53,020 --> 00:10:56,529
nothing here is real we've just want

226
00:10:55,390 --> 00:10:58,899
everybody to know that

227
00:10:56,529 --> 00:11:01,420
relationship is not real anything that

228
00:10:58,899 --> 00:11:04,120
resemble reality is not it's not

229
00:11:01,420 --> 00:11:06,490
intentional for the sake of this

230
00:11:04,120 --> 00:11:09,699
presentation I would just focus on

231
00:11:06,490 --> 00:11:12,189
Grayson and model the security

232
00:11:09,699 --> 00:11:14,680
architecture for Grayson and just so

233
00:11:12,189 --> 00:11:18,248
that we do not expose any sensitive data

234
00:11:14,680 --> 00:11:21,779
I will pretend that Grayson has a

235
00:11:18,249 --> 00:11:26,019
netbook three mission asset to protect

236
00:11:21,779 --> 00:11:29,499
to protection solution in place that is

237
00:11:26,019 --> 00:11:32,620
the network's security and the spectrum

238
00:11:29,499 --> 00:11:38,980
security solution and a couple of

239
00:11:32,620 --> 00:11:40,809
attackers so once you finish your

240
00:11:38,980 --> 00:11:42,490
architecture the second step in the

241
00:11:40,809 --> 00:11:46,420
framework is to create what we call

242
00:11:42,490 --> 00:11:49,209
scoring of those attributes well the way

243
00:11:46,420 --> 00:11:52,300
to do that is to first you identify your

244
00:11:49,209 --> 00:11:55,209
attackers and we call them attackers but

245
00:11:52,300 --> 00:11:57,370
there could be that guy or they could be

246
00:11:55,209 --> 00:11:59,559
a good guy okay so we just called them

247
00:11:57,370 --> 00:12:01,660
attackers so once we identified them

248
00:11:59,559 --> 00:12:03,879
they are usually the systems and user

249
00:12:01,660 --> 00:12:06,730
outside of your security perimeter in

250
00:12:03,879 --> 00:12:09,660
this case we got to in this example the

251
00:12:06,730 --> 00:12:12,550
spectrum spoof and the general attackers

252
00:12:09,660 --> 00:12:15,189
so we labeled them you know you know

253
00:12:12,550 --> 00:12:16,839
framework we label all packet with an a

254
00:12:15,189 --> 00:12:19,059
dot and whatever names you want to give

255
00:12:16,839 --> 00:12:22,389
it and then we assigned it an occurrence

256
00:12:19,059 --> 00:12:24,969
value of one to nine okay one being the

257
00:12:22,389 --> 00:12:28,329
most trusted nine being the least

258
00:12:24,970 --> 00:12:31,059
trusted an example of a trusted attacker

259
00:12:28,329 --> 00:12:33,279
would be somebody like a pilot okay

260
00:12:31,059 --> 00:12:36,459
who has access to the system but he's

261
00:12:33,279 --> 00:12:40,000
trusted we can count on him an example

262
00:12:36,459 --> 00:12:41,829
of an untrusted attacker would be an

263
00:12:40,000 --> 00:12:45,519
Internet or if you have to avionics

264
00:12:41,829 --> 00:12:47,739
system attached to the Internet the

265
00:12:45,519 --> 00:12:50,170
second thing you do is you define your

266
00:12:47,740 --> 00:12:52,420
vulnerabilities of your system the

267
00:12:50,170 --> 00:12:54,849
easiest way to define your vulnerability

268
00:12:52,420 --> 00:12:58,689
is to identify your protections you have

269
00:12:54,850 --> 00:13:01,749
in place the protection has some level

270
00:12:58,689 --> 00:13:03,969
of vulnerability built-in so in our case

271
00:13:01,749 --> 00:13:05,889
we got two so we named them in our

272
00:13:03,970 --> 00:13:07,870
framework it starts with F and whatever

273
00:13:05,889 --> 00:13:08,990
names you want it and we assign it some

274
00:13:07,870 --> 00:13:13,820
values but

275
00:13:08,990 --> 00:13:16,430
1 & 9 1 being the most robust 9 being

276
00:13:13,820 --> 00:13:18,320
the least robust now you probably asked

277
00:13:16,430 --> 00:13:20,390
the question of where these numbers come

278
00:13:18,320 --> 00:13:22,780
from how do I know what numbers to

279
00:13:20,390 --> 00:13:26,689
assign at this point in our framework

280
00:13:22,780 --> 00:13:29,540
that is up to the architect that is

281
00:13:26,690 --> 00:13:31,910
following the system we are working with

282
00:13:29,540 --> 00:13:34,760
as they eg 32 to come up with standards

283
00:13:31,910 --> 00:13:38,360
so each one of these number stands for

284
00:13:34,760 --> 00:13:39,980
something that's meaningful the next

285
00:13:38,360 --> 00:13:42,110
thing in our process is to find got

286
00:13:39,980 --> 00:13:43,930
protection in place and we talked about

287
00:13:42,110 --> 00:13:47,240
those beings there are two of them and

288
00:13:43,930 --> 00:13:48,859
we our framework actually I'll require

289
00:13:47,240 --> 00:13:51,590
you to name those that start with an O

290
00:13:48,860 --> 00:13:53,990
and then we have to associate it with

291
00:13:51,590 --> 00:13:56,650
the failure that we just identify or the

292
00:13:53,990 --> 00:13:59,620
vulnerability that we identified earlier

293
00:13:56,650 --> 00:14:02,750
the next thing is to identify your

294
00:13:59,620 --> 00:14:05,810
attacks s your attack vectors which is

295
00:14:02,750 --> 00:14:08,840
access into your phone abilities or

296
00:14:05,810 --> 00:14:12,170
accessing to detect conditions in this

297
00:14:08,840 --> 00:14:14,750
situation we have two the path that gets

298
00:14:12,170 --> 00:14:17,329
into the grace and network so we name

299
00:14:14,750 --> 00:14:19,670
those two paths with an ape we dot

300
00:14:17,330 --> 00:14:24,830
something and we associate that with the

301
00:14:19,670 --> 00:14:27,199
protection that's in the system the next

302
00:14:24,830 --> 00:14:29,990
thing to do is to actually define your

303
00:14:27,200 --> 00:14:32,240
threat conditions the threat conditions

304
00:14:29,990 --> 00:14:35,330
is a condition that will cause a failure

305
00:14:32,240 --> 00:14:37,490
of your assets and in this situation we

306
00:14:35,330 --> 00:14:40,370
have two threat condition coming from

307
00:14:37,490 --> 00:14:42,230
that two vectors so adult threat

308
00:14:40,370 --> 00:14:44,690
conditions are named with T dot

309
00:14:42,230 --> 00:14:47,510
something and we associate that with the

310
00:14:44,690 --> 00:14:49,400
access vector that comes from the last

311
00:14:47,510 --> 00:14:53,060
thing that we needed to associate and

312
00:14:49,400 --> 00:14:55,939
score is the identity of the asset so we

313
00:14:53,060 --> 00:14:59,569
named the the assets in place all this

314
00:14:55,940 --> 00:15:02,420
information along with the security

315
00:14:59,570 --> 00:15:07,750
architecture are used as inputs into the

316
00:15:02,420 --> 00:15:07,750
next step which is the mauling itself

317
00:15:09,880 --> 00:15:15,439
so in step three we take the security

318
00:15:12,680 --> 00:15:18,079
architecture your scores that you come

319
00:15:15,440 --> 00:15:20,720
up with and the relationship we feed

320
00:15:18,080 --> 00:15:23,600
that into our modeling engines and we

321
00:15:20,720 --> 00:15:25,520
generate what we call cut sets the

322
00:15:23,600 --> 00:15:27,980
modeling engines consist of two

323
00:15:25,520 --> 00:15:29,960
different models and those information

324
00:15:27,980 --> 00:15:32,570
are available for you to do what if

325
00:15:29,960 --> 00:15:35,120
studies the first model is the security

326
00:15:32,570 --> 00:15:37,040
ontology model that shows relationship

327
00:15:35,120 --> 00:15:40,580
between all your security elements like

328
00:15:37,040 --> 00:15:43,160
what vectors is access by which threat

329
00:15:40,580 --> 00:15:44,600
conditions and then the second one our

330
00:15:43,160 --> 00:15:46,760
threat modeling that show you the

331
00:15:44,600 --> 00:15:52,810
probability of an attack for a

332
00:15:46,760 --> 00:15:55,460
particular cut set so cut sets is a

333
00:15:52,810 --> 00:15:58,160
collections of your vulnerabilities and

334
00:15:55,460 --> 00:16:00,170
your attackers that would cause the

335
00:15:58,160 --> 00:16:02,120
threat condition to occur so you can

336
00:16:00,170 --> 00:16:04,780
think of cut set us past all the

337
00:16:02,120 --> 00:16:08,960
possible paths into your targeted system

338
00:16:04,780 --> 00:16:12,740
we take those cut sets we feed it into

339
00:16:08,960 --> 00:16:14,900
our calculation engine and we create

340
00:16:12,740 --> 00:16:17,420
what we call threat scenario threat

341
00:16:14,900 --> 00:16:20,930
scenarios is a situation that will cost

342
00:16:17,420 --> 00:16:24,140
your assets to fail the calculation

343
00:16:20,930 --> 00:16:26,359
engine will create various numbers that

344
00:16:24,140 --> 00:16:31,280
is critical to the security risk

345
00:16:26,360 --> 00:16:34,400
assessments so these numbers are used in

346
00:16:31,280 --> 00:16:36,560
the final step which we looked up in the

347
00:16:34,400 --> 00:16:39,500
acceptable matrix to determine whether

348
00:16:36,560 --> 00:16:43,729
those worst level probabilities and

349
00:16:39,500 --> 00:16:45,470
severity are acceptable or not so if

350
00:16:43,730 --> 00:16:48,380
your number comes out as a negative

351
00:16:45,470 --> 00:16:51,650
number then that's a low risk to your

352
00:16:48,380 --> 00:16:54,890
system and that's acceptable if your

353
00:16:51,650 --> 00:16:58,250
number is zero then it's a medium risk

354
00:16:54,890 --> 00:17:01,870
small changes need to be made but not

355
00:16:58,250 --> 00:17:05,209
huge changes if the numbers is positive

356
00:17:01,870 --> 00:17:08,000
that means it's a hybrid situation and

357
00:17:05,209 --> 00:17:10,809
you need to do some fixing the other

358
00:17:08,000 --> 00:17:13,480
thing that it does give you an idea

359
00:17:10,809 --> 00:17:16,898
an indicator is that if it's a positive

360
00:17:13,480 --> 00:17:19,209
number let's say 2 then you can look at

361
00:17:16,898 --> 00:17:20,378
the criticality in your assets and say

362
00:17:19,209 --> 00:17:23,079
is my asset

363
00:17:20,378 --> 00:17:26,168
critical that if it does get attacked

364
00:17:23,079 --> 00:17:31,809
you know am I in a situation that I'm

365
00:17:26,169 --> 00:17:34,149
causing damages to to human health so if

366
00:17:31,809 --> 00:17:35,830
your asset is a maintenance system for

367
00:17:34,149 --> 00:17:38,649
example and it never touched the

368
00:17:35,830 --> 00:17:41,230
avionics system to fly the flap though

369
00:17:38,649 --> 00:17:43,119
of the brakes then you may make the

370
00:17:41,230 --> 00:17:46,509
decision that was a lower priority for

371
00:17:43,119 --> 00:17:49,240
me to fix if your assets turn out to be

372
00:17:46,509 --> 00:17:51,129
a critical asset in your space system

373
00:17:49,240 --> 00:17:53,830
then that will give you some alarm that

374
00:17:51,129 --> 00:17:57,969
that needs to be higher priority on the

375
00:17:53,830 --> 00:18:00,539
other extreme if your risk level is

376
00:17:57,970 --> 00:18:03,610
really low let's say minus a hundred

377
00:18:00,539 --> 00:18:07,240
then you can ask the question do I have

378
00:18:03,610 --> 00:18:08,918
too much protection in place in theory

379
00:18:07,240 --> 00:18:12,730
there's no such thing as too much

380
00:18:08,919 --> 00:18:14,710
protection but keep in mind that every

381
00:18:12,730 --> 00:18:17,499
time you add security solution into a

382
00:18:14,710 --> 00:18:19,840
system it affects the system attributes

383
00:18:17,499 --> 00:18:21,940
like performance right it also affects

384
00:18:19,840 --> 00:18:24,279
the bottom dollars as well as

385
00:18:21,940 --> 00:18:26,259
maintenance that system so is it

386
00:18:24,279 --> 00:18:28,509
worthwhile to remove some of those

387
00:18:26,259 --> 00:18:31,450
security protections so that you will

388
00:18:28,509 --> 00:18:33,399
have more of an agile system in place so

389
00:18:31,450 --> 00:18:35,559
all that information can be used and

390
00:18:33,399 --> 00:18:38,139
that's just said this morning in the

391
00:18:35,559 --> 00:18:40,269
keynote speaker to communicate to

392
00:18:38,139 --> 00:18:41,860
leadership to put the right priority in

393
00:18:40,269 --> 00:18:46,210
the right place to get the right problem

394
00:18:41,860 --> 00:18:49,299
fixed so that's it that my five steps

395
00:18:46,210 --> 00:18:51,399
what are we working on next we're trying

396
00:18:49,299 --> 00:18:53,740
to finish the automation so that you

397
00:18:51,399 --> 00:18:55,689
have an end-to-end automations of our

398
00:18:53,740 --> 00:18:59,259
frameworks so that you can start with

399
00:18:55,690 --> 00:19:01,629
the architecture model and in with your

400
00:18:59,259 --> 00:19:05,320
risk level and you can go back and 400

401
00:19:01,629 --> 00:19:06,639
data stay persistent the other things

402
00:19:05,320 --> 00:19:09,428
we're doing and I'm very passionate

403
00:19:06,639 --> 00:19:11,379
about is to actually work with the

404
00:19:09,429 --> 00:19:14,499
standard committees to define standards

405
00:19:11,379 --> 00:19:16,629
for how to assess vulnerabilities for

406
00:19:14,499 --> 00:19:19,149
cyber-physical system not in the price

407
00:19:16,629 --> 00:19:24,299
system but cyber fiscal system as well

408
00:19:19,149 --> 00:19:24,299
as testing attackers in the system

409
00:19:24,869 --> 00:19:30,970
so once we finish the automation we will

410
00:19:28,749 --> 00:19:35,169
have a toolset that security

411
00:19:30,970 --> 00:19:38,440
professional can use to assess risk and

412
00:19:35,169 --> 00:19:40,019
produce a rapidly result that is

413
00:19:38,440 --> 00:19:44,679
repeatable

414
00:19:40,019 --> 00:19:47,019
in summary cyberattack is real it's here

415
00:19:44,679 --> 00:19:51,580
it's attacking as you can see with the

416
00:19:47,019 --> 00:19:54,970
JPL problem space system one way to

417
00:19:51,580 --> 00:19:57,820
actually to begin to remediate some of

418
00:19:54,970 --> 00:20:00,729
these issue we have is to know what

419
00:19:57,820 --> 00:20:03,639
we're facing and to have priorities on

420
00:20:00,729 --> 00:20:05,379
what we need to fix Honeywell has could

421
00:20:03,639 --> 00:20:07,748
do us a repeatable framework that is

422
00:20:05,379 --> 00:20:11,559
standardized and it's based on on the

423
00:20:07,749 --> 00:20:13,720
standard process for assessing risk we

424
00:20:11,559 --> 00:20:16,269
also have a paper at the end of this

425
00:20:13,720 --> 00:20:20,799
presentation feel free to read it and

426
00:20:16,269 --> 00:20:23,859
give me your thoughts here are my

427
00:20:20,799 --> 00:20:24,279
information I look forward to hearing

428
00:20:23,859 --> 00:20:26,289
from you

429
00:20:24,279 --> 00:20:29,289
and getting your feedback and

430
00:20:26,289 --> 00:20:32,889
collaborating with you on all the works

431
00:20:29,289 --> 00:20:34,658
that we have done so far I will take

432
00:20:32,889 --> 00:20:38,738
some question if you have some question

433
00:20:34,659 --> 00:20:41,409
there's mics up there but I will also be

434
00:20:38,739 --> 00:20:47,440
in the Rapp room for some of the more

435
00:20:41,409 --> 00:20:55,120
critical questions that's it

436
00:20:47,440 --> 00:21:01,160
[Applause]

437
00:20:55,120 --> 00:21:07,659
okay good can you I can't hear you can

438
00:21:01,160 --> 00:21:07,660
use the mic okay huh

439
00:21:11,120 --> 00:21:16,399
okay ah since I beat him to Mike let me

440
00:21:14,810 --> 00:21:20,659
ask the question okay

441
00:21:16,400 --> 00:21:23,750
I have actually two questions the way

442
00:21:20,660 --> 00:21:26,690
you are describing the system to me it

443
00:21:23,750 --> 00:21:29,630
looks like a regular cyber system rather

444
00:21:26,690 --> 00:21:31,220
a cyber physical system because normally

445
00:21:29,630 --> 00:21:33,740
cyber physical systems they controlled

446
00:21:31,220 --> 00:21:36,020
some physical part of the world so I'm

447
00:21:33,740 --> 00:21:39,500
not quite sure where is the physical

448
00:21:36,020 --> 00:21:44,650
control comes from okay my second

449
00:21:39,500 --> 00:21:51,080
question is how are you different from

450
00:21:44,650 --> 00:21:53,210
NIST risk methodology make it because

451
00:21:51,080 --> 00:21:57,949
this methodology also starts with assets

452
00:21:53,210 --> 00:22:02,330
and what one of them yeah and what are

453
00:21:57,950 --> 00:22:06,710
the controls you already have and then

454
00:22:02,330 --> 00:22:09,620
you explore what is the probability some

455
00:22:06,710 --> 00:22:12,080
threat actor may exploit the

456
00:22:09,620 --> 00:22:13,909
vulnerability and so on and so forth so

457
00:22:12,080 --> 00:22:16,159
anyway I'm trying to get a better feel

458
00:22:13,910 --> 00:22:19,940
for how your methodology is different

459
00:22:16,160 --> 00:22:22,100
from the mister methodology and the

460
00:22:19,940 --> 00:22:24,440
second thing is what is so fiber

461
00:22:22,100 --> 00:22:27,199
physical about your system it seems to

462
00:22:24,440 --> 00:22:29,990
me very cyber anyway if you can comment

463
00:22:27,200 --> 00:22:32,510
on both or be good and so I want to make

464
00:22:29,990 --> 00:22:35,210
sure the the difference that our

465
00:22:32,510 --> 00:22:42,530
framework has from NIST is that we

466
00:22:35,210 --> 00:22:44,360
actually assess risk based on a cyber

467
00:22:42,530 --> 00:22:49,690
physical system which is a system that

468
00:22:44,360 --> 00:22:54,199
is a combinations of physical network

469
00:22:49,690 --> 00:22:58,660
ciphers and you know analogs right we

470
00:22:54,200 --> 00:23:03,020
are focusing more on scoring that that

471
00:22:58,660 --> 00:23:05,150
risk closer to real-time system than it

472
00:23:03,020 --> 00:23:08,540
is for NIST where its core medium high

473
00:23:05,150 --> 00:23:11,320
or low you know we don't have that that

474
00:23:08,540 --> 00:23:14,720
larger granularity we need to score a

475
00:23:11,320 --> 00:23:18,050
smaller granularity between between the

476
00:23:14,720 --> 00:23:20,720
probabilities this doesn't do that so

477
00:23:18,050 --> 00:23:23,530
this gives you the ability to tomorrow

478
00:23:20,720 --> 00:23:23,530
closer to real time

479
00:23:24,700 --> 00:23:29,630
man my question is similar when would

480
00:23:27,590 --> 00:23:32,000
you recommend the framework you proposed

481
00:23:29,630 --> 00:23:34,640
now as opposed to us like the NIST

482
00:23:32,000 --> 00:23:37,910
framework or other methodologies I would

483
00:23:34,640 --> 00:23:41,030
use this for more of an enterprise type

484
00:23:37,910 --> 00:23:44,330
systems I would use this for more of a

485
00:23:41,030 --> 00:23:47,740
safety type system so I answer your

486
00:23:44,330 --> 00:23:51,649
question yeah just also has an example

487
00:23:47,740 --> 00:23:56,050
where they apply it to infusion pump

488
00:23:51,650 --> 00:23:59,690
which is the real cyber-physical system

489
00:23:56,050 --> 00:24:01,850
you think that this has an example so

490
00:23:59,690 --> 00:24:03,320
I'm not familiar with that I can take a

491
00:24:01,850 --> 00:24:06,490
look at that and get back to you on that

492
00:24:03,320 --> 00:24:06,490
I haven't seen it

493
00:24:13,930 --> 00:24:19,540
my question is a little bit similar it's

494
00:24:16,120 --> 00:24:21,159
all based off mist I currently do risk

495
00:24:19,540 --> 00:24:23,500
assessment for the Department of Defense

496
00:24:21,160 --> 00:24:26,770
and we have a number of overlays that

497
00:24:23,500 --> 00:24:28,420
are involved with the NIST 853 and as

498
00:24:26,770 --> 00:24:30,850
this develops because this is the next

499
00:24:28,420 --> 00:24:33,930
big thing do you foresee anything

500
00:24:30,850 --> 00:24:37,959
another overlay being applied into the

501
00:24:33,930 --> 00:24:40,240
this risk assessment and would this be

502
00:24:37,960 --> 00:24:42,910
able to be utilized and some sort of

503
00:24:40,240 --> 00:24:47,290
enterprise solutions such as a mass or

504
00:24:42,910 --> 00:24:50,260
exacta so you're saying that you woke on

505
00:24:47,290 --> 00:24:52,210
oracle is somebody said can you repeat

506
00:24:50,260 --> 00:24:54,850
that sorry do you say to work on oracle

507
00:24:52,210 --> 00:24:56,679
as you were assessing risk on a worker

508
00:24:54,850 --> 00:25:01,449
is that what you said no okay

509
00:24:56,679 --> 00:25:06,240
say that again I didn't hear you the the

510
00:25:01,450 --> 00:25:10,090
the NIST frameworks the 853 the overlays

511
00:25:06,240 --> 00:25:14,260
do you foresee this being a new overlay

512
00:25:10,090 --> 00:25:18,790
for space systems I don't and the reason

513
00:25:14,260 --> 00:25:22,090
being is this is more of a tools that

514
00:25:18,790 --> 00:25:25,600
you can use for safety critical system

515
00:25:22,090 --> 00:25:27,159
not so much as an overlay for the RMF

516
00:25:25,600 --> 00:25:29,139
that make sense

517
00:25:27,160 --> 00:25:32,350
you can use this throughout your life

518
00:25:29,140 --> 00:25:35,110
cycle as you assess your your assurance

519
00:25:32,350 --> 00:25:39,070
level into your development of your

520
00:25:35,110 --> 00:25:42,100
system where RMS is tailored toward more

521
00:25:39,070 --> 00:25:45,939
for certification of your system RMS is

522
00:25:42,100 --> 00:25:48,639
a broader standard where this is more of

523
00:25:45,940 --> 00:25:52,590
a feed into that I don't see this as an

524
00:25:48,640 --> 00:25:52,590
overlay that makes sense yes thank you

525
00:25:55,669 --> 00:26:00,020
thank you

526
00:25:57,550 --> 00:26:00,020
[Applause]

