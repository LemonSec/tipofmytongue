1
00:00:00,000 --> 00:00:04,770
good morning and welcome to day two of

2
00:00:01,560 --> 00:00:08,069
blackhat you are in islander AI watt

3
00:00:04,770 --> 00:00:10,170
listening to GDP are using privacy laws

4
00:00:08,069 --> 00:00:12,540
to steal identities with James power a

5
00:00:10,170 --> 00:00:14,280
couple of brief notes this morning stop

6
00:00:12,540 --> 00:00:16,529
by the business hall located in Mandalay

7
00:00:14,280 --> 00:00:17,189
Bay Oceanside and shoreline ballrooms on

8
00:00:16,529 --> 00:00:19,830
level two

9
00:00:17,190 --> 00:00:21,900
we have blackout Arsenal also in the

10
00:00:19,830 --> 00:00:24,720
business hall in level two lunch today

11
00:00:21,900 --> 00:00:26,609
we'll be in bait Bayside's a and B from

12
00:00:24,720 --> 00:00:28,500
1:00 to 2:30 and don't forget the

13
00:00:26,609 --> 00:00:31,160
merchandise store on level two with that

14
00:00:28,500 --> 00:00:31,160
I give you James

15
00:00:40,630 --> 00:00:46,000
hi I'm James pavor I'm a PhD researcher

16
00:00:43,780 --> 00:00:48,760
at Oxford University and I'm only here

17
00:00:46,000 --> 00:00:50,590
today because of a bet you see my real

18
00:00:48,760 --> 00:00:52,900
life research is all about hacking

19
00:00:50,590 --> 00:00:54,880
satellites so it's very weird to be on a

20
00:00:52,900 --> 00:00:57,280
stage today talking about privacy laws

21
00:00:54,880 --> 00:00:59,980
and the project that led to this

22
00:00:57,280 --> 00:01:01,660
presentation started with a conversation

23
00:00:59,980 --> 00:01:05,050
I had sitting on the floor of an airport

24
00:01:01,660 --> 00:01:06,610
in Poland I was with my fiance and we

25
00:01:05,050 --> 00:01:08,320
were grumbling to each other both about

26
00:01:06,610 --> 00:01:10,420
the lack of seats in the airport and

27
00:01:08,320 --> 00:01:12,100
sitting on the floor and also about

28
00:01:10,420 --> 00:01:13,630
significant delays we were experiencing

29
00:01:12,100 --> 00:01:16,000
on the low-cost carrier we were dumb

30
00:01:13,630 --> 00:01:17,410
enough to fly with and she's a pen

31
00:01:16,000 --> 00:01:19,420
tester and really clever and she had

32
00:01:17,410 --> 00:01:21,399
this great idea to take advantage of

33
00:01:19,420 --> 00:01:23,860
Europe's new privacy law to get a sort

34
00:01:21,400 --> 00:01:24,970
of petty revenge on the airline she

35
00:01:23,860 --> 00:01:27,550
thought we could send them right of

36
00:01:24,970 --> 00:01:29,170
access requests and sort of waste their

37
00:01:27,550 --> 00:01:31,570
time much in the same way that they were

38
00:01:29,170 --> 00:01:33,369
wasting ours I thought that was really

39
00:01:31,570 --> 00:01:35,740
clever but I took it a step further

40
00:01:33,369 --> 00:01:38,080
saying you know what this airline is so

41
00:01:35,740 --> 00:01:40,690
incompetent I bet they won't even check

42
00:01:38,080 --> 00:01:44,190
that the requests came from us I bet I

43
00:01:40,690 --> 00:01:47,200
could steal your identity using the gdpr

44
00:01:44,190 --> 00:01:49,149
she said you're on two months and a

45
00:01:47,200 --> 00:01:50,679
hundred and fifty gdpr requests later I

46
00:01:49,149 --> 00:01:53,170
had assembled a treasure trove of

47
00:01:50,679 --> 00:01:55,569
sensitive information about her I'm here

48
00:01:53,170 --> 00:01:57,460
today to talk about that experiment but

49
00:01:55,569 --> 00:01:59,259
also to present a broader case which is

50
00:01:57,460 --> 00:02:01,568
that privacy laws like any other

51
00:01:59,259 --> 00:02:03,520
information security control can have

52
00:02:01,569 --> 00:02:06,160
repeatedly exploitable vulnerabilities

53
00:02:03,520 --> 00:02:08,139
and if we look at these laws like we

54
00:02:06,160 --> 00:02:09,508
would look at a piece of software we met

55
00:02:08,139 --> 00:02:11,679
uncover these vulnerabilities before

56
00:02:09,508 --> 00:02:14,019
rather than after they're compiled into

57
00:02:11,680 --> 00:02:15,520
our national law so the way I'm going to

58
00:02:14,020 --> 00:02:17,620
structure this conversation is to do

59
00:02:15,520 --> 00:02:19,480
just that I'm gonna treat the gdpr like

60
00:02:17,620 --> 00:02:20,680
a piece of software and kind of walk

61
00:02:19,480 --> 00:02:23,019
through a simplified version of the

62
00:02:20,680 --> 00:02:24,580
cyber kill chain so first we'll look for

63
00:02:23,020 --> 00:02:26,980
vulnerabilities from a social engineers

64
00:02:24,580 --> 00:02:29,200
perspective we'll weaponize one in the

65
00:02:26,980 --> 00:02:31,000
right of access process deliver it at

66
00:02:29,200 --> 00:02:34,119
scale to more than a hundred and fifty

67
00:02:31,000 --> 00:02:35,890
organisations exploit that at the at

68
00:02:34,120 --> 00:02:38,290
that scale and then exit rate some

69
00:02:35,890 --> 00:02:39,940
sensitive data about my fiance I'll wrap

70
00:02:38,290 --> 00:02:41,590
up the presentation with some tangible

71
00:02:39,940 --> 00:02:43,990
recommendations for individuals

72
00:02:41,590 --> 00:02:47,680
businesses and lawmakers seeking to

73
00:02:43,990 --> 00:02:49,840
improve the status quo so why target GDP

74
00:02:47,680 --> 00:02:51,550
are for those of you who don't know the

75
00:02:49,840 --> 00:02:53,800
general data protection regulation was a

76
00:02:51,550 --> 00:02:53,970
massive European privacy law they came

77
00:02:53,800 --> 00:02:55,560
in

78
00:02:53,970 --> 00:02:57,210
effect last year and really represented

79
00:02:55,560 --> 00:02:59,040
a sea change in the way that European

80
00:02:57,210 --> 00:03:00,840
data subjects could exercise their

81
00:02:59,040 --> 00:03:02,609
rights I don't have time to get into

82
00:03:00,840 --> 00:03:04,590
every detail of the law but there are

83
00:03:02,610 --> 00:03:06,240
four features that I think play really

84
00:03:04,590 --> 00:03:10,050
well in the hands of a social engineer

85
00:03:06,240 --> 00:03:12,180
the first is fear organizations that

86
00:03:10,050 --> 00:03:14,580
fail to comply with GDP are can be

87
00:03:12,180 --> 00:03:16,590
subject to fines up to four percent of

88
00:03:14,580 --> 00:03:18,750
their annual global turnover this is

89
00:03:16,590 --> 00:03:20,160
legislation with teeth and those teeth

90
00:03:18,750 --> 00:03:21,960
have bit at companies like British

91
00:03:20,160 --> 00:03:23,820
Airways and Marriott hotels this summer

92
00:03:21,960 --> 00:03:25,440
with hundreds of millions of dollars in

93
00:03:23,820 --> 00:03:27,810
fines this is the stuff of nightmares

94
00:03:25,440 --> 00:03:30,359
for a lot of CEOs and as we learned in

95
00:03:27,810 --> 00:03:32,220
the keynote yesterday that fear can

96
00:03:30,360 --> 00:03:34,260
cause really bad decision-making if

97
00:03:32,220 --> 00:03:35,580
that's what drives a decision bad

98
00:03:34,260 --> 00:03:38,370
decisions are great for us as social

99
00:03:35,580 --> 00:03:40,170
engineers additionally these frightened

100
00:03:38,370 --> 00:03:42,750
individuals are under immense time

101
00:03:40,170 --> 00:03:44,850
pressure the gdpr sets prescribed

102
00:03:42,750 --> 00:03:46,350
deadlines for certain actions responding

103
00:03:44,850 --> 00:03:48,420
to requests for information from

104
00:03:46,350 --> 00:03:49,890
consumers and regulators and when people

105
00:03:48,420 --> 00:03:52,230
are under a deadline there's a natural

106
00:03:49,890 --> 00:03:53,609
temptation to take shortcuts if we can

107
00:03:52,230 --> 00:03:55,260
make those shortcuts fall in our favor

108
00:03:53,610 --> 00:03:57,750
we'd be able to get stuff that we

109
00:03:55,260 --> 00:04:00,179
shouldn't adding to our arsenal

110
00:03:57,750 --> 00:04:02,670
the gdpr is ambitious it attempts to

111
00:04:00,180 --> 00:04:03,930
apply to every European and almost every

112
00:04:02,670 --> 00:04:06,480
circumstance where their data is stored

113
00:04:03,930 --> 00:04:08,070
and to write a law like that you need to

114
00:04:06,480 --> 00:04:09,690
be ambiguous to keep it in a finite

115
00:04:08,070 --> 00:04:12,480
number of pages you need flexible

116
00:04:09,690 --> 00:04:14,670
language so regulators can apply it on a

117
00:04:12,480 --> 00:04:17,130
case-by-case basis to a diverse array of

118
00:04:14,670 --> 00:04:18,510
businesses this same flexible language

119
00:04:17,130 --> 00:04:20,370
is something we can use as social

120
00:04:18,510 --> 00:04:22,469
engineers to pervert the law and say it

121
00:04:20,370 --> 00:04:23,550
argue stuff that it shouldn't or that

122
00:04:22,470 --> 00:04:25,410
company should do things that they

123
00:04:23,550 --> 00:04:27,390
shouldn't and we'll be arguing with

124
00:04:25,410 --> 00:04:29,190
people most of the time because unless

125
00:04:27,390 --> 00:04:30,659
you're a big organization like Facebook

126
00:04:29,190 --> 00:04:31,890
or Google who can afford to automate

127
00:04:30,660 --> 00:04:33,450
your gdpr process

128
00:04:31,890 --> 00:04:35,159
chances are there's gonna be a real

129
00:04:33,450 --> 00:04:37,140
person at the end of the line processing

130
00:04:35,160 --> 00:04:39,090
the requests and even more importantly

131
00:04:37,140 --> 00:04:40,710
this isn't likely to be your entry level

132
00:04:39,090 --> 00:04:42,030
support team this is likely to be

133
00:04:40,710 --> 00:04:44,070
someone in your legal department or a

134
00:04:42,030 --> 00:04:46,020
data protection officer empowered

135
00:04:44,070 --> 00:04:48,599
individuals with a capacity to really

136
00:04:46,020 --> 00:04:50,130
screw things up the exact kind of person

137
00:04:48,600 --> 00:04:52,320
you would always want to target in a

138
00:04:50,130 --> 00:04:54,450
social engineering attack is given to us

139
00:04:52,320 --> 00:04:57,450
by default under the pretense of gdpr

140
00:04:54,450 --> 00:04:58,710
in my attack I'm gonna be targeting the

141
00:04:57,450 --> 00:05:00,630
right of access process which

142
00:04:58,710 --> 00:05:03,030
essentially does what it says on the tin

143
00:05:00,630 --> 00:05:04,770
it asserts that European residents have

144
00:05:03,030 --> 00:05:06,510
the right to access all of the personal

145
00:05:04,770 --> 00:05:07,318
information that an organization stores

146
00:05:06,510 --> 00:05:08,909
about them

147
00:05:07,319 --> 00:05:10,169
for those of you have submitted right of

148
00:05:08,909 --> 00:05:12,659
access requests you know that the

149
00:05:10,169 --> 00:05:14,430
process is pretty straightforward first

150
00:05:12,659 --> 00:05:15,748
you identify a point of contact this is

151
00:05:14,430 --> 00:05:18,629
normally an email address that appears

152
00:05:15,749 --> 00:05:20,669
in a company's privacy policy next you

153
00:05:18,629 --> 00:05:22,949
send a letter to that address either via

154
00:05:20,669 --> 00:05:24,479
post or email detailing what kind of

155
00:05:22,949 --> 00:05:25,770
information you'd like to receive and

156
00:05:24,479 --> 00:05:27,688
the nice thing about this from the

157
00:05:25,770 --> 00:05:29,998
attackers perspective is that we get to

158
00:05:27,689 --> 00:05:31,770
dictate the terms of the engagement so

159
00:05:29,999 --> 00:05:33,990
we can create a deliberately vague or

160
00:05:31,770 --> 00:05:36,869
complicated request and push up against

161
00:05:33,990 --> 00:05:39,389
those time deadlines in the case of gdpr

162
00:05:36,869 --> 00:05:41,879
the deadline is generally one calendar

163
00:05:39,389 --> 00:05:43,800
month I launched my attack in February

164
00:05:41,879 --> 00:05:46,199
so if you think about that that's 28

165
00:05:43,800 --> 00:05:47,580
days or about 20 business days to get

166
00:05:46,199 --> 00:05:50,009
all of the information about me together

167
00:05:47,580 --> 00:05:51,779
and send it in a format that I can

168
00:05:50,009 --> 00:05:53,399
interpret that's not a lot of time and

169
00:05:51,779 --> 00:05:54,869
so there's a good chance that all those

170
00:05:53,399 --> 00:05:56,339
dynamics I just talked about will come

171
00:05:54,869 --> 00:05:59,189
into play in the right of access process

172
00:05:56,339 --> 00:06:01,169
to exploit these dynamics I sent this

173
00:05:59,189 --> 00:06:02,550
letter to organizations I discourage you

174
00:06:01,169 --> 00:06:04,378
from squinting and trying to read it now

175
00:06:02,550 --> 00:06:05,999
the full text appears in the white paper

176
00:06:04,379 --> 00:06:07,919
but there are a couple of things I'd

177
00:06:05,999 --> 00:06:10,349
like to highlight so the general gist of

178
00:06:07,919 --> 00:06:12,299
the letter as I say hi I am my fiancee

179
00:06:10,349 --> 00:06:13,800
so I'm impersonating her here's some

180
00:06:12,300 --> 00:06:14,969
basic information about me can you

181
00:06:13,800 --> 00:06:16,649
search your databases or anything

182
00:06:14,969 --> 00:06:19,949
related to this and then send it to me

183
00:06:16,649 --> 00:06:21,389
within one month because of gdpr one

184
00:06:19,949 --> 00:06:23,039
important thing to lock down is what our

185
00:06:21,389 --> 00:06:25,319
threat model is what is that basic

186
00:06:23,039 --> 00:06:27,300
information the attacker has for this

187
00:06:25,319 --> 00:06:28,709
attack I tried to roleplay someone who

188
00:06:27,300 --> 00:06:29,309
knew essentially nothing about my

189
00:06:28,709 --> 00:06:31,110
fiancee

190
00:06:29,309 --> 00:06:32,999
so I restricted the attacker to an open

191
00:06:31,110 --> 00:06:35,129
source intelligence model with these

192
00:06:32,999 --> 00:06:37,919
first few points of data as the starting

193
00:06:35,129 --> 00:06:39,719
point so I had her full name I created a

194
00:06:37,919 --> 00:06:41,159
fake email address to impersonate her

195
00:06:39,719 --> 00:06:43,319
which was her first name her middle

196
00:06:41,159 --> 00:06:45,569
initial and her last name at gmail.com I

197
00:06:43,319 --> 00:06:46,979
also did some basic googling and

198
00:06:45,569 --> 00:06:48,449
guesswork to try to figure out what

199
00:06:46,979 --> 00:06:50,490
other email addresses might belong to

200
00:06:48,449 --> 00:06:53,069
her and stuff on like company websites

201
00:06:50,490 --> 00:06:54,869
and so forth ideally when a company gets

202
00:06:53,069 --> 00:06:56,610
this list of information they would say

203
00:06:54,869 --> 00:06:58,050
okay can you prove that you actually are

204
00:06:56,610 --> 00:06:59,580
your fiancee and that this belongs to

205
00:06:58,050 --> 00:07:01,439
you and that's what the law tells

206
00:06:59,580 --> 00:07:03,289
companies to do so it says that

207
00:07:01,439 --> 00:07:05,729
organizations should apply all

208
00:07:03,289 --> 00:07:07,169
reasonable measures to verify the

209
00:07:05,729 --> 00:07:09,539
identity of a data subject when they

210
00:07:07,169 --> 00:07:11,938
receive a request the problem is it's

211
00:07:09,539 --> 00:07:13,800
unclear what the term reasonable means

212
00:07:11,939 --> 00:07:15,870
in a lot of circumstances especially

213
00:07:13,800 --> 00:07:17,699
with this second caveat at the end here

214
00:07:15,870 --> 00:07:19,849
which says that data controllers aren't

215
00:07:17,699 --> 00:07:21,949
allowed to request information solely

216
00:07:19,849 --> 00:07:23,959
for the purpose of identifying potential

217
00:07:21,949 --> 00:07:26,119
subject access requests so if you're a

218
00:07:23,959 --> 00:07:28,039
retail chain or an advertiser who's

219
00:07:26,119 --> 00:07:30,289
never really directly interfaced with my

220
00:07:28,039 --> 00:07:31,550
fiancee on an identity basis it's very

221
00:07:30,289 --> 00:07:33,558
hard to come up with what the right

222
00:07:31,550 --> 00:07:36,110
measure for checking her identity would

223
00:07:33,559 --> 00:07:38,209
be in that circumstance we can take

224
00:07:36,110 --> 00:07:40,339
advantage of this ambiguity and build it

225
00:07:38,209 --> 00:07:42,259
into our request letter so what I do is

226
00:07:40,339 --> 00:07:44,119
I say that I'm actually happy to provide

227
00:07:42,259 --> 00:07:46,639
identity documents proving that I'm my

228
00:07:44,119 --> 00:07:48,469
fiancee but only if those documents are

229
00:07:46,639 --> 00:07:50,240
proportional to the existing

230
00:07:48,469 --> 00:07:51,679
relationship I have with an organization

231
00:07:50,240 --> 00:07:53,569
and you'll notice I use the word

232
00:07:51,679 --> 00:07:55,039
proportional here which is a bit of a

233
00:07:53,569 --> 00:07:56,809
perversion of the word reasonable from

234
00:07:55,039 --> 00:07:58,699
the law and is much more limiting and

235
00:07:56,809 --> 00:08:00,709
restrictive and it gives me a grounds to

236
00:07:58,699 --> 00:08:02,149
argue later on about why I don't want to

237
00:08:00,709 --> 00:08:03,709
provide identity documents without

238
00:08:02,149 --> 00:08:06,469
looking at suspicious so I've kind of

239
00:08:03,709 --> 00:08:07,699
set up this pretense or refusal to make

240
00:08:06,469 --> 00:08:09,919
things even harder on the receiving

241
00:08:07,699 --> 00:08:12,139
company I also say that I'm only willing

242
00:08:09,919 --> 00:08:14,959
to provide these documents via a secure

243
00:08:12,139 --> 00:08:18,110
online portal disk is a company three

244
00:08:14,959 --> 00:08:19,789
bad options the first they could provide

245
00:08:18,110 --> 00:08:21,679
that secure online portal which is

246
00:08:19,789 --> 00:08:24,259
honestly great if they have it but most

247
00:08:21,679 --> 00:08:25,578
organizations don't and twenty business

248
00:08:24,259 --> 00:08:27,680
days is not a lot of time to get a

249
00:08:25,579 --> 00:08:30,769
product vouch for its security and have

250
00:08:27,680 --> 00:08:32,240
it into production alternatively they

251
00:08:30,769 --> 00:08:34,938
can demand that I send my identity

252
00:08:32,240 --> 00:08:36,589
documents via normal email in this case

253
00:08:34,938 --> 00:08:38,838
they're either denying me my rights as a

254
00:08:36,589 --> 00:08:40,250
European data subject or they're forcing

255
00:08:38,839 --> 00:08:42,139
me to do something that I feel is

256
00:08:40,250 --> 00:08:44,029
insecure with my personal information

257
00:08:42,139 --> 00:08:46,399
neither thing would look good in a

258
00:08:44,029 --> 00:08:47,540
courtroom especially if the data got

259
00:08:46,399 --> 00:08:49,939
breached later on from their mail

260
00:08:47,540 --> 00:08:52,099
servers the third option and the one we

261
00:08:49,939 --> 00:08:53,899
want them to take is to accept a weaker

262
00:08:52,100 --> 00:08:57,230
form of identity I'm happy to send over

263
00:08:53,899 --> 00:08:58,730
email or no identity at all you'll

264
00:08:57,230 --> 00:09:00,319
notice up to this point I haven't said

265
00:08:58,730 --> 00:09:01,880
anything specific about a given

266
00:09:00,319 --> 00:09:04,339
organization and that's because it

267
00:09:01,880 --> 00:09:07,430
doesn't really matter the gdpr process

268
00:09:04,339 --> 00:09:09,110
is so standardized and so universal that

269
00:09:07,430 --> 00:09:10,758
you don't have to target very much and

270
00:09:09,110 --> 00:09:13,880
that makes it easy to scale this attack

271
00:09:10,759 --> 00:09:15,740
so what I did is I found 150 data

272
00:09:13,880 --> 00:09:17,779
protection officer email addresses on

273
00:09:15,740 --> 00:09:18,980
various privacy policies I kind of just

274
00:09:17,779 --> 00:09:20,509
looked at market leaders in different

275
00:09:18,980 --> 00:09:22,370
sectors think transportation

276
00:09:20,509 --> 00:09:25,160
entertainment education and so forth and

277
00:09:22,370 --> 00:09:26,569
I wrote python script that sent the form

278
00:09:25,160 --> 00:09:28,760
letter to all of them just changing a

279
00:09:26,569 --> 00:09:31,399
few words for me this attack took a

280
00:09:28,760 --> 00:09:32,780
matter of minutes to run where for

281
00:09:31,399 --> 00:09:34,640
organizations it was day

282
00:09:32,780 --> 00:09:36,920
if not weeks of work to issue their

283
00:09:34,640 --> 00:09:38,510
responses so is a huge disproportionate

284
00:09:36,920 --> 00:09:41,390
advantage right off the bat for an

285
00:09:38,510 --> 00:09:43,640
attacker employing this methodology when

286
00:09:41,390 --> 00:09:45,199
we start getting responses we see that

287
00:09:43,640 --> 00:09:48,800
in practice there's a lot of diversity

288
00:09:45,200 --> 00:09:50,600
and how gdpr is implemented so this

289
00:09:48,800 --> 00:09:52,790
chart here kind of shows that only about

290
00:09:50,600 --> 00:09:54,620
three of the of every four companies I

291
00:09:52,790 --> 00:09:56,390
talk to you actually ever got back to me

292
00:09:54,620 --> 00:09:57,830
we could give the benefit of the doubt

293
00:09:56,390 --> 00:09:59,390
to the remaining quarter and say that

294
00:09:57,830 --> 00:10:01,790
they knew something was suspicious about

295
00:09:59,390 --> 00:10:04,760
the request or perhaps more likely they

296
00:10:01,790 --> 00:10:06,500
didn't have a gdpr process in place this

297
00:10:04,760 --> 00:10:07,819
isn't super relevant to my talk but I

298
00:10:06,500 --> 00:10:09,290
like to highlight this little five

299
00:10:07,820 --> 00:10:11,660
percent at the top of the chart

300
00:10:09,290 --> 00:10:13,430
these are big fortune 200 companies in

301
00:10:11,660 --> 00:10:15,500
the United States who responded to the

302
00:10:13,430 --> 00:10:17,120
request saying even though my fiancee

303
00:10:15,500 --> 00:10:19,220
was a European resident and a data

304
00:10:17,120 --> 00:10:21,170
subject they were American businesses

305
00:10:19,220 --> 00:10:23,810
and not liable to European legislation

306
00:10:21,170 --> 00:10:26,030
and so she had no rights to exercise the

307
00:10:23,810 --> 00:10:27,260
gdpr request process whether that that

308
00:10:26,030 --> 00:10:29,000
would hold up in a courtroom is

309
00:10:27,260 --> 00:10:30,170
something for lawyers to debate but I

310
00:10:29,000 --> 00:10:31,430
thought it was least interesting that

311
00:10:30,170 --> 00:10:34,069
some companies are trying to take that

312
00:10:31,430 --> 00:10:35,510
angle on JEP are much more relevant to

313
00:10:34,070 --> 00:10:37,160
this attack though is the blue section

314
00:10:35,510 --> 00:10:40,250
here and if we delve into it we can see

315
00:10:37,160 --> 00:10:41,750
even more diversity in responses so of

316
00:10:40,250 --> 00:10:44,510
the hundred and fifty organizations I

317
00:10:41,750 --> 00:10:47,360
talked to only 83 as a ground truth

318
00:10:44,510 --> 00:10:48,770
ended up having my fiancees data within

319
00:10:47,360 --> 00:10:51,290
that subset I'll start with the good

320
00:10:48,770 --> 00:10:53,449
news which is that about 40% of the

321
00:10:51,290 --> 00:10:55,550
companies ask for a form of identity

322
00:10:53,450 --> 00:10:57,350
that I wasn't capable of forging or

323
00:10:55,550 --> 00:10:59,089
willing to forge this is definitely

324
00:10:57,350 --> 00:11:00,650
glugging into my fiance's original

325
00:10:59,090 --> 00:11:03,350
account with them or ascending her

326
00:11:00,650 --> 00:11:05,870
passport the flipside of that is that

327
00:11:03,350 --> 00:11:08,270
roughly one in four companies took my

328
00:11:05,870 --> 00:11:10,580
knowledge of her email address and her

329
00:11:08,270 --> 00:11:12,680
phone number as proof that I was her and

330
00:11:10,580 --> 00:11:15,230
simply gave me all of the personal

331
00:11:12,680 --> 00:11:17,630
information they store about her there's

332
00:11:15,230 --> 00:11:19,580
an additional 16% of companies that I

333
00:11:17,630 --> 00:11:21,500
talked to that requested a form of

334
00:11:19,580 --> 00:11:23,600
identity that I feel I probably could

335
00:11:21,500 --> 00:11:25,760
have forged but elected not to do to

336
00:11:23,600 --> 00:11:27,620
keep the experiment clean this would be

337
00:11:25,760 --> 00:11:30,140
stuff like a signed statement swearing

338
00:11:27,620 --> 00:11:31,880
that I'm my fiancee there's a handful of

339
00:11:30,140 --> 00:11:33,860
organizations that never got back and

340
00:11:31,880 --> 00:11:35,600
then there's a handful of organizations

341
00:11:33,860 --> 00:11:37,310
that weren't able to find her

342
00:11:35,600 --> 00:11:38,630
information this might be because my

343
00:11:37,310 --> 00:11:40,400
threat model wasn't able to provide

344
00:11:38,630 --> 00:11:42,140
enough identifiers for them to search

345
00:11:40,400 --> 00:11:43,550
their database or it might be because

346
00:11:42,140 --> 00:11:45,620
there was a flaw in their process for

347
00:11:43,550 --> 00:11:46,790
finding people I think the worst

348
00:11:45,620 --> 00:11:48,110
response I got though

349
00:11:46,790 --> 00:11:49,550
from just a small handful of

350
00:11:48,110 --> 00:11:52,490
organizations like three or four

351
00:11:49,550 --> 00:11:54,650
companies who saw the word gdpr my

352
00:11:52,490 --> 00:11:58,130
fiance's name and immediately deleted

353
00:11:54,650 --> 00:12:00,079
her account denial of service via the

354
00:11:58,130 --> 00:12:02,720
gdpr was very much an unintended

355
00:12:00,080 --> 00:12:04,370
consequence lucky for me I'm still

356
00:12:02,720 --> 00:12:07,040
engaged none of the accounts were

357
00:12:04,370 --> 00:12:08,510
important to her but you could imagine a

358
00:12:07,040 --> 00:12:10,520
worse version of this attack where

359
00:12:08,510 --> 00:12:11,990
instead of asking for information I told

360
00:12:10,520 --> 00:12:14,030
that bottom quarter of companies to

361
00:12:11,990 --> 00:12:17,150
delete her account and what impact that

362
00:12:14,030 --> 00:12:18,620
might have had on her digital life if we

363
00:12:17,150 --> 00:12:20,240
delve a little deeper into the blue

364
00:12:18,620 --> 00:12:24,200
section we again see a lot of diversity

365
00:12:20,240 --> 00:12:26,390
in practice so organizations who ask for

366
00:12:24,200 --> 00:12:27,740
identity ask for various types if there

367
00:12:26,390 --> 00:12:29,540
were an online business they had it

368
00:12:27,740 --> 00:12:31,850
pretty easy they could ask for me to log

369
00:12:29,540 --> 00:12:33,110
into her account or to click a link they

370
00:12:31,850 --> 00:12:34,130
send to original email and I think

371
00:12:33,110 --> 00:12:35,630
that's great because it's very

372
00:12:34,130 --> 00:12:37,580
proportional and it's what you'd already

373
00:12:35,630 --> 00:12:39,020
need to get that data but if they

374
00:12:37,580 --> 00:12:40,970
weren't if they were an advertising

375
00:12:39,020 --> 00:12:42,350
chain it's much harder they could ask

376
00:12:40,970 --> 00:12:43,670
for device cookies but those aren't

377
00:12:42,350 --> 00:12:45,020
really tied to the human and there might

378
00:12:43,670 --> 00:12:47,240
be many cookies associated with my

379
00:12:45,020 --> 00:12:48,770
fiancee they could ask for a passport or

380
00:12:47,240 --> 00:12:50,780
a driver's license but that's wildly

381
00:12:48,770 --> 00:12:52,220
disproportionate and so this tension

382
00:12:50,780 --> 00:12:54,250
that we've set up in our letter is

383
00:12:52,220 --> 00:12:56,630
something we can take advantage of now

384
00:12:54,250 --> 00:12:58,610
this is a response I received from a

385
00:12:56,630 --> 00:13:00,170
railroad company in the UK that said

386
00:12:58,610 --> 00:13:01,820
they'd be happy to give me my fiancees

387
00:13:00,170 --> 00:13:04,130
data if I sent them her passport to

388
00:13:01,820 --> 00:13:05,510
prove that I was her I said you're a

389
00:13:04,130 --> 00:13:07,370
railroad I think you're largely

390
00:13:05,510 --> 00:13:09,860
incompetent with data security I'm not

391
00:13:07,370 --> 00:13:11,810
willing to share my passport would you

392
00:13:09,860 --> 00:13:15,230
take a envelope sent to my address

393
00:13:11,810 --> 00:13:17,150
instead and they said sure so I was able

394
00:13:15,230 --> 00:13:19,520
to talk down this really strong form of

395
00:13:17,150 --> 00:13:21,020
identity a passport into something very

396
00:13:19,520 --> 00:13:23,329
weak something you could forage with an

397
00:13:21,020 --> 00:13:24,890
eraser and a pencil and I think this

398
00:13:23,330 --> 00:13:26,510
shows that even when organisations say

399
00:13:24,890 --> 00:13:29,030
no they're not necessarily comfortable

400
00:13:26,510 --> 00:13:31,010
on the legal grounds to refuse someone

401
00:13:29,030 --> 00:13:33,290
access to their data if you kind of play

402
00:13:31,010 --> 00:13:35,060
your cards right another good example of

403
00:13:33,290 --> 00:13:36,829
this is this incredibly sketchy

404
00:13:35,060 --> 00:13:38,719
photograph of a bank statement I sent to

405
00:13:36,830 --> 00:13:40,250
organisations you notice I've covered it

406
00:13:38,720 --> 00:13:42,650
up with like random post-it notes and

407
00:13:40,250 --> 00:13:44,240
scraps of torn paper from my desk the

408
00:13:42,650 --> 00:13:46,430
only information that was visible to

409
00:13:44,240 --> 00:13:48,410
organisations I sent this to was my

410
00:13:46,430 --> 00:13:49,790
fiance's name and her address and then a

411
00:13:48,410 --> 00:13:51,770
public sort code that belonged to the

412
00:13:49,790 --> 00:13:53,000
bank in this case it was a legitimate

413
00:13:51,770 --> 00:13:55,250
bank statement that she gave me for the

414
00:13:53,000 --> 00:13:56,810
experiment but there's no way a company

415
00:13:55,250 --> 00:13:58,700
receiving this could have verified that

416
00:13:56,810 --> 00:14:00,079
authenticity heck even part of the

417
00:13:58,700 --> 00:14:01,540
Barclays logo is covered up

418
00:14:00,080 --> 00:14:03,410
and that shows that even when

419
00:14:01,540 --> 00:14:05,599
organizations ask for an identity

420
00:14:03,410 --> 00:14:07,160
document they don't necessarily verify

421
00:14:05,600 --> 00:14:09,680
it or have the capacity to tell whether

422
00:14:07,160 --> 00:14:11,390
or not it's real now one of the

423
00:14:09,680 --> 00:14:13,640
organization bites you get a response

424
00:14:11,390 --> 00:14:15,199
like this this came from a gaming

425
00:14:13,640 --> 00:14:17,089
company with more than a billion dollars

426
00:14:15,200 --> 00:14:18,529
in annual revenues to think 40 million

427
00:14:17,089 --> 00:14:21,260
dollars in GDP our fines for the

428
00:14:18,529 --> 00:14:22,579
existence of the screenshot and in this

429
00:14:21,260 --> 00:14:24,170
case they originally asked me to log

430
00:14:22,579 --> 00:14:26,239
into my fiance's account to prove I was

431
00:14:24,170 --> 00:14:27,769
her I said I forgot my password is there

432
00:14:26,240 --> 00:14:30,290
anything you can do and I said oh that's

433
00:14:27,769 --> 00:14:32,029
fine here's all of the information now

434
00:14:30,290 --> 00:14:33,319
in this case it was nothing too

435
00:14:32,029 --> 00:14:34,760
important right it's a gaming

436
00:14:33,320 --> 00:14:36,560
information it's high scores maybe a

437
00:14:34,760 --> 00:14:38,089
little bit about her phone but nothing

438
00:14:36,560 --> 00:14:39,890
like deeply relevant and there was a lot

439
00:14:38,089 --> 00:14:41,540
of low level sensitivity data like that

440
00:14:39,890 --> 00:14:43,550
most advertising agencies for example

441
00:14:41,540 --> 00:14:45,680
were able to tell me stuff like her

442
00:14:43,550 --> 00:14:47,750
parents owned a cat but that's not super

443
00:14:45,680 --> 00:14:49,519
useful to an attacker one thing I

444
00:14:47,750 --> 00:14:51,170
thought was particularly interesting at

445
00:14:49,519 --> 00:14:53,269
this low sensitivity level though was

446
00:14:51,170 --> 00:14:54,979
that organizations who didn't have her

447
00:14:53,269 --> 00:14:56,720
information had two different ways of

448
00:14:54,980 --> 00:14:58,100
responding to requests so they would

449
00:14:56,720 --> 00:15:00,079
either ask for me to prove that I was

450
00:14:58,100 --> 00:15:01,399
her before saying anything else or they

451
00:15:00,079 --> 00:15:02,870
would say sorry we don't have any

452
00:15:01,399 --> 00:15:04,970
information about this person so we

453
00:15:02,870 --> 00:15:06,260
can't process a request further that

454
00:15:04,970 --> 00:15:08,209
second option is a really interesting

455
00:15:06,260 --> 00:15:09,800
route towards enumerate accounts and

456
00:15:08,209 --> 00:15:11,239
obviously that's not always a very

457
00:15:09,800 --> 00:15:13,189
severe vulnerability but you might

458
00:15:11,240 --> 00:15:15,230
imagine in the case of say an online

459
00:15:13,190 --> 00:15:16,970
dating site asking whether or not my

460
00:15:15,230 --> 00:15:19,430
fiancee has an account with them maybe

461
00:15:16,970 --> 00:15:21,410
the entire story so even when you're

462
00:15:19,430 --> 00:15:22,609
saying no to a gdpr request you have to

463
00:15:21,410 --> 00:15:24,260
be careful you do it in a way that

464
00:15:22,610 --> 00:15:27,110
doesn't reveal information about your

465
00:15:24,260 --> 00:15:29,390
real customers when we kick it up to a

466
00:15:27,110 --> 00:15:31,130
higher level at medium sensitivity we

467
00:15:29,390 --> 00:15:33,470
see some of that juicy data you can only

468
00:15:31,130 --> 00:15:35,270
get out with gdpr requests this is a

469
00:15:33,470 --> 00:15:36,620
response from a major hotel chain that

470
00:15:35,270 --> 00:15:38,270
gave me a list of all the time she

471
00:15:36,620 --> 00:15:40,490
stayed at their hotels and every time

472
00:15:38,270 --> 00:15:41,870
she purchased Hotel Wi-Fi that railroad

473
00:15:40,490 --> 00:15:42,890
company I mentioned earlier ended up

474
00:15:41,870 --> 00:15:44,120
giving me a list of all the train

475
00:15:42,890 --> 00:15:46,189
journey she's taken over the past

476
00:15:44,120 --> 00:15:47,480
several years this information isn't

477
00:15:46,190 --> 00:15:49,430
immediately useful but you could imagine

478
00:15:47,480 --> 00:15:50,899
me calling and saying hi I'm from your

479
00:15:49,430 --> 00:15:52,609
bank I'm inquiring about this recent

480
00:15:50,899 --> 00:15:53,720
purchase for Wi-Fi can you give me

481
00:15:52,610 --> 00:15:55,130
information to prove that you are who

482
00:15:53,720 --> 00:15:57,170
you say or in your card hasn't been

483
00:15:55,130 --> 00:15:58,670
stolen and that kind of attack is really

484
00:15:57,170 --> 00:16:01,579
powerful with this granular information

485
00:15:58,670 --> 00:16:03,649
I also got extra information about her

486
00:16:01,579 --> 00:16:05,540
that I could bake in a future GDP our

487
00:16:03,649 --> 00:16:07,370
request letter stuff like user names or

488
00:16:05,540 --> 00:16:09,319
additional addresses and that might

489
00:16:07,370 --> 00:16:12,380
increase the success rate over time and

490
00:16:09,320 --> 00:16:12,620
help target this attack further at the

491
00:16:12,380 --> 00:16:14,660
high

492
00:16:12,620 --> 00:16:16,510
sensitivity level we start seeing the

493
00:16:14,660 --> 00:16:18,949
data that really should not be shared

494
00:16:16,510 --> 00:16:21,860
this is a response I got from an

495
00:16:18,950 --> 00:16:24,140
educational services company they gave

496
00:16:21,860 --> 00:16:26,030
me her social security number her date

497
00:16:24,140 --> 00:16:28,130
of birth her mother's maiden name her

498
00:16:26,030 --> 00:16:30,020
high school grades a bunch of pretty

499
00:16:28,130 --> 00:16:32,390
deeply sensitive information and this

500
00:16:30,020 --> 00:16:34,340
organization only required me to know

501
00:16:32,390 --> 00:16:35,810
her name her email address and her phone

502
00:16:34,340 --> 00:16:38,630
number to get access to this they asked

503
00:16:35,810 --> 00:16:40,250
for no further verification even more

504
00:16:38,630 --> 00:16:42,260
concerning Lea the website of this

505
00:16:40,250 --> 00:16:44,720
company suggested they have at least 10

506
00:16:42,260 --> 00:16:46,040
million records like this that are

507
00:16:44,720 --> 00:16:49,130
potentially vulnerable to this route of

508
00:16:46,040 --> 00:16:51,290
attack I got some financial data as well

509
00:16:49,130 --> 00:16:53,300
I unfortunately didn't manage to get her

510
00:16:51,290 --> 00:16:55,339
whole credit card number but I got ten

511
00:16:53,300 --> 00:16:57,199
digits of it the expiration date the

512
00:16:55,340 --> 00:16:58,970
issuing bank in The Associated postcode

513
00:16:57,200 --> 00:17:01,370
which is perhaps enough to really

514
00:16:58,970 --> 00:17:02,450
bolster that previous attack in terms of

515
00:17:01,370 --> 00:17:03,800
letting me pretend to be the bank

516
00:17:02,450 --> 00:17:06,680
calling about the card ending in

517
00:17:03,800 --> 00:17:08,419
whatever digits one particularly novel

518
00:17:06,680 --> 00:17:10,280
bit of high sensitivity information I

519
00:17:08,420 --> 00:17:12,770
encountered was actual account

520
00:17:10,280 --> 00:17:14,000
credentials to log into her accounts so

521
00:17:12,770 --> 00:17:16,430
I reached out to a threat intelligence

522
00:17:14,000 --> 00:17:18,079
company their business model is similar

523
00:17:16,430 --> 00:17:20,060
to the website have I been pwned it

524
00:17:18,079 --> 00:17:22,010
wasn't them but essentially what they do

525
00:17:20,060 --> 00:17:23,480
is they download paste bins and data

526
00:17:22,010 --> 00:17:25,040
breaches before they get deleted and

527
00:17:23,480 --> 00:17:26,360
they store that and then sell it to

528
00:17:25,040 --> 00:17:28,730
corporations to check whether their

529
00:17:26,359 --> 00:17:30,830
employees have been compromised and in

530
00:17:28,730 --> 00:17:32,720
this case they provided me in response

531
00:17:30,830 --> 00:17:34,580
to that sketchy bank statement my

532
00:17:32,720 --> 00:17:36,200
fiance's passwords that have been

533
00:17:34,580 --> 00:17:38,060
breached over the past several years I

534
00:17:36,200 --> 00:17:40,040
was actually able to use these passwords

535
00:17:38,060 --> 00:17:41,480
to log into financial services accounts

536
00:17:40,040 --> 00:17:43,850
and transportation services accounts

537
00:17:41,480 --> 00:17:46,190
that belonged to her she since atoned

538
00:17:43,850 --> 00:17:47,899
for her sins and no longer reuses

539
00:17:46,190 --> 00:17:49,370
passwords she's got a password manager

540
00:17:47,900 --> 00:17:51,440
and all of that but that's not really

541
00:17:49,370 --> 00:17:53,780
the point I think the real lesson here

542
00:17:51,440 --> 00:17:56,450
is that an organization she had never

543
00:17:53,780 --> 00:17:58,670
heard of and never interacted with had

544
00:17:56,450 --> 00:18:01,520
some of the most sensitive data about

545
00:17:58,670 --> 00:18:03,560
her in GDP are provided a pretense for

546
00:18:01,520 --> 00:18:04,690
anyone in the world to ask for that

547
00:18:03,560 --> 00:18:07,100
information

548
00:18:04,690 --> 00:18:09,200
so obviously the status quo is

549
00:18:07,100 --> 00:18:10,610
unacceptable we need to find a way to

550
00:18:09,200 --> 00:18:12,500
protect this information and make

551
00:18:10,610 --> 00:18:14,899
privacy laws achieve their objectives

552
00:18:12,500 --> 00:18:16,460
and to that end I think we should avoid

553
00:18:14,900 --> 00:18:18,440
doing stuff like this so this is a

554
00:18:16,460 --> 00:18:20,570
proposed bill in the US Congress which

555
00:18:18,440 --> 00:18:22,820
essentially copies and pastes the

556
00:18:20,570 --> 00:18:24,770
subject access request process from gdpr

557
00:18:22,820 --> 00:18:26,240
into u.s. legislation

558
00:18:24,770 --> 00:18:27,860
and I think that we need to be careful

559
00:18:26,240 --> 00:18:30,260
that these vulnerabilities don't become

560
00:18:27,860 --> 00:18:32,689
a legacy of laws because gdpr is very

561
00:18:30,260 --> 00:18:35,060
much a model for how future privacy laws

562
00:18:32,690 --> 00:18:36,560
will work but if you're a company or

563
00:18:35,060 --> 00:18:38,659
someone who works for one you don't

564
00:18:36,560 --> 00:18:40,340
really care so much about what the law

565
00:18:38,660 --> 00:18:42,200
should be you care about what you can do

566
00:18:40,340 --> 00:18:43,669
now and I'm not a lawyer so I don't have

567
00:18:42,200 --> 00:18:45,920
perfect answers but I think there are a

568
00:18:43,670 --> 00:18:48,710
couple of common-sense steps you can

569
00:18:45,920 --> 00:18:50,030
take to at least make my job harder so

570
00:18:48,710 --> 00:18:52,430
the first is if you're an online

571
00:18:50,030 --> 00:18:54,170
business who has an email address or an

572
00:18:52,430 --> 00:18:56,000
original account log in I think this is

573
00:18:54,170 --> 00:18:57,710
a very proportionate and reliable way of

574
00:18:56,000 --> 00:19:00,320
verifying someone because it's what they

575
00:18:57,710 --> 00:19:02,150
already need to get data if not if you

576
00:19:00,320 --> 00:19:04,189
need to ask for a driver's license or a

577
00:19:02,150 --> 00:19:06,110
bank statement you should be sure as a

578
00:19:04,190 --> 00:19:07,490
company that you're capable of verifying

579
00:19:06,110 --> 00:19:09,169
not just the information on those

580
00:19:07,490 --> 00:19:11,330
documents but that they're the real

581
00:19:09,170 --> 00:19:12,830
documents associated with a real person

582
00:19:11,330 --> 00:19:15,139
and if you can't do that you should find

583
00:19:12,830 --> 00:19:17,240
a way to outsource that or some someone

584
00:19:15,140 --> 00:19:20,180
who can I think most importantly

585
00:19:17,240 --> 00:19:23,600
companies should just say no to

586
00:19:20,180 --> 00:19:25,640
suspicious gdpr requests that might land

587
00:19:23,600 --> 00:19:27,169
them in a courtroom but maybe they

588
00:19:25,640 --> 00:19:29,720
should be willing to go to court to

589
00:19:27,170 --> 00:19:32,000
defend their customers data and perhaps

590
00:19:29,720 --> 00:19:33,520
more importantly it really shouldn't be

591
00:19:32,000 --> 00:19:35,840
that kind of choice

592
00:19:33,520 --> 00:19:38,240
legislators should reassure companies

593
00:19:35,840 --> 00:19:40,220
that rejecting gdpr requests in good

594
00:19:38,240 --> 00:19:41,480
faith won't come back to bite them down

595
00:19:40,220 --> 00:19:43,070
the line if it turns out it was a

596
00:19:41,480 --> 00:19:45,350
legitimate person who is just acting

597
00:19:43,070 --> 00:19:46,879
weirdly additionally I think that

598
00:19:45,350 --> 00:19:48,830
there's a role for legislators and the

599
00:19:46,880 --> 00:19:50,360
Information Commissioner's offices to

600
00:19:48,830 --> 00:19:52,460
clarify what a reasonable form of

601
00:19:50,360 --> 00:19:54,439
identity is in different circumstances

602
00:19:52,460 --> 00:19:55,970
and perhaps in the long run

603
00:19:54,440 --> 00:19:57,830
there's even an opportunity for a

604
00:19:55,970 --> 00:19:59,660
government operated kind of third-party

605
00:19:57,830 --> 00:20:01,730
service where instead of setting my

606
00:19:59,660 --> 00:20:04,070
passport directly to a shoe store to

607
00:20:01,730 --> 00:20:05,390
make a gdpr request I could send it to

608
00:20:04,070 --> 00:20:07,250
this third-party service to provide a

609
00:20:05,390 --> 00:20:09,560
yes-or-no answer to whether or not that

610
00:20:07,250 --> 00:20:11,000
document is authentically mine so I give

611
00:20:09,560 --> 00:20:12,980
the benefits of that strong identity

612
00:20:11,000 --> 00:20:15,680
without the risks of just sharing it

613
00:20:12,980 --> 00:20:17,810
with any company who asks if you're an

614
00:20:15,680 --> 00:20:19,550
individual things are a little bit more

615
00:20:17,810 --> 00:20:20,659
bleak right there's not a lot you can do

616
00:20:19,550 --> 00:20:23,090
to change how companies you've never

617
00:20:20,660 --> 00:20:24,320
heard of interact but I think that it's

618
00:20:23,090 --> 00:20:26,300
a good example of why you should be

619
00:20:24,320 --> 00:20:27,649
proactive about data hygiene delete

620
00:20:26,300 --> 00:20:29,120
information that's out there that you no

621
00:20:27,650 --> 00:20:31,340
longer need or with services you no

622
00:20:29,120 --> 00:20:32,810
longer need and if something weird is

623
00:20:31,340 --> 00:20:34,490
going on with your accounts it might be

624
00:20:32,810 --> 00:20:36,690
worth just checking if anyone's been

625
00:20:34,490 --> 00:20:38,009
submitting gdpr requests in your name

626
00:20:36,690 --> 00:20:40,309
because that's a pretty good warning

627
00:20:38,009 --> 00:20:43,259
Simon someone is trying to target you

628
00:20:40,309 --> 00:20:45,119
finally this talk is a great example of

629
00:20:43,259 --> 00:20:47,249
why you should never give personal

630
00:20:45,119 --> 00:20:49,259
information in a phone call you didn't

631
00:20:47,249 --> 00:20:50,909
start if someone calls you and they know

632
00:20:49,259 --> 00:20:52,710
about the last train trip you took the

633
00:20:50,909 --> 00:20:54,210
last hotel you stayed at that's not

634
00:20:52,710 --> 00:20:56,129
proof that they work for your bank or a

635
00:20:54,210 --> 00:20:58,379
railroad or a hotel because the sort of

636
00:20:56,129 --> 00:21:00,029
granular information is now readily

637
00:20:58,379 --> 00:21:04,619
accessible through a pretty standardized

638
00:21:00,029 --> 00:21:06,059
process so I guess to tie things up the

639
00:21:04,619 --> 00:21:07,978
core point of this presentation is

640
00:21:06,059 --> 00:21:11,009
pretty simple and that's that privacy

641
00:21:07,979 --> 00:21:14,519
laws should enhance privacy not endanger

642
00:21:11,009 --> 00:21:15,809
it this is not always an easy task and I

643
00:21:14,519 --> 00:21:17,609
think that a lot of it comes from the

644
00:21:15,809 --> 00:21:19,918
way we think about regulations which is

645
00:21:17,609 --> 00:21:22,349
in an adversarial model of regulator

646
00:21:19,919 --> 00:21:24,330
versus regulated in the information

647
00:21:22,349 --> 00:21:25,769
security community we understand that

648
00:21:24,330 --> 00:21:27,449
the threat model is more complicated

649
00:21:25,769 --> 00:21:29,159
than that when it comes to data there's

650
00:21:27,450 --> 00:21:31,019
a diverse range of threat actors seeking

651
00:21:29,159 --> 00:21:32,999
to attack it and I think if we take some

652
00:21:31,019 --> 00:21:34,619
of the experience we have from pen

653
00:21:32,999 --> 00:21:36,960
testing and software auditing and stuff

654
00:21:34,619 --> 00:21:38,279
like that into the legislative arena we

655
00:21:36,960 --> 00:21:40,769
might better be able to understand how

656
00:21:38,279 --> 00:21:43,229
different data inputs into laws could

657
00:21:40,769 --> 00:21:44,519
become vulnerabilities thank you so much

658
00:21:43,229 --> 00:21:46,080
for listening in the presentation my

659
00:21:44,519 --> 00:21:48,030
email is here and I'm also happy to

660
00:21:46,080 --> 00:21:58,299
answer a few questions now

661
00:21:48,030 --> 00:21:58,299
[Applause]

