1
00:00:00,000 --> 00:00:07,740
good morning and welcome to detecting

2
00:00:03,300 --> 00:00:10,200
deep fakes with mice in Laguna gah I

3
00:00:07,740 --> 00:00:13,590
that your speakers this morning are Alex

4
00:00:10,200 --> 00:00:16,139
come record Jonathan Sanders Saunders

5
00:00:13,590 --> 00:00:17,400
and George Williams just a couple of

6
00:00:16,139 --> 00:00:19,080
quick announcements before we get

7
00:00:17,400 --> 00:00:21,180
started stop by the business hall

8
00:00:19,080 --> 00:00:23,939
located in Mandalay Bay Oceanside and

9
00:00:21,180 --> 00:00:25,590
shoreline ballrooms on level 2 during

10
00:00:23,939 --> 00:00:28,890
the day and there's a welcome reception

11
00:00:25,590 --> 00:00:30,929
tonight at 5:30 blackhat Arsenal is in

12
00:00:28,890 --> 00:00:32,940
the business hall on level 2

13
00:00:30,929 --> 00:00:36,989
the Pawnee awards are in this room

14
00:00:32,940 --> 00:00:39,089
tonight at 1830 that's 6:30 for those of

15
00:00:36,989 --> 00:00:41,640
us not in the military and finally

16
00:00:39,090 --> 00:00:43,620
please remember to turn your phone's off

17
00:00:41,640 --> 00:00:47,960
or silence them and with that I will

18
00:00:43,620 --> 00:00:51,030
turn it over to our speakers all right

19
00:00:47,960 --> 00:00:53,760
great thanks Kevin and thanks black hat

20
00:00:51,030 --> 00:00:56,579
for having us

21
00:00:53,760 --> 00:00:59,879
so I'm George by the way and I'll be

22
00:00:56,579 --> 00:01:03,300
reintroducing Alex and Jonathan here in

23
00:00:59,879 --> 00:01:08,429
a second but I wanted to start out by

24
00:01:03,300 --> 00:01:12,479
going back in time a little bit ooh yes

25
00:01:08,430 --> 00:01:14,970
October 31st 1938 to be exact and here

26
00:01:12,479 --> 00:01:17,580
are some of the headlines from that day

27
00:01:14,970 --> 00:01:20,880
and as you can see there was an alleged

28
00:01:17,580 --> 00:01:24,240
panic caused by a fake news radio

29
00:01:20,880 --> 00:01:28,350
broadcast that occurred the night before

30
00:01:24,240 --> 00:01:32,729
on CBS Radio and so this broadcast

31
00:01:28,350 --> 00:01:38,240
depicted the invasion of a small town in

32
00:01:32,729 --> 00:01:42,780
New Jersey of course we know this today

33
00:01:38,240 --> 00:01:46,710
as the legendary and well orchestrated

34
00:01:42,780 --> 00:01:50,040
hoax by very young Orson Welles who

35
00:01:46,710 --> 00:01:53,880
hired a team of professional actors to

36
00:01:50,040 --> 00:01:55,920
perform a live dramatization of the HG

37
00:01:53,880 --> 00:02:01,890
Welles science-fiction work or the

38
00:01:55,920 --> 00:02:04,740
world's so you know reports of the panic

39
00:02:01,890 --> 00:02:08,340
were possibly exaggerated but it's still

40
00:02:04,740 --> 00:02:11,129
useful I think to compare draw some

41
00:02:08,340 --> 00:02:13,830
parallels between those events and the

42
00:02:11,129 --> 00:02:16,829
events of today the era of

43
00:02:13,830 --> 00:02:18,470
disinformation in fake news that we live

44
00:02:16,830 --> 00:02:21,480
in today

45
00:02:18,470 --> 00:02:23,160
of course today right it's very

46
00:02:21,480 --> 00:02:23,760
different big difference between then

47
00:02:23,160 --> 00:02:28,740
and now

48
00:02:23,760 --> 00:02:32,820
is that you can craft high-quality

49
00:02:28,740 --> 00:02:35,610
realistic content for disinformation

50
00:02:32,820 --> 00:02:37,829
campaigns and the techniques are

51
00:02:35,610 --> 00:02:40,440
evolving quite rapidly from

52
00:02:37,830 --> 00:02:42,890
sophisticated face swapping to this

53
00:02:40,440 --> 00:02:45,750
puppet master technique you see here

54
00:02:42,890 --> 00:02:48,359
lip-synching to being able to clone

55
00:02:45,750 --> 00:02:53,340
anyone's voice with just a few samples

56
00:02:48,360 --> 00:02:54,900
of their speech the tools are generally

57
00:02:53,340 --> 00:02:57,930
available some of them are open-source

58
00:02:54,900 --> 00:03:02,010
and the techniques have become so

59
00:02:57,930 --> 00:03:04,080
sophisticated and available that a lot

60
00:03:02,010 --> 00:03:10,679
of officials have started to get very

61
00:03:04,080 --> 00:03:13,110
concerned so a parade of politicians and

62
00:03:10,680 --> 00:03:18,030
tech leaders have joined on Capitol Hill

63
00:03:13,110 --> 00:03:22,459
to warn us of all the dangers the idea

64
00:03:18,030 --> 00:03:26,459
is that a well-timed fake of a CEO or a

65
00:03:22,459 --> 00:03:30,420
politician doing something or saying

66
00:03:26,459 --> 00:03:37,520
something they did not do or say may

67
00:03:30,420 --> 00:03:40,440
spark some kind of catastrophe such as

68
00:03:37,520 --> 00:03:45,150
destabilizing a brittle financial market

69
00:03:40,440 --> 00:03:47,850
or igniting a powder keg like civil or

70
00:03:45,150 --> 00:03:53,130
military conflict somewhere on the globe

71
00:03:47,850 --> 00:03:55,620
a true war of the worlds' now whether

72
00:03:53,130 --> 00:03:58,049
this happens or not I think we have an

73
00:03:55,620 --> 00:04:00,450
interesting election year coming up it's

74
00:03:58,050 --> 00:04:04,880
hard to say but we can ask ourselves

75
00:04:00,450 --> 00:04:08,760
today who's being fooled by these fakes

76
00:04:04,880 --> 00:04:11,910
so we did a small informal study and we

77
00:04:08,760 --> 00:04:15,269
asked participants to differentiate

78
00:04:11,910 --> 00:04:18,810
between real speech clips of real people

79
00:04:15,269 --> 00:04:22,860
talking versus fake ones generated by

80
00:04:18,810 --> 00:04:26,130
state-of-the-art techniques and we found

81
00:04:22,860 --> 00:04:27,330
that you know on average the median for

82
00:04:26,130 --> 00:04:30,599
humans was about 80

83
00:04:27,330 --> 00:04:33,270
percent they got 88% right and compare

84
00:04:30,599 --> 00:04:35,969
this to a lot of the state-of-the-art

85
00:04:33,270 --> 00:04:39,389
algorithms that were trained and

86
00:04:35,969 --> 00:04:41,099
evaluated on the same data set around 92

87
00:04:39,389 --> 00:04:42,840
percent was the median and as you can

88
00:04:41,099 --> 00:04:45,628
see in the box plot there right some

89
00:04:42,840 --> 00:04:48,750
humans and some machines actually do a

90
00:04:45,629 --> 00:04:51,000
lot better but on average you know

91
00:04:48,750 --> 00:04:54,509
humans and machines get about get about

92
00:04:51,000 --> 00:04:57,599
90% which seems pretty good but if you

93
00:04:54,509 --> 00:05:00,690
think about the millions of items of

94
00:04:57,599 --> 00:05:03,710
content that are created on a daily

95
00:05:00,690 --> 00:05:08,280
basis uploaded to YouTube to Facebook

96
00:05:03,710 --> 00:05:09,900
even a small error rate means that some

97
00:05:08,280 --> 00:05:12,030
of the fakes are going to get through

98
00:05:09,900 --> 00:05:15,150
human reviewers and are going to get

99
00:05:12,030 --> 00:05:19,529
through automated systems and possibly

100
00:05:15,150 --> 00:05:22,020
worse some of the genuine content will

101
00:05:19,529 --> 00:05:29,099
be spotted as fakes will be flagged as

102
00:05:22,020 --> 00:05:30,210
fakes so we're gonna explore that

103
00:05:29,099 --> 00:05:33,180
further

104
00:05:30,210 --> 00:05:34,258
in the next part of the talk the

105
00:05:33,180 --> 00:05:36,240
remainder of the talk and we're gonna

106
00:05:34,259 --> 00:05:38,159
divide it up into machines and biology

107
00:05:36,240 --> 00:05:40,889
and on the machine side

108
00:05:38,159 --> 00:05:42,300
Alex Comerford of Bloomberg he'll talk

109
00:05:40,889 --> 00:05:45,180
about state-of-the-art methods for

110
00:05:42,300 --> 00:05:46,080
generating and detecting fakes and on

111
00:05:45,180 --> 00:05:48,389
the biology side

112
00:05:46,080 --> 00:05:49,830
Jonathan Saunders of the Institute of

113
00:05:48,389 --> 00:05:51,870
neural science at the University of

114
00:05:49,830 --> 00:05:54,300
Oregon will talk about the neuroscience

115
00:05:51,870 --> 00:05:57,210
around all of this and he'll propose a

116
00:05:54,300 --> 00:06:00,180
novel detection technique neither based

117
00:05:57,210 --> 00:06:04,349
on humans or machines hand it off to

118
00:06:00,180 --> 00:06:06,479
Alex now hello everyone

119
00:06:04,349 --> 00:06:09,060
everyone's having a good day today I'm

120
00:06:06,479 --> 00:06:10,460
Alex I'm a data scientist at Bloomberg

121
00:06:09,060 --> 00:06:14,580
and today I'm going to talk about

122
00:06:10,460 --> 00:06:16,229
detecting deep audio defects with a with

123
00:06:14,580 --> 00:06:18,180
the machine approach so I want to start

124
00:06:16,229 --> 00:06:19,740
with what is a deep fake for people in

125
00:06:18,180 --> 00:06:21,779
the audience who've never heard of the

126
00:06:19,740 --> 00:06:23,580
term before a little bit vague on it

127
00:06:21,779 --> 00:06:24,839
my definition that's a little bit

128
00:06:23,580 --> 00:06:27,389
different than what you can find online

129
00:06:24,839 --> 00:06:30,150
is using deep neural network to create

130
00:06:27,389 --> 00:06:32,190
human-like data that tricks humans into

131
00:06:30,150 --> 00:06:35,179
thinking it's real so this term is

132
00:06:32,190 --> 00:06:38,240
pretty new whose coined a few years ago

133
00:06:35,180 --> 00:06:40,220
back in 2017 and

134
00:06:38,240 --> 00:06:42,800
the public generally associate Steve

135
00:06:40,220 --> 00:06:45,170
fakes with synthesizing images or video

136
00:06:42,800 --> 00:06:46,700
and specifically synthesizing fake

137
00:06:45,170 --> 00:06:49,880
political videos or even fake

138
00:06:46,700 --> 00:06:52,340
pornography but it's useful to think

139
00:06:49,880 --> 00:06:54,200
about deep fakes as a function where you

140
00:06:52,340 --> 00:06:56,359
input a bunch of data about a person and

141
00:06:54,200 --> 00:07:00,349
you output essentially a puppet of said

142
00:06:56,360 --> 00:07:03,800
person so now going into how they're

143
00:07:00,350 --> 00:07:05,210
made so Dee fakes are product of a

144
00:07:03,800 --> 00:07:11,270
larger category called generative

145
00:07:05,210 --> 00:07:13,969
modeling with the addition of the great

146
00:07:11,270 --> 00:07:15,409
advances in neural networks and beep

147
00:07:13,970 --> 00:07:17,420
learning in general and what deep

148
00:07:15,410 --> 00:07:20,240
learning is really good at is creating

149
00:07:17,420 --> 00:07:22,970
mappings from one long form of data to

150
00:07:20,240 --> 00:07:24,680
another examples doing text to speech or

151
00:07:22,970 --> 00:07:28,430
speech to text or even faces the faces

152
00:07:24,680 --> 00:07:31,280
or pictures to pictures etc and with

153
00:07:28,430 --> 00:07:32,630
these high fidelity future mappings deep

154
00:07:31,280 --> 00:07:35,390
neural networks have produced the most

155
00:07:32,630 --> 00:07:37,280
fake looking samples compared to any or

156
00:07:35,390 --> 00:07:40,789
any other model however it comes at a

157
00:07:37,280 --> 00:07:43,099
cost training these and making high

158
00:07:40,790 --> 00:07:45,440
fidelity fakes require a significant

159
00:07:43,100 --> 00:07:46,940
amount of resources namely fully

160
00:07:45,440 --> 00:07:50,960
representative datasets and a lot of

161
00:07:46,940 --> 00:07:53,330
compute so making good deep fakes is

162
00:07:50,960 --> 00:07:55,520
really hard in one famous paper

163
00:07:53,330 --> 00:07:57,609
synthesizing Obama the author mentions

164
00:07:55,520 --> 00:08:00,440
that it took over seventeen hours of

165
00:07:57,610 --> 00:08:02,870
presidential addresses of Obama to come

166
00:08:00,440 --> 00:08:06,380
up with these samples if you see

167
00:08:02,870 --> 00:08:09,560
on-screen and he also mentions oh so one

168
00:08:06,380 --> 00:08:11,030
thing is that there's if you're not a

169
00:08:09,560 --> 00:08:13,370
public figure seventeen hours there's a

170
00:08:11,030 --> 00:08:17,419
lot of data to have just in your pocket

171
00:08:13,370 --> 00:08:19,700
about a person and the often notes that

172
00:08:17,420 --> 00:08:21,470
training and doing training times that

173
00:08:19,700 --> 00:08:23,479
it took about two weeks to train these

174
00:08:21,470 --> 00:08:26,060
models on the CPU and about two hours to

175
00:08:23,480 --> 00:08:27,380
do it on the CPI on it on a GPU but what

176
00:08:26,060 --> 00:08:30,860
we don't know is the amount of hours it

177
00:08:27,380 --> 00:08:33,799
took to do feature engineering creating

178
00:08:30,860 --> 00:08:35,630
these facial masks fixing lip synching

179
00:08:33,799 --> 00:08:37,689
and teeth which are all mentioned in the

180
00:08:35,630 --> 00:08:39,950
paper which adds to this difficulty

181
00:08:37,690 --> 00:08:42,110
however if you want to make a general

182
00:08:39,950 --> 00:08:43,910
deep fake they're pretty easy and fun to

183
00:08:42,110 --> 00:08:46,640
do you just clone projects off github

184
00:08:43,909 --> 00:08:48,469
you can make celebrity faces or you'd

185
00:08:46,640 --> 00:08:51,390
even synthesized voices so we're going

186
00:08:48,470 --> 00:08:53,279
to listen to clip by

187
00:08:51,390 --> 00:08:55,560
deepmind specific architecture they came

188
00:08:53,279 --> 00:08:58,140
out called wavenet the blue lagoon is a

189
00:08:55,560 --> 00:09:00,630
1980 American romance and adventure film

190
00:08:58,140 --> 00:09:03,060
directed by Randal Kleiser so a little

191
00:09:00,630 --> 00:09:05,010
robotic but it's pretty good and some

192
00:09:03,060 --> 00:09:06,119
text speech systems in the past and

193
00:09:05,010 --> 00:09:07,950
that's kind of where I want to pivot

194
00:09:06,120 --> 00:09:09,959
into a little bit of the history of

195
00:09:07,950 --> 00:09:13,500
Texas Beach with the goal that we want

196
00:09:09,959 --> 00:09:16,170
to type a phrase and output an audio

197
00:09:13,500 --> 00:09:18,149
file that sounds as realistic or is

198
00:09:16,170 --> 00:09:20,579
similar to humans saying that phrase and

199
00:09:18,149 --> 00:09:21,750
reading it aloud so looking at the

200
00:09:20,580 --> 00:09:23,910
phrase I've been looking forward to

201
00:09:21,750 --> 00:09:26,930
blackhead all year we're going to go way

202
00:09:23,910 --> 00:09:29,819
back in time to 1999 with Microsoft Mike

203
00:09:26,930 --> 00:09:32,819
speaking this I've been looking forward

204
00:09:29,820 --> 00:09:35,220
to black and all year so a little bit

205
00:09:32,820 --> 00:09:36,990
robotic it's a concatenative system

206
00:09:35,220 --> 00:09:38,399
where it strings together a bunch of

207
00:09:36,990 --> 00:09:42,330
phonemes to make words and whole

208
00:09:38,399 --> 00:09:44,700
sentences but not so bad

209
00:09:42,330 --> 00:09:48,690
fast-forward another seven years we have

210
00:09:44,700 --> 00:09:50,990
a system Mary 3 I've been looking

211
00:09:48,690 --> 00:09:52,770
forward to blackhat all year so

212
00:09:50,990 --> 00:09:55,470
significant improvement a little

213
00:09:52,770 --> 00:09:57,689
monotonic but we're getting there and

214
00:09:55,470 --> 00:10:00,390
Mary 3 was made by a University of

215
00:09:57,690 --> 00:10:02,279
Saarland in Germany and it's using

216
00:10:00,390 --> 00:10:04,740
hidden Markov models to generate

217
00:10:02,279 --> 00:10:06,660
parameters for synthesizers parametric

218
00:10:04,740 --> 00:10:08,520
model and now fast-forward again we have

219
00:10:06,660 --> 00:10:11,100
a big product release by Apple

220
00:10:08,520 --> 00:10:13,579
coming out with Siri but I've been

221
00:10:11,100 --> 00:10:16,140
looking forward to blackhat all year so

222
00:10:13,580 --> 00:10:17,520
to our ears we can still hear a little

223
00:10:16,140 --> 00:10:19,350
bit of the robot eNOS but it's getting

224
00:10:17,520 --> 00:10:22,110
much better and we don't exactly know

225
00:10:19,350 --> 00:10:23,520
how co-work s-- but it's fair to assume

226
00:10:22,110 --> 00:10:25,080
that it uses a bunch of different

227
00:10:23,520 --> 00:10:26,400
approaches together concatenative

228
00:10:25,080 --> 00:10:28,500
parametric and even deep learning

229
00:10:26,400 --> 00:10:31,350
nowadays and so now we're gonna fast

230
00:10:28,500 --> 00:10:34,350
forward to close to today 1 or 2 years

231
00:10:31,350 --> 00:10:37,110
ago we're listening to DC TTS which is

232
00:10:34,350 --> 00:10:39,900
deep convolutional Texas peach I've been

233
00:10:37,110 --> 00:10:40,890
looking forward to blackhead all year so

234
00:10:39,900 --> 00:10:42,569
we're starting to get a little bit of

235
00:10:40,890 --> 00:10:43,920
highs and lows pitched a little bit of

236
00:10:42,570 --> 00:10:45,510
interesting pauses and start and get

237
00:10:43,920 --> 00:10:47,670
much much better now

238
00:10:45,510 --> 00:10:51,959
this was this work was done by two

239
00:10:47,670 --> 00:10:53,790
independent researchers in Tokyo and now

240
00:10:51,959 --> 00:10:56,489
the last model that I want to talk about

241
00:10:53,790 --> 00:10:59,010
is Taco Tron 2 which came out by Google

242
00:10:56,490 --> 00:11:01,589
last year I've been looking forward to

243
00:10:59,010 --> 00:11:03,270
blackhat all year and if you were

244
00:11:01,589 --> 00:11:04,530
listening over the phone to somebody

245
00:11:03,270 --> 00:11:08,010
like this it would

246
00:11:04,530 --> 00:11:12,150
I'd be fooled and it was trying to talk

247
00:11:08,010 --> 00:11:14,610
to me I'd listen I'd buy and say yeah

248
00:11:12,150 --> 00:11:16,020
this is me this model made by Google and

249
00:11:14,610 --> 00:11:19,410
this is a deep learning approach the

250
00:11:16,020 --> 00:11:21,960
same thing with DC TTS which is trained

251
00:11:19,410 --> 00:11:23,939
purely just by examples text and audio

252
00:11:21,960 --> 00:11:27,900
and just shown a bunch of them know

253
00:11:23,940 --> 00:11:31,320
handwritten rules so now we've heard a

254
00:11:27,900 --> 00:11:32,880
few of the samples I want to go into a

255
00:11:31,320 --> 00:11:35,970
first approach which was taking

256
00:11:32,880 --> 00:11:37,680
advantage of Gann discriminators so we

257
00:11:35,970 --> 00:11:40,560
wanted to use gams but a generative

258
00:11:37,680 --> 00:11:42,569
adversarial networks quickly dan's

259
00:11:40,560 --> 00:11:44,699
are composed of two components a

260
00:11:42,570 --> 00:11:46,200
discriminator and a generator one tries

261
00:11:44,700 --> 00:11:47,670
to fool the other and the other tries to

262
00:11:46,200 --> 00:11:49,680
discriminate and trying to detect if

263
00:11:47,670 --> 00:11:51,000
it's being fooled and after playing this

264
00:11:49,680 --> 00:11:51,959
game the discriminator and generator

265
00:11:51,000 --> 00:11:54,090
become very good at their respective

266
00:11:51,960 --> 00:11:56,790
roles and what we want is a very

267
00:11:54,090 --> 00:11:58,620
powerful discriminator unlike what most

268
00:11:56,790 --> 00:12:00,270
researchers want which is having a very

269
00:11:58,620 --> 00:12:02,130
powerful generator generate fake samples

270
00:12:00,270 --> 00:12:06,390
we want a powerful discriminator to tell

271
00:12:02,130 --> 00:12:07,920
us what's fake and so in this framework

272
00:12:06,390 --> 00:12:09,540
we trained an existing architecture

273
00:12:07,920 --> 00:12:12,270
called wave Gann on the ASV spoof

274
00:12:09,540 --> 00:12:14,189
dataset per significant amount of epochs

275
00:12:12,270 --> 00:12:17,579
and a bunch of hyper parameter

276
00:12:14,190 --> 00:12:20,070
combinations on our discriminate to be

277
00:12:17,580 --> 00:12:21,390
nice and strong however we found that

278
00:12:20,070 --> 00:12:22,680
after training that the discriminator

279
00:12:21,390 --> 00:12:25,500
wasn't really powerful enough to

280
00:12:22,680 --> 00:12:26,579
generalize to other forms of speech by

281
00:12:25,500 --> 00:12:28,230
other models that's never seen before

282
00:12:26,580 --> 00:12:30,570
and we don't think that this training

283
00:12:28,230 --> 00:12:32,280
approach is a lost cause we believe that

284
00:12:30,570 --> 00:12:34,740
there's a couple of future directions we

285
00:12:32,280 --> 00:12:36,600
can take this approach to really beef up

286
00:12:34,740 --> 00:12:38,940
the discriminator namely giving it

287
00:12:36,600 --> 00:12:40,080
samples from different models giving it

288
00:12:38,940 --> 00:12:43,710
richer features which I'll be talking

289
00:12:40,080 --> 00:12:47,580
about in a second and or doing some sort

290
00:12:43,710 --> 00:12:49,290
of multi-phase training approach like

291
00:12:47,580 --> 00:12:52,020
training the discriminator after this

292
00:12:49,290 --> 00:12:55,709
converged inside of Ag and framework and

293
00:12:52,020 --> 00:12:56,730
in its own separate training loop so and

294
00:12:55,710 --> 00:12:59,790
I'm gonna go to our second approach

295
00:12:56,730 --> 00:13:02,250
which we're taking influence from from

296
00:12:59,790 --> 00:13:03,810
signal processing and using by spectral

297
00:13:02,250 --> 00:13:06,420
analysis specifically using the by

298
00:13:03,810 --> 00:13:08,459
spectrum of raw audio as the evaluating

299
00:13:06,420 --> 00:13:10,680
feature and this was shown to work by

300
00:13:08,460 --> 00:13:13,410
young researchers at Albany in Berkeley

301
00:13:10,680 --> 00:13:17,310
so we're gonna take the BAI coherence of

302
00:13:13,410 --> 00:13:18,030
a signal which is a calculation to

303
00:13:17,310 --> 00:13:20,270
represent

304
00:13:18,030 --> 00:13:23,430
or correlations in the frequency domain

305
00:13:20,270 --> 00:13:27,810
and quanta quantifies phase coupling

306
00:13:23,430 --> 00:13:29,699
across two different waveforms and this

307
00:13:27,810 --> 00:13:31,589
is a picture of a small section of the

308
00:13:29,700 --> 00:13:32,280
back coherence of a human saying there

309
00:13:31,590 --> 00:13:34,260
are different cultures in different

310
00:13:32,280 --> 00:13:36,120
apartments and it's a nice pretty

311
00:13:34,260 --> 00:13:39,240
picture we'll talk about how we use that

312
00:13:36,120 --> 00:13:41,280
so we're gonna take the aggregated by

313
00:13:39,240 --> 00:13:44,190
coherence by doing a sliding window over

314
00:13:41,280 --> 00:13:47,189
this entire waveform and average up by

315
00:13:44,190 --> 00:13:50,400
spectrums to produce a unique signature

316
00:13:47,190 --> 00:13:51,690
about this waveform and we can see but I

317
00:13:50,400 --> 00:13:53,490
have a little 3x3 right here of

318
00:13:51,690 --> 00:13:55,470
different text speech systems saying

319
00:13:53,490 --> 00:13:56,910
different phrases and they look like

320
00:13:55,470 --> 00:13:59,310
pretty pictures but actually they

321
00:13:56,910 --> 00:14:02,430
contain information about who is

322
00:13:59,310 --> 00:14:04,339
speaking and how they're speaking and we

323
00:14:02,430 --> 00:14:06,390
can take high-level statistical features

324
00:14:04,340 --> 00:14:09,960
namely just the mean or standard

325
00:14:06,390 --> 00:14:13,230
deviation and plot this and we get some

326
00:14:09,960 --> 00:14:16,580
interesting results that so here's a

327
00:14:13,230 --> 00:14:19,650
figure on the left side every dot is a

328
00:14:16,580 --> 00:14:22,350
individual audio recording on the x-axis

329
00:14:19,650 --> 00:14:24,150
is the mean magnitude of the micro

330
00:14:22,350 --> 00:14:26,490
hearing tested by spectrum and on the

331
00:14:24,150 --> 00:14:28,620
y-axis is the mean phase and if we plot

332
00:14:26,490 --> 00:14:30,420
for each waveform color is indicating

333
00:14:28,620 --> 00:14:32,070
who is speaker we can start to see a

334
00:14:30,420 --> 00:14:34,469
little bit of interesting clustering

335
00:14:32,070 --> 00:14:36,660
effects going on indicating who which

336
00:14:34,470 --> 00:14:39,810
speakers what and so we can plug this

337
00:14:36,660 --> 00:14:42,270
into an out-of-the-box classifier namely

338
00:14:39,810 --> 00:14:44,310
we use an SVM and we can plot the

339
00:14:42,270 --> 00:14:47,460
decision boundary and if you fall within

340
00:14:44,310 --> 00:14:49,619
the blue blob you are real but if you're

341
00:14:47,460 --> 00:14:52,350
in the red blob we call you a deep fake

342
00:14:49,620 --> 00:14:55,140
and this achieves upwards of 95%

343
00:14:52,350 --> 00:15:00,210
accuracy on the LJ speech it is a subset

344
00:14:55,140 --> 00:15:02,280
of it so I want to talk about the

345
00:15:00,210 --> 00:15:03,600
takeaways now that detection with these

346
00:15:02,280 --> 00:15:06,449
machines is an inevitable cat and mouse

347
00:15:03,600 --> 00:15:08,910
game and by spectral analysis works for

348
00:15:06,450 --> 00:15:10,740
now but you can easily incorporate these

349
00:15:08,910 --> 00:15:12,990
artifacts in these neural network loss

350
00:15:10,740 --> 00:15:15,900
functions to try and make sure that

351
00:15:12,990 --> 00:15:18,210
these by coherence artifacts mimic what

352
00:15:15,900 --> 00:15:20,930
humans do and we believe that Ganz might

353
00:15:18,210 --> 00:15:25,130
be the long-term solution instead to

354
00:15:20,930 --> 00:15:27,479
reach this high fidelity discrimination

355
00:15:25,130 --> 00:15:28,680
so here are some references if you want

356
00:15:27,480 --> 00:15:30,390
to download the code to reproduce some

357
00:15:28,680 --> 00:15:31,378
of this some research you can find on my

358
00:15:30,390 --> 00:15:35,389
github and

359
00:15:31,379 --> 00:15:35,389
I'm gonna transfer that to Jonathan

360
00:15:37,009 --> 00:15:44,429
alright okay so we won't ask the

361
00:15:42,689 --> 00:15:46,410
question what kind of deep fake

362
00:15:44,429 --> 00:15:48,539
detection do we want so on the one hand

363
00:15:46,410 --> 00:15:50,519
we can just continue throwing data at it

364
00:15:48,539 --> 00:15:52,379
I mean we're pretty good at that and

365
00:15:50,519 --> 00:15:53,399
that works for now but it's like as I

366
00:15:52,379 --> 00:15:55,529
also saying it's always this

367
00:15:53,399 --> 00:15:57,199
cat-and-mouse game but if we want to

368
00:15:55,529 --> 00:15:59,489
move towards a more general-purpose

369
00:15:57,199 --> 00:16:01,079
algorithm independent sort of

370
00:15:59,489 --> 00:16:03,059
independent of the generation algorithm

371
00:16:01,079 --> 00:16:05,219
defect detection we need to take

372
00:16:03,059 --> 00:16:06,899
insights from phonetics and neuroscience

373
00:16:05,220 --> 00:16:08,970
which will tell us respectively what

374
00:16:06,899 --> 00:16:11,099
speech should sound like and how the

375
00:16:08,970 --> 00:16:13,049
human auditory system processes it and

376
00:16:11,099 --> 00:16:15,169
so with that I'm gonna give you three

377
00:16:13,049 --> 00:16:17,879
things today I'm going to talk about one

378
00:16:15,169 --> 00:16:19,319
one possible way we can use phonetics to

379
00:16:17,879 --> 00:16:23,009
look for new features to detect these

380
00:16:19,319 --> 00:16:24,509
defects to one possible new architecture

381
00:16:23,009 --> 00:16:26,099
we can implement in our artificial

382
00:16:24,509 --> 00:16:28,289
neural networks that's inspired by the

383
00:16:26,099 --> 00:16:30,179
auditory system and then three new

384
00:16:28,289 --> 00:16:32,939
technique using mice to try and study

385
00:16:30,179 --> 00:16:35,189
these mechanistically so listening to

386
00:16:32,939 --> 00:16:36,809
speech is hard first of all it's a

387
00:16:35,189 --> 00:16:38,998
hierarchical process so starting at the

388
00:16:36,809 --> 00:16:40,889
top level of sentences we have dear

389
00:16:38,999 --> 00:16:44,369
Verna Hertz are giving us an existing

390
00:16:40,889 --> 00:16:46,229
it's insanity among penguins and so that

391
00:16:44,369 --> 00:16:48,059
top sentence levels broken down into

392
00:16:46,229 --> 00:16:49,470
individual words but then the atoms of

393
00:16:48,059 --> 00:16:52,169
speech are really phonemes the

394
00:16:49,470 --> 00:16:53,999
individual so and Gwynn's the smallest

395
00:16:52,169 --> 00:16:56,519
thing you can think of but here these

396
00:16:53,999 --> 00:16:58,879
phonemes is extremely fast we have 10 to

397
00:16:56,519 --> 00:17:01,139
30 phonemes per second in normal speech

398
00:16:58,879 --> 00:17:03,449
and not only that everyone's voice is

399
00:17:01,139 --> 00:17:06,329
different so we have to normalize to the

400
00:17:03,449 --> 00:17:08,398
voiced Amber rate prosody etc and so

401
00:17:06,329 --> 00:17:10,769
what that means is that the auditory

402
00:17:08,398 --> 00:17:12,418
system has to compress its

403
00:17:10,769 --> 00:17:14,128
representation of speech it has to throw

404
00:17:12,419 --> 00:17:16,199
away a lot of redundant information

405
00:17:14,128 --> 00:17:18,980
that's not informative and it also has

406
00:17:16,199 --> 00:17:21,029
to normalize to each of these features

407
00:17:18,980 --> 00:17:24,149
but it's not just the problem that

408
00:17:21,029 --> 00:17:26,009
speech is extremely variable because it

409
00:17:24,148 --> 00:17:28,018
the rate normal rates of speech the

410
00:17:26,009 --> 00:17:30,509
preceding and succeeding phonemes will

411
00:17:28,019 --> 00:17:31,769
influence each individual phoneme we

412
00:17:30,509 --> 00:17:33,090
actually have rid of this problem of Co

413
00:17:31,769 --> 00:17:34,980
articulation so for example in these

414
00:17:33,090 --> 00:17:37,350
videos take a look at where the tongue

415
00:17:34,980 --> 00:17:42,149
is when we produce the but in each of

416
00:17:37,350 --> 00:17:44,480
these sounds so starting with EB EB and

417
00:17:42,149 --> 00:17:44,479
then

418
00:17:44,850 --> 00:17:49,289
so even though the sound sounds nearly

419
00:17:47,399 --> 00:17:51,090
identical when you look at the actual

420
00:17:49,289 --> 00:17:52,529
spectrum of the sound the frequencies

421
00:17:51,090 --> 00:17:54,480
that are present in it in the center

422
00:17:52,529 --> 00:17:56,220
plot here they're actually not even

423
00:17:54,480 --> 00:17:59,159
close to identical so Co articulation

424
00:17:56,220 --> 00:18:01,470
means that we don't have a unique

425
00:17:59,159 --> 00:18:05,100
acoustic signature for each individual

426
00:18:01,470 --> 00:18:06,600
phonemes but this is useful because this

427
00:18:05,100 --> 00:18:09,570
is it means means that we have this sort

428
00:18:06,600 --> 00:18:11,100
of combinatoric explosion of possible

429
00:18:09,570 --> 00:18:12,899
speech waveforms that could be used to

430
00:18:11,100 --> 00:18:15,149
actually sound like an individual

431
00:18:12,899 --> 00:18:18,000
phoneme and so when generating these

432
00:18:15,149 --> 00:18:20,100
defects if the neural network isn't

433
00:18:18,000 --> 00:18:21,929
specifically conditioned to take into

434
00:18:20,100 --> 00:18:23,658
account this Co articulation phenomenon

435
00:18:21,929 --> 00:18:26,669
it's possible that it would generate

436
00:18:23,659 --> 00:18:28,980
sounds that sound real but acoustically

437
00:18:26,669 --> 00:18:30,960
aren't anywhere near to what the actual

438
00:18:28,980 --> 00:18:32,789
speech sounds like and so this is just a

439
00:18:30,960 --> 00:18:36,809
possible new vector we can use to target

440
00:18:32,789 --> 00:18:38,700
these targets deep fakes and so the

441
00:18:36,809 --> 00:18:40,168
auditory system is designed to be

442
00:18:38,700 --> 00:18:43,289
gullible because this speech perception

443
00:18:40,169 --> 00:18:44,970
project problem is so hard it has to

444
00:18:43,289 --> 00:18:47,070
collapse across these sort of redundant

445
00:18:44,970 --> 00:18:49,049
and complex and overlapping feature

446
00:18:47,070 --> 00:18:50,879
spaces and so that's why he fakes work

447
00:18:49,049 --> 00:18:53,039
is because they might not be

448
00:18:50,879 --> 00:18:54,928
acoustically perfect but because the

449
00:18:53,039 --> 00:18:57,120
objective of the auditory system is just

450
00:18:54,929 --> 00:18:59,039
to understand speech rather than dissect

451
00:18:57,120 --> 00:19:00,959
every possible acoustic detail about it

452
00:18:59,039 --> 00:19:03,360
it's possible to hide in the feature

453
00:19:00,960 --> 00:19:04,740
space and so the little that we know

454
00:19:03,360 --> 00:19:06,750
about how the brain actually does this

455
00:19:04,740 --> 00:19:08,669
comes from epileptic patients mostly who

456
00:19:06,750 --> 00:19:10,649
need to have electrodes embedded in

457
00:19:08,669 --> 00:19:12,659
their brains and their patients enough

458
00:19:10,649 --> 00:19:14,039
to let us do experiments on them but we

459
00:19:12,659 --> 00:19:16,470
know very little and so really all we

460
00:19:14,039 --> 00:19:18,470
know is that just like some regions so

461
00:19:16,470 --> 00:19:21,299
some posterior or rear part of the

462
00:19:18,470 --> 00:19:23,159
temporal cortex signals on sets of

463
00:19:21,299 --> 00:19:24,750
phrases and then there's recurrent

464
00:19:23,159 --> 00:19:27,950
circuitry that sort of computes these

465
00:19:24,750 --> 00:19:29,789
sort of trajectories betwee between

466
00:19:27,950 --> 00:19:32,610
phonemes but the rest is basically

467
00:19:29,789 --> 00:19:34,110
theory and so the reason why we can't

468
00:19:32,610 --> 00:19:36,899
really study this is because speech is

469
00:19:34,110 --> 00:19:38,610
too fast basically 20 milliseconds of

470
00:19:36,899 --> 00:19:42,239
sound is gonna distinguish a book from a

471
00:19:38,610 --> 00:19:44,250
putt and neurons are too small for the

472
00:19:42,240 --> 00:19:45,059
typical fMRI resolution to resolve so

473
00:19:44,250 --> 00:19:47,700
there are about six hundred thirty

474
00:19:45,059 --> 00:19:50,190
thousand neurons in one voxel so if our

475
00:19:47,700 --> 00:19:53,549
techniques are 1 million times too big

476
00:19:50,190 --> 00:19:55,139
and 1,000 times too slow we can do what

477
00:19:53,549 --> 00:19:58,440
we always do as neuroscientists and that

478
00:19:55,139 --> 00:20:01,168
is use mice so what we

479
00:19:58,440 --> 00:20:02,759
done already is we've taught my student

480
00:20:01,169 --> 00:20:04,169
it between English phonemes and so in

481
00:20:02,759 --> 00:20:05,789
particular where they're discriminating

482
00:20:04,169 --> 00:20:07,799
between these consonant vowel pairs

483
00:20:05,789 --> 00:20:10,710
consonant vowel classes so they want to

484
00:20:07,799 --> 00:20:12,269
learn but versus gut and so I'll show

485
00:20:10,710 --> 00:20:14,370
you a demonstration of the task in just

486
00:20:12,269 --> 00:20:16,139
one minute but the general ideas that we

487
00:20:14,370 --> 00:20:17,580
want to walk them through a series of

488
00:20:16,139 --> 00:20:19,769
stages that increase in difficulty

489
00:20:17,580 --> 00:20:21,449
adding new recordings vowels and

490
00:20:19,769 --> 00:20:22,740
speakers and then eventually test them

491
00:20:21,450 --> 00:20:24,990
on tokens that they've never heard

492
00:20:22,740 --> 00:20:27,269
before so this is a mouse performing the

493
00:20:24,990 --> 00:20:29,399
task and poke in the center here some

494
00:20:27,269 --> 00:20:31,529
sound got this one right went and got

495
00:20:29,399 --> 00:20:32,789
some water on the right here that one

496
00:20:31,529 --> 00:20:34,409
was a good sound so these are pitch

497
00:20:32,789 --> 00:20:35,309
shifted because the mouse audiogram is

498
00:20:34,409 --> 00:20:38,159
different but they're otherwise

499
00:20:35,309 --> 00:20:40,649
identical to normal speech sounds and so

500
00:20:38,159 --> 00:20:43,110
they're quite good at it and so when we

501
00:20:40,649 --> 00:20:45,299
evaluate their actual performance we can

502
00:20:43,110 --> 00:20:46,620
see that just walking through the levels

503
00:20:45,299 --> 00:20:49,350
of difficulty on this plot on the right

504
00:20:46,620 --> 00:20:51,629
their training set accuracy it has a

505
00:20:49,350 --> 00:20:53,490
wide range naturally but about 75%

506
00:20:51,629 --> 00:20:55,980
accurate and then as you increase the

507
00:20:53,490 --> 00:20:57,779
difficulty going to novel tokens novel

508
00:20:55,980 --> 00:20:59,460
vowels speakers and then finally the

509
00:20:57,779 --> 00:21:01,169
hardest category novel speaker in Bell

510
00:20:59,460 --> 00:21:03,210
word there basically is nothing similar

511
00:21:01,169 --> 00:21:05,549
to what's going on in the training set

512
00:21:03,210 --> 00:21:09,870
there their accuracy only drops by about

513
00:21:05,549 --> 00:21:12,360
10% and youthfully their accuracy is

514
00:21:09,870 --> 00:21:14,850
sort of non-uniform so each Mouse

515
00:21:12,360 --> 00:21:16,110
doesn't get everything wrong for it

516
00:21:14,850 --> 00:21:18,059
equally they have these unique

517
00:21:16,110 --> 00:21:21,029
characteristic patterns of what they get

518
00:21:18,059 --> 00:21:23,840
wrong and this is stable across several

519
00:21:21,029 --> 00:21:26,129
mice trained on the same training set so

520
00:21:23,840 --> 00:21:28,259
we've also validated this by training

521
00:21:26,129 --> 00:21:29,459
them on a different set of so I sorry I

522
00:21:28,259 --> 00:21:31,289
should have walked it left it is flawed

523
00:21:29,460 --> 00:21:33,629
a bit more so this plot is broken down

524
00:21:31,289 --> 00:21:35,309
vertically by breaking in first by

525
00:21:33,629 --> 00:21:37,259
consonant pairs that's the big blocks

526
00:21:35,309 --> 00:21:38,340
top and bottom and then within those you

527
00:21:37,259 --> 00:21:40,230
have different speakers and then

528
00:21:38,340 --> 00:21:43,049
different vowels and then so accuracy

529
00:21:40,230 --> 00:21:45,330
goes from black to red from zero to a

530
00:21:43,049 --> 00:21:46,529
hundred percent so anyway we compare two

531
00:21:45,330 --> 00:21:48,928
different groups of mice trained on

532
00:21:46,529 --> 00:21:51,419
different sets of tokens and they have

533
00:21:48,929 --> 00:21:53,879
completely separate patterns of accuracy

534
00:21:51,419 --> 00:21:57,149
so if you take a look at speaker three

535
00:21:53,879 --> 00:21:59,009
and look at the accuracy for the g's and

536
00:21:57,149 --> 00:22:01,320
the bees they basically totally reverse

537
00:21:59,009 --> 00:22:02,940
the bias of the first group and so this

538
00:22:01,320 --> 00:22:04,980
is useful for us because we can look at

539
00:22:02,940 --> 00:22:07,259
us as neuroscience because we look at

540
00:22:04,980 --> 00:22:09,690
the way that mice process speech but

541
00:22:07,259 --> 00:22:11,220
it's useful for detecting deep pigs

542
00:22:09,690 --> 00:22:11,610
because we believe that the mice are

543
00:22:11,220 --> 00:22:13,440
sort of

544
00:22:11,610 --> 00:22:15,780
auditory blank slates that they can

545
00:22:13,440 --> 00:22:17,640
learn really complex feature feature

546
00:22:15,780 --> 00:22:20,580
sets it's possible for them to sort of

547
00:22:17,640 --> 00:22:22,410
learn really complicated classification

548
00:22:20,580 --> 00:22:24,030
problems because they're cat they're

549
00:22:22,410 --> 00:22:27,630
these they have these really complex

550
00:22:24,030 --> 00:22:31,110
representations of the classes so why

551
00:22:27,630 --> 00:22:32,910
mice is because we can do this so this

552
00:22:31,110 --> 00:22:34,919
is calcium imaging looking at the

553
00:22:32,910 --> 00:22:37,290
activity of thousands of neurons

554
00:22:34,920 --> 00:22:39,510
simultaneously across the entire surface

555
00:22:37,290 --> 00:22:42,240
of cortex at two different spatial and

556
00:22:39,510 --> 00:22:43,860
temporal scales and so what we can do by

557
00:22:42,240 --> 00:22:46,860
using mice is we can actually observe

558
00:22:43,860 --> 00:22:49,139
the way that the mice learn these these

559
00:22:46,860 --> 00:22:53,459
deep fade categories and the way that

560
00:22:49,140 --> 00:22:54,870
they compute them and so what we next

561
00:22:53,460 --> 00:22:57,540
wanted to learn is that some of our mice

562
00:22:54,870 --> 00:22:59,909
failed to learn the tasks we wanted to

563
00:22:57,540 --> 00:23:01,740
know why and so humans have the same

564
00:22:59,910 --> 00:23:03,630
problem to where you can't really hear

565
00:23:01,740 --> 00:23:07,140
acoustic contrasts that are outside of

566
00:23:03,630 --> 00:23:08,760
your language and so one common example

567
00:23:07,140 --> 00:23:10,740
is that just like some south east

568
00:23:08,760 --> 00:23:13,010
language Southeast Asian language

569
00:23:10,740 --> 00:23:16,080
speakers can't distinguish between

570
00:23:13,010 --> 00:23:17,400
liquids ORS and oles because in that in

571
00:23:16,080 --> 00:23:18,928
those languages there that's not a

572
00:23:17,400 --> 00:23:21,210
contrast that's not a difference that

573
00:23:18,929 --> 00:23:24,299
exists in that language and this is

574
00:23:21,210 --> 00:23:25,679
generally true with languages and so we

575
00:23:24,299 --> 00:23:27,840
believe that this is the same sort of

576
00:23:25,679 --> 00:23:29,970
mechanism as what causes deep-six to be

577
00:23:27,840 --> 00:23:32,120
effective because we have these really

578
00:23:29,970 --> 00:23:34,410
fast and abbreviated processing rules

579
00:23:32,120 --> 00:23:35,570
that become concrete throughout our

580
00:23:34,410 --> 00:23:39,750
lifetime that allow us to actually

581
00:23:35,570 --> 00:23:41,520
extract phonetic identity and so to

582
00:23:39,750 --> 00:23:42,900
investigate this first we to start by

583
00:23:41,520 --> 00:23:45,030
information is stored in the synapses

584
00:23:42,900 --> 00:23:46,860
like artificial neural networks it's the

585
00:23:45,030 --> 00:23:49,500
pattern of weights and connectivity that

586
00:23:46,860 --> 00:23:52,168
stores the information but some neurons

587
00:23:49,500 --> 00:23:54,450
have sort of sweaters that prevent new

588
00:23:52,169 --> 00:23:57,960
new synapses from being formed and

589
00:23:54,450 --> 00:23:58,950
stabilized existing synapses so this is

590
00:23:57,960 --> 00:24:00,600
where they actually look like they're

591
00:23:58,950 --> 00:24:03,270
sort of staining for these synapses they

592
00:24:00,600 --> 00:24:05,580
completely coat the neuron but then we

593
00:24:03,270 --> 00:24:09,090
wondered what if we destroy them and let

594
00:24:05,580 --> 00:24:10,649
them grow back basically reset the set

595
00:24:09,090 --> 00:24:13,830
of synaptic weights and connections for

596
00:24:10,650 --> 00:24:15,780
these neurons and so in mice what that

597
00:24:13,830 --> 00:24:18,299
had previously completely failed to

598
00:24:15,780 --> 00:24:19,889
learn the tasks they've been failing

599
00:24:18,299 --> 00:24:21,179
basically at chance so just like on the

600
00:24:19,890 --> 00:24:23,550
y-axis you have the different levels of

601
00:24:21,179 --> 00:24:25,020
training and accuracy these mites that

602
00:24:23,550 --> 00:24:27,570
we're at complete chance for

603
00:24:25,020 --> 00:24:29,810
months we injected this enzyme that

604
00:24:27,570 --> 00:24:33,540
digested their peri neuronal that's I

605
00:24:29,810 --> 00:24:35,220
reset inapt equate matrix and then

606
00:24:33,540 --> 00:24:37,320
suddenly they were able to learn so

607
00:24:35,220 --> 00:24:38,550
suddenly they were able to learn to hear

608
00:24:37,320 --> 00:24:40,830
acoustic contract so they were not

609
00:24:38,550 --> 00:24:42,570
before and so what this is useful for

610
00:24:40,830 --> 00:24:45,600
detecting defects is because it gives us

611
00:24:42,570 --> 00:24:48,120
an a mechanistic clue into what we can

612
00:24:45,600 --> 00:24:50,850
improve in our networks so not all

613
00:24:48,120 --> 00:24:53,070
neurons where peri neuronal Nets indeed

614
00:24:50,850 --> 00:24:55,980
it's just these types of local

615
00:24:53,070 --> 00:24:57,770
inhibitory neurons that pool excitation

616
00:24:55,980 --> 00:24:59,790
and then have this sort of global

617
00:24:57,770 --> 00:25:02,510
nonspecific inhibition of the cells

618
00:24:59,790 --> 00:25:05,280
around them and so we think that this is

619
00:25:02,510 --> 00:25:07,230
computationally distinct from regular

620
00:25:05,280 --> 00:25:08,910
excitation that we use in artificial

621
00:25:07,230 --> 00:25:11,100
neural networks because these local

622
00:25:08,910 --> 00:25:13,050
inhibitory neurons integrate the recent

623
00:25:11,100 --> 00:25:15,179
past to steer recruit this recurrent

624
00:25:13,050 --> 00:25:16,980
computation and this is the way that it

625
00:25:15,180 --> 00:25:21,060
stores these sort of long term stable

626
00:25:16,980 --> 00:25:23,100
auditory percepts and so finally we

627
00:25:21,060 --> 00:25:24,389
think that it's time to do what we did

628
00:25:23,100 --> 00:25:26,310
with the visual system to make

629
00:25:24,390 --> 00:25:28,440
convolutional neural nets and pick

630
00:25:26,310 --> 00:25:30,270
inspiration from the auditory system in

631
00:25:28,440 --> 00:25:32,340
order to use that to make the next

632
00:25:30,270 --> 00:25:35,340
generation of defect detecting

633
00:25:32,340 --> 00:25:36,810
algorithms and so to do that we think

634
00:25:35,340 --> 00:25:39,179
the technique that we should do is

635
00:25:36,810 --> 00:25:42,690
training mice to detect fake and real

636
00:25:39,180 --> 00:25:45,060
speech thank you oh I'll give you some

637
00:25:42,690 --> 00:25:46,530
takeaways just as a summary here people

638
00:25:45,060 --> 00:25:48,300
are still pretty good at spotting fakes

639
00:25:46,530 --> 00:25:50,370
but it's always going to be a cat and

640
00:25:48,300 --> 00:25:52,100
mouse game and so the real way to solve

641
00:25:50,370 --> 00:25:54,750
this problem is to take inspiration from

642
00:25:52,100 --> 00:25:57,419
phonetics and from biological neural

643
00:25:54,750 --> 00:26:03,420
networks thank you

644
00:25:57,420 --> 00:26:03,420
[Applause]

