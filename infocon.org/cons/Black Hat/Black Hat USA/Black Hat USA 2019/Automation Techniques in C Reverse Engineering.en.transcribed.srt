1
00:00:00,000 --> 00:00:05,790
good afternoon and welcome to automation

2
00:00:02,460 --> 00:00:07,379
techniques in C++ reverse engineering in

3
00:00:05,790 --> 00:00:10,769
Laguna JKL

4
00:00:07,379 --> 00:00:12,540
presented by rolf rolous just a couple

5
00:00:10,769 --> 00:00:14,400
of quick notes don't forget to stop by

6
00:00:12,540 --> 00:00:17,250
the business hall located in Mandalay

7
00:00:14,400 --> 00:00:19,680
Bay and blackhat Arsenal is also in the

8
00:00:17,250 --> 00:00:21,300
business hall on level 2 and then one

9
00:00:19,680 --> 00:00:23,550
final reminder to make sure that all of

10
00:00:21,300 --> 00:00:25,699
your phones are silenced thank you very

11
00:00:23,550 --> 00:00:25,699
much

12
00:00:30,179 --> 00:00:36,660
hello everybody thank you for coming to

13
00:00:32,668 --> 00:00:39,199
my talk this is about automation

14
00:00:36,660 --> 00:00:42,718
techniques and C++ reverse engineering

15
00:00:39,200 --> 00:00:46,800
the genesis of this research is I was

16
00:00:42,719 --> 00:00:50,010
doing research for an upcoming training

17
00:00:46,800 --> 00:00:51,809
class in C++ reverse engineering so I

18
00:00:50,010 --> 00:00:54,680
was practicing statically reverse

19
00:00:51,809 --> 00:00:57,120
engineering some large C++ binaries and

20
00:00:54,680 --> 00:00:58,949
for the first few weeks of this I was

21
00:00:57,120 --> 00:01:03,660
just using the same techniques that I've

22
00:00:58,949 --> 00:01:05,640
been using for the past 15 years and it

23
00:01:03,660 --> 00:01:06,210
was it was working but it was a slow

24
00:01:05,640 --> 00:01:08,580
going

25
00:01:06,210 --> 00:01:12,179
tedious process I noticed I was spending

26
00:01:08,580 --> 00:01:14,250
85 to 95 percent of my time creating

27
00:01:12,180 --> 00:01:17,780
type information that is to say

28
00:01:14,250 --> 00:01:20,700
recreating structures and assigning

29
00:01:17,780 --> 00:01:23,100
structures in the disassembly listing as

30
00:01:20,700 --> 00:01:26,280
well as setting types to hex raised

31
00:01:23,100 --> 00:01:28,199
variables and because this was consuming

32
00:01:26,280 --> 00:01:30,329
so much of my time I decided maybe it's

33
00:01:28,200 --> 00:01:33,810
a good idea to try to figure out can I

34
00:01:30,329 --> 00:01:36,360
automate these techniques so we're gonna

35
00:01:33,810 --> 00:01:38,070
be focusing on dynamically allocated

36
00:01:36,360 --> 00:01:41,729
structures we're gonna be deriving

37
00:01:38,070 --> 00:01:44,100
metadata from run time accesses and then

38
00:01:41,729 --> 00:01:46,890
collecting this data and exploiting it

39
00:01:44,100 --> 00:01:48,600
within Ida and hex rays there are two

40
00:01:46,890 --> 00:01:51,299
primary analyses that I'm going to

41
00:01:48,600 --> 00:01:54,210
present one tracks accesses two

42
00:01:51,299 --> 00:01:56,909
structures and the other one is a

43
00:01:54,210 --> 00:01:59,130
dynamic data flow analysis tracking data

44
00:01:56,909 --> 00:02:05,549
from allocation sites into function

45
00:01:59,130 --> 00:02:07,949
arguments so pictorially the big picture

46
00:02:05,549 --> 00:02:11,129
behind why did I do this research in the

47
00:02:07,950 --> 00:02:13,270
first place what is this all about this

48
00:02:11,129 --> 00:02:15,519
is your stereotypical

49
00:02:13,270 --> 00:02:18,760
see looking D compilation listing all of

50
00:02:15,520 --> 00:02:22,690
this naked size type pointer

51
00:02:18,760 --> 00:02:26,280
dereferences frankly I find this stuff

52
00:02:22,690 --> 00:02:29,910
borderline unreadable or at least

53
00:02:26,280 --> 00:02:32,410
requiring more effort than necessary so

54
00:02:29,910 --> 00:02:35,020
on the other hand when I switched to the

55
00:02:32,410 --> 00:02:38,170
next slide the difference here is I've

56
00:02:35,020 --> 00:02:40,210
created a structure and I have set the

57
00:02:38,170 --> 00:02:42,130
function prototype such that both

58
00:02:40,210 --> 00:02:44,830
arguments are that structure and it

59
00:02:42,130 --> 00:02:47,500
returns void and now you can see all of

60
00:02:44,830 --> 00:02:49,540
those nasty casts disappear that this

61
00:02:47,500 --> 00:02:52,360
looks more or less what the original

62
00:02:49,540 --> 00:02:55,480
source code look like - names and

63
00:02:52,360 --> 00:02:57,640
comments so type information is the

64
00:02:55,480 --> 00:03:00,489
difference between unreadable gibberish

65
00:02:57,640 --> 00:03:03,070
and stuff that's Pleasant and easy to

66
00:03:00,490 --> 00:03:04,930
read but it's tedious to create and

67
00:03:03,070 --> 00:03:07,000
apply all this type information to the

68
00:03:04,930 --> 00:03:13,480
database so we're gonna focus on

69
00:03:07,000 --> 00:03:17,130
automating these tasks so we're going to

70
00:03:13,480 --> 00:03:17,130
be targeting each structure that is

71
00:03:17,700 --> 00:03:24,579
exercised through through runtime

72
00:03:21,670 --> 00:03:26,140
runtime behavior we're gonna want to

73
00:03:24,580 --> 00:03:28,750
figure out the size of each structure

74
00:03:26,140 --> 00:03:30,670
the layout which is to say where the

75
00:03:28,750 --> 00:03:33,820
fields are within the structure as well

76
00:03:30,670 --> 00:03:35,920
as what their sizes are every location

77
00:03:33,820 --> 00:03:37,209
within the binary that accesses the

78
00:03:35,920 --> 00:03:39,609
structures that were interested in

79
00:03:37,209 --> 00:03:42,280
figure out type relationships between

80
00:03:39,610 --> 00:03:44,080
fields of different structures and also

81
00:03:42,280 --> 00:03:46,090
we'll be interested in variable and

82
00:03:44,080 --> 00:03:51,190
function argument types and there's some

83
00:03:46,090 --> 00:03:53,260
more experimental stuff also so once I

84
00:03:51,190 --> 00:03:57,040
really got in the swing of applying

85
00:03:53,260 --> 00:04:00,820
these techniques I found that I was

86
00:03:57,040 --> 00:04:03,370
applying more more type information to

87
00:04:00,820 --> 00:04:05,590
my database in a matter of days than I

88
00:04:03,370 --> 00:04:07,990
had in six weeks of manual reverse

89
00:04:05,590 --> 00:04:09,580
engineering for the for one of the

90
00:04:07,990 --> 00:04:11,020
targets I've been looking at these

91
00:04:09,580 --> 00:04:15,970
techniques helped me to recover about

92
00:04:11,020 --> 00:04:18,070
two 200 structures and sent about the

93
00:04:15,970 --> 00:04:20,858
types for about six thousand variables

94
00:04:18,070 --> 00:04:23,770
and x-rays automatically and apply tens

95
00:04:20,858 --> 00:04:26,388
of thousands of structure offsets in the

96
00:04:23,770 --> 00:04:32,150
disassembly listing all

97
00:04:26,389 --> 00:04:35,180
made or semi-automated fashion so

98
00:04:32,150 --> 00:04:37,669
without further ado this is the first of

99
00:04:35,180 --> 00:04:39,560
the two analyses that I mentioned this

100
00:04:37,669 --> 00:04:44,448
has to do with tracking accesses to

101
00:04:39,560 --> 00:04:47,060
structures so in this regard I was

102
00:04:44,449 --> 00:04:49,460
inspired by existing academic work I

103
00:04:47,060 --> 00:04:53,990
remembered a paper that I had read many

104
00:04:49,460 --> 00:04:56,688
years ago called Howard and there's a

105
00:04:53,990 --> 00:04:58,550
few other related works such as die

106
00:04:56,689 --> 00:05:02,719
instruct for which source code is

107
00:04:58,550 --> 00:05:04,759
available so I had in mind that I wanted

108
00:05:02,719 --> 00:05:05,240
to experiment with ideas similar to

109
00:05:04,759 --> 00:05:08,659
these

110
00:05:05,240 --> 00:05:10,669
however these ideas seem to have some

111
00:05:08,659 --> 00:05:12,490
fundamental performance overhead

112
00:05:10,669 --> 00:05:14,359
associated with them so I wanted to

113
00:05:12,490 --> 00:05:16,250
experiment with them to see if I could

114
00:05:14,360 --> 00:05:18,919
eliminate that as well as make the

115
00:05:16,250 --> 00:05:21,289
techniques a little bit more flexible so

116
00:05:18,919 --> 00:05:28,188
what follows is my journey along those

117
00:05:21,289 --> 00:05:32,060
lines so on the high level the way these

118
00:05:28,189 --> 00:05:35,089
tools work is they locate and hook the

119
00:05:32,060 --> 00:05:40,219
memory allocation functions malloc and

120
00:05:35,089 --> 00:05:42,469
free but also things like realloc inside

121
00:05:40,219 --> 00:05:45,680
of these hooks they record metadata

122
00:05:42,469 --> 00:05:47,629
about every memory allocation where it

123
00:05:45,680 --> 00:05:51,050
was allocated from what's the allocated

124
00:05:47,629 --> 00:05:52,909
pointer how big is it then they run the

125
00:05:51,050 --> 00:05:55,789
programs under a dynamic binary

126
00:05:52,909 --> 00:05:57,949
instrumentation log every access within

127
00:05:55,789 --> 00:06:00,438
one of these dynamically allocated

128
00:05:57,949 --> 00:06:02,120
memory regions and finally this

129
00:06:00,439 --> 00:06:04,490
generates a lot of data which within

130
00:06:02,120 --> 00:06:07,370
post process to obtain information about

131
00:06:04,490 --> 00:06:12,169
structures so I'll go through these

132
00:06:07,370 --> 00:06:14,419
steps individually step one is to locate

133
00:06:12,169 --> 00:06:16,060
the memory allocators that you're

134
00:06:14,419 --> 00:06:19,039
interested in

135
00:06:16,060 --> 00:06:22,520
this might different depending upon the

136
00:06:19,039 --> 00:06:24,979
scenario upon the slide here I have your

137
00:06:22,520 --> 00:06:28,460
memory allocator czar imported from some

138
00:06:24,979 --> 00:06:29,990
other library via the import table but

139
00:06:28,460 --> 00:06:31,818
it might also be the case that maybe

140
00:06:29,990 --> 00:06:34,960
there's a custom memory allocator in the

141
00:06:31,819 --> 00:06:36,940
binary which is a function so

142
00:06:34,960 --> 00:06:41,859
just locate the locate these things

143
00:06:36,940 --> 00:06:44,770
number one number two hook them redirect

144
00:06:41,860 --> 00:06:47,139
them into our own memory allocation

145
00:06:44,770 --> 00:06:49,120
functions again this might be as simple

146
00:06:47,139 --> 00:06:51,310
as overwriting a function pointer if

147
00:06:49,120 --> 00:06:53,380
it's an import or it might be more along

148
00:06:51,310 --> 00:06:54,639
the lines of having to hook a function

149
00:06:53,380 --> 00:06:59,199
prologue if it's something that's

150
00:06:54,639 --> 00:07:03,220
contained in the binary the hooks

151
00:06:59,199 --> 00:07:05,199
themselves are not that difficult for

152
00:07:03,220 --> 00:07:07,479
example looking at the hook for malloc

153
00:07:05,199 --> 00:07:10,330
off to the left first thing it does is

154
00:07:07,479 --> 00:07:11,860
just call the original malloc two to

155
00:07:10,330 --> 00:07:14,560
obtain whatever pointer would have been

156
00:07:11,860 --> 00:07:18,039
obtained by calling malloc then it calls

157
00:07:14,560 --> 00:07:19,960
this function remember which memorizes

158
00:07:18,039 --> 00:07:22,630
the details for the memory allocation

159
00:07:19,960 --> 00:07:25,090
which is to say what the pointer is how

160
00:07:22,630 --> 00:07:27,460
big is it and where was it allocated

161
00:07:25,090 --> 00:07:29,919
from and finally just return that back

162
00:07:27,460 --> 00:07:32,109
to the caller and the free hook is even

163
00:07:29,919 --> 00:07:34,270
simpler just discard the information

164
00:07:32,110 --> 00:07:36,819
about that allocation and return back to

165
00:07:34,270 --> 00:07:39,070
the caller so this is all transparent to

166
00:07:36,819 --> 00:07:40,720
the application when it comes down to it

167
00:07:39,070 --> 00:07:42,550
the application really doesn't care

168
00:07:40,720 --> 00:07:44,139
about its memory allocator it's pretty

169
00:07:42,550 --> 00:07:48,720
much just a function that it calls to

170
00:07:44,139 --> 00:07:48,720
obtain pointers or to destroy pointers

171
00:07:50,190 --> 00:07:55,030
so inside of the malloc hook the

172
00:07:53,349 --> 00:07:58,030
remember function is going to store

173
00:07:55,030 --> 00:08:00,369
allocation records which is the pointer

174
00:07:58,030 --> 00:08:02,799
itself that was allocated the size and

175
00:08:00,370 --> 00:08:05,409
the r-va within the image that it was

176
00:08:02,800 --> 00:08:07,210
allocated so this is recorded relative

177
00:08:05,409 --> 00:08:09,570
to the base address of the image so we

178
00:08:07,210 --> 00:08:11,710
don't have issues with a SLR and

179
00:08:09,570 --> 00:08:18,580
aggregating the results across multiple

180
00:08:11,710 --> 00:08:20,948
runs it's going to store these

181
00:08:18,580 --> 00:08:24,370
allocation records in some sort of data

182
00:08:20,949 --> 00:08:26,949
structure so later on we're going to

183
00:08:24,370 --> 00:08:29,860
have to look up addresses within these

184
00:08:26,949 --> 00:08:31,900
allocations so we'll be looking up not

185
00:08:29,860 --> 00:08:34,440
just by the base of the allocation but

186
00:08:31,900 --> 00:08:37,059
also anywhere within the allocations so

187
00:08:34,440 --> 00:08:40,930
for this purpose usually something like

188
00:08:37,059 --> 00:08:43,569
a binary tree is preferred AVL trees are

189
00:08:40,929 --> 00:08:44,410
good here they have strict balancing

190
00:08:43,570 --> 00:08:46,930
requirements

191
00:08:44,410 --> 00:08:49,240
whereas red-black trees work but

192
00:08:46,930 --> 00:08:52,449
their lookups are a little slower than

193
00:08:49,240 --> 00:08:54,460
AVL trees I recently realized you could

194
00:08:52,450 --> 00:08:56,680
use something along the lines of not

195
00:08:54,460 --> 00:08:58,330
quite a hash table but sort of segment

196
00:08:56,680 --> 00:09:01,890
the address is the same way that the

197
00:08:58,330 --> 00:09:05,730
page table translation process does it

198
00:09:01,890 --> 00:09:05,730
that's yet to be explored

199
00:09:06,390 --> 00:09:16,900
so remember adds items into this map and

200
00:09:09,990 --> 00:09:18,850
forget removes them okay so that's the

201
00:09:16,900 --> 00:09:20,980
part where we hook the memory allocator

202
00:09:18,850 --> 00:09:24,580
and record allocation memory to a

203
00:09:20,980 --> 00:09:30,130
metadata now we're going to find

204
00:09:24,580 --> 00:09:32,350
accesses to these allocations so the

205
00:09:30,130 --> 00:09:34,660
next step in these tools is to run the

206
00:09:32,350 --> 00:09:37,210
programs under dynamic binary

207
00:09:34,660 --> 00:09:39,910
instrumentation and provide whatever

208
00:09:37,210 --> 00:09:42,070
inputs you need to drive execution

209
00:09:39,910 --> 00:09:44,949
throughout the program you know if

210
00:09:42,070 --> 00:09:47,410
you're running Adobe Reader or something

211
00:09:44,950 --> 00:09:50,470
this means provide a PDF for it to open

212
00:09:47,410 --> 00:09:52,510
or something along these lines and then

213
00:09:50,470 --> 00:09:59,380
we're going to log accesses to the

214
00:09:52,510 --> 00:10:02,200
allocated structures and record it so

215
00:09:59,380 --> 00:10:07,350
via dbi we are going to insert callback

216
00:10:02,200 --> 00:10:07,350
routines on every memory access

217
00:10:09,570 --> 00:10:16,720
so the callback routine is going to be

218
00:10:14,200 --> 00:10:19,330
given the address that is to be accessed

219
00:10:16,720 --> 00:10:22,330
by the memory access it's going to take

220
00:10:19,330 --> 00:10:24,370
that look it up within the map that

221
00:10:22,330 --> 00:10:28,209
we're that we keep the allocation

222
00:10:24,370 --> 00:10:30,339
metadata in and if we find the address

223
00:10:28,209 --> 00:10:32,380
within one of the allocation records

224
00:10:30,339 --> 00:10:34,779
that means we have just discovered a

225
00:10:32,380 --> 00:10:36,910
memory access to one of the dynamically

226
00:10:34,779 --> 00:10:40,120
allocated memory regions so we're going

227
00:10:36,910 --> 00:10:43,600
to log that which is to say let's say

228
00:10:40,120 --> 00:10:46,140
this instruction was observed accessing

229
00:10:43,600 --> 00:10:48,790
that particular address ending in 28 and

230
00:10:46,140 --> 00:10:51,160
we look that address up in the map and

231
00:10:48,790 --> 00:10:54,010
we find that we have that same address

232
00:10:51,160 --> 00:10:56,230
ending in 0-0 with the size of 80

233
00:10:54,010 --> 00:11:00,339
hexadecimal having been allocated at

234
00:10:56,230 --> 00:11:00,850
that RBA so now we just log the details

235
00:11:00,339 --> 00:11:02,860
of that

236
00:11:00,850 --> 00:11:05,470
access where the allocation came from

237
00:11:02,860 --> 00:11:07,540
how big the allocation was where'd the

238
00:11:05,470 --> 00:11:09,430
instruction that access it was how big

239
00:11:07,540 --> 00:11:11,349
the access was we're within the

240
00:11:09,430 --> 00:11:16,388
structure was it accessing and was it a

241
00:11:11,350 --> 00:11:21,779
read or write so we just run the program

242
00:11:16,389 --> 00:11:25,540
and collect up all of this metadata and

243
00:11:21,779 --> 00:11:28,750
afterwards we have a enormous text file

244
00:11:25,540 --> 00:11:36,399
which we then take and post process to

245
00:11:28,750 --> 00:11:38,949
recover higher-level information so

246
00:11:36,399 --> 00:11:41,529
we'll have information set logged

247
00:11:38,949 --> 00:11:43,389
through the proceeding process such as

248
00:11:41,529 --> 00:11:49,779
the following the table that we see on

249
00:11:43,389 --> 00:11:51,819
the slide here so the first step is to

250
00:11:49,779 --> 00:11:56,199
take these things and just segregate

251
00:11:51,819 --> 00:11:57,699
them by the allocation site just take

252
00:11:56,199 --> 00:12:01,029
everything that was allocated from the

253
00:11:57,699 --> 00:12:07,750
same location and aggregate all of those

254
00:12:01,029 --> 00:12:10,209
things together and at this point if we

255
00:12:07,750 --> 00:12:13,779
happen to know for some reason a priori

256
00:12:10,209 --> 00:12:15,670
that two sites allocate the same data

257
00:12:13,779 --> 00:12:21,819
type that we can at this point just

258
00:12:15,670 --> 00:12:23,649
merge their data together and now we can

259
00:12:21,819 --> 00:12:27,099
take this information and rebuild

260
00:12:23,649 --> 00:12:30,130
structures from it so sort for any given

261
00:12:27,100 --> 00:12:33,370
allocation take take the accesses that

262
00:12:30,130 --> 00:12:35,470
we observed sort the offsets at which

263
00:12:33,370 --> 00:12:40,449
the accesses took place and remove

264
00:12:35,470 --> 00:12:44,649
duplicates and then simply convert those

265
00:12:40,449 --> 00:12:48,279
into structured declarations choose C

266
00:12:44,649 --> 00:12:49,959
data types of the appropriate size and

267
00:12:48,279 --> 00:12:52,839
lay them out in the sequence in which

268
00:12:49,959 --> 00:13:00,160
they were observed so that seems pretty

269
00:12:52,839 --> 00:13:02,199
easy a brief digression in fact through

270
00:13:00,160 --> 00:13:04,870
this process we don't just discover a

271
00:13:02,199 --> 00:13:07,240
flat list of fields but we can discover

272
00:13:04,870 --> 00:13:12,059
nested structures contained within other

273
00:13:07,240 --> 00:13:14,000
structures so for example if we observed

274
00:13:12,059 --> 00:13:15,829
the access

275
00:13:14,000 --> 00:13:20,080
we see on the top of the slide here you

276
00:13:15,830 --> 00:13:24,110
can see the x86 instruction has EA X + 8

277
00:13:20,080 --> 00:13:28,010
whereas the recorded accent offset is 28

278
00:13:24,110 --> 00:13:29,750
so the only way that's possible is if at

279
00:13:28,010 --> 00:13:32,780
that at the time that we logged this

280
00:13:29,750 --> 00:13:34,610
data that EA X was pointing plus 20

281
00:13:32,780 --> 00:13:37,310
hexadecimal into that particular

282
00:13:34,610 --> 00:13:39,650
allocation site so that means the

283
00:13:37,310 --> 00:13:42,140
program is passing around pointers plus

284
00:13:39,650 --> 00:13:44,569
20 hexadecimal into that allocation and

285
00:13:42,140 --> 00:13:46,580
what that means in brief is that there's

286
00:13:44,570 --> 00:13:49,100
a structure that begins at plus 20

287
00:13:46,580 --> 00:13:51,920
hexadecimal so we can use this

288
00:13:49,100 --> 00:13:59,920
information to recover nested structures

289
00:13:51,920 --> 00:14:02,900
not just a flat list of fields okay so

290
00:13:59,920 --> 00:14:05,810
the picture so far was a little

291
00:14:02,900 --> 00:14:08,840
simplified compared to real life as it

292
00:14:05,810 --> 00:14:11,780
happens there is some noise some

293
00:14:08,840 --> 00:14:13,790
imperfection in the data some of its

294
00:14:11,780 --> 00:14:15,350
from natural causes in the source code

295
00:14:13,790 --> 00:14:17,360
some of it comes from compiler

296
00:14:15,350 --> 00:14:24,170
optimizations we'll talk briefly about

297
00:14:17,360 --> 00:14:28,100
those and what we do about them so first

298
00:14:24,170 --> 00:14:31,069
of all it's perfectly legal to cast

299
00:14:28,100 --> 00:14:33,890
integer data types from one size to the

300
00:14:31,070 --> 00:14:35,780
other so we might be dealing with a

301
00:14:33,890 --> 00:14:37,640
situation where we have a structure in

302
00:14:35,780 --> 00:14:40,640
the source code which has a 32-bit

303
00:14:37,640 --> 00:14:43,790
integer and then if some access to that

304
00:14:40,640 --> 00:14:46,130
structure is actually only using 16 bits

305
00:14:43,790 --> 00:14:48,290
worth of it we'll see what's in the

306
00:14:46,130 --> 00:14:51,740
middle column which is the use of a

307
00:14:48,290 --> 00:14:54,079
16-bit register or for example we could

308
00:14:51,740 --> 00:14:56,480
also just cast to the low eight bits of

309
00:14:54,080 --> 00:14:58,460
that of that structure of that field and

310
00:14:56,480 --> 00:15:04,760
so we'll see the use of an 8-bit

311
00:14:58,460 --> 00:15:07,670
register and so this casting might give

312
00:15:04,760 --> 00:15:10,220
us multiple different sized accesses to

313
00:15:07,670 --> 00:15:13,189
the same location in the structure which

314
00:15:10,220 --> 00:15:15,650
leads to ambiguity about what field

315
00:15:13,190 --> 00:15:19,520
actually is supposed to be at that

316
00:15:15,650 --> 00:15:21,740
location so my solution to this and most

317
00:15:19,520 --> 00:15:24,880
of most of these related issues that

318
00:15:21,740 --> 00:15:27,460
we'll see is I just use the ax

319
00:15:24,880 --> 00:15:29,620
that we generated at runtime and then

320
00:15:27,460 --> 00:15:31,660
choose the configuration that agrees

321
00:15:29,620 --> 00:15:34,060
with the largest number of observed data

322
00:15:31,660 --> 00:15:41,140
points and this turns out to work very

323
00:15:34,060 --> 00:15:42,969
well for most of these issues another

324
00:15:41,140 --> 00:15:45,340
issue has to do with compiler

325
00:15:42,970 --> 00:15:47,650
optimizations here again we're assuming

326
00:15:45,340 --> 00:15:49,480
there's a 32-bit integer contained

327
00:15:47,650 --> 00:15:51,850
within a structure and here we're

328
00:15:49,480 --> 00:15:55,060
testing it against the 32-bit constant

329
00:15:51,850 --> 00:15:56,440
40 hexadecimal so the natural way to

330
00:15:55,060 --> 00:15:58,420
implement that an assembly language

331
00:15:56,440 --> 00:16:00,610
would be the topmost assembly language

332
00:15:58,420 --> 00:16:03,670
instruction which is treat that location

333
00:16:00,610 --> 00:16:06,490
as a D word and encode a D word size

334
00:16:03,670 --> 00:16:09,790
constant as the last four bytes of the

335
00:16:06,490 --> 00:16:12,670
instruction but actually it's perfectly

336
00:16:09,790 --> 00:16:16,000
legal to convert the instruction into a

337
00:16:12,670 --> 00:16:18,910
bite-sized access instead where since

338
00:16:16,000 --> 00:16:20,560
the only nonzero byte within that 32-bit

339
00:16:18,910 --> 00:16:23,530
constant that we're adding in is the

340
00:16:20,560 --> 00:16:26,920
lowest one and just take that and turn

341
00:16:23,530 --> 00:16:29,230
it into an 8-bit access instead so again

342
00:16:26,920 --> 00:16:31,300
this leads to ambiguity about what is

343
00:16:29,230 --> 00:16:36,000
the size of the field at that location

344
00:16:31,300 --> 00:16:36,000
we might see multiple size accesses

345
00:16:37,230 --> 00:16:46,270
highly related but slightly different

346
00:16:40,180 --> 00:16:49,239
is this what if on the last slide

347
00:16:46,270 --> 00:16:54,010
instead of ending with 40 hexadecimal we

348
00:16:49,240 --> 00:16:57,520
ended with 400 hexadecimal so this this

349
00:16:54,010 --> 00:17:01,630
gives rise to a similar optimization

350
00:16:57,520 --> 00:17:04,569
opportunity except since the 400

351
00:17:01,630 --> 00:17:08,800
hexadecimal only has a nonzero byte at

352
00:17:04,569 --> 00:17:10,869
+1 into the constant that we can still

353
00:17:08,800 --> 00:17:12,970
convert it into a byte size access

354
00:17:10,869 --> 00:17:15,819
exactly as we did on the previous slide

355
00:17:12,970 --> 00:17:18,130
but we have to increment the address

356
00:17:15,819 --> 00:17:20,619
that we're accessing by 1 which is why

357
00:17:18,130 --> 00:17:22,900
you see the es I plus 1 in the second

358
00:17:20,619 --> 00:17:24,909
assembly language instruction so now it

359
00:17:22,900 --> 00:17:26,740
looks like we have this field within the

360
00:17:24,910 --> 00:17:28,780
structure that's not really there that

361
00:17:26,740 --> 00:17:32,730
just sort of that access arose as a

362
00:17:28,780 --> 00:17:32,730
result of a compiler optimization

363
00:17:35,519 --> 00:17:41,220
another another issue is called store

364
00:17:38,860 --> 00:17:45,039
aggregation this is when you have

365
00:17:41,220 --> 00:17:47,470
multiple smaller writes all targeting

366
00:17:45,039 --> 00:17:50,408
adjacent fields that the compiler can

367
00:17:47,470 --> 00:17:53,830
take them and aggregate them into one

368
00:17:50,409 --> 00:17:56,169
larger write in this case we have two

369
00:17:53,830 --> 00:17:57,789
boolean variables right next to one

370
00:17:56,169 --> 00:18:00,309
another in the structure and we're

371
00:17:57,789 --> 00:18:03,129
assigning both of them to zero so rather

372
00:18:00,309 --> 00:18:05,769
than generating two instructions that

373
00:18:03,130 --> 00:18:07,330
move one byte at a time the compiler can

374
00:18:05,769 --> 00:18:09,129
detect that these things are right next

375
00:18:07,330 --> 00:18:11,439
to one another and it said write one

376
00:18:09,129 --> 00:18:14,230
word at a time to override both of those

377
00:18:11,440 --> 00:18:16,659
fields at the same time so whereas the

378
00:18:14,230 --> 00:18:19,000
previous optimizations that we saw can

379
00:18:16,659 --> 00:18:20,649
lead to smaller accesses at a given

380
00:18:19,000 --> 00:18:24,509
location this one can actually lead to

381
00:18:20,649 --> 00:18:24,508
bigger accesses at a given location

382
00:18:27,389 --> 00:18:33,309
another source of imprecision is bulk

383
00:18:31,120 --> 00:18:37,809
copies and assignment things like mem

384
00:18:33,309 --> 00:18:40,200
set and mem copy so off to the left we

385
00:18:37,809 --> 00:18:43,090
see a structure with a fairly intricate

386
00:18:40,200 --> 00:18:45,820
configuration of fields within the first

387
00:18:43,090 --> 00:18:48,158
eight byte there are two 8-bit sized

388
00:18:45,820 --> 00:18:52,000
fields one 16-bit field and then the

389
00:18:48,159 --> 00:18:54,700
32-bit field and whereas memset if we

390
00:18:52,000 --> 00:18:58,000
set this structure to zero the code that

391
00:18:54,700 --> 00:19:01,059
might be generated simply overwrites 64

392
00:18:58,000 --> 00:19:03,669
bits at a time of zeroes oblivious to

393
00:19:01,059 --> 00:19:12,759
whatever the layout of the structure is

394
00:19:03,669 --> 00:19:15,340
just right bulk data so for all of the

395
00:19:12,759 --> 00:19:19,049
issues so far my solution has just been

396
00:19:15,340 --> 00:19:22,330
to count the number of accesses we see

397
00:19:19,049 --> 00:19:23,980
to given at given sizes and offsets

398
00:19:22,330 --> 00:19:25,600
within the structure and then just

399
00:19:23,980 --> 00:19:27,399
choose the configuration that agrees

400
00:19:25,600 --> 00:19:30,100
with the largest number of accesses and

401
00:19:27,399 --> 00:19:31,959
this works very well plus its principal

402
00:19:30,100 --> 00:19:34,029
we don't have to make guesses we just

403
00:19:31,960 --> 00:19:39,190
try to optimize according to the data

404
00:19:34,029 --> 00:19:42,700
that we see now there are two more that

405
00:19:39,190 --> 00:19:46,539
are a little uglier unions for example

406
00:19:42,700 --> 00:19:48,260
allows us to statically assign different

407
00:19:46,539 --> 00:19:50,210
types and different

408
00:19:48,260 --> 00:19:52,700
sizes to the same location within a

409
00:19:50,210 --> 00:19:54,740
structure so we might have an integer

410
00:19:52,700 --> 00:19:57,200
and a character pointer let's say in a

411
00:19:54,740 --> 00:19:59,630
union that means it's perfectly legal

412
00:19:57,200 --> 00:20:01,490
for us to see differently size access to

413
00:19:59,630 --> 00:20:04,070
the same field because there are in fact

414
00:20:01,490 --> 00:20:06,770
differently sized types being stored at

415
00:20:04,070 --> 00:20:08,510
that location so my solution of this one

416
00:20:06,770 --> 00:20:10,160
is the same as before and it's not a

417
00:20:08,510 --> 00:20:13,310
good solution it's basically to just

418
00:20:10,160 --> 00:20:16,660
ignore the fact that unions exist unions

419
00:20:13,310 --> 00:20:16,659
are kind of thorny honestly

420
00:20:16,960 --> 00:20:24,290
and finally array accesses produce these

421
00:20:21,260 --> 00:20:27,140
offsets non-constant offsets area of

422
00:20:24,290 --> 00:20:29,360
this RB x x for within the memory access

423
00:20:27,140 --> 00:20:30,920
so I have it in mind in the future I

424
00:20:29,360 --> 00:20:32,780
have some ideas for what to do about

425
00:20:30,920 --> 00:20:34,580
this but for now I'm just not handling

426
00:20:32,780 --> 00:20:36,170
this case at all I just punt

427
00:20:34,580 --> 00:20:38,379
anytime we see in access with a

428
00:20:36,170 --> 00:20:42,640
non-constant location just thrown away

429
00:20:38,380 --> 00:20:42,640
now that's not a real solution obviously

430
00:20:47,200 --> 00:20:54,290
ok so thus far I've largely been talking

431
00:20:51,650 --> 00:20:57,530
about the existing dbi based solutions

432
00:20:54,290 --> 00:21:00,020
as well as some of my solutions to the

433
00:20:57,530 --> 00:21:02,840
issues that I saw coming from using

434
00:21:00,020 --> 00:21:05,420
solutions like that one in actuality I

435
00:21:02,840 --> 00:21:09,919
did not use D bi for my implementation

436
00:21:05,420 --> 00:21:10,460
of this idea there are several reasons

437
00:21:09,920 --> 00:21:13,280
for this

438
00:21:10,460 --> 00:21:15,620
first one is I am simply not an expert

439
00:21:13,280 --> 00:21:18,050
when it comes to D bi and I anticipated

440
00:21:15,620 --> 00:21:20,090
there would be a learning curve to it

441
00:21:18,050 --> 00:21:22,639
and I wanted to see if the idea would

442
00:21:20,090 --> 00:21:25,580
work immediately so I kind of wanted to

443
00:21:22,640 --> 00:21:28,160
come up with a quick implementation but

444
00:21:25,580 --> 00:21:30,590
in fact there are some more principal

445
00:21:28,160 --> 00:21:33,290
and realistic reasons to look for

446
00:21:30,590 --> 00:21:35,990
solutions other than D bi so although

447
00:21:33,290 --> 00:21:38,330
the D bi solution is comprehensive and

448
00:21:35,990 --> 00:21:41,090
fully automated it also requires that

449
00:21:38,330 --> 00:21:43,129
you instrument every memory access that

450
00:21:41,090 --> 00:21:45,949
takes place throughout runtime execution

451
00:21:43,130 --> 00:21:47,930
means every time there's a memory access

452
00:21:45,950 --> 00:21:50,750
we're going to insert a lookup into a

453
00:21:47,930 --> 00:21:53,900
map so this is a fairly heavyweight

454
00:21:50,750 --> 00:21:55,790
application of D bi and the larger the

455
00:21:53,900 --> 00:21:58,250
overhead that means the harder it is to

456
00:21:55,790 --> 00:21:59,460
interact with the application the harder

457
00:21:58,250 --> 00:22:01,260
it is to interact with the app

458
00:21:59,460 --> 00:22:03,450
that means the less coverage we're able

459
00:22:01,260 --> 00:22:07,379
to drive and the less coverage there is

460
00:22:03,450 --> 00:22:09,060
means the fewer the a smaller amount of

461
00:22:07,380 --> 00:22:12,810
information we're able to observe about

462
00:22:09,060 --> 00:22:15,540
the structure accesses and furthermore

463
00:22:12,810 --> 00:22:18,120
no matter how we might try to optimize a

464
00:22:15,540 --> 00:22:19,950
dbi implementation that fundamentally

465
00:22:18,120 --> 00:22:22,290
the way the solution works is by

466
00:22:19,950 --> 00:22:25,140
instrumenting every memory access so

467
00:22:22,290 --> 00:22:33,810
there are real limitations about how far

468
00:22:25,140 --> 00:22:35,850
we can go with optimization so I just

469
00:22:33,810 --> 00:22:37,679
described the fundamental overhead from

470
00:22:35,850 --> 00:22:39,750
the approach itself

471
00:22:37,680 --> 00:22:42,840
there's also overhead with regards to

472
00:22:39,750 --> 00:22:46,140
having to track every allocation site

473
00:22:42,840 --> 00:22:48,750
within the program so we're in we're

474
00:22:46,140 --> 00:22:51,000
inserting these map lookups all over the

475
00:22:48,750 --> 00:22:53,900
place and the more allocation sites that

476
00:22:51,000 --> 00:22:56,580
we're tracking at any given time that

477
00:22:53,900 --> 00:23:00,620
more expensive of these map lookups are

478
00:22:56,580 --> 00:23:04,620
going to be so I wanted to know

479
00:23:00,620 --> 00:23:06,989
experiment with maybe maybe tracking

480
00:23:04,620 --> 00:23:11,760
less data at any given time could lead

481
00:23:06,990 --> 00:23:14,340
to better performance and finally these

482
00:23:11,760 --> 00:23:17,340
dbi based solutions are sort of just

483
00:23:14,340 --> 00:23:19,800
these like monolithic black box we're

484
00:23:17,340 --> 00:23:22,050
put in program press button get out

485
00:23:19,800 --> 00:23:23,820
structure configurations and I'm a

486
00:23:22,050 --> 00:23:26,430
professional reverse engineer maybe I

487
00:23:23,820 --> 00:23:28,830
can figure out better uses to which to

488
00:23:26,430 --> 00:23:30,030
put that data recovering structures is

489
00:23:28,830 --> 00:23:32,040
cool and all but maybe there's more

490
00:23:30,030 --> 00:23:35,280
there's more I can do with the data

491
00:23:32,040 --> 00:23:37,320
perhaps so I wanted to experiment how

492
00:23:35,280 --> 00:23:39,510
could I make this an interactive tool

493
00:23:37,320 --> 00:23:44,310
that reverse engineers could use in a

494
00:23:39,510 --> 00:23:45,990
friendly fashion so the ability to to

495
00:23:44,310 --> 00:23:47,760
choose parts of the program that we're

496
00:23:45,990 --> 00:23:50,280
interested in and how do I present the

497
00:23:47,760 --> 00:23:52,170
results to the user in a way that's most

498
00:23:50,280 --> 00:23:59,220
beneficial to them while they're reverse

499
00:23:52,170 --> 00:24:00,660
engineering so right roughly those are

500
00:23:59,220 --> 00:24:03,690
the directions that I'm going to explore

501
00:24:00,660 --> 00:24:06,150
trying to replace dbi with some other

502
00:24:03,690 --> 00:24:09,610
form of tracking accesses to structures

503
00:24:06,150 --> 00:24:11,560
and then allow more flexibility

504
00:24:09,610 --> 00:24:13,780
in what we're tracking and how we're

505
00:24:11,560 --> 00:24:15,850
tracking it performance optimize

506
00:24:13,780 --> 00:24:18,580
everything and try to make good use of

507
00:24:15,850 --> 00:24:28,449
the data be as friendly as we can make

508
00:24:18,580 --> 00:24:30,460
the reverse engineers lives easier so my

509
00:24:28,450 --> 00:24:33,150
first order of business was to figure

510
00:24:30,460 --> 00:24:36,340
out some way to track accesses to

511
00:24:33,150 --> 00:24:40,150
allocated data without using dynamic

512
00:24:36,340 --> 00:24:43,480
binary instrumentation and brainstorming

513
00:24:40,150 --> 00:24:47,350
about this my first idea was maybe I can

514
00:24:43,480 --> 00:24:50,950
use the x86 hardware read and write

515
00:24:47,350 --> 00:24:52,600
debug breakpoints so for example every

516
00:24:50,950 --> 00:24:54,400
time I call to malloc takes place just

517
00:24:52,600 --> 00:24:57,070
set read and write breakpoints across

518
00:24:54,400 --> 00:25:00,610
the entire structure so this isn't a

519
00:24:57,070 --> 00:25:03,280
good idea it does not work because we

520
00:25:00,610 --> 00:25:05,770
simply don't have enough breakpoints x86

521
00:25:03,280 --> 00:25:08,560
only gives us four breakpoints which

522
00:25:05,770 --> 00:25:13,330
means a total of 32 bytes of memory that

523
00:25:08,560 --> 00:25:17,169
we can track and that's not even enough

524
00:25:13,330 --> 00:25:19,060
to cover one small size structure that

525
00:25:17,170 --> 00:25:21,070
said though although the breakpoint idea

526
00:25:19,060 --> 00:25:24,310
does not work it does have this

527
00:25:21,070 --> 00:25:26,439
interesting feature where it sort of is

528
00:25:24,310 --> 00:25:28,960
fundamentally different in how it tracks

529
00:25:26,440 --> 00:25:30,900
the accesses whereas with the DPI

530
00:25:28,960 --> 00:25:35,140
solution we have to insert

531
00:25:30,900 --> 00:25:37,660
instrumentation all over the place and

532
00:25:35,140 --> 00:25:39,670
dig out the memory accesses by looking

533
00:25:37,660 --> 00:25:41,310
them up every time in the map with the

534
00:25:39,670 --> 00:25:43,690
breakpoint approach we can just specify

535
00:25:41,310 --> 00:25:45,639
here's the memory locations that were

536
00:25:43,690 --> 00:25:47,620
interested in and then the processor

537
00:25:45,640 --> 00:25:49,960
effectively gives us callbacks in the

538
00:25:47,620 --> 00:25:53,050
form of debug exceptions telling us when

539
00:25:49,960 --> 00:25:55,480
that memory is accesses so I wanted a

540
00:25:53,050 --> 00:25:57,550
solution with that kind of feature to it

541
00:25:55,480 --> 00:25:59,620
where I didn't have to instrument

542
00:25:57,550 --> 00:26:03,340
everything I could just sort of specify

543
00:25:59,620 --> 00:26:05,919
what it was that I wanted to track but

544
00:26:03,340 --> 00:26:07,600
fundamentally x86 hardware breakpoints

545
00:26:05,920 --> 00:26:09,220
can't do the job for us because we

546
00:26:07,600 --> 00:26:13,600
simply don't have enough of them on an

547
00:26:09,220 --> 00:26:15,610
architectural level so then I remembered

548
00:26:13,600 --> 00:26:19,270
there was a command in the kernel

549
00:26:15,610 --> 00:26:20,830
debugger soft dice and it's also been

550
00:26:19,270 --> 00:26:21,760
implemented in a couple of other tools

551
00:26:20,830 --> 00:26:25,210
in the meantime

552
00:26:21,760 --> 00:26:27,640
called breakpoint on memory range which

553
00:26:25,210 --> 00:26:30,130
allowed you to set as memory as many

554
00:26:27,640 --> 00:26:33,880
memory breakpoints as you wanted and of

555
00:26:30,130 --> 00:26:35,950
as large size as you wanted you can

556
00:26:33,880 --> 00:26:39,310
implement this in either user mode or

557
00:26:35,950 --> 00:26:42,400
kernel mode so Ida also implements this

558
00:26:39,310 --> 00:26:43,120
as does Olli debug so that sounds

559
00:26:42,400 --> 00:26:47,340
promising

560
00:26:43,120 --> 00:26:47,340
let's review briefly how that works

561
00:26:49,020 --> 00:26:53,490
fundamentally the implementation has to

562
00:26:51,490 --> 00:27:00,060
do with virtual memory and on-demand

563
00:26:53,490 --> 00:27:02,800
paging so in a demand paged environment

564
00:27:00,060 --> 00:27:06,190
processes appear to have a large address

565
00:27:02,800 --> 00:27:08,590
space but in reality they only consume

566
00:27:06,190 --> 00:27:12,190
as much memory as there are physical

567
00:27:08,590 --> 00:27:14,080
pages assigned to their virtual pages so

568
00:27:12,190 --> 00:27:16,120
for example on this diagram that the

569
00:27:14,080 --> 00:27:18,070
virtual page number 4 does not have a

570
00:27:16,120 --> 00:27:20,649
corresponding physical mapping so it

571
00:27:18,070 --> 00:27:27,639
doesn't have to consume a physical page

572
00:27:20,650 --> 00:27:32,920
for that for that virtual page the page

573
00:27:27,640 --> 00:27:35,710
table dictates the translations between

574
00:27:32,920 --> 00:27:37,330
virtual and physical pages basically

575
00:27:35,710 --> 00:27:40,060
specifies the high bits of the virtual

576
00:27:37,330 --> 00:27:42,280
page and the high bits of the

577
00:27:40,060 --> 00:27:44,950
corresponding physical page with some

578
00:27:42,280 --> 00:27:46,570
flags and also this present bit at the

579
00:27:44,950 --> 00:27:52,390
bottom which we'll talk about again in a

580
00:27:46,570 --> 00:27:54,370
minute as the program requested the

581
00:27:52,390 --> 00:27:58,180
operating system can allocate more

582
00:27:54,370 --> 00:28:02,699
memory and basically add new physical

583
00:27:58,180 --> 00:28:02,700
virtual to physical mappings on the fly

584
00:28:04,650 --> 00:28:11,380
at some point if the process starts

585
00:28:08,950 --> 00:28:12,940
running out of memory then the operating

586
00:28:11,380 --> 00:28:16,420
system can go around and start

587
00:28:12,940 --> 00:28:19,150
reclaiming memory so this makes use of

588
00:28:16,420 --> 00:28:21,300
the present flag at the bottom of the

589
00:28:19,150 --> 00:28:24,550
page table entry for that corresponding

590
00:28:21,300 --> 00:28:26,379
virtual to physical mapping so the

591
00:28:24,550 --> 00:28:28,419
operating system just writes the cott

592
00:28:26,380 --> 00:28:31,210
that copy of that physical page to disk

593
00:28:28,420 --> 00:28:33,930
sets the present bit to 0 and the page

594
00:28:31,210 --> 00:28:33,930
table entry

595
00:28:35,290 --> 00:28:40,360
and then later on when the program goes

596
00:28:37,960 --> 00:28:43,210
to try to access that page

597
00:28:40,360 --> 00:28:45,540
since the present bit is not set this

598
00:28:43,210 --> 00:28:48,160
results in an exception being generated

599
00:28:45,540 --> 00:28:50,520
the the the operating system kernel

600
00:28:48,160 --> 00:28:53,260
catches that page fault exception

601
00:28:50,520 --> 00:28:55,840
realizes that the exception arises from

602
00:28:53,260 --> 00:28:58,330
a member a page having been reclaimed

603
00:28:55,840 --> 00:29:00,909
and written to disk reads the page off

604
00:28:58,330 --> 00:29:04,360
the disk and then sets the present flag

605
00:29:00,910 --> 00:29:06,790
to 0 to 1 again and then continues

606
00:29:04,360 --> 00:29:09,429
execution so all of this happens in a

607
00:29:06,790 --> 00:29:11,139
transparent fashion the user mode

608
00:29:09,430 --> 00:29:12,670
application doesn't even realize that

609
00:29:11,140 --> 00:29:16,350
anything has happened the kernel just

610
00:29:12,670 --> 00:29:16,350
takes care of all that in the background

611
00:29:19,440 --> 00:29:25,780
so that's the background that this is

612
00:29:22,870 --> 00:29:29,679
how the BPR memory breakpoint feature

613
00:29:25,780 --> 00:29:32,920
works so we're going to make use of this

614
00:29:29,680 --> 00:29:34,960
nonpresent mechanism where for pages

615
00:29:32,920 --> 00:29:39,370
that were interested in tracking we set

616
00:29:34,960 --> 00:29:43,090
the present flag to to false that's

617
00:29:39,370 --> 00:29:44,500
going to give us exceptions when we try

618
00:29:43,090 --> 00:29:47,770
to add when the application tries to

619
00:29:44,500 --> 00:29:50,530
access the pages with if we find an

620
00:29:47,770 --> 00:29:53,590
access to what we're interested in we'll

621
00:29:50,530 --> 00:29:58,420
log it other than continue execution in

622
00:29:53,590 --> 00:30:00,879
any case so here's an animation of how

623
00:29:58,420 --> 00:30:03,070
this process plays out in real-time so

624
00:30:00,880 --> 00:30:07,180
let's assume that this first instruction

625
00:30:03,070 --> 00:30:10,030
here is going to access memory so let's

626
00:30:07,180 --> 00:30:15,730
assume that we have marked this page at

627
00:30:10,030 --> 00:30:18,730
eb x + 4 as non present so then when the

628
00:30:15,730 --> 00:30:22,300
instruction goes to execute because the

629
00:30:18,730 --> 00:30:26,410
memory is non present that processor

630
00:30:22,300 --> 00:30:28,570
generates a page fault exception now we

631
00:30:26,410 --> 00:30:31,000
have installed an exception Handler and

632
00:30:28,570 --> 00:30:34,689
we're able to inspect these inception

633
00:30:31,000 --> 00:30:36,970
exceptions that come in so first we see

634
00:30:34,690 --> 00:30:38,740
was this exception our fault which is to

635
00:30:36,970 --> 00:30:41,290
say is it a page fault that arose

636
00:30:38,740 --> 00:30:44,200
because we set the present flag to false

637
00:30:41,290 --> 00:30:46,300
on some page so if it wasn't we just

638
00:30:44,200 --> 00:30:47,330
pass it off the next exception handler

639
00:30:46,300 --> 00:30:55,850
in the chain if it

640
00:30:47,330 --> 00:30:58,189
we process it so if it was our fault now

641
00:30:55,850 --> 00:31:00,679
we are in the exact same position as the

642
00:30:58,190 --> 00:31:02,750
dbi based tools are where at this very

643
00:31:00,680 --> 00:31:05,660
moment now we know that this particular

644
00:31:02,750 --> 00:31:07,640
instruction tried to access some

645
00:31:05,660 --> 00:31:11,060
allocated region that we're interested

646
00:31:07,640 --> 00:31:14,390
in so right here this is how we replace

647
00:31:11,060 --> 00:31:17,030
D bi is log right in the in the page

648
00:31:14,390 --> 00:31:19,580
fault handler the details of where the

649
00:31:17,030 --> 00:31:23,480
allocation came from as well as what

650
00:31:19,580 --> 00:31:26,300
instruction accessed it so now we need

651
00:31:23,480 --> 00:31:29,000
to let the process a continued execution

652
00:31:26,300 --> 00:31:33,350
but it's a little tricky so we save the

653
00:31:29,000 --> 00:31:38,990
address of defaulting instruction we

654
00:31:33,350 --> 00:31:41,060
mark the page as present and before we

655
00:31:38,990 --> 00:31:44,780
continue execution we have to have some

656
00:31:41,060 --> 00:31:47,960
way of making sure that we get control

657
00:31:44,780 --> 00:31:49,460
again if we were to simply mark the page

658
00:31:47,960 --> 00:31:51,350
as non present and then just let the

659
00:31:49,460 --> 00:31:54,560
application run then we would basically

660
00:31:51,350 --> 00:31:56,540
have one-shot breakpoints we want to be

661
00:31:54,560 --> 00:31:59,960
able to track subsequent accesses to the

662
00:31:56,540 --> 00:32:02,510
same allocation so to do that we set the

663
00:31:59,960 --> 00:32:04,340
x86 trap flag which is the same

664
00:32:02,510 --> 00:32:06,800
mechanism that debuggers use to

665
00:32:04,340 --> 00:32:08,780
implement single stepping if the trap

666
00:32:06,800 --> 00:32:12,290
flag is set at the end of an instruction

667
00:32:08,780 --> 00:32:15,610
it causes the processor to generate a

668
00:32:12,290 --> 00:32:21,290
single step exception after it executes

669
00:32:15,610 --> 00:32:23,479
so then we resume execution now back

670
00:32:21,290 --> 00:32:25,550
trying to execute the program again the

671
00:32:23,480 --> 00:32:29,020
structure access succeeds this time

672
00:32:25,550 --> 00:32:32,149
because that memory is marked as present

673
00:32:29,020 --> 00:32:38,629
but since we set the trap flag that now

674
00:32:32,150 --> 00:32:40,940
the subsequent instruction false so back

675
00:32:38,630 --> 00:32:43,340
in our exception handler we see if this

676
00:32:40,940 --> 00:32:45,410
is a single step exception is it a

677
00:32:43,340 --> 00:32:47,330
single step exception immediately after

678
00:32:45,410 --> 00:32:49,430
the last instruction that we saw ie is

679
00:32:47,330 --> 00:32:50,960
this our fault if not pass it off the

680
00:32:49,430 --> 00:32:55,070
next Handler and the chain otherwise

681
00:32:50,960 --> 00:32:57,320
process it so now we make the page non

682
00:32:55,070 --> 00:33:00,290
present again so that on subsequent

683
00:32:57,320 --> 00:33:08,629
accesses will catch the we'll catch them

684
00:33:00,290 --> 00:33:10,670
and then just resume execution so that

685
00:33:08,630 --> 00:33:13,820
there is the architecture that I came up

686
00:33:10,670 --> 00:33:17,270
with for replacing dbi in tracking

687
00:33:13,820 --> 00:33:20,570
structure accesses where I install this

688
00:33:17,270 --> 00:33:23,389
exception Handler and it's has it

689
00:33:20,570 --> 00:33:25,669
activates it runs inside of each thread

690
00:33:23,390 --> 00:33:28,670
that is associated with the ordinary

691
00:33:25,670 --> 00:33:30,590
program so each thread just catches

692
00:33:28,670 --> 00:33:32,870
these page faults implements the

693
00:33:30,590 --> 00:33:35,270
exception logic and stores these

694
00:33:32,870 --> 00:33:37,070
accesses into a ring buffer and then I

695
00:33:35,270 --> 00:33:39,350
have a controller thread which just

696
00:33:37,070 --> 00:33:42,500
periodically pulls the ring buffers from

697
00:33:39,350 --> 00:33:49,459
the other threads and D duplicates the

698
00:33:42,500 --> 00:33:52,430
data and logs it to disk so since the

699
00:33:49,460 --> 00:33:54,500
last time I gave this presentation I had

700
00:33:52,430 --> 00:33:57,080
a few optimization ideas and some

701
00:33:54,500 --> 00:34:00,740
members of my prior audience also had

702
00:33:57,080 --> 00:34:04,520
some suggestions for me one person

703
00:34:00,740 --> 00:34:07,550
suggested that having two single step

704
00:34:04,520 --> 00:34:10,009
inside of the page fault handler is slow

705
00:34:07,550 --> 00:34:12,590
because this results in an extra user to

706
00:34:10,010 --> 00:34:15,860
kernel mode transition so if I were to

707
00:34:12,590 --> 00:34:18,590
implement a little emulator to mimic the

708
00:34:15,860 --> 00:34:20,960
effects of the instructions rather than

709
00:34:18,590 --> 00:34:23,179
simply letting it execute and having to

710
00:34:20,960 --> 00:34:25,790
incur this extra user kernel transition

711
00:34:23,179 --> 00:34:28,280
overhead that I might get a performance

712
00:34:25,790 --> 00:34:32,239
boost and he was right it was a nice 40

713
00:34:28,280 --> 00:34:35,419
percent performance increase some other

714
00:34:32,239 --> 00:34:37,790
people suggested that I could use guard

715
00:34:35,418 --> 00:34:41,469
pages instead of setting the pages as

716
00:34:37,790 --> 00:34:45,320
non presence guard pages has have this

717
00:34:41,469 --> 00:34:47,509
advantage of number one the operating

718
00:34:45,320 --> 00:34:49,790
system has optimized pathways for them

719
00:34:47,510 --> 00:34:54,080
because it uses guard pages internally

720
00:34:49,790 --> 00:34:56,570
and number two that what a guard page

721
00:34:54,080 --> 00:34:59,270
exception takes place that the operating

722
00:34:56,570 --> 00:35:02,120
system automatically marks the page as

723
00:34:59,270 --> 00:35:04,190
present so this eliminates another user

724
00:35:02,120 --> 00:35:06,770
kernel transition where we would have to

725
00:35:04,190 --> 00:35:09,650
call virtual protect to mark the page as

726
00:35:06,770 --> 00:35:12,560
present before we could single step that

727
00:35:09,650 --> 00:35:13,580
was another reasonable speed up and I

728
00:35:12,560 --> 00:35:15,920
did some standard

729
00:35:13,580 --> 00:35:18,620
optimization tricks with like forcing

730
00:35:15,920 --> 00:35:20,570
things to reside on different cores my

731
00:35:18,620 --> 00:35:22,250
lager thread should have low priority

732
00:35:20,570 --> 00:35:24,110
and it should be on the bad course and

733
00:35:22,250 --> 00:35:26,240
give all the good course with high

734
00:35:24,110 --> 00:35:28,940
priority to the the application itself

735
00:35:26,240 --> 00:35:32,600
and then I implemented a second version

736
00:35:28,940 --> 00:35:34,610
of the x86 emulator based on JIT so

737
00:35:32,600 --> 00:35:36,350
these numbers come from my laptop that

738
00:35:34,610 --> 00:35:39,620
was the trail of performance on my

739
00:35:36,350 --> 00:35:42,110
desktop it's more like 15.6 million page

740
00:35:39,620 --> 00:35:49,549
faults per minute million structure

741
00:35:42,110 --> 00:35:52,250
accesses it's pretty good so another

742
00:35:49,550 --> 00:35:54,950
major optimization idea I had had to do

743
00:35:52,250 --> 00:35:59,300
with only tracking specific allocation

744
00:35:54,950 --> 00:36:01,700
sites so it's heretofore I've shown you

745
00:35:59,300 --> 00:36:03,800
how these dbi tools work and the basic

746
00:36:01,700 --> 00:36:05,270
idea behind my replacement for it

747
00:36:03,800 --> 00:36:07,730
but I haven't really told you how we

748
00:36:05,270 --> 00:36:11,390
apply this page fault based memory

749
00:36:07,730 --> 00:36:14,060
tracking so we could either go the dbi

750
00:36:11,390 --> 00:36:16,490
route and just track every allocation in

751
00:36:14,060 --> 00:36:21,049
the program or perhaps we could track

752
00:36:16,490 --> 00:36:22,970
only certain allocations so if we're

753
00:36:21,050 --> 00:36:25,010
going the dbi route of just track

754
00:36:22,970 --> 00:36:27,350
everything in the program all of them on

755
00:36:25,010 --> 00:36:29,360
execution then it's pretty simple to

756
00:36:27,350 --> 00:36:33,170
accommodate that we just add a

757
00:36:29,360 --> 00:36:35,180
breakpoint a base on paging in the

758
00:36:33,170 --> 00:36:40,490
allocation hook and in the free hook we

759
00:36:35,180 --> 00:36:42,379
just removed that breakpoint however if

760
00:36:40,490 --> 00:36:44,660
we're only tracking certain allocation

761
00:36:42,380 --> 00:36:46,670
sites we end up with situations like

762
00:36:44,660 --> 00:36:50,810
this where let's say we're interested in

763
00:36:46,670 --> 00:36:52,400
the red region in the middle and because

764
00:36:50,810 --> 00:36:55,670
we're only tracking certain allocations

765
00:36:52,400 --> 00:36:58,340
that the adjacent memory regions might

766
00:36:55,670 --> 00:36:59,930
contain other allocations that we are

767
00:36:58,340 --> 00:37:02,750
not tracking that we are not interested

768
00:36:59,930 --> 00:37:05,149
in but because the technique works at

769
00:37:02,750 --> 00:37:07,550
the granularity of pages that means we

770
00:37:05,150 --> 00:37:10,220
are going to take page faults in these

771
00:37:07,550 --> 00:37:11,810
allocated regions regardless despite the

772
00:37:10,220 --> 00:37:14,629
fact that we're not interested in them

773
00:37:11,810 --> 00:37:17,930
and so more page faults means more

774
00:37:14,630 --> 00:37:20,000
overhead and this situation gets even

775
00:37:17,930 --> 00:37:21,620
worse if for example that allocation

776
00:37:20,000 --> 00:37:23,780
that we're interested happens to lie

777
00:37:21,620 --> 00:37:26,420
right across a page boundary we might be

778
00:37:23,780 --> 00:37:27,360
say tracking 8 kilobytes of memory

779
00:37:26,420 --> 00:37:29,400
despite the

780
00:37:27,360 --> 00:37:31,710
we're only interested in 32 bytes or

781
00:37:29,400 --> 00:37:33,660
something like this so for best

782
00:37:31,710 --> 00:37:37,380
performance we only want to take page

783
00:37:33,660 --> 00:37:43,920
faults upon accesses that we're

784
00:37:37,380 --> 00:37:46,140
interested in so my idea here was just

785
00:37:43,920 --> 00:37:48,800
sort of allow the user to specify the

786
00:37:46,140 --> 00:37:53,819
sites that they are interested in and

787
00:37:48,800 --> 00:37:57,030
then redirect these things into a custom

788
00:37:53,820 --> 00:37:58,320
allocator so why not we hook the memory

789
00:37:57,030 --> 00:38:00,450
allocator we can do that

790
00:37:58,320 --> 00:38:02,580
I'll let let the user specify a list of

791
00:38:00,450 --> 00:38:04,830
allocation sites that they want and any

792
00:38:02,580 --> 00:38:06,779
time we see allocations taking place

793
00:38:04,830 --> 00:38:08,819
from those sites we put those things

794
00:38:06,780 --> 00:38:11,970
into our own private memory allocator

795
00:38:08,820 --> 00:38:14,070
and that way that memory allocator only

796
00:38:11,970 --> 00:38:16,020
has objects that we are interested in

797
00:38:14,070 --> 00:38:20,730
tracking we don't have any additional

798
00:38:16,020 --> 00:38:27,780
overhead that comes from spurious page

799
00:38:20,730 --> 00:38:29,340
faults so the most flexibility you can

800
00:38:27,780 --> 00:38:31,200
get here is just used some sort of

801
00:38:29,340 --> 00:38:33,300
off-the-shelf memory allocator that

802
00:38:31,200 --> 00:38:35,759
allows you to you know variable size

803
00:38:33,300 --> 00:38:38,010
accesses and this - and performance and

804
00:38:35,760 --> 00:38:40,370
so on so this is you easy to implement

805
00:38:38,010 --> 00:38:42,390
usually these things are thread safe and

806
00:38:40,370 --> 00:38:43,680
performance tuned and they handle

807
00:38:42,390 --> 00:38:45,870
different sized allocations

808
00:38:43,680 --> 00:38:48,089
however these things have in band

809
00:38:45,870 --> 00:38:49,830
metadata which means you're also going

810
00:38:48,090 --> 00:38:54,300
to be taking page faults within the

811
00:38:49,830 --> 00:38:56,850
allocator itself so for optimum

812
00:38:54,300 --> 00:38:59,430
performance mostly the way I apply this

813
00:38:56,850 --> 00:39:00,270
technique is I use a fixed size slab

814
00:38:59,430 --> 00:39:02,640
allocator

815
00:39:00,270 --> 00:39:05,400
basically I select a bunch of allocation

816
00:39:02,640 --> 00:39:08,220
sites and then I choose the largest size

817
00:39:05,400 --> 00:39:10,440
that is allocated and then I just create

818
00:39:08,220 --> 00:39:13,649
a slab allocator where every allocation

819
00:39:10,440 --> 00:39:18,140
is that size and then there's no in-band

820
00:39:13,650 --> 00:39:20,880
metadata and allocation and free are

821
00:39:18,140 --> 00:39:23,100
basically basically free in terms of

822
00:39:20,880 --> 00:39:26,490
performance and it's very easy to do

823
00:39:23,100 --> 00:39:28,920
range lookups and so on so this is how

824
00:39:26,490 --> 00:39:30,629
you get the best performance but you

825
00:39:28,920 --> 00:39:31,430
have to be judicious about how you apply

826
00:39:30,630 --> 00:39:34,050
it

827
00:39:31,430 --> 00:39:36,480
so the way I use these techniques in the

828
00:39:34,050 --> 00:39:39,720
present is basically if I want to say

829
00:39:36,480 --> 00:39:40,450
track track all of the allocations in a

830
00:39:39,720 --> 00:39:42,790
given program

831
00:39:40,450 --> 00:39:44,919
I'll just take a list of all the

832
00:39:42,790 --> 00:39:47,460
allocation sites all divided by the

833
00:39:44,920 --> 00:39:49,390
number of cores I'm willing to provide

834
00:39:47,460 --> 00:39:52,380
to this procedure

835
00:39:49,390 --> 00:39:55,029
I'll run say six copies of the program

836
00:39:52,380 --> 00:39:57,820
divide the allocation sites up into six

837
00:39:55,030 --> 00:40:00,070
groups so I can parallel paralyze the

838
00:39:57,820 --> 00:40:01,900
data collection and I'll use a slab

839
00:40:00,070 --> 00:40:10,900
allocation to make sure it's as fast as

840
00:40:01,900 --> 00:40:15,940
possible so basically the difference

841
00:40:10,900 --> 00:40:23,050
here is rather than instrumenting every

842
00:40:15,940 --> 00:40:25,030
memory reference and and looking looking

843
00:40:23,050 --> 00:40:26,290
up at the time of every memory reference

844
00:40:25,030 --> 00:40:29,440
whether or not it refers to an

845
00:40:26,290 --> 00:40:31,300
allocation instead I just divert the

846
00:40:29,440 --> 00:40:34,180
allocations that I want into a custom

847
00:40:31,300 --> 00:40:36,460
allocator and then mark the pages as non

848
00:40:34,180 --> 00:40:38,470
present and catch those in an exception

849
00:40:36,460 --> 00:40:40,870
handler so that is the large-scale

850
00:40:38,470 --> 00:40:44,350
summary of the difference between what I

851
00:40:40,870 --> 00:40:46,900
did and the DPI based solutions is it

852
00:40:44,350 --> 00:40:49,060
better is it worse I can't I can't

853
00:40:46,900 --> 00:40:51,760
answer that question because I haven't

854
00:40:49,060 --> 00:40:53,380
implemented the dbi based one what I can

855
00:40:51,760 --> 00:40:55,420
say for certain that this is a lot more

856
00:40:53,380 --> 00:40:57,430
flexible than the dbi based solution

857
00:40:55,420 --> 00:41:00,040
especially with all the performance

858
00:40:57,430 --> 00:41:02,140
optimizations I'm able to target

859
00:41:00,040 --> 00:41:03,970
specific allocation sites and in some

860
00:41:02,140 --> 00:41:06,370
cases if the structures aren't used all

861
00:41:03,970 --> 00:41:08,799
that frequently I can continue using the

862
00:41:06,370 --> 00:41:10,359
application interactively as though it

863
00:41:08,800 --> 00:41:13,030
were not being instrumented you don't

864
00:41:10,360 --> 00:41:14,500
notice the overhead again that depends

865
00:41:13,030 --> 00:41:19,750
on how frequently the structure is being

866
00:41:14,500 --> 00:41:22,570
accessed so I think in the interest of

867
00:41:19,750 --> 00:41:23,860
time I'm going to skip ahead to the next

868
00:41:22,570 --> 00:41:28,600
one and then hopefully give a

869
00:41:23,860 --> 00:41:29,980
demonstration of both so as I mentioned

870
00:41:28,600 --> 00:41:31,960
there are two different analyses that

871
00:41:29,980 --> 00:41:33,370
are taking place here we were just

872
00:41:31,960 --> 00:41:37,510
talking about tracking accesses to

873
00:41:33,370 --> 00:41:39,759
structures by a dbi or by a non present

874
00:41:37,510 --> 00:41:41,650
pages we're not doing that anymore this

875
00:41:39,760 --> 00:41:45,940
is analysis number two it is something

876
00:41:41,650 --> 00:41:49,330
completely separate the big picture here

877
00:41:45,940 --> 00:41:51,670
is I want to track allocations from

878
00:41:49,330 --> 00:41:52,630
their allocation sites into function

879
00:41:51,670 --> 00:41:55,660
arguments

880
00:41:52,630 --> 00:41:57,880
so basically anytime a pointer is

881
00:41:55,660 --> 00:42:00,100
allocated I want to find out anytime

882
00:41:57,880 --> 00:42:02,410
subsequently a function is called where

883
00:42:00,100 --> 00:42:06,610
one of its arguments is derived from

884
00:42:02,410 --> 00:42:09,129
that pointer so for example we have this

885
00:42:06,610 --> 00:42:11,980
allocation taking place at location 5 6

886
00:42:09,130 --> 00:42:16,150
7 it's an allocation of size 138 and

887
00:42:11,980 --> 00:42:19,210
it's flowing into sub 3 4 5 the third

888
00:42:16,150 --> 00:42:22,780
argument and the offset is 16 so I want

889
00:42:19,210 --> 00:42:26,140
to record data such as a liqu function

890
00:42:22,780 --> 00:42:30,040
was 345 argument was 3 allocation site

891
00:42:26,140 --> 00:42:39,370
was 5 6 7 size was 138 and the offset

892
00:42:30,040 --> 00:42:44,410
was 16 so I chose to go X 64 specific on

893
00:42:39,370 --> 00:42:46,870
this for simplicity on my on my part the

894
00:42:44,410 --> 00:42:49,149
X 64 exception metadata gives you the

895
00:42:46,870 --> 00:42:50,859
addresses of all of the functions within

896
00:42:49,150 --> 00:42:53,110
the binary this is a change from the

897
00:42:50,860 --> 00:42:54,970
32-bit Windows environment so it tells

898
00:42:53,110 --> 00:42:57,910
you where the function begins as well as

899
00:42:54,970 --> 00:43:00,160
where as its first region like its first

900
00:42:57,910 --> 00:43:04,839
triblock or its the end of it if there

901
00:43:00,160 --> 00:43:06,460
is none so then I just filter out

902
00:43:04,840 --> 00:43:08,170
functions that I'm interested in

903
00:43:06,460 --> 00:43:09,220
basically I want to see is there

904
00:43:08,170 --> 00:43:11,020
something that would prevent me from

905
00:43:09,220 --> 00:43:12,939
hooking this function like is there

906
00:43:11,020 --> 00:43:15,160
control flow somewhere in the first

907
00:43:12,940 --> 00:43:16,810
several instructions or is there

908
00:43:15,160 --> 00:43:19,600
cross-references coming from somewhere

909
00:43:16,810 --> 00:43:21,130
else or things like this so I just

910
00:43:19,600 --> 00:43:23,020
iterate through the instructions I have

911
00:43:21,130 --> 00:43:25,780
a couple of checks that I do and then

912
00:43:23,020 --> 00:43:27,430
once I get 5 bytes into the function if

913
00:43:25,780 --> 00:43:29,890
none of the checks has failed that means

914
00:43:27,430 --> 00:43:38,230
I have at least 5 bytes of space to work

915
00:43:29,890 --> 00:43:42,580
with so I noticed in practice that hex

916
00:43:38,230 --> 00:43:44,470
Ray's would generate calling conventions

917
00:43:42,580 --> 00:43:47,259
that did not match up with real life

918
00:43:44,470 --> 00:43:49,480
whereas on x64 windows there is only one

919
00:43:47,260 --> 00:43:52,120
calling convention fast call by default

920
00:43:49,480 --> 00:43:54,040
that hex rays would nevertheless

921
00:43:52,120 --> 00:43:56,710
generate user-defined calling

922
00:43:54,040 --> 00:43:58,930
conventions so this sort of wreaks havoc

923
00:43:56,710 --> 00:44:02,200
on our ability to give a consistent name

924
00:43:58,930 --> 00:44:04,569
to an argument or its location so I

925
00:44:02,200 --> 00:44:05,799
wrote a little script that just converts

926
00:44:04,570 --> 00:44:08,140
all of these user call

927
00:44:05,800 --> 00:44:13,060
function Prolog function prototypes into

928
00:44:08,140 --> 00:44:16,000
standard fast call and then for every

929
00:44:13,060 --> 00:44:18,790
function I just make a list of all of

930
00:44:16,000 --> 00:44:20,650
the pointer sized arguments as well as

931
00:44:18,790 --> 00:44:22,660
their argument numbers now that we have

932
00:44:20,650 --> 00:44:28,810
consistently numbered them according to

933
00:44:22,660 --> 00:44:32,290
fast call so this is the data that I

934
00:44:28,810 --> 00:44:34,029
collect I just where the function is how

935
00:44:32,290 --> 00:44:39,370
many bytes in the prologue are we going

936
00:44:34,030 --> 00:44:41,020
to will be we be over writing and then

937
00:44:39,370 --> 00:44:47,109
how many arguments are we tracking and

938
00:44:41,020 --> 00:44:49,210
where are the arguments so now at

939
00:44:47,110 --> 00:44:52,690
runtime we hook the memory allocators

940
00:44:49,210 --> 00:44:54,220
same as before not not the paging stuff

941
00:44:52,690 --> 00:44:56,380
but just keeping track of where the

942
00:44:54,220 --> 00:44:57,700
allocations are where the pointers are

943
00:44:56,380 --> 00:45:01,720
how big they are and where they came

944
00:44:57,700 --> 00:45:06,310
from now for every function that we

945
00:45:01,720 --> 00:45:09,490
collected metadata about just going to

946
00:45:06,310 --> 00:45:11,799
hook every function in the binary copy

947
00:45:09,490 --> 00:45:14,020
the leading instructions into some other

948
00:45:11,800 --> 00:45:16,270
memory that we've allocated insert a

949
00:45:14,020 --> 00:45:18,580
jump back after those copied

950
00:45:16,270 --> 00:45:20,530
instructions this is our reentry thunk

951
00:45:18,580 --> 00:45:22,060
this is if we want to actually if we

952
00:45:20,530 --> 00:45:26,020
want to actually call this function in a

953
00:45:22,060 --> 00:45:27,549
non hooked fashion this will do it then

954
00:45:26,020 --> 00:45:30,430
we record this information in the hash

955
00:45:27,550 --> 00:45:34,260
table basically where is the new new

956
00:45:30,430 --> 00:45:34,259
function entry for for every function

957
00:45:34,380 --> 00:45:42,880
divert every function into a common

958
00:45:37,330 --> 00:45:44,710
logging routine common logging routine

959
00:45:42,880 --> 00:45:46,840
basically is a little assembly language

960
00:45:44,710 --> 00:45:49,210
the thunk that just saves the registers

961
00:45:46,840 --> 00:45:51,580
and flags calls another common logging

962
00:45:49,210 --> 00:45:53,620
routine then afterwards it adjusts the

963
00:45:51,580 --> 00:45:55,330
return address to go back to the non

964
00:45:53,620 --> 00:45:56,770
hooked version of the function restores

965
00:45:55,330 --> 00:46:01,779
the registers and the flags and

966
00:45:56,770 --> 00:46:03,610
continues so then this is the C version

967
00:46:01,780 --> 00:46:06,280
of the logging function which is just

968
00:46:03,610 --> 00:46:08,470
look up in the hash table the list of

969
00:46:06,280 --> 00:46:11,200
pointer sized arguments as well as the

970
00:46:08,470 --> 00:46:16,000
re-entry location and then for each

971
00:46:11,200 --> 00:46:17,990
argument log it which is to say for each

972
00:46:16,000 --> 00:46:20,720
pointer sized argument lookup

973
00:46:17,990 --> 00:46:22,669
is this within our allocation map does

974
00:46:20,720 --> 00:46:24,140
this does this argument correspond to

975
00:46:22,670 --> 00:46:29,140
something that is currently allocated

976
00:46:24,140 --> 00:46:32,390
and then log if so log the function

977
00:46:29,140 --> 00:46:34,640
which arguments where the allocation

978
00:46:32,390 --> 00:46:40,730
came from how big the allocation was and

979
00:46:34,640 --> 00:46:43,180
the offset into the allocation so we

980
00:46:40,730 --> 00:46:46,609
generate a lot of data in this fashion

981
00:46:43,180 --> 00:46:49,669
60,000 entries for my target but that's

982
00:46:46,609 --> 00:46:56,839
a good thing because this data is

983
00:46:49,670 --> 00:46:58,550
extremely valuable so this is a little

984
00:46:56,839 --> 00:47:02,180
unfortunate I have about three and a

985
00:46:58,550 --> 00:47:04,730
half minutes left and I had I wanted to

986
00:47:02,180 --> 00:47:08,180
show you demos of all of this stuff in

987
00:47:04,730 --> 00:47:10,250
action but it's looking like I'm not

988
00:47:08,180 --> 00:47:13,669
going to have time that's very

989
00:47:10,250 --> 00:47:15,140
unfortunate so instead I'm just going to

990
00:47:13,670 --> 00:47:16,640
talk about some of the challenges that

991
00:47:15,140 --> 00:47:19,460
arise and trying to use this data

992
00:47:16,640 --> 00:47:20,720
properly and then I'll conclude and if I

993
00:47:19,460 --> 00:47:23,630
have time left we'll take questions

994
00:47:20,720 --> 00:47:33,770
otherwise afterwards I'll be in the wrap

995
00:47:23,630 --> 00:47:36,170
room across the hall taking questions so

996
00:47:33,770 --> 00:47:38,960
this is a dynamic analysis which means

997
00:47:36,170 --> 00:47:42,320
it can only record information about the

998
00:47:38,960 --> 00:47:45,619
program which was observed at at run

999
00:47:42,320 --> 00:47:47,390
time through execution so if there are

1000
00:47:45,619 --> 00:47:49,099
locations in the program that were never

1001
00:47:47,390 --> 00:47:51,680
accessed but they would have had

1002
00:47:49,099 --> 00:47:54,170
structure accesses in them that means we

1003
00:47:51,680 --> 00:47:56,299
aren't going to observe them so I don't

1004
00:47:54,170 --> 00:47:58,700
have any contribution to every dynamic

1005
00:47:56,300 --> 00:48:01,369
analysis has this problem although I did

1006
00:47:58,700 --> 00:48:04,160
incorporate a static analysis that uses

1007
00:48:01,369 --> 00:48:06,380
hex rays to find other accesses to the

1008
00:48:04,160 --> 00:48:11,000
same structure variables that were not

1009
00:48:06,380 --> 00:48:14,630
observed at run time and a fundamental

1010
00:48:11,000 --> 00:48:16,520
issue really is that once I get once

1011
00:48:14,630 --> 00:48:18,230
I've recovered my structures and I go to

1012
00:48:16,520 --> 00:48:21,140
apply this type information in the

1013
00:48:18,230 --> 00:48:24,230
database basically I need to assign one

1014
00:48:21,140 --> 00:48:27,529
unique type at every location in the

1015
00:48:24,230 --> 00:48:30,320
database so that presents ambiguities

1016
00:48:27,530 --> 00:48:30,890
when I have multiple one instruction is

1017
00:48:30,320 --> 00:48:34,970
observed

1018
00:48:30,890 --> 00:48:36,140
accessing multiple allocations so for

1019
00:48:34,970 --> 00:48:38,839
example if I will observe this

1020
00:48:36,140 --> 00:48:44,150
instruction is accessing these four

1021
00:48:38,840 --> 00:48:48,020
allocations I need to assign one type

1022
00:48:44,150 --> 00:48:49,550
here and what is the type so as it turns

1023
00:48:48,020 --> 00:48:52,400
out I have the source code for this one

1024
00:48:49,550 --> 00:48:55,070
so I know two of those allocation sites

1025
00:48:52,400 --> 00:48:58,370
allocate the same type ns for the third

1026
00:48:55,070 --> 00:49:00,740
one well there's there's three copies of

1027
00:48:58,370 --> 00:49:02,420
that type within the other ones so there

1028
00:49:00,740 --> 00:49:05,899
in fact there is a type that we can

1029
00:49:02,420 --> 00:49:08,000
associate with that location but it is

1030
00:49:05,900 --> 00:49:19,820
it's not trivial to know what the type

1031
00:49:08,000 --> 00:49:22,850
is so none of these techniques are crazy

1032
00:49:19,820 --> 00:49:25,370
sophisticated I've run into some some

1033
00:49:22,850 --> 00:49:27,410
serious mathematics in trying to recover

1034
00:49:25,370 --> 00:49:29,660
every single structure in the program at

1035
00:49:27,410 --> 00:49:31,850
the same time recovering one structure

1036
00:49:29,660 --> 00:49:33,710
individually or a couple of structures

1037
00:49:31,850 --> 00:49:35,240
this is no problem but if you want to

1038
00:49:33,710 --> 00:49:37,790
recover every structure in the binary

1039
00:49:35,240 --> 00:49:39,830
it's not just a problem of recovering

1040
00:49:37,790 --> 00:49:42,500
each individual structure in isolation

1041
00:49:39,830 --> 00:49:45,020
from one another that you have to take

1042
00:49:42,500 --> 00:49:48,080
into account overlapping accesses and so

1043
00:49:45,020 --> 00:49:51,440
on this is kind of difficult but that

1044
00:49:48,080 --> 00:49:54,230
being said these techniques even if they

1045
00:49:51,440 --> 00:49:56,660
haven't produced full automation yet in

1046
00:49:54,230 --> 00:50:00,710
a semi-automated fashion they are

1047
00:49:56,660 --> 00:50:02,660
they're very useful in that in allowing

1048
00:50:00,710 --> 00:50:04,340
me to reverse engineer programs with

1049
00:50:02,660 --> 00:50:08,359
structures in them in a much more rapid

1050
00:50:04,340 --> 00:50:10,310
fashion like I said I applied more type

1051
00:50:08,360 --> 00:50:12,140
information to my database in two days

1052
00:50:10,310 --> 00:50:14,029
than I had in six weeks of manual

1053
00:50:12,140 --> 00:50:16,100
reverse engineering it turned out this

1054
00:50:14,030 --> 00:50:18,290
stuff was a better use of my time than

1055
00:50:16,100 --> 00:50:22,370
actually reading code which is kind of

1056
00:50:18,290 --> 00:50:24,020
trippy to think about so I'm still

1057
00:50:22,370 --> 00:50:27,259
working on getting the code ready for a

1058
00:50:24,020 --> 00:50:29,500
release of I spent my time coming up

1059
00:50:27,260 --> 00:50:33,740
with new features but it's coming soon

1060
00:50:29,500 --> 00:50:36,770
so my light just went red I am over my

1061
00:50:33,740 --> 00:50:38,569
time which means I'll have to divert any

1062
00:50:36,770 --> 00:50:40,550
questions to the wrap room across the

1063
00:50:38,570 --> 00:50:42,530
hall thanks everybody for coming

1064
00:50:40,550 --> 00:50:46,219
sorry I didn't have time for the demo

1065
00:50:42,530 --> 00:50:46,219
[Applause]

