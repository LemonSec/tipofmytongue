1
00:00:00,000 --> 00:00:12,980
necessarily hear that your came in
today's totals westerdam's matters and

2
00:00:12,980 --> 00:00:13,880
how it's different

3
00:00:13,880 --> 00:00:18,880
promises of designs which section 3
intelligence is going to be a two-part

4
00:00:18,880 --> 00:00:25,460
talk to the first the first 15 minutes
of the talk to be sort of a very broad

5
00:00:25,460 --> 00:00:28,220
and general and talk about what the
sciences and in some unique problems

6
00:00:28,220 --> 00:00:31,698
that come up when you when you played in
a sense of security problems in this

7
00:00:31,699 --> 00:00:36,489
episode 15 minutes 20 minute break in
the second part of the talk and talk

8
00:00:36,489 --> 00:00:41,110
about some like three different projects
that we've done in my group so that's

9
00:00:41,110 --> 00:00:45,079
gonna be more technical part of the talk
and hopefully inspire you and show you

10
00:00:45,079 --> 00:00:51,610
some interesting applications of machine
learning and data visualization to call

11
00:00:51,610 --> 00:00:55,489
out that a lot of the work I'm doing my
job is done by me but also by other

12
00:00:55,489 --> 00:00:59,910
members of the group so Alex long who's
actually in the audience were gonna

13
00:00:59,910 --> 00:01:03,599
constant relented and Robert goes thanks
them for their country since I'm not

14
00:01:03,600 --> 00:01:07,030
sure that I can actually in terms of
areas where they've contributed to the

15
00:01:07,030 --> 00:01:12,409
work I mean I guess it is this quickly
to give you some contacts violated UN

16
00:01:12,409 --> 00:01:21,729
and Organization I work for anybody out
there and the people who know I'm think

17
00:01:21,729 --> 00:01:26,908
of us as you know commercial computer
security company and we also that's the

18
00:01:26,909 --> 00:01:30,189
majority of your boyfriend or so that's
how the company I work for an

19
00:01:30,189 --> 00:01:34,279
organization within 60 minutes he
allowed that has about 40 researchers

20
00:01:34,280 --> 00:01:38,880
divided into three different teams the
different security related research my

21
00:01:38,880 --> 00:01:42,170
group is a people and we we do

22
00:01:42,170 --> 00:01:44,280
machine learning and data visualization

23
00:01:44,280 --> 00:01:50,299
and did a story to say researchers
applied security again this is the first

24
00:01:50,299 --> 00:01:54,729
president a position to go through what
did a science is pretty general level

25
00:01:54,729 --> 00:01:58,900
hopefully everybody can get something
out of it and we've really very diverse

26
00:01:58,900 --> 00:02:05,560
group here and introduce and
individualization and then talk about

27
00:02:05,560 --> 00:02:11,840
some issues that come up when you played
it and security over the history section

28
00:02:11,840 --> 00:02:20,040
ok so let's get into the stands at a
high level there there are three through

29
00:02:20,040 --> 00:02:23,010
skill areas that you need to be the
scientists easy need to know how the

30
00:02:23,010 --> 00:02:30,470
money is not a story data it's gil is
really sort of knowledge of a diversity

31
00:02:30,470 --> 00:02:35,670
of databases and data storage
technologies to analyze data about

32
00:02:35,670 --> 00:02:39,119
machine learning he'd never competition
statistics and you know it's cool

33
00:02:39,120 --> 00:02:43,500
statistics you need to be able to
explain your results to there is and

34
00:02:43,500 --> 00:02:51,290
also if you're celebrating visualized it
actually actually actually complex

35
00:02:51,290 --> 00:02:55,220
lasted managers and also to make sense
of this before you start building models

36
00:02:55,220 --> 00:02:59,780
to analyze them this is a huge range as
it is it's not just the curious thing

37
00:02:59,780 --> 00:03:03,150
obviously invade it's a growing fields
become a big deal in a lot of different

38
00:03:03,150 --> 00:03:07,000
areas though there have been recent
breakthroughs in computer vision using

39
00:03:07,000 --> 00:03:11,290
using data science methods obviously
voice recognition as network analysis

40
00:03:11,290 --> 00:03:15,160
robotics is all fields in which people
use they have big data storage problems

41
00:03:15,160 --> 00:03:19,880
they have machinery problems sometimes
their visualization problems as well

42
00:03:19,880 --> 00:03:23,739
when you get a sense of security
benefits and the work that's been done

43
00:03:23,739 --> 00:03:27,950
these other fields as well as a lot of
applicability of Everton insane computer

44
00:03:27,950 --> 00:03:38,358
vision and image processing to computer
security is that like most most

45
00:03:38,359 --> 00:03:42,170
technical difficulties

46
00:03:42,170 --> 00:03:47,549
ok so so that most most Innocence
Project we do in my group involved all

47
00:03:47,550 --> 00:03:51,400
three areas of things so this is just an
example prototype to build a few years

48
00:03:51,400 --> 00:03:57,560
ago where we are probably as well as we
we had all these security alerts coming

49
00:03:57,560 --> 00:04:00,920
and coming from our products from our
customers networks coming to our system

50
00:04:00,920 --> 00:04:03,569
and we wanted to make sense of like the
thousands and tens of thousands of

51
00:04:03,569 --> 00:04:07,179
scurrilous we're seeing throughout the
building to building clustering system

52
00:04:07,180 --> 00:04:13,269
of a similar groups of events in a
security alert doesn't have to look at

53
00:04:13,269 --> 00:04:15,790
what 11 other at a time

54
00:04:15,790 --> 00:04:19,820
groups of alert said that share common
attributes this video tape it we

55
00:04:19,820 --> 00:04:25,229
individualization you're seeing each one
of these balls an individual security

56
00:04:25,229 --> 00:04:28,510
learned in the balls are close together
as a function of how similar they are

57
00:04:28,510 --> 00:04:33,810
and what we find is that we have in this
week and romantically speed up our

58
00:04:33,810 --> 00:04:36,240
comprehension of what's going on in the
network ratings you don't have to go

59
00:04:36,240 --> 00:04:39,669
through a thousand likes by themselves
began beating go through like a hundred

60
00:04:39,669 --> 00:04:43,909
clusters characterize the classes
individualism we find anything cluster

61
00:04:43,910 --> 00:04:48,680
we can we can drill in its employees
amplification we had to go to store the

62
00:04:48,680 --> 00:04:51,580
data to figure out a time machine and
method for identifying the clusters and

63
00:04:51,580 --> 00:04:55,030
we had to come to the visitation was
compelling that made people see the

64
00:04:55,030 --> 00:05:00,289
benefits of clustering in eleven
analysts actually learns ok there was no

65
00:05:00,289 --> 00:05:04,860
way he needed it as lots of skill areas
insecurity and vulnerability Research

66
00:05:04,860 --> 00:05:09,030
since you know like network
administration in other areas that are

67
00:05:09,030 --> 00:05:12,840
clearly not necessarily didn't answer is
what way can we benefited security

68
00:05:12,840 --> 00:05:18,280
practitioners who designs approaches to
the big point on what one of the big 21

69
00:05:18,280 --> 00:05:23,739
get a custom this talk is that well I
don't make the point that it is really

70
00:05:23,740 --> 00:05:24,330
important

71
00:05:24,330 --> 00:05:29,180
doing security particularly during
detection and so is this the way I see

72
00:05:29,180 --> 00:05:32,930
it is like you know that their their
advance adversaries breaking into our

73
00:05:32,930 --> 00:05:36,129
networks and there's lots of talk about
the need to collect more data

74
00:05:36,129 --> 00:05:39,919
actually suspect that in many cases we
already have the data that we need to

75
00:05:39,919 --> 00:05:44,429
detect viruses we just don't know how do
you know how to analyze the data they

76
00:05:44,429 --> 00:05:47,799
are so so they're people who do you like
you know like organizations are serious

77
00:05:47,800 --> 00:05:50,629
about security do you like full packet
capture their checking every packet

78
00:05:50,629 --> 00:05:57,599
network and when you have time w seems
to have a huge amounts of data and most

79
00:05:57,599 --> 00:06:00,819
of these data argue it I never never
really fully explain its inspection

80
00:06:00,819 --> 00:06:04,179
purposes and is because they like you
human analysts say they heard her sort

81
00:06:04,179 --> 00:06:06,888
of manually going through the data I
just never gonna be able to take

82
00:06:06,889 --> 00:06:13,369
advantage of automated algorithms that
can look at that deal in recent

83
00:06:13,369 --> 00:06:17,379
intelligently about it that is not just
humans are picking through the dayton

84
00:06:17,379 --> 00:06:20,389
looking for a needle in the haystack
with so we have intelligence important

85
00:06:20,389 --> 00:06:25,909
there is a bunch of different types of
data that we can take advantage of you

86
00:06:25,909 --> 00:06:31,300
talked about the dog behavior then
there's also a threat intelligence

87
00:06:31,300 --> 00:06:38,179
respective of malware and we are
collecting as a community and the latest

88
00:06:38,179 --> 00:06:43,609
stats count on every test that targets
the nonprofit attracts malware that

89
00:06:43,610 --> 00:06:46,649
there there been 400 miss simpson since
the inception of the internet there than

90
00:06:46,649 --> 00:06:53,490
400 million now are simply unique in our
sample that tested later a tiny tiny

91
00:06:53,490 --> 00:06:56,819
fraction of this number symbols of ever
been reverse engineers and so is heading

92
00:06:56,819 --> 00:07:02,459
in those huge pile of malware could be
the next x-men friends but we don't know

93
00:07:02,459 --> 00:07:05,209
that because we don't have to go through
some of the working to talk about in the

94
00:07:05,209 --> 00:07:09,889
stock has to do with automatic reverse
engineering intelligence using machine

95
00:07:09,889 --> 00:07:17,519
learning techniques have been a lot of
talk about the design security very well

96
00:07:17,519 --> 00:07:25,969
and it's natural and cynics who say that
you know the anomaly detector has no

97
00:07:25,969 --> 00:07:33,389
chance of working before they are you
that they're just there well I think the

98
00:07:33,389 --> 00:07:36,240
heading there are good reasons to be
cynical actually if we look at other and

99
00:07:36,240 --> 00:07:39,550
their demands to find it sounds too hard
problems

100
00:07:39,550 --> 00:07:43,450
but they like speech recognition they
really really cut costs especially in

101
00:07:43,450 --> 00:07:47,140
the last few years between machine
learning approaches that that they try

102
00:07:47,140 --> 00:07:53,260
to transcribe and translate to in speech
and language syntax we've seen breakers

103
00:07:53,260 --> 00:07:57,159
against against the end of problems and
other systems like approaches the

104
00:07:57,160 --> 00:08:03,310
problems that seem intractable in years
past have now installed to the point

105
00:08:03,310 --> 00:08:06,140
that we have we now have skied
recognition technologies that are using

106
00:08:06,140 --> 00:08:14,280
any data bases with this is this charges
a scenario of a number of systems over

107
00:08:14,280 --> 00:08:19,880
the years that have taken on the
challenge that night he did it as it is

108
00:08:19,880 --> 00:08:23,980
a baseline through validation did it
again speech recognition algorithms and

109
00:08:23,980 --> 00:08:28,780
shows is this recognition systems
justice incrementally gotten better and

110
00:08:28,780 --> 00:08:33,270
better over the years to the point where
you know we reduce their reliance in

111
00:08:33,270 --> 00:08:38,949
1998 Ruggeri was 24% were never down to
eighteen percent and somehow that seems

112
00:08:38,950 --> 00:08:43,190
to be a crucial transition wait we're
now we have no way of things like Syria

113
00:08:43,190 --> 00:08:46,480
would actually seemed to work pretty
well I use this kind of technologies

114
00:08:46,480 --> 00:08:50,450
we've seen it in public and even more
dramatic increase in our ability to

115
00:08:50,450 --> 00:08:54,210
recognize objects in images using
machine learning techniques to this is a

116
00:08:54,210 --> 00:09:03,150
child is a similar charge that showing
how how well did they use machine

117
00:09:03,150 --> 00:09:09,110
learning approach is recognizing objects
in images from 2010 to 2015

118
00:09:09,110 --> 00:09:16,730
in 2010 the average 30% and we've seen a
drop just in the last five years down to

119
00:09:16,730 --> 00:09:20,700
an error rate of 10% I'm to the point
where it is pretty incredible what we

120
00:09:20,700 --> 00:09:27,410
can do now so I think I may sort of
provocation here is if if if data

121
00:09:27,410 --> 00:09:30,890
scientists been able to make make those
kinds of victory is likely qualitative

122
00:09:30,890 --> 00:09:33,699
breakthroughs that have enabled new
kinds of technologies and another

123
00:09:33,700 --> 00:09:38,850
application areas of this sounds like it
it seems quite likely it's like is it

124
00:09:38,850 --> 00:09:43,209
possible to design could produce really
game-changing technologies and security

125
00:09:43,209 --> 00:09:55,569
any that is the hope is that there is
talk about the high level of the talk go

126
00:09:55,569 --> 00:10:00,699
into more technical terms and introduce
some basic machine learning ideas so

127
00:10:00,699 --> 00:10:05,269
people have a background in machine
learning the basic and probably done

128
00:10:05,269 --> 00:10:10,129
this may seem difficult to drive so bear
with me and ask questions if anything is

129
00:10:10,129 --> 00:10:17,189
confusing him with just lay the
groundwork for some definitions so

130
00:10:17,189 --> 00:10:20,379
there's this idea of training data in
machine learning so that that's the day

131
00:10:20,379 --> 00:10:23,480
that you would you give to a machine
learning algorithms that it might learn

132
00:10:23,480 --> 00:10:27,079
from the data for example if your
training and machine learning model to

133
00:10:27,079 --> 00:10:31,329
think things between images of cats and
dogs it's raining deter the images of

134
00:10:31,329 --> 00:10:35,050
the cats and dogs now there's a
distinction between labeled training

135
00:10:35,050 --> 00:10:38,670
data and unlabeled training didn't so so
so labeled training data or data that

136
00:10:38,670 --> 00:10:43,979
you give to a machine model and are you
sure you give it a label made so if you

137
00:10:43,980 --> 00:10:47,149
would if you were giving the cats and
dogs problem would show that our

138
00:10:47,149 --> 00:10:51,230
algorithm images New to his image and
this is a cast his name is in this

139
00:10:51,230 --> 00:10:56,079
document that second that this is the
kind of shit August is the label then

140
00:10:56,079 --> 00:10:59,638
there are the missing items at a crime
labeled training data and cities in this

141
00:10:59,639 --> 00:11:03,860
case you with you it's so taking any
cats and dogs analogy you would show you

142
00:11:03,860 --> 00:11:08,279
charm machinery model a bunch of images
that maybe you don't know that cats and

143
00:11:08,279 --> 00:11:13,809
dogs for some reason and you don't tell
them I'll get them if their cats and

144
00:11:13,809 --> 00:11:17,009
dogs you just you just expected to do
something useful with with what I

145
00:11:17,009 --> 00:11:20,689
learned that maybe learn said million
for the quarter doug is on its own so

146
00:11:20,689 --> 00:11:23,360
that those are that's more challenging
problem but there are there lots of

147
00:11:23,360 --> 00:11:31,519
working that we also have tested it
suggested that you showed a machine

148
00:11:31,519 --> 00:11:35,679
learning how you actually trained in
that you haven't read it on the ask you

149
00:11:35,679 --> 00:11:41,119
to make some useful interest rates and
the cats and dogs example you know cats

150
00:11:41,119 --> 00:11:44,940
and dogs leashes and new image as good
as the other dog

151
00:11:44,940 --> 00:11:49,770
and the test is usually called tested it
is people use that data to evaluate how

152
00:11:49,770 --> 00:11:53,030
the machine learning system is actually
doing in terms of its actually learning

153
00:11:53,030 --> 00:11:59,380
to use it just as they're they're too
big categories machine learning

154
00:11:59,380 --> 00:12:03,950
algorithms their supervisor then they
require labeled training data and the

155
00:12:03,950 --> 00:12:14,340
darker training did an ok so that future
space abstract them and give them a

156
00:12:14,340 --> 00:12:18,640
dramatic increase in in giving examples
I suppose you have a directory full of

157
00:12:18,640 --> 00:12:22,860
malicious files that have been recovered
in some sort of incidents in a sense of

158
00:12:22,860 --> 00:12:30,840
security incident their malicious and
analyze them using machine learning so

159
00:12:30,840 --> 00:12:34,340
we would pull out some money on this
violence we would tell us what are

160
00:12:34,340 --> 00:12:37,340
called features of the styles and this
is a visit to examples it was the

161
00:12:37,340 --> 00:12:42,590
teachers are just by all sides and file
compression level we have we have two

162
00:12:42,590 --> 00:12:51,320
features within the features and
impressionable interweave you could also

163
00:12:51,320 --> 00:12:56,600
see this issue two dimensional feature
space in the sense that you can

164
00:12:56,600 --> 00:13:01,690
participate and if you mention the graph
of the depleted the files of it have a

165
00:13:01,690 --> 00:13:07,100
position that space and we have that
space is very useful if you've started

166
00:13:07,100 --> 00:13:10,330
missing you you immediately started
thinking Chief Minister geometric terms

167
00:13:10,330 --> 00:13:14,750
you can start to think about it and I
was pretty clear that there are two

168
00:13:14,750 --> 00:13:19,070
clusters here by clustering algorithms
to identify their two clusters of Dayton

169
00:13:19,070 --> 00:13:21,860
perhaps these days much as sales come
from two different now we're lineages

170
00:13:21,860 --> 00:13:31,180
that you didn't everything every three
crews so it's a matter of example really

171
00:13:31,180 --> 00:13:35,660
aren't any matters that reduces the
workload an actual analyst automatically

172
00:13:35,660 --> 00:13:42,660
summarizes the day that we were looking
at other applications of very few if you

173
00:13:42,660 --> 00:13:45,480
have never traffic on your network

174
00:13:45,480 --> 00:13:48,750
incurring day but you can still looking
at each individual notes lower rates may

175
00:13:48,750 --> 00:13:54,100
be used cluster cluster the players
together in some areas like clustering

176
00:13:54,100 --> 00:13:57,220
is useful in the key and looking at
large datasets and raising them in in

177
00:13:57,220 --> 00:14:02,480
analyzing more and I'll be going over
some examples of clustering done for

178
00:14:02,480 --> 00:14:03,180
their own the time

179
00:14:03,180 --> 00:14:12,420
ok because of classification but you
don't need to tell it you don't need to

180
00:14:12,420 --> 00:14:21,939
tell us what I kind of did it it's
looking at in order to identify clusters

181
00:14:21,940 --> 00:14:43,570
classification it is it is back on the
name and location made a tradition is

182
00:14:43,570 --> 00:14:46,370
like the example of the cats vs dogs
there to make it more security

183
00:14:46,370 --> 00:14:50,510
relatively malware versus the nine where
you can change a machine learning

184
00:14:50,510 --> 00:14:51,470
classifier

185
00:14:51,470 --> 00:14:56,810
discussed kitchen redone bunch of
malicious files and files and and

186
00:14:56,810 --> 00:15:04,268
teachers recognize the difference in
this case later you know only one

187
00:15:04,269 --> 00:15:09,790
interview with us from our family soon
you with the task of the classifier

188
00:15:09,790 --> 00:15:18,290
classification algorithm there would you
identify a line through this said that

189
00:15:18,290 --> 00:15:22,930
basically gives you a rule for deciding
which which family and youth violence

190
00:15:22,930 --> 00:15:33,370
from Red Violin releases and the line it
would be classified as one is also

191
00:15:33,370 --> 00:15:42,310
considering it's going to get more
exciting way to an issue though is like

192
00:15:42,310 --> 00:15:43,829
a real world class affair

193
00:15:43,830 --> 00:15:53,150
network and machine learning researchers
central

194
00:15:53,150 --> 00:15:59,730
the software I just say is in transit
networks using his number so basically

195
00:15:59,730 --> 00:16:03,080
if we have an entertaining points like
let's say that the city's green points

196
00:16:03,080 --> 00:16:11,230
in his red points we can identify
decision boundary that's the point that

197
00:16:11,230 --> 00:16:17,060
they can make a decision about which if
that's when should be color green like

198
00:16:17,060 --> 00:16:22,060
me to do it has this sort of situation
like this and it sort of in this blog

199
00:16:22,060 --> 00:16:22,500
here

200
00:16:22,500 --> 00:16:30,010
be surveyed points out here is an
amazing network adapter different kinds

201
00:16:30,010 --> 00:16:35,810
of the data in a raid and within a few
seconds their network learns so here's a

202
00:16:35,810 --> 00:16:38,900
good decision boundary this is a good
rules for deciding whether or not a new

203
00:16:38,900 --> 00:16:46,090
plan should be possible as we get into
the blob we can get this monkey shaved

204
00:16:46,090 --> 00:16:56,820
we're gonna give it some really really
weird shapes just anything in general

205
00:16:56,820 --> 00:17:01,670
that sort of greens that is this is this
is going to be much more useful later

206
00:17:01,670 --> 00:17:04,909
when I show that we've built up a
network of very effective very effective

207
00:17:04,910 --> 00:17:08,880
malware detector in the data center
terrorism and its portrayal of false

208
00:17:08,880 --> 00:17:15,730
positive in that case is that works that
have links those ways that matter raises

209
00:17:15,730 --> 00:17:23,020
the classic security at detecting good
vs bad goodfellas that fails an extreme

210
00:17:23,020 --> 00:17:29,720
cases like like like somea decreasing
examples of detecting the does this now

211
00:17:29,720 --> 00:17:38,020
resemble implement screenwriting and
finally this regression predicting a

212
00:17:38,020 --> 00:17:39,730
continuous value

213
00:17:39,730 --> 00:17:44,820
example of where and if anybody's
delegation how they dealt with through

214
00:17:44,820 --> 00:17:50,500
the time series analysis you know so you
can usually predict the stock market for

215
00:17:50,500 --> 00:17:52,169
example you know so

216
00:17:52,169 --> 00:18:09,359
given you know given past performance of
Apple's stock like Apple's yeah yeah I

217
00:18:09,359 --> 00:18:14,428
gotta keep talking yes it's very serious
questions about predicting a continuous

218
00:18:14,429 --> 00:18:15,480
value

219
00:18:15,480 --> 00:18:19,909
oftentimes we use reduction for
forecasting again later in the time to

220
00:18:19,909 --> 00:18:25,169
talk about everyone in the group
predicts

221
00:18:25,169 --> 00:18:29,889
given our is like giving our family's
history

222
00:18:29,889 --> 00:18:33,590
user storms headed this little sister
any of these sort of like a celebrity

223
00:18:33,590 --> 00:18:37,859
now our families can you predict how
many how many examples like how

224
00:18:37,859 --> 00:18:40,840
successful that then we will be in the
future as an example of how we can use

225
00:18:40,840 --> 00:18:46,738
Russian security ok so I've been giving
these two dimensional examples like you

226
00:18:46,739 --> 00:18:52,019
know obviously not very useful exiles
compression in fact Great Lakes machine

227
00:18:52,019 --> 00:18:54,649
learning algorithms working very
high-dimensional spaces

228
00:18:54,649 --> 00:18:58,219
listed as a pioneer in your minds to
thinking about about that

229
00:18:58,220 --> 00:19:02,840
imagine imagine an error file example we
had we will use file compression is the

230
00:19:02,840 --> 00:19:07,658
future and we want to look over thumbs
file sizes future but it also wanted ads

231
00:19:07,659 --> 00:19:11,739
like the first time to file it did seem
like a timestamp something like this and

232
00:19:11,739 --> 00:19:15,100
we have a three-dimensional space every
one of their decisions decisions about

233
00:19:15,100 --> 00:19:21,230
whether or not as if I was good or bad
thing we have to identify a plane they

234
00:19:21,230 --> 00:19:24,230
would define a role that was they will
appear on this side of the plane

235
00:19:24,230 --> 00:19:31,539
you know you're a bluegrass if you're in
the right class that gives an interest

236
00:19:31,539 --> 00:19:36,840
in three dimensions in reality we build
real-world missing we use millions of

237
00:19:36,840 --> 00:19:41,149
dimensions rains imagined he started
mentioning 1010 dimensions in

238
00:19:41,149 --> 00:19:43,859
identifying a plane in 10 dimensions
that separates two types of data

239
00:19:43,859 --> 00:19:49,960
visualization of attention look you play
best best looked at on mushrooms or

240
00:19:49,960 --> 00:19:55,830
something like that but they actually
exist if you can really really wish list

241
00:19:55,830 --> 00:19:59,590
to mention the cuban to in its on a
two-dimensional screen if we could see

242
00:19:59,590 --> 00:20:01,720
every every one of the angles

243
00:20:01,720 --> 00:20:05,820
in this image would be ninety degrees
and then uses a lot of distortion going

244
00:20:05,820 --> 00:20:11,090
on in every one of the lines of equal
length but when you start doing anything

245
00:20:11,090 --> 00:20:17,129
he needs high-dimensional spaces and
it's hard it's hard to do but you really

246
00:20:17,130 --> 00:20:20,520
that's really the best way as having a
high dimensional feature space in which

247
00:20:20,520 --> 00:20:23,700
we're learning boundaries around the
classes that were trying to identify

248
00:20:23,700 --> 00:20:35,290
read my mind blowing things up to
high-dimensional models the most of the

249
00:20:35,290 --> 00:20:40,600
time to be talking about how to mention
other questions at this point and then

250
00:20:40,600 --> 00:21:14,250
to the machining introduction

251
00:21:14,250 --> 00:21:21,310
yes then computes the the similarity
between every pair of pants I'm confused

252
00:21:21,310 --> 00:21:25,620
this big sellers are you majoring in

253
00:21:25,620 --> 00:21:30,600
yeah yeah yeah

254
00:21:30,600 --> 00:21:38,600
at the questions yet

255
00:21:38,600 --> 00:21:48,020
oh thank you thank you for using it to
build that the experiments there were no

256
00:21:48,020 --> 00:21:54,020
the protests that have shown that we
used to use paid on scientific computing

257
00:21:54,020 --> 00:22:00,320
ecology and pythons there's there's a
library calls a scalar and relearn is

258
00:22:00,320 --> 00:22:09,399
probably the best bet on any library and
actually the Middle East news I wasn't

259
00:22:09,400 --> 00:22:20,180
flash this is back with his thing yes
usually but usually it's sort of the

260
00:22:20,180 --> 00:22:23,760
nineties

261
00:22:23,760 --> 00:22:29,620
question

262
00:22:29,620 --> 00:22:40,360
yeah so that's the question things are
you move to reuse them you say so i

263
00:22:40,360 --> 00:22:45,860
guess i misspoke when he said that he
did was give you the similarity matrix

264
00:22:45,860 --> 00:22:50,240
reduce the dimensionality and
visualizations and what pops out her

265
00:22:50,240 --> 00:22:58,070
clusters visually there is no question
that case I wanted to actually used

266
00:22:58,070 --> 00:23:03,200
components in the similarity graph and
then we heard them differently to be you

267
00:23:03,200 --> 00:23:07,010
know the travel agency can get to the
hotel

268
00:23:07,010 --> 00:23:12,790
keep going in there will be more
opportunities for questions later

269
00:23:12,790 --> 00:23:18,178
gonna talk about a visualization and
service also some examples of his listen

270
00:23:18,179 --> 00:23:28,309
and talk about some of the theory behind
this is now ok let me know if this is

271
00:23:28,309 --> 00:23:40,290
who hasn't seen evaluation before this
visualization so this is sort of an

272
00:23:40,290 --> 00:23:46,070
artist is also a good day devastation
person he is a city do you think

273
00:23:46,070 --> 00:23:51,270
and these are sort of late flight path
so they're they're like latitude

274
00:23:51,270 --> 00:23:58,389
longitude parents for flights on the USS
just wanted them on an ATV space that is

275
00:23:58,390 --> 00:24:01,450
interesting structure and so it's
immediately think when you look at the

276
00:24:01,450 --> 00:24:04,890
position you get all sorts of stories
that it even start to think about where

277
00:24:04,890 --> 00:24:11,340
these hubs like what's going on here is
this going la you start to get a sense

278
00:24:11,340 --> 00:24:14,090
of what's going on in terms of the fate
of you can never get if you just looking

279
00:24:14,090 --> 00:24:19,449
at a textile industry like a big point
of visualization is literally no other

280
00:24:19,450 --> 00:24:26,600
way to make them to the data that in
some way of simple and this is the

281
00:24:26,600 --> 00:24:31,219
classic film is Edward Tufte you folks
maybe some people not in a position to

282
00:24:31,220 --> 00:24:32,500
four

283
00:24:32,500 --> 00:24:36,490
visualization it tells the story of
Napoleon's demise in the early 19th

284
00:24:36,490 --> 00:24:38,840
century and so

285
00:24:38,840 --> 00:24:49,540
gatorade is then here is renewable and
Russia this is where he started on the

286
00:24:49,540 --> 00:24:57,680
man and his the patterns are meeting the
thickness of this line is in proportion

287
00:24:57,680 --> 00:25:02,390
to the number of troops and they started
out doing what he was doing pretty well

288
00:25:02,390 --> 00:25:08,270
initially he splits off and some good to
go through that over here and then in

289
00:25:08,270 --> 00:25:13,139
the winter comes in this are dying off
just to Moscow in the history of that

290
00:25:13,140 --> 00:25:18,830
you know there's an order of magnitude
less troops retreated Blackline the name

291
00:25:18,830 --> 00:25:25,600
is back he's he's taking it over you
know so you get it is hard to find

292
00:25:25,600 --> 00:25:28,969
another way of communicating that story
you could read history book about ends

293
00:25:28,970 --> 00:25:33,760
but I did this is a very good this is a
classic example of visualization retail

294
00:25:33,760 --> 00:25:40,660
complex very very intelligently chosen
through visual attributes and their

295
00:25:40,660 --> 00:25:49,110
associations that it used to be in
static susan is before in the

296
00:25:49,110 --> 00:25:52,080
visualization of the evolution of the
Python interpreter and starting in early

297
00:25:52,080 --> 00:25:55,010
nineties you're seeing a different
developers moving around and adding

298
00:25:55,010 --> 00:26:01,760
adding files to the debate on certain
that this example of like telling

299
00:26:01,760 --> 00:26:05,970
telling you really telling a complicated
story using using elegant visualization

300
00:26:05,970 --> 00:26:12,010
using the birth of anything you can keep
watching and you can see all the way to

301
00:26:12,010 --> 00:26:17,200
the present from my perspective

302
00:26:17,200 --> 00:26:21,490
visualization good so it has to do with
it really has to do with the data

303
00:26:21,490 --> 00:26:24,730
processing capabilities of the human
visual cortex and the sentiments of

304
00:26:24,730 --> 00:26:30,670
research on enough to talk about in the
target and so if you look at these

305
00:26:30,670 --> 00:26:36,870
panels here and hopefully you'll have
the city which is that the number is pop

306
00:26:36,870 --> 00:26:37,969
out right away

307
00:26:37,970 --> 00:26:48,690
so there's there's one that's different
and it doesn't feel like I'm not doing a

308
00:26:48,690 --> 00:26:53,090
brute forcing linear search to identify
the anomaly which is what may be like a

309
00:26:53,090 --> 00:26:57,899
traditional computer doing overall
dayton's and try to figure out which one

310
00:26:57,900 --> 00:27:04,260
is different and you did in the right
way

311
00:27:04,260 --> 00:27:12,220
like complex patterns pop out in this in
this example is more complicated like

312
00:27:12,220 --> 00:27:17,070
this you really see it and if you like
you mention hopefully everybody sees the

313
00:27:17,070 --> 00:27:18,460
square every year

314
00:27:18,460 --> 00:27:25,460
popping out so ready now for them they
would identify so they wouldn't even

315
00:27:25,460 --> 00:27:28,180
when you look at this legislation we
don't even know what to look for I

316
00:27:28,180 --> 00:27:35,590
didn't know to the risk of these plus
signs maybe he was just looking for

317
00:27:35,590 --> 00:27:38,590
interesting structure is in in within
within probably less than a second rate

318
00:27:38,590 --> 00:27:40,189
that that's for sure popped out

319
00:27:40,190 --> 00:27:42,700
imaginary including of energy trying to
program a computer to anything

320
00:27:42,700 --> 00:27:46,840
interesting structure is a very hard
training task diversity we have a visual

321
00:27:46,840 --> 00:27:54,010
system is designed to identify the four
are like a higher-order cognition in

322
00:27:54,010 --> 00:27:59,470
those kinds of things you know that
doesn't always you know that doesn't

323
00:27:59,470 --> 00:28:03,230
always happen as well as well though so
they can wear as well there is like

324
00:28:03,230 --> 00:28:07,090
almost like a hacker could appear as
well as you know for certain denial of

325
00:28:07,090 --> 00:28:10,490
service or visit our visual system
enforces the brute force of a visual

326
00:28:10,490 --> 00:28:15,180
image like any part of the pleasure of
it is like as your before senior thing

327
00:28:15,180 --> 00:28:18,340
interesting funny stories you know but
it's really not sure that there is much

328
00:28:18,340 --> 00:28:23,240
better it doesn't think this is an
example of bad luck that's important

329
00:28:23,240 --> 00:28:31,740
business vision for the purposes of
everything you do them so there there is

330
00:28:31,740 --> 00:28:35,300
some design principles that go into
individualization

331
00:28:35,300 --> 00:28:40,350
adviser one of the guys in major trouble
goes on as an entrance

332
00:28:40,350 --> 00:28:45,928
overview first details on any suspension
Maryland and there is a vegetarian menu

333
00:28:45,929 --> 00:28:53,910
design visualization like in the case of
you know the visitation will give an

334
00:28:53,910 --> 00:28:55,990
overview of the clusters in the screen

335
00:28:55,990 --> 00:29:02,360
move your mouse to get some details so
it's it's it's useful to people that are

336
00:29:02,360 --> 00:29:02,939
useful

337
00:29:02,940 --> 00:29:09,700
basically when you do you see that is OK
and then yes answer specific questions

338
00:29:09,700 --> 00:29:11,179
later

339
00:29:11,179 --> 00:29:14,880
you know quickly tell somebody like
what's the trend in like my stock

340
00:29:14,880 --> 00:29:19,630
briefly over the last day to be able to
really efficiently and vision or if

341
00:29:19,630 --> 00:29:23,419
you're gonna make an exploratory
position like that said you should make

342
00:29:23,419 --> 00:29:27,380
sure the actually do something in
between where they're not really sure

343
00:29:27,380 --> 00:29:32,679
whether but the goals of insulation our
many people then take it seriously

344
00:29:32,679 --> 00:29:37,650
the user and ninth grades we found this
a lot of other words the company's

345
00:29:37,650 --> 00:29:39,090
research company

346
00:29:39,090 --> 00:29:45,158
researchers are somewhat disconnected
from practitioners sometimes there is it

347
00:29:45,159 --> 00:29:48,159
will be fine as we need to go out and
actually interviewing people are you

348
00:29:48,159 --> 00:29:51,340
using our tools understand what their
needs are and then go back in like be

349
00:29:51,340 --> 00:29:53,970
very disciplined about designing the
tool with those with those people's

350
00:29:53,970 --> 00:29:55,299
needs in nineteen their skills

351
00:29:55,299 --> 00:30:01,059
the visualization design for a doctor
around like what's going on in a

352
00:30:01,059 --> 00:30:05,918
hospital or invade which is very
different than it was that kind of thing

353
00:30:05,919 --> 00:30:09,870
in the security space designed for an
hour over centenarian is different when

354
00:30:09,870 --> 00:30:15,939
you design for the night security
administrator ok any any questions about

355
00:30:15,940 --> 00:30:38,240
the visitations to this I will review
your question yeah

356
00:30:38,240 --> 00:30:43,800
yeah yeah if you can find it pretty
magical its own say she said it was

357
00:30:43,800 --> 00:30:46,860
unclear what you're doing when you give
it as a shin isn't looking over

358
00:30:46,860 --> 00:30:56,559
thousands of lives individually your
objection to screen them all at once

359
00:30:56,559 --> 00:31:02,260
yes many pics through thousands of
injuries you can see them on one screen

360
00:31:02,260 --> 00:31:05,870
and inserting data sets of the issue in
with an alien vegetation it can be

361
00:31:05,870 --> 00:31:09,399
pretty magical what can happen in terms
of your ability to take up a lot of

362
00:31:09,400 --> 00:31:18,559
little ones in general and the general
information about did a science examples

363
00:31:18,559 --> 00:31:21,309
and they're they're really some
fundamental but there are some

364
00:31:21,309 --> 00:31:25,850
differences between the way that you do
did it stands in general like the way

365
00:31:25,850 --> 00:31:32,209
that aired rendered computer scientist
to change it to machine learning and we

366
00:31:32,210 --> 00:31:37,370
have to do this and how we do security
argument for those differences are in

367
00:31:37,370 --> 00:31:42,169
and what's up with some potential
solutions are different cities the

368
00:31:42,170 --> 00:31:47,170
presence of an adversary that's a big
difference if you're so they can in the

369
00:31:47,170 --> 00:31:49,740
hard computer vision problems that
people at places like Facebook and

370
00:31:49,740 --> 00:31:53,240
Google are trying to solve that there
isn't an area behind the scenes trying

371
00:31:53,240 --> 00:31:58,270
to trick them into thinking that like an
old cow disease in cats have nine

372
00:31:58,270 --> 00:31:59,690
strains

373
00:31:59,690 --> 00:32:03,059
that's like there is a never say they're
trying to trick them into many systems

374
00:32:03,059 --> 00:32:09,190
and that's that's a big that's a big
difference that that that that is a big

375
00:32:09,190 --> 00:32:13,650
difference if you train it one of the
ways in which the difference is if you

376
00:32:13,650 --> 00:32:17,870
train a system to recognize the
difference between cats and dogs it's

377
00:32:17,870 --> 00:32:21,320
likely that system will continue to work
over the years in in 12 Grade very

378
00:32:21,320 --> 00:32:23,860
rapidly in terms of performance they
probably cats and dogs and look very

379
00:32:23,860 --> 00:32:27,709
different five years from now that's not
the case when you'll never see that's

380
00:32:27,710 --> 00:32:33,220
evolving and trying to defuse action
mechanisms we very much do you see that

381
00:32:33,220 --> 00:32:37,960
our machinery models that we build an
ark you definitely go out of the show

382
00:32:37,960 --> 00:32:43,650
you guys examples of that so this is
love her descended on mathematics intend

383
00:32:43,650 --> 00:32:46,040
to explain and basically so here's an
example of

384
00:32:46,040 --> 00:32:50,389
so many talk about it assist in the
rebuilding of last year in a group to

385
00:32:50,390 --> 00:32:56,580
detect behavior in system logs and this
is a big project we we develop we we

386
00:32:56,580 --> 00:33:01,370
gathered a huge amount of training data
we ran malware in a sandbox and we also

387
00:33:01,370 --> 00:33:06,760
collected data from our network and
interact through looks like this machine

388
00:33:06,760 --> 00:33:10,670
model that works pretty well at
detecting malicious behavior it will be

389
00:33:10,670 --> 00:33:17,730
found in so here is sort of years your
own and using this model and then go

390
00:33:17,730 --> 00:33:23,830
into more detail how did they did use
your own when we train the model on on

391
00:33:23,830 --> 00:33:28,570
examples of malware and examples but I'm
behavior we're able to detect

392
00:33:28,570 --> 00:33:33,639
solicitation rain on the y axis is the
false-positive readings and access

393
00:33:33,640 --> 00:33:39,930
directly 0 as the false-positive a
converges on 03 able to detect about 82%

394
00:33:39,930 --> 00:33:44,060
of the most useful since they're not
gonna take everything but it would take

395
00:33:44,060 --> 00:33:48,179
a lot of stuff along with the other
sensors I'm sorry but then you know if

396
00:33:48,180 --> 00:33:50,400
we don't continue to train the model

397
00:33:50,400 --> 00:33:55,370
a year later and we can only detect it
as a positive rating and what is that

398
00:33:55,370 --> 00:33:59,510
like 75% of the Miller and in two years
later in right now where is above

399
00:33:59,510 --> 00:34:04,710
sufficiently that only we can only text
it's like 60 65 percent of our index is

400
00:34:04,710 --> 00:34:07,280
like totally different than it's been a
mystery any system that would you like

401
00:34:07,280 --> 00:34:11,540
there would be no class medical images
or you know classifying objects on

402
00:34:11,540 --> 00:34:16,100
Facebook doing facial recognition is
just a little different so we find a lot

403
00:34:16,100 --> 00:34:20,440
of hard work and think about that and
when you're ready when you might like to

404
00:34:20,440 --> 00:34:23,510
see you need you to build in ways of
doing it online learning or training

405
00:34:23,510 --> 00:34:27,620
allows you to make sure you're getting
new data and keep in mind you check your

406
00:34:27,620 --> 00:34:30,949
model's accuracy as it degrades over
time so you actually aware of how you

407
00:34:30,949 --> 00:34:39,339
sleep sensor is that surprised when they
started flying machine learning to

408
00:34:39,340 --> 00:34:43,590
security active in other fields friends
is that the false-positive problem and

409
00:34:43,590 --> 00:34:46,530
it's really the issue here is that the
events that were looking for

410
00:34:46,530 --> 00:34:52,360
certainly get all the time a comment
like this there and when it comes to

411
00:34:52,360 --> 00:34:53,560
like the data we look at it

412
00:34:53,560 --> 00:34:57,420
let's say like looking at all of the
executables network or something like

413
00:34:57,420 --> 00:35:01,770
that I'm probably out of let's say we
see maybe 10,000 unique executables and

414
00:35:01,770 --> 00:35:07,490
their customers networks may be handed
us a malicious network but you know that

415
00:35:07,490 --> 00:35:11,569
I need any faction earner militias and
the implications of that are that if you

416
00:35:11,570 --> 00:35:14,980
have a system that's a like for every
behind binary that it sees like one in a

417
00:35:14,980 --> 00:35:19,000
thousand times it's going to falsely

418
00:35:19,000 --> 00:35:25,070
10019 blend binaries you're gonna get
your attention on those you know if

419
00:35:25,070 --> 00:35:31,700
you're even 1000 false-positive rate and
then you know that's a positive sign if

420
00:35:31,700 --> 00:35:36,149
you only have 10 malicious banners you
only detecting a bit more false

421
00:35:36,150 --> 00:35:39,330
positives the yard your positives

422
00:35:39,330 --> 00:35:45,730
even though you're even though he's very
very accurate as the one in 2008 to be

423
00:35:45,730 --> 00:35:52,120
working very very low false-positive
rates in the securities being raised

424
00:35:52,120 --> 00:35:58,400
fears example it actually calculated out
the probability is very soon so if you

425
00:35:58,400 --> 00:36:02,800
get a consistent has a 75% detection
rate of 24% was positively injury when

426
00:36:02,800 --> 00:36:05,760
you do the math you see the 34 34
percent of the Lambs will be false

427
00:36:05,760 --> 00:36:12,310
positives we assume 109 ratio but by the
time you get to a one in 10,000 our time

428
00:36:12,310 --> 00:36:16,529
our issues when in 2009 areas on the
network are actually militias nine years

429
00:36:16,530 --> 00:36:21,840
in the limestone that sensor to be false
positives basically useless so it is

430
00:36:21,840 --> 00:36:25,970
enormous and like when you do when you
do a C-section enormous amount of

431
00:36:25,970 --> 00:36:33,209
evidence of positive rains and the ratio
between the two of you looking for is

432
00:36:33,210 --> 00:36:39,100
this much more well behaves

433
00:36:39,100 --> 00:36:46,819
talked about that already in OK and then
here's a big difference for the cases in

434
00:36:46,820 --> 00:36:50,710
a case of say like a younger than that
this special recognition is a big

435
00:36:50,710 --> 00:36:57,760
research area and machine learning we
don't really cared if things that you

436
00:36:57,760 --> 00:37:00,770
know you're looking to picture John Doe
when it says that you are going to be a

437
00:37:00,770 --> 00:37:01,060
cure

438
00:37:01,060 --> 00:37:05,520
but in the case of machine learning in
security context it matters a lot why

439
00:37:05,520 --> 00:37:09,690
and why it said that you know something
bad happened because if if if if the

440
00:37:09,690 --> 00:37:15,260
sensor tells me that you know like all
the records have been compromised later

441
00:37:15,260 --> 00:37:19,160
I bet you see some evidence that tells
me that's for sure the case of rabies

442
00:37:19,160 --> 00:37:24,649
the lengthy periods and they know the
troops and you know whatever you

443
00:37:24,650 --> 00:37:27,850
seriously drastic action like shutting
things down in a kind of thing so

444
00:37:27,850 --> 00:37:31,540
there's no need to explain in many many
cases and security designed this need to

445
00:37:31,540 --> 00:37:36,540
explain it very clear way great way when
we made a detection by everything that's

446
00:37:36,540 --> 00:37:41,870
actually the case and so we felt like
like for example like an example is done

447
00:37:41,870 --> 00:37:46,339
here that the talking the talk more
about this we build innovative build

448
00:37:46,340 --> 00:37:49,870
machine many systems explained results
to the user is in its in this case we've

449
00:37:49,870 --> 00:37:54,250
built this automatic reverse engineering
system so it attacks

450
00:37:54,250 --> 00:37:57,680
functionality and existing in a
malicious banners in this case it it

451
00:37:57,680 --> 00:38:03,129
it's telling us how this country's
massive data exfiltration a prisoner in

452
00:38:03,130 --> 00:38:07,110
whatever user profiling is the reason
rate in Indonesia here's the reason why

453
00:38:07,110 --> 00:38:11,700
we think it is because it uses the API
calls

454
00:38:11,700 --> 00:38:18,100
position and furthermore there these
postings on Stack Overflow in which you

455
00:38:18,100 --> 00:38:23,140
know this was mentioned in relation to
mouth movements and then click on the

456
00:38:23,140 --> 00:38:27,370
link rating and go to go into the
relationship between secretary position

457
00:38:27,370 --> 00:38:31,359
and movement and is I'm going to a more
detailed how it works later in but I'm

458
00:38:31,360 --> 00:38:34,940
basically like there's there's a need to
emphasize explaining there is a

459
00:38:34,940 --> 00:38:47,840
securities so you think that's where
there is no example of late though this

460
00:38:47,840 --> 00:38:52,710
is an example of questions in the
balance here here here and not for

461
00:38:52,710 --> 00:39:01,180
security alert system for malware itself
so that we built this from our analysts

462
00:39:01,180 --> 00:39:05,750
have to look for through hundreds of our
samples obtained an idea was a lot of

463
00:39:05,750 --> 00:39:08,850
them our samples on this in the studio
space where it now resembles that are

464
00:39:08,850 --> 00:39:10,200
that are similar

465
00:39:10,200 --> 00:39:16,618
iron are sort of visually close together
so that no one listens to the analyzing

466
00:39:16,619 --> 00:39:19,400
all the malware and one by one they can
look at this link look at the

467
00:39:19,400 --> 00:39:23,579
similarities between our samples in the
identified as a family of now over here

468
00:39:23,579 --> 00:39:29,550
coming over there and then proceeded to
analyze the underlying the tool was the

469
00:39:29,550 --> 00:39:34,430
analysts and investors need to trust us
our samples are actually similar we show

470
00:39:34,430 --> 00:39:37,200
them evidence when the demand enjoyed
that they that these samples are

471
00:39:37,200 --> 00:39:41,970
actually similar when when the analysts
select group of samples were actually

472
00:39:41,970 --> 00:39:45,140
bring out the bunch of attributes of an
hour in this panel adhere to hear the

473
00:39:45,140 --> 00:39:49,700
analyst is selected from samples were
showing regime behaviour in the

474
00:39:49,700 --> 00:39:54,799
color-coded way resembles didn't we ran
it in a sandbox citizen programs and I

475
00:39:54,800 --> 00:39:59,650
can see when we highly then they always
did similar sequences of behavior and

476
00:39:59,650 --> 00:40:03,440
then if they can mouse over these
behaviors and get information about what

477
00:40:03,440 --> 00:40:08,290
his behavior means anything that's what
we experience handling that too is that

478
00:40:08,290 --> 00:40:13,599
the actual analysts who evaluated the
tool development of understands like the

479
00:40:13,599 --> 00:40:16,589
math behind like gripping the samples
that are somewhat together in one state

480
00:40:16,589 --> 00:40:21,500
when they saw the visualization and
actually use that to explain themselves

481
00:40:21,500 --> 00:40:24,250
that their unlike you know why samples
belong to you there should be analyzed

482
00:40:24,250 --> 00:40:30,640
the other than 10 people then people use
the tool intended for use them again in

483
00:40:30,640 --> 00:40:33,480
the fourth in NASA's difference between
doing

484
00:40:33,480 --> 00:40:38,619
designs in general dresses designs and
security context is the lack of labeled

485
00:40:38,619 --> 00:40:48,339
data so likable didn't pay a lot of
cases we have goods like nowadays likely

486
00:40:48,339 --> 00:40:52,240
in doing computer vision there had a big
database of images that are like tags

487
00:40:52,240 --> 00:40:57,399
have been tagged as like oh this is
worse and you can you can use that you

488
00:40:57,400 --> 00:41:00,319
can use this label to training to train
a machine learning systems detect those

489
00:41:00,319 --> 00:41:03,119
objects in images in the case of
cybersecurity its way different

490
00:41:03,119 --> 00:41:07,270
adversaries are actively keeping
information the information we need to

491
00:41:07,270 --> 00:41:10,130
train them many systems away from us we
always have to assume that we don't

492
00:41:10,130 --> 00:41:14,760
actually have the day today we need to
turn our models and so anything that

493
00:41:14,760 --> 00:41:15,550
makes things harder

494
00:41:15,550 --> 00:41:20,080
so there's no doubt about that so it i
mean they can medication for that is

495
00:41:20,080 --> 00:41:23,790
like the example issued earlier we can
use things that are very disservice to

496
00:41:23,790 --> 00:41:28,370
train a model that we built a system
earlier earlier version of it two years

497
00:41:28,370 --> 00:41:33,600
ago here at the house where we we we
didn't use any malware 2010 we'd be

498
00:41:33,600 --> 00:41:36,710
trained a machine learning system on
Stack Overflow to recognize what

499
00:41:36,710 --> 00:41:40,950
combinations of API calls are used in
the men's Nike slogan your webcam

500
00:41:40,950 --> 00:41:45,270
grabbing your device driver loading file
unlike six millions that overflow

501
00:41:45,270 --> 00:41:51,090
question-and-answer post talked about
how to manage a device driver found that

502
00:41:51,090 --> 00:41:54,870
when we apply the model to samples
extracted from now we're actually is

503
00:41:54,870 --> 00:41:59,660
accurate in detecting utilities
insecurity and looks like that because

504
00:41:59,660 --> 00:42:03,100
we don't have example we don't have to
reverse engineer examples they can use

505
00:42:03,100 --> 00:42:06,290
to train them as we need to go look at
me look rather do sources that are more

506
00:42:06,290 --> 00:42:12,279
reliable and we can and we can obtain
higher volume and other dental

507
00:42:12,280 --> 00:42:17,010
medication you know using unsupervised
learning algorithms is just a visitation

508
00:42:17,010 --> 00:42:21,270
of the of the behavioral questions that
they showed earlier but there's no

509
00:42:21,270 --> 00:42:24,550
evidence that they don't require that we
know what's now in with nine advance

510
00:42:24,550 --> 00:42:31,200
they're so is it is a need to look at
the look at this is the reason and I'm a

511
00:42:31,200 --> 00:42:34,149
detection has been so popular in
securities because we don't have labeled

512
00:42:34,150 --> 00:42:39,410
it unfortunately anomaly detection is
very hard to get that on bed anyways

513
00:42:39,410 --> 00:42:45,140
medication to the public not having a
lot of labels label data ok actually

514
00:42:45,140 --> 00:42:51,129
it's 42 minutes into the talk and that's
all I have to do something to get some

515
00:42:51,130 --> 00:43:02,130
questions and discussion and analysis of
the tug

516
00:43:02,130 --> 00:43:06,289
yes the question posed a question
whether the prevailing methods are

517
00:43:06,289 --> 00:43:11,940
useful and yes we find

518
00:43:11,940 --> 00:43:18,880
importance is also called dimensionality
reduction algorithms that high

519
00:43:18,880 --> 00:43:23,480
dimensional space and try to pin you
know then try to learn some tasks like

520
00:43:23,480 --> 00:43:24,930
preserving

521
00:43:24,930 --> 00:43:28,259
in mathematical terms of preserving
pairwise distances are preserving

522
00:43:28,259 --> 00:43:30,710
distances between items in the
dimensional space in the dimensional

523
00:43:30,710 --> 00:43:36,910
space in the presentation we were using
techniques like that like in there and

524
00:43:36,910 --> 00:43:44,230
the video shows I mean here used to
mention we use dimensionality reduction

525
00:43:44,230 --> 00:43:47,950
technique to take it as we had actually
each one of these behaviors color-coded

526
00:43:47,950 --> 00:43:54,939
behaviour forms of dementia and in terms
of this this and this and it went down a

527
00:43:54,940 --> 00:44:00,839
number of dimensions like I mentioned we
are using our than component analysis to

528
00:44:00,839 --> 00:44:06,680
projects that it onto a two-dimensional
surface and it still it sort of is sort

529
00:44:06,680 --> 00:44:11,399
of like a shadow of the high-dimensional
space in this million dimensional space

530
00:44:11,400 --> 00:44:16,470
remind me to visualize it turns out to
be that we found it to be very useful

531
00:44:16,470 --> 00:44:23,118
and in this case it was actually very
similar to that I would highly recommend

532
00:44:23,119 --> 00:44:38,799
nance yeah yeah yeah

533
00:44:38,799 --> 00:44:43,479
yes the question was given a rare event
problem that we talked about and we ran

534
00:44:43,479 --> 00:44:45,379
into the curse of dimensionality

535
00:44:45,380 --> 00:44:51,699
Alliance has to do nationally reaction
anyways classifiers I think the answer

536
00:44:51,699 --> 00:44:54,199
is yes we almost always do

537
00:44:54,199 --> 00:45:02,920
dimensionality reduction algorithms the
reuse so this is you know this is like a

538
00:45:02,920 --> 00:45:08,309
random forests that actually don't ever
tell you that we found very useful yeah

539
00:45:08,309 --> 00:45:37,450
I mean there is almost always a keeper
of the questions this

540
00:45:37,450 --> 00:46:08,629
yeah

541
00:46:08,630 --> 00:46:16,980
so much greater Toledo using

542
00:46:16,980 --> 00:46:46,320
sure we can probably get the phone then
yeah yeah

543
00:46:46,320 --> 00:46:53,720
ok so the question then prevents
confirmation bias and analysis where you

544
00:46:53,720 --> 00:46:58,770
know we're showing analyst teachers are
using things together i mean of course

545
00:46:58,770 --> 00:47:06,110
they give you the reason this features
because mentally similar yes we solve

546
00:47:06,110 --> 00:47:12,480
that problem by using a validation so we
actually for the system and this lady we

547
00:47:12,480 --> 00:47:17,920
had we had some labels and we measure
ourselves we measure how good our system

548
00:47:17,920 --> 00:47:22,270
is based on how he could reconstruct the
action that you simply relationships you

549
00:47:22,270 --> 00:47:49,009
know given to the grand jury that we had

550
00:47:49,010 --> 00:47:51,930
yeah

551
00:47:51,930 --> 00:47:57,410
that makes sense so he's making a point
that even with the validation says

552
00:47:57,410 --> 00:48:07,060
analyst because well after undergoing
before everybody leaves elsewhere to say

553
00:48:07,060 --> 00:48:10,590
I hope you will stick around for the
next rather talk which will describe in

554
00:48:10,590 --> 00:48:16,600
detail builds and evaluate these
networks

555
00:48:16,600 --> 00:48:26,029
predicts the future success given our
families and visualization tools and

556
00:48:26,030 --> 00:48:33,440
analysis tools that automatically revert
to the next phase is a question with go

557
00:48:33,440 --> 00:48:39,490
to make sure yeah I think there may be
onto something

558
00:48:39,490 --> 00:48:58,580
yeah

559
00:48:58,580 --> 00:49:04,250
question was about their ratio in terms
of our effort between the sort of an

560
00:49:04,250 --> 00:49:07,610
election she marrying and and
visualization as he spent on the project

561
00:49:07,610 --> 00:49:13,980
we just did this in this expertise
networks there we did we don't even

562
00:49:13,980 --> 00:49:18,070
listen we didn't then made her colleague
and I had to the present rate which

563
00:49:18,070 --> 00:49:20,030
despair and edification

564
00:49:20,030 --> 00:49:25,000
visualize the neurons in the networking
like they were never sent anybody but

565
00:49:25,000 --> 00:49:31,230
ourselves and not anybody in there was
no problem there is an extreme case with

566
00:49:31,230 --> 00:49:37,780
no position usually it's been about
fifty 50 and I think that's makes an

567
00:49:37,780 --> 00:49:45,410
important they're both very hard in
their own minds but I can do one more

568
00:49:45,410 --> 00:50:09,420
question if ya we have any questions
please go ahead and yeah yeah yeah

569
00:50:09,420 --> 00:50:17,760
which features to include in model
sometimes this model is approaching this

570
00:50:17,760 --> 00:50:22,849
rain which one is you keep all your
features around by using our them to

571
00:50:22,849 --> 00:50:25,940
transform the high-dimensional space
into a lower dimensional space

572
00:50:25,940 --> 00:50:29,960
throughout any features that's like to
mention principal component analysis

573
00:50:29,960 --> 00:50:38,119
that's a way of doing that has there's a
reason for that and then another is yeah

574
00:50:38,119 --> 00:50:42,990
you select features based on so when you
can do is typically work we have lots of

575
00:50:42,990 --> 00:50:46,520
debates over how we should do this you
just basically based on how correlated

576
00:50:46,520 --> 00:50:53,290
your house created your features are
with your target variable rate so if I

577
00:50:53,290 --> 00:50:53,799
mean

578
00:50:53,799 --> 00:51:01,910
intuitively fight outside talking
seriously I mean it's obvious that the

579
00:51:01,910 --> 00:51:07,740
malware has like this amount is unsigned
that suspicious rate hikes disagrees

580
00:51:07,740 --> 00:51:13,930
that cemented maybe that's correlated
with with with a mouse brain injuries as

581
00:51:13,930 --> 00:51:20,230
an excuse so he's very few simple
methods for technical reasons to hire

582
00:51:20,230 --> 00:51:29,019
purchase and that's how we doing

583
00:51:29,019 --> 00:51:38,749
yeah it's a big topic thanks everybody
who's talking about things that are you

584
00:51:38,749 --> 00:51:40,669
came back the next seven

