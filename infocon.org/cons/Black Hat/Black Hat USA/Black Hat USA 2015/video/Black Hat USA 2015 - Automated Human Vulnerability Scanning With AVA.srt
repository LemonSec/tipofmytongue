1
00:00:00,000 --> 00:00:04,220
session name is automated human
vulnerability scanning with a VA by

2
00:00:04,220 --> 00:00:10,120
Laura Bell

3
00:00:10,120 --> 00:00:18,009
yeah we only for lunch feeling that kind
of fuzzy warm of sitting in a warm room

4
00:00:18,010 --> 00:00:23,699
in it then the dog four-hours a good
idea right ok let's get started my name

5
00:00:23,699 --> 00:00:28,560
is Laura I'm gonna draw too much on that
because we've got a lot to cover I'm

6
00:00:28,560 --> 00:00:31,779
gonna break a few conventions are going
to encourage you to go and use the

7
00:00:31,779 --> 00:00:38,390
social universe there are a couple of
sorry is very echo -e I'm going to step

8
00:00:38,390 --> 00:00:43,200
back a little bit a little bit better
right I'm going to encourage you to use

9
00:00:43,200 --> 00:00:46,670
it with his I want you to get involved
with this discussion and as we go with

10
00:00:46,670 --> 00:00:51,600
the stalk you realize this really is a
discussion we're back to talk about

11
00:00:51,600 --> 00:00:57,559
things that might make you uncomfortable
and I say might but having spoken about

12
00:00:57,559 --> 00:01:02,620
this a few times now I know that some of
you will feel uncomfortable previous

13
00:01:02,620 --> 00:01:07,280
numbers of audiences have said that I
should be thrown in prison so either way

14
00:01:07,280 --> 00:01:14,650
I'm really sorry but I'm kinda not
because it turns out I want you to feel

15
00:01:14,650 --> 00:01:20,070
slightly uncomfortable we are going to
be discussing things that are some of

16
00:01:20,070 --> 00:01:24,860
the squishy areas we generally avoid
insecurity we're gonna be talking about

17
00:01:24,860 --> 00:01:30,229
things that go against how we relate to
other people he said I like people

18
00:01:30,229 --> 00:01:34,060
that's the mistake people make they
think that because I want to do bad

19
00:01:34,060 --> 00:01:38,570
things tonight people that I am a bad
person and I inherently don't like

20
00:01:38,570 --> 00:01:42,570
people well that's not true I have a
young daughter I'm invested in creating

21
00:01:42,570 --> 00:01:48,169
more people I think people are pretty
awesome so do I really like people and I

22
00:01:48,170 --> 00:01:52,250
like them so much I want to protect them
and I want you to go to organizations or

23
00:01:52,250 --> 00:01:57,689
whatever the hell you come from in the
world and protect your people because I

24
00:01:57,689 --> 00:02:02,100
think the vendors you know I i've i've
been around the whole of one does and

25
00:02:02,100 --> 00:02:03,630
I've been told

26
00:02:03,630 --> 00:02:10,329
we've conquered it we have secured a
border there is a magic bookstore secure

27
00:02:10,330 --> 00:02:12,290
applications

28
00:02:12,290 --> 00:02:19,459
threat intelligence is not just a rare
unicorn now it is cattle we all have

29
00:02:19,459 --> 00:02:29,680
these things in vast amounts for a very
skilled dedicated security teams turns

30
00:02:29,680 --> 00:02:38,389
out however attackers are relatively
lazy we're not really interested in

31
00:02:38,389 --> 00:02:45,680
proving we can best your technology
stack penetration has a very rarely

32
00:02:45,680 --> 00:02:49,590
interest in proving that Microsoft have
books their interest in seeing what they

33
00:02:49,590 --> 00:02:54,569
can use those books to attain so he
secured a boorda and we've secured our

34
00:02:54,569 --> 00:02:58,379
applications and we have threat
intelligence so we know what is coming

35
00:02:58,379 --> 00:03:04,659
for us then if I'm the attacker it might
just be me I'm going after the people

36
00:03:04,659 --> 00:03:10,668
because if you read the study in the
rich so last week for $100 people will

37
00:03:10,669 --> 00:03:15,829
give you pretty much anything from the
organization now I'm pretty bad at maths

38
00:03:15,829 --> 00:03:20,849
but when it's gonna cost $200,000 for
boorda device

39
00:03:20,849 --> 00:03:26,619
investment is kind of outweighing the
cost of an attack people are the path of

40
00:03:26,620 --> 00:03:31,440
least resistance we have to do something
about it so in this talk we gonna cover

41
00:03:31,440 --> 00:03:34,650
three things were going to talk about
the problem the problem with people why

42
00:03:34,650 --> 00:03:39,810
we need to protect them and what we're
doing what's going wrong they're gonna

43
00:03:39,810 --> 00:03:43,150
introduce a tool but I'm gonna get a
break back at convention I'm going to

44
00:03:43,150 --> 00:03:50,299
release an unfinished at all actually
needs the help and development he said

45
00:03:50,299 --> 00:03:55,229
we don't sell at all it's open source
and the reasons that finished is we've

46
00:03:55,229 --> 00:03:59,829
got questions and we need people like
you to answer them they will get a look

47
00:03:59,829 --> 00:04:02,699
at some of the challenges here on the
reason people think that I should be in

48
00:04:02,699 --> 00:04:07,129
prison and the reason that people don't
want to talk to me anymore and the

49
00:04:07,129 --> 00:04:13,268
reason we try to avoid talking about
personal security at all she would

50
00:04:13,269 --> 00:04:17,340
really really comfortable we talk about
technology when we talk about technical

51
00:04:17,339 --> 00:04:19,250
vulnerabilities it's easy right

52
00:04:19,250 --> 00:04:20,170
we have

53
00:04:20,170 --> 00:04:24,260
language system taxonomy we have CD test
scores

54
00:04:24,260 --> 00:04:30,030
we've got it down to an art now we don't
emphasize empathize at all without

55
00:04:30,030 --> 00:04:33,890
technology is just a machine it you know
when we do get funded built assessment

56
00:04:33,890 --> 00:04:37,800
or penetration test with doing the
logical equivalent of smashing hit with

57
00:04:37,800 --> 00:04:43,510
a big hammer but we don't care it's
gonna cry is gonna come play its

58
00:04:43,510 --> 00:04:51,719
computer people however are a big part
of our system and there are a lot of

59
00:04:51,720 --> 00:04:55,760
what we're not looking at dinner so we
got technology space we've got the

60
00:04:55,760 --> 00:05:00,010
personal space Scott process so I
technical space what you're right we're

61
00:05:00,010 --> 00:05:03,580
actually commoditized penetration
testing is a race to the bottom price

62
00:05:03,580 --> 00:05:08,120
was at the moment as many fans will
attest to vulnerability scanning is

63
00:05:08,120 --> 00:05:12,150
something you can do yourself with the
device in your environment

64
00:05:12,150 --> 00:05:17,190
processes audited by what it might be
the devil's work but still doing it we

65
00:05:17,190 --> 00:05:22,340
have a mutual system in place many
compliance for compliance regime to make

66
00:05:22,340 --> 00:05:26,489
a lot of money out of that it's gonna be
a good thing so what are we doing about

67
00:05:26,490 --> 00:05:31,560
how people what are we doing about the
squishy stuff

68
00:05:31,560 --> 00:05:38,210
the problem with people she
maneuverability as in things in humans

69
00:05:38,210 --> 00:05:42,940
that makes them susceptible to risk
likely to be hurt or exploited is

70
00:05:42,940 --> 00:05:48,870
actually really natural it's part of
what makes us a society we are today

71
00:05:48,870 --> 00:05:53,370
vulnerability comes from all sorts of
places it comes from that beer you know

72
00:05:53,370 --> 00:05:56,880
that we're gonna be harmed in some way
physically or mentally or emotionally

73
00:05:56,880 --> 00:06:01,630
will be discovered that you know all
closed my eyes for a second but raise

74
00:06:01,630 --> 00:06:06,370
your hand if you make up your job for a
living every day you know nobody was

75
00:06:06,370 --> 00:06:10,420
raised a hand but actually professional
life is about making things up quicker

76
00:06:10,420 --> 00:06:11,550
than the people around you

77
00:06:11,550 --> 00:06:16,410
we are vulnerable all the time and we
hide it we don't want to talk about

78
00:06:16,410 --> 00:06:23,200
vulnerability love love makes us
vulnerable the things we love you know

79
00:06:23,200 --> 00:06:27,710
the fact that you like that she's a TV
show and you watch it tonight the fact

80
00:06:27,710 --> 00:06:31,520
that you spend you know all of your free
time and money on whatever hope you're

81
00:06:31,520 --> 00:06:32,960
obsessed with you

82
00:06:32,960 --> 00:06:36,758
fill your life with people that you care
about all of these things make us

83
00:06:36,759 --> 00:06:41,849
vulnerable if you ever go anywhere near
kind of these spy movies and things you

84
00:06:41,849 --> 00:06:46,710
notice when they gonna exploitive person
they're trying to get a leave and I'll

85
00:06:46,710 --> 00:06:50,710
do it with either feel all the do it
with love that show that you care about

86
00:06:50,710 --> 00:06:57,590
this vulnerability that we're also a
really strange creature because you see

87
00:06:57,590 --> 00:07:03,400
we think we understand people pretty
well no it's fine we know people will

88
00:07:03,400 --> 00:07:10,070
react in you know expires at ways but
people like water we do anything in a

89
00:07:10,070 --> 00:07:13,630
power to get to what we're going to try
and do it why technology adoption of

90
00:07:13,630 --> 00:07:17,000
things like encryption is so called
because people don't want to spend time

91
00:07:17,000 --> 00:07:20,669
on the journey their interest in sending
the email sending a message they don't

92
00:07:20,669 --> 00:07:25,620
have to deal with PGP and then we get
surprised as a security community when

93
00:07:25,620 --> 00:07:29,009
we can't predict them because we've
assumed we already knew so we didn't pay

94
00:07:29,009 --> 00:07:35,169
attention we need to change some of the
things we need to kind of embrace we

95
00:07:35,169 --> 00:07:40,859
need to challenge some of them we need
to find a way to do defense in the human

96
00:07:40,860 --> 00:07:45,630
security space now I'm standing on the
shoulders of giants in some ways Chris

97
00:07:45,630 --> 00:07:49,139
hang me and all of those professionals
in the social engineering space have

98
00:07:49,139 --> 00:07:53,500
been doing the offensive side very well
for a number of years 950 a range of

99
00:07:53,500 --> 00:07:57,690
great books you can buy them from the
blackout still here today I I just got

100
00:07:57,690 --> 00:08:01,820
everything I don't get commissioned by
the way flights in the good books but

101
00:08:01,820 --> 00:08:07,530
you gotta find one about defending large
numbers of people not much at all we

102
00:08:07,530 --> 00:08:11,638
like attacking we like the offense
because it's glamorous it makes us feel

103
00:08:11,639 --> 00:08:16,979
like we're being a spy or being
deceptive but in fact it's the defense

104
00:08:16,979 --> 00:08:18,849
it's important

105
00:08:18,849 --> 00:08:23,688
and then comes compliance so PCI
compliance just to name one and I'm not

106
00:08:23,689 --> 00:08:29,069
picking on them there are many equally
terrible regimes they have a nice

107
00:08:29,069 --> 00:08:32,380
checkbooks and it says every member of
staff in your organization should be

108
00:08:32,380 --> 00:08:37,448
given information security awareness
training fantastic that spawned an

109
00:08:37,448 --> 00:08:43,708
entire industry of learned to collect
left video learning so we have tried an

110
00:08:43,708 --> 00:08:48,619
entire generation of our staff to get to
the final exit button as quickly as

111
00:08:48,620 --> 00:08:53,120
possible so we learned very quickly to
find the button is sitting next to hit

112
00:08:53,120 --> 00:08:57,550
enter as many times as it would allow in
some systems we learn how to do sequel

113
00:08:57,550 --> 00:09:00,870
injection purely because that's the best
way to get a hundred percent on most

114
00:09:00,870 --> 00:09:08,740
things we do video training we do
e-learning thats going super well we

115
00:09:08,740 --> 00:09:10,509
take boxes were compliant

116
00:09:10,509 --> 00:09:18,089
certificates for us and we might post
office so security awareness education

117
00:09:18,089 --> 00:09:23,529
really sucks and you have inflicted this
on someone in your company have a full I

118
00:09:23,529 --> 00:09:28,240
am guilty of this it really does not put
yourself through I do encourage you to

119
00:09:28,240 --> 00:09:32,220
go back to your office and put yourself
through your own course this is an

120
00:09:32,220 --> 00:09:36,709
example of a poster if you can google
information security awareness poster

121
00:09:36,709 --> 00:09:42,219
these are the types of gold we see don't
share your password with others it's

122
00:09:42,220 --> 00:09:48,149
like your toothbrush change it often so
long to people leave between changing

123
00:09:48,149 --> 00:09:51,759
their toothbrushes at the moment you
don't wanna know that number that number

124
00:09:51,759 --> 00:09:52,880
is not good

125
00:09:52,880 --> 00:09:58,540
this is not a good analogy so if you
have a compulsion of your desk and he's

126
00:09:58,540 --> 00:10:03,029
got some kind of like Photoshop opening
you like to make a poster stop consider

127
00:10:03,029 --> 00:10:08,120
this an intervention you're among
friends friends friends make information

128
00:10:08,120 --> 00:10:13,610
security wanted posters this isn't how
people learn at all in fact

129
00:10:13,610 --> 00:10:16,939
psychologists and the education sector
of known this for years we're just a

130
00:10:16,939 --> 00:10:20,240
community that's not very good at
playing well with others so we kinda

131
00:10:20,240 --> 00:10:25,810
didn't reach and ask them there's lots
of tricks to forming good habits doing

132
00:10:25,810 --> 00:10:27,869
one poster is not doing these things

133
00:10:27,870 --> 00:10:29,200
this is the three rd

134
00:10:29,200 --> 00:10:34,350
formation this is you know the rules
cycle hire people for habit I recommend

135
00:10:34,350 --> 00:10:38,590
reading psychology books but I'm not
here to tell you about this I'm trying

136
00:10:38,590 --> 00:10:41,950
to tell you about domain that exists we
could have learned from and we should be

137
00:10:41,950 --> 00:10:47,760
learning from and I'm hoping through a
ver we are one of the most despicable

138
00:10:47,760 --> 00:10:53,510
thing is that we Shane victims of
information security attacks in New

139
00:10:53,510 --> 00:10:57,970
Zealand where I come from today the
giant government preaches wear is being

140
00:10:57,970 --> 00:11:01,160
caused by nothing more than someone
trying to be helpful

141
00:11:01,160 --> 00:11:04,170
someone answering a question they
thought they were authorized to answer

142
00:11:04,170 --> 00:11:09,390
shared the document they didn't see any
harm this is this something that we

143
00:11:09,390 --> 00:11:13,560
should shameful because secretly we're
doing it all the time

144
00:11:13,560 --> 00:11:19,729
ourselves when I do social engineering
jobs or pen test that type it's the

145
00:11:19,730 --> 00:11:25,400
systems administrators the security team
that has the eager the music they forget

146
00:11:25,400 --> 00:11:29,860
they're actually vulnerable most of the
success in these jobs is done through

147
00:11:29,860 --> 00:11:34,610
attacking people who think they know
better

148
00:11:34,610 --> 00:11:40,310
we forget that we're connected species
if their entire such as a species has

149
00:11:40,310 --> 00:11:44,390
related to the fact human beings play
well with other human beings trust them

150
00:11:44,390 --> 00:11:49,760
and build things together so when we do
things like automated phishing attacks

151
00:11:49,760 --> 00:11:52,810
at the moment which are quite common as
a measure you might be using your

152
00:11:52,810 --> 00:11:59,099
organization we did against individuals
is an isolated think we ignore the fact

153
00:11:59,100 --> 00:12:03,650
that if say for example you have a call
center for the people that they're

154
00:12:03,650 --> 00:12:07,939
always communicating with each other
that they actually function as a unit

155
00:12:07,940 --> 00:12:12,420
the person you attack may not be the one
with access they may actually go and ask

156
00:12:12,420 --> 00:12:16,810
their friend because their friend has
more commissions and then we overlook

157
00:12:16,810 --> 00:12:20,420
the fact that to understand a security
risk we don't need to know the risk of

158
00:12:20,420 --> 00:12:24,719
one person calling for social
engineering attack we need to know the

159
00:12:24,720 --> 00:12:30,640
risk of a group or community falling for
it together because of a successful

160
00:12:30,640 --> 00:12:38,060
attacks don't necessarily find the right
person the first time so why don't we

161
00:12:38,060 --> 00:12:42,439
actively assess this bits and pieces
right we do red tape RED team

162
00:12:42,440 --> 00:12:47,380
social engineering pen test but believe
me these are reserved for the most

163
00:12:47,380 --> 00:12:52,980
mature of organizations with big-budget
these are such a small fraction of the

164
00:12:52,980 --> 00:12:56,490
security work we're doing that it's
negligible and it doesn't reach most

165
00:12:56,490 --> 00:13:00,760
organizations that companies like fish
two fish 5 all of these kind of fishing

166
00:13:00,760 --> 00:13:03,500
of the service things this is a step in
the right direction

167
00:13:03,500 --> 00:13:07,060
a continual assessment but isn't gonna
show use only shown you part of the

168
00:13:07,060 --> 00:13:13,729
picture I we don't test because we're
actually slightly arrogant myself

169
00:13:13,730 --> 00:13:17,830
included I include myself in all of this
we don't have because it's too easy to

170
00:13:17,830 --> 00:13:21,410
hack a person you just tell them all I
offer and can be given a hundred bucks

171
00:13:21,410 --> 00:13:27,689
we don't tip do it because people can't
be told people are lazy and stupid

172
00:13:27,690 --> 00:13:32,100
people other than ourselves obviously we
don't need teaching cause we're better

173
00:13:32,100 --> 00:13:40,800
than them but the reality is we aren't
lazy or stupid and we can we talk we

174
00:13:40,800 --> 00:13:47,449
just really terrible educators really
awful we don't test because it makes us

175
00:13:47,450 --> 00:13:51,130
feel uncomfortable we don't engage in
this because it makes us feel weird and

176
00:13:51,130 --> 00:13:56,050
people might get fired because it's hard
because we have no freaking clue how we

177
00:13:56,050 --> 00:14:01,760
would fix it knowing that you're broken
is really really scary knowing that the

178
00:14:01,760 --> 00:14:06,740
system US-built could be compromised by
a simple thing like an email or just

179
00:14:06,740 --> 00:14:11,830
somebody finding a USB stick is
terrifying because we spend billions of

180
00:14:11,830 --> 00:14:16,360
dollars a year building these giant
castles and we're gonna be let in by

181
00:14:16,360 --> 00:14:22,290
somebody politely the frontal border
devices aren't enough I went to a talk

182
00:14:22,290 --> 00:14:28,980
about six months ago and he said it's ok
my spam filter will stop it all huh

183
00:14:28,980 --> 00:14:33,250
border devices are great and the
unnecessary another part of defense in

184
00:14:33,250 --> 00:14:38,880
depth fantastic keep doing that but
really they are not enough for every

185
00:14:38,880 --> 00:14:43,300
time we created a vice the offensive
community is ahead of us they are

186
00:14:43,300 --> 00:14:48,930
adapting they are evolving there is such
a fragmentation evolution patently

187
00:14:48,930 --> 00:14:51,839
offensive space to add more devices have
no hope

188
00:14:51,840 --> 00:14:56,310
up this way we can predict how these
things will meet at next now this might

189
00:14:56,310 --> 00:15:00,030
change one day but right now we're not
there but we spend millions of dollars a

190
00:15:00,030 --> 00:15:04,089
year on these things and hope they will
just save us something to tell you about

191
00:15:04,090 --> 00:15:12,040
a ver ava is I told that I built to
scratch an itch I had a theory I I was

192
00:15:12,040 --> 00:15:16,280
getting frustrated I couldn't
communicate in an organization how the

193
00:15:16,280 --> 00:15:20,870
risk in the people looked how the
organization fitted together and how

194
00:15:20,870 --> 00:15:25,360
they responded to a range of risks even
what you stand for something I'm sure

195
00:15:25,360 --> 00:15:31,590
but as most acronyms go it's pretty
useless just call it a ver is a

196
00:15:31,590 --> 00:15:35,290
first-generation proof of concept
three-phase automated human

197
00:15:35,290 --> 00:15:39,280
vulnerability scanner that sounds very
swish doesn't it basically means Python

198
00:15:39,280 --> 00:15:41,270
code

199
00:15:41,270 --> 00:15:46,020
hi code that nobody's written like this
before and I wish they had I'm not

200
00:15:46,020 --> 00:15:50,020
trying to say I'm super cover anything
I'm trying to say I can't find anything

201
00:15:50,020 --> 00:15:54,400
that doesn't I think it's important
enough that we do do it so it's three

202
00:15:54,400 --> 00:16:01,590
face let's don't talk about the phases
the first lady's no we don't know what

203
00:16:01,590 --> 00:16:07,020
our organizations look like we don't
have the faintest idea she remembers

204
00:16:07,020 --> 00:16:11,949
polite diagrams showed you on your first
week in your job where you know had 16

205
00:16:11,950 --> 00:16:15,920
million people at the bottom and you
were somewhat on the bottom it was a

206
00:16:15,920 --> 00:16:21,380
nice hierarchy that's not how
organizations look if you start looking

207
00:16:21,380 --> 00:16:25,070
at the interactions between people how
they communicate if you look at the

208
00:16:25,070 --> 00:16:30,080
commission structures and who has access
to what that hierarchy that we believe

209
00:16:30,080 --> 00:16:37,200
exists is very very different in fact he
looks a bit like a graph in fact exactly

210
00:16:37,200 --> 00:16:41,840
like a graph nodes and edges groups
mailing list all sorts of things because

211
00:16:41,840 --> 00:16:46,570
we're highly connected insider
organizations and that connection gives

212
00:16:46,570 --> 00:16:52,180
us power in ways that a job titles and a
great dinner rolls don't give us the

213
00:16:52,180 --> 00:16:55,739
human security risk of the people is
magnified by this the more highly

214
00:16:55,740 --> 00:17:01,270
connected on the more permissions they
have the law they're vulnerable target

215
00:17:01,270 --> 00:17:06,050
now we know this this is not new this is
cool principle of least privilege and we

216
00:17:06,050 --> 00:17:10,560
should all be doing this right we should
all be auditing our held up every week

217
00:17:10,560 --> 00:17:15,679
yeah and it doesn't happen it happens in
the one unicorn organization that you

218
00:17:15,680 --> 00:17:21,740
know how I seventy security people but
for most of us is a key so I want to

219
00:17:21,740 --> 00:17:26,170
come back by pulling information buy it
from authorities sources is pulling from

220
00:17:26,170 --> 00:17:30,900
Active Directory Twitter LinkedIn
Facebook email providers like exchange

221
00:17:30,900 --> 00:17:35,320
in addis Google Apps for Business and
we're pulling anything we can truly

222
00:17:35,320 --> 00:17:42,100
channels I will not very clearly I'm not
breaking the law technically we are

223
00:17:42,100 --> 00:17:47,590
pulling the metadata about accounts we
are pulling the people identify as I

224
00:17:47,590 --> 00:17:51,389
have a email addresses a user names IP
addresses associated with them groups

225
00:17:51,390 --> 00:17:54,130
were pulling relationships who's talking
to her

226
00:17:54,130 --> 00:17:59,020
who is in the same group as who who
works with each other we're not putting

227
00:17:59,020 --> 00:18:02,490
content I'm just gonna say that
categorically I do not want to see

228
00:18:02,490 --> 00:18:04,600
what's in your email I've seen what's in
your email

229
00:18:04,600 --> 00:18:11,699
really know nobody else to say it but we
are pulling these are the things we're

230
00:18:11,700 --> 00:18:15,920
playing friends and contacts were
filling the frequency logged in how many

231
00:18:15,920 --> 00:18:18,580
times your password is changed when it
last changed

232
00:18:18,580 --> 00:18:22,810
administrator are you a member of group
that has inherited an administrator

233
00:18:22,810 --> 00:18:28,220
permissions for you the sender or
receiver of anything what public

234
00:18:28,220 --> 00:18:35,820
profiles we're profiling people and it
will stifle squishy I know what we gonna

235
00:18:35,820 --> 00:18:36,840
do with all of this

236
00:18:36,840 --> 00:18:40,610
well that brings in face to once you
know what your organization looks like

237
00:18:40,610 --> 00:18:44,729
you have this lovely graph of people and
all of the associated information about

238
00:18:44,730 --> 00:18:49,380
them you've got an idea of the types of
people who might be more interesting

239
00:18:49,380 --> 00:18:52,770
than others and trust me it's not gonna
be your CIO I'm sorry any CIA is in the

240
00:18:52,770 --> 00:18:58,879
room you're not an interesting person to
me and I'm gonna go into why cause we're

241
00:18:58,880 --> 00:19:02,810
going to inject threat now this is
phishing attacks that's all we're kind

242
00:19:02,810 --> 00:19:07,840
of familiar with the school we can
inject all sorts of threat into this

243
00:19:07,840 --> 00:19:12,020
network in Safeway's we're not gonna
check my leather is nothing malicious

244
00:19:12,020 --> 00:19:19,400
nobody will be heart we gonna do it by
email by social networks by removable

245
00:19:19,400 --> 00:19:24,130
media files on honey pots that you know
if I'll share that claims it's got the

246
00:19:24,130 --> 00:19:29,890
latest Avengers movie on Yahoo thought
that'd be a honeypot SMS we're gonna use

247
00:19:29,890 --> 00:19:34,080
attack vectors actually represent the
way you communicate your organizations

248
00:19:34,080 --> 00:19:38,899
using slack first and kind of DevOps
sort of development life cycle then we

249
00:19:38,900 --> 00:19:42,130
should be there to the security
community needs to be wherever a people

250
00:19:42,130 --> 00:19:47,000
we're not right now we're hanging out an
email to tell you the development

251
00:19:47,000 --> 00:19:50,730
community left about five years ago and
they occasionally revisit when we make

252
00:19:50,730 --> 00:19:55,870
them on the email side alone fishing is
one of the categories were familiar with

253
00:19:55,870 --> 00:20:01,729
but what about power play what about if
you have an executive hire company that

254
00:20:01,730 --> 00:20:04,240
email frontline support person

255
00:20:04,240 --> 00:20:08,120
ask them using their commanding slightly
patronizing tone of voice I need that

256
00:20:08,120 --> 00:20:13,270
password I need that file how many T one
analyst in your organization would feel

257
00:20:13,270 --> 00:20:18,500
brave enough to say no I should be no
more likely to say yes shouldn't we be

258
00:20:18,500 --> 00:20:23,470
able to test this and find out if there
is a case for helping them what we put

259
00:20:23,470 --> 00:20:27,820
this information into a network where
does it come out from that it would be

260
00:20:27,820 --> 00:20:31,428
interesting that's a technique has been
going on since well will too

261
00:20:31,429 --> 00:20:35,200
we don't have enough security tools we
ignore it because you know that might

262
00:20:35,200 --> 00:20:40,820
make us you know slightly weird how it
turns out when I was looking for ways to

263
00:20:40,820 --> 00:20:44,720
do this I got quite excited because I
need examples of phishing emails and bad

264
00:20:44,720 --> 00:20:47,929
things that happen to people now I
thought I was alone in this but I've

265
00:20:47,929 --> 00:20:53,110
been keeping these things for wile other
people collect them to show he's my

266
00:20:53,110 --> 00:20:56,678
first call to action for you if you
happen to be sitting on a stash of

267
00:20:56,679 --> 00:21:01,500
malicious emails or tweets or anything
in fact that has been used to treat the

268
00:21:01,500 --> 00:21:06,290
people in your organization or yourself
please let me know because we have a

269
00:21:06,290 --> 00:21:10,550
growing corpus of this stuff and we're
turning into benign so not malicious

270
00:21:10,550 --> 00:21:16,419
examples of things we know work so we
have a reusable open-source corpus that

271
00:21:16,420 --> 00:21:22,530
we can use to test people with my heart
is something I've been mentioned a lot

272
00:21:22,530 --> 00:21:27,559
of avenues of Takia that are not inside
your business I've been mentioning

273
00:21:27,559 --> 00:21:32,600
LinkedIn and Twitter Facebook and that's
because these are the places you people

274
00:21:32,600 --> 00:21:39,199
are actually hanging out I believe we
have to take a step and we have to go

275
00:21:39,200 --> 00:21:44,300
from just the systems we look at Wii
controller we bought two sisters people

276
00:21:44,300 --> 00:21:51,830
are actually using I had a client really
lovely very small client had very very

277
00:21:51,830 --> 00:21:55,750
posh fancy you know I could directory
BAE Systems they've built their divine

278
00:21:55,750 --> 00:21:59,780
around but it turns out the people the
front line couldn't really figure out

279
00:21:59,780 --> 00:22:04,389
how to share the date they needed so
they'd always find resistance from ITC

280
00:22:04,390 --> 00:22:07,420
what are they done they set up a private
facebook group with the person they

281
00:22:07,420 --> 00:22:11,559
wanted to share it with shared
consistently files over that private

282
00:22:11,559 --> 00:22:14,559
facebook group for years now

283
00:22:14,559 --> 00:22:18,080
think about your organization would you
be aware if people in your organization

284
00:22:18,080 --> 00:22:23,580
will pop it pop in their work documents
in a Facebook group will be no this is

285
00:22:23,580 --> 00:22:27,509
not going to show up in your lungs your
fancy border device is not going to tell

286
00:22:27,509 --> 00:22:30,799
you this is happening because there are
legitimate reasons are probably using

287
00:22:30,799 --> 00:22:35,620
facebook during the day you know most of
us have a relaxed policy around so why

288
00:22:35,620 --> 00:22:39,199
on earth have we filled our organization
for the people who will take the path

289
00:22:39,200 --> 00:22:43,059
that is least painful to them and expect
them to do anything but uses social

290
00:22:43,059 --> 00:22:48,330
things we need to go there are security
people in a calm and constructive way

291
00:22:48,330 --> 00:22:53,100
but we need to go there we need to do it
all the time security fails we dress it

292
00:22:53,100 --> 00:22:56,730
up like a special event when you going
toward it somewhere and it's just once a

293
00:22:56,730 --> 00:23:00,220
year they pull out that person in the
fancy suit that they've drilled with the

294
00:23:00,220 --> 00:23:05,190
answers and they feel really gonna have
a little party at the end but nothing

295
00:23:05,190 --> 00:23:08,999
changed we did improve security happen
we provide proof that one person a

296
00:23:08,999 --> 00:23:13,970
really nice suit can answer interview
questions we want to be able to do it

297
00:23:13,970 --> 00:23:18,129
instantly we want to do it on a
scheduled basis we went to recurring I

298
00:23:18,129 --> 00:23:25,090
wouldn't do over different groups will
be able to segment when we have to give

299
00:23:25,090 --> 00:23:28,519
the option of succeeding now it's all
very well saying you know well you

300
00:23:28,519 --> 00:23:33,509
failed this test you clicked on the link
he went to the bad site but are we

301
00:23:33,509 --> 00:23:37,399
giving people the option of going
actually I saw this thing and it looked

302
00:23:37,399 --> 00:23:41,469
really dodgy but I thought you should
know your security team and I trust you

303
00:23:41,470 --> 00:23:47,740
and let you should look at this at all
ever given the option of succeeding so

304
00:23:47,740 --> 00:23:52,549
let's make it okay for them to bring
their crazy to earth bring the things

305
00:23:52,549 --> 00:23:56,429
that look a bit silly the ideas you
heard going on in the office and make it

306
00:23:56,429 --> 00:23:57,980
safe to do that

307
00:23:57,980 --> 00:24:03,129
unreinforced good behaviour wouldn't it
be amazing if in your team one person

308
00:24:03,129 --> 00:24:07,539
failed a test and arrested in but
instead of them laughing at bubble Betty

309
00:24:07,539 --> 00:24:13,100
they said hey let's talk about that so I
thought it was dodgy because I saw this

310
00:24:13,100 --> 00:24:17,809
type of here did you look for that oh no
I saw this over here and I thought this

311
00:24:17,809 --> 00:24:21,940
made it look real what if people the on
security people were having that

312
00:24:21,940 --> 00:24:25,190
conversation we just have one person

313
00:24:25,190 --> 00:24:30,360
paid to do security we would have an
organizational security on me and then

314
00:24:30,360 --> 00:24:35,050
we went to analysis we want to look at
behavior over time can you correlate

315
00:24:35,050 --> 00:24:40,050
what is happening risk lies with what
we're doing talk people so if you run

316
00:24:40,050 --> 00:24:44,940
your training latest update on your
timeline what if you've had a really

317
00:24:44,940 --> 00:24:49,400
busy period in the executive level of
said you will work more hours you will

318
00:24:49,400 --> 00:24:55,320
get the job done can we correlate an
increase in poor security behaviour with

319
00:24:55,320 --> 00:25:00,090
periods of high stress in our
organization can we categorically say

320
00:25:00,090 --> 00:25:03,939
that the cost of you having a high
impact released this month

321
00:25:03,940 --> 00:25:08,290
didn't just affect us in terms of
overtime paid it increased a security

322
00:25:08,290 --> 00:25:12,850
risk for a people that would be a
powerful message when we're planning

323
00:25:12,850 --> 00:25:18,959
things when we're trying to avoid
burnout and stress things going back to

324
00:25:18,960 --> 00:25:22,420
that training if you've ever been to a
trying to cause I can too many I spent

325
00:25:22,420 --> 00:25:23,980
hundreds of thousands of dollars on this

326
00:25:23,980 --> 00:25:28,530
michael's my life training is big
business I'm not doing you could

327
00:25:28,530 --> 00:25:32,500
actually mother nature whether it worked
or not whether it actually worked for

328
00:25:32,500 --> 00:25:38,010
HRT no sales team will you take teens
have been choose what you bought the

329
00:25:38,010 --> 00:25:41,310
team training again or whether it needed
to be something else we don't have that

330
00:25:41,310 --> 00:25:43,870
power right now we have no way of
measuring our effectiveness of that

331
00:25:43,870 --> 00:25:49,909
training and then there's a couple of
things on the edge of graphs I'm a bit

332
00:25:49,910 --> 00:25:55,840
of a date and this is really fascinating
graphs that you can look at and its

333
00:25:55,840 --> 00:25:59,409
properties of graphs that we should
probably be looking at who are the week

334
00:25:59,410 --> 00:26:04,520
Bridges who who connect communities in
our organization now these are gonna be

335
00:26:04,520 --> 00:26:07,790
the people you know them you know them
probably quite well they've been in your

336
00:26:07,790 --> 00:26:12,270
organisation seven or eight is they've
moved a couple of jobs there really

337
00:26:12,270 --> 00:26:16,790
friendly and of course he gets the job
done so when you're struggling with us

338
00:26:16,790 --> 00:26:20,830
the change request process or you know
whatever requisition process

339
00:26:20,830 --> 00:26:24,540
person who you know in the back you mind
if i just want to see them they can help

340
00:26:24,540 --> 00:26:29,600
me they always do their amazing what if
we can spot those people what if instead

341
00:26:29,600 --> 00:26:33,480
of making that go way we can understand
what role they were playing and actually

342
00:26:33,480 --> 00:26:35,779
trying to build that naturally into our
organizations in the

343
00:26:35,779 --> 00:26:41,460
now in network security I used to do
network penetration testing for a long

344
00:26:41,460 --> 00:26:45,210
time we talked about pivoting as the
idea that you come in through one and

345
00:26:45,210 --> 00:26:48,649
tree we might actually help through
several boxes for network before going

346
00:26:48,649 --> 00:26:54,018
to high-value target do that with people
what if I can tell you where I would get

347
00:26:54,019 --> 00:26:58,719
in so who is most likely to take the
initial bait but then who is going to be

348
00:26:58,719 --> 00:27:02,809
the person who follows through with the
next attack how can I get through your

349
00:27:02,809 --> 00:27:08,779
people this is why people find this
uncomfortable this is not talking about

350
00:27:08,779 --> 00:27:11,989
people and their emotions and the
feelings this is people in the same way

351
00:27:11,989 --> 00:27:18,759
we talk about service you know what will
be fun but no one ever predictive risk

352
00:27:18,759 --> 00:27:24,129
behavior analysis goes all minority
report this one right can we prove from

353
00:27:24,129 --> 00:27:26,269
past behavior what they're gonna do in
the future

354
00:27:26,269 --> 00:27:31,719
probably not but we can probably look at
this as an interesting place to gain

355
00:27:31,719 --> 00:27:36,889
insights were not even aware we could
have yet to supporting technologies

356
00:27:36,889 --> 00:27:42,519
involved I'm not gonna keep going
through this list we use doctor before

357
00:27:42,519 --> 00:27:46,029
anyone gets me and goes all my go doctor
insecurity I've had that conversation

358
00:27:46,029 --> 00:27:54,409
just save you time what I'm trying to
say here is these are open source

359
00:27:54,409 --> 00:28:01,200
technologies all of them is an open
source project is Italian tonight in

360
00:28:01,200 --> 00:28:05,749
fact I'm gonna give you a ride the demo
is not the whole thing I like I said

361
00:28:05,749 --> 00:28:08,960
this is an unfinished all I want to show
you just one pop I want to show you how

362
00:28:08,960 --> 00:28:11,609
easy it will be for anyone in your
organization to pull all of this

363
00:28:11,609 --> 00:28:15,449
information for your Active Directory
new Google so let's see if the video

364
00:28:15,450 --> 00:28:21,710
works

365
00:28:21,710 --> 00:28:28,130
ok I'm gonna talk through it has a sound
so what a change to begin with is quite

366
00:28:28,130 --> 00:28:34,490
how easy it is to get going so that's
meaning one script I don't view you

367
00:28:34,490 --> 00:28:38,350
still have a full season on a Mac you
can use on Mac or Linux it doesn't

368
00:28:38,350 --> 00:28:45,590
really matter and this is me starting it
three words done so you can get the code

369
00:28:45,590 --> 00:28:51,080
yourself you can get it at the running
job down there was no sales people or

370
00:28:51,080 --> 00:28:58,309
anything wasn't that sweet ok so in this
case I've got a local DNS reference to

371
00:28:58,309 --> 00:29:02,460
what I'm calling obscured a company
could have it on a local IP and this is

372
00:29:02,460 --> 00:29:07,210
why aren't face looks like we actually
have you experts on staff is so

373
00:29:07,210 --> 00:29:11,890
important in this that we need to focus
on it from number to number two concern

374
00:29:11,890 --> 00:29:16,899
is you access this we're seeing here is
actually what it looks like this is an

375
00:29:16,899 --> 00:29:20,918
organization this is a test date you can
go and get through the repo is modeled

376
00:29:20,919 --> 00:29:25,659
after a cartoon show called gravity
falls so no real humans were hurt in the

377
00:29:25,659 --> 00:29:30,320
creation of this you can go and explore
you can go and look at who's an

378
00:29:30,320 --> 00:29:34,070
administrator you can go look at their
identifies you can go and see who's in

379
00:29:34,070 --> 00:29:38,129
groups that have admin access who you
would have tweaked to there will be no

380
00:29:38,130 --> 00:29:42,419
idea is that it should be easy and this
is how is it should be we're gonna

381
00:29:42,419 --> 00:29:46,120
import from Active Directory here's a
standard LDAP server running on a

382
00:29:46,120 --> 00:29:51,270
virtual machine there is another side
project you can do to build one of those

383
00:29:51,270 --> 00:29:58,510
yourself just seemed letters we do not
save usernames and passwords to secure

384
00:29:58,510 --> 00:30:05,320
the mister never ever have two minutes
later

385
00:30:05,320 --> 00:30:14,240
job done I didn't need a specialist I
didn't need a big Systems Administrator

386
00:30:14,240 --> 00:30:23,360
I didn't get a box into a network this
is just it seventy people between them

387
00:30:23,360 --> 00:30:28,549
this fits that don't share well in this
presentation and that's the

388
00:30:28,549 --> 00:30:32,450
visualization but the graph part now I
tried to get into the video but given

389
00:30:32,450 --> 00:30:36,230
the size of this room you wouldn't have
seen you to see a lot of circles and I

390
00:30:36,230 --> 00:30:41,309
just wanted ah I felt really good and
you got no value so I encourage you to

391
00:30:41,309 --> 00:30:45,509
go and have a play when it comes to case
studies you can't do this without a

392
00:30:45,509 --> 00:30:48,269
shirt on right some businesses using it
in real life and that's what we've been

393
00:30:48,269 --> 00:30:52,490
trying to do I product is unfinished but
some finish because we need to work with

394
00:30:52,490 --> 00:30:57,759
business to finish this he was a process
we decided on its the only wall of text

395
00:30:57,759 --> 00:31:01,240
light I have in this Dec but I needed
you to have like the same idea that we

396
00:31:01,240 --> 00:31:07,000
didn't just kind of go you know it'll be
fun how people so this is we had a bit

397
00:31:07,000 --> 00:31:10,269
of a plan we were gonna get big
organizations and we were gonna do a big

398
00:31:10,269 --> 00:31:18,889
case study for you and then this
happened I was so pleased I'm gonna do

399
00:31:18,889 --> 00:31:22,258
the store ballin otherwise it but it's
just talked all black hat and like this

400
00:31:22,259 --> 00:31:29,769
place in the USA and security will go
there you want shows a black hat also

401
00:31:29,769 --> 00:31:40,669
keen to hear from me and I want peace
and they went well you're serious and

402
00:31:40,669 --> 00:31:51,759
then I said yes and they went which an
American is oil oil oil oil oil so we

403
00:31:51,759 --> 00:31:55,899
struggled with a case study but we were
lucky New Zealand is a little more

404
00:31:55,899 --> 00:31:59,908
trusting that america we did find three
organizations who are willing to play

405
00:31:59,909 --> 00:32:03,850
with the No section but only in the way
that we could give you a very anonymized

406
00:32:03,850 --> 00:32:06,779
dumbed down version but I'm gonna share
that with you anyway because it turns

407
00:32:06,779 --> 00:32:10,190
out I when you comin present something
that tax people that hacking conference

408
00:32:10,190 --> 00:32:15,740
people get a bit scruffy so we find 540
people in these three organizations

409
00:32:15,740 --> 00:32:17,520
across the public and private sector

410
00:32:17,520 --> 00:32:21,410
they were relatively large organizations
by New Zealand standards I remember New

411
00:32:21,410 --> 00:32:28,080
Zealand is a tiny island the bottom of
the planet we have hope it's a big

412
00:32:28,080 --> 00:32:32,210
companies are about the size of your
small companies so you know bear in mind

413
00:32:32,210 --> 00:32:39,760
scale is a problem for us and his my
stats are gonna read them to you that

414
00:32:39,760 --> 00:32:44,250
was the first Intel we got within two
minutes of putting the data into over

415
00:32:44,250 --> 00:32:53,790
now there's a number eleven years inside
me a penetration test it died because we

416
00:32:53,790 --> 00:32:58,370
don't need to worry about 20 days we
don't need to worry about fantasy threat

417
00:32:58,370 --> 00:33:06,790
intelligence we really don't it is 2015
why are we still having this issue so

418
00:33:06,790 --> 00:33:08,590
sorry personal rant over

419
00:33:08,590 --> 00:33:14,490
yes we need more case studies and i
wanna talk a little bit about how you

420
00:33:14,490 --> 00:33:18,440
could be a case of your organization and
why I don't need to see the data for you

421
00:33:18,440 --> 00:33:23,090
to do that but before we get there are
some challenges and there's some things

422
00:33:23,090 --> 00:33:27,699
we need to consider you see this is
actually what I'm calling a public

423
00:33:27,700 --> 00:33:29,110
interest security tool

424
00:33:29,110 --> 00:33:33,909
this is all we need to talk about not
just inside a community but actually

425
00:33:33,910 --> 00:33:37,640
with everyone in our organization
because we are about to look into an

426
00:33:37,640 --> 00:33:42,500
area that is going to make people deeply
unhappy and we need to do this very

427
00:33:42,500 --> 00:33:46,930
carefully and we need to do it very
consciously I remember that a view of

428
00:33:46,930 --> 00:33:51,770
the world of security people is not the
same as everyone else's with the

429
00:33:51,770 --> 00:33:55,010
traditional security program change when
we start to embrace threat intelligence

430
00:33:55,010 --> 00:34:00,860
or application security is a top down so
you sell to the sea level by the ones

431
00:34:00,860 --> 00:34:03,990
with the money and everyone else follows
suit because neither been expensive

432
00:34:03,990 --> 00:34:08,110
devices somebody who cares about it in
this we have to set up from the bottom

433
00:34:08,110 --> 00:34:09,140
up

434
00:34:09,139 --> 00:34:13,940
you make you know get hold of a copy or
you know find it all is that your

435
00:34:13,940 --> 00:34:15,010
painful

436
00:34:15,010 --> 00:34:21,139
but if your people revolt at this point
if they pull out their terms of service

437
00:34:21,139 --> 00:34:25,260
to their employment agreement and say
this is a human rights violation which

438
00:34:25,260 --> 00:34:31,000
we've heard before then you've got a
problem you can't just vulnerability

439
00:34:31,000 --> 00:34:38,219
scan people if you don't get there by
infest common question is this even

440
00:34:38,219 --> 00:34:49,480
legal to be quite honest probably maybe
definitely sometimes in Australia for

441
00:34:49,480 --> 00:34:56,350
example it's illegal to send an email
but is it technically span if it's

442
00:34:56,350 --> 00:35:01,069
inside your system from an account you
control to people that you employ is

443
00:35:01,070 --> 00:35:07,800
that still sound is it ok to pull
together lots of information to guide us

444
00:35:07,800 --> 00:35:10,000
around then the more than the answer is
No

445
00:35:10,000 --> 00:35:14,630
in the USU got a lot of constitutional
rights that would be an interesting

446
00:35:14,630 --> 00:35:18,100
discussion in the space we don't have
them in New Zealand Australia and I'm

447
00:35:18,100 --> 00:35:21,430
not qualified to talk about them but I
do you really think that we should be

448
00:35:21,430 --> 00:35:25,810
having this discussion is there
something we need to do here do we need

449
00:35:25,810 --> 00:35:29,790
to make sure we understand the law
because we certainly need to protect our

450
00:35:29,790 --> 00:35:36,040
people now the trick for us is that
we're looking for publicly already

451
00:35:36,040 --> 00:35:40,759
published information so if somebody is
already got tweet side there are there

452
00:35:40,760 --> 00:35:44,190
already publicly sharing things on
Facebook like you don't have to be a

453
00:35:44,190 --> 00:35:48,310
friend with them to see it then is it
fair game

454
00:35:48,310 --> 00:35:53,680
your LinkedIn profile which is like a
honey trap for recruiters will put them

455
00:35:53,680 --> 00:35:58,299
out there you know with a little sparkly
bits as they come come find me is it

456
00:35:58,300 --> 00:36:03,330
fair game because we intentionally put
it out there I don't know but I think we

457
00:36:03,330 --> 00:36:09,509
need to ask I think we really need to
start to catch can we do this without

458
00:36:09,510 --> 00:36:15,030
compromising privacy now this is a
really sticky subject people need to

459
00:36:15,030 --> 00:36:18,510
protect their privacy it's a
foundational right we had a human beings

460
00:36:18,510 --> 00:36:25,560
to privacy and I am a proponent of
privacy and that's about what somebody

461
00:36:25,560 --> 00:36:26,420
has on you

462
00:36:26,420 --> 00:36:34,730
the ability to update it to get it
deleted to ask about it we think this is

463
00:36:34,730 --> 00:36:38,450
such a problem that is actually another
talk you can go watch we did a talk on

464
00:36:38,450 --> 00:36:44,009
just two weeks ago about the ethics of
open source in weaponized code it has

465
00:36:44,010 --> 00:36:47,780
either has been a lot of public debate
about this we wish they had because we'd

466
00:36:47,780 --> 00:36:53,339
have somebody to go and ask we wanted to
get people answering these and asking

467
00:36:53,339 --> 00:36:59,099
these questions we formed an ethics and
previously bought just rattle we join

468
00:36:59,099 --> 00:37:02,450
together using slapped the
communications thoughtful and we're

469
00:37:02,450 --> 00:37:05,609
hoping to have an objective
representative independent and

470
00:37:05,609 --> 00:37:09,450
collaborative group of people
challenging this tool and tools like it

471
00:37:09,450 --> 00:37:14,430
because I firmly believe we need to do
it but I know I don't know all the

472
00:37:14,430 --> 00:37:19,359
questions and i know if i dont go and
ask if I don't find the people in the

473
00:37:19,359 --> 00:37:24,049
world who can represent their minority
or their specific set of needs and

474
00:37:24,049 --> 00:37:28,420
concerns I'm going to overlook something
my team will overlook it we as a

475
00:37:28,420 --> 00:37:32,460
community will overlook it doesn't
matter what we do that with computers we

476
00:37:32,460 --> 00:37:38,720
just retrofit its fine but people will
get hurt if we don't do this right

477
00:37:38,720 --> 00:37:43,200
new members are welcome please do come
along and apply a contraption email we

478
00:37:43,200 --> 00:37:47,040
also have an open plain English policy
you will notice if you are looking to

479
00:37:47,040 --> 00:37:51,020
get her we have a privacy policy we have
a code of conduct

480
00:37:51,020 --> 00:37:54,740
now they're not enforceable you know
this is a product you can put in your

481
00:37:54,740 --> 00:37:58,879
environment to do whatever the hell you
like with you for a project I'm gonna be

482
00:37:58,880 --> 00:38:02,869
like Redlands you know I started with a
cute little thing and then you go

483
00:38:02,869 --> 00:38:07,790
tenants in the destroys New York we try
to be very open with what we're trying

484
00:38:07,790 --> 00:38:12,410
to do so I encourage interest in the
space to work with us to contribute to a

485
00:38:12,410 --> 00:38:16,700
version and help us keep in that path
all of our guidance is written in plain

486
00:38:16,700 --> 00:38:21,569
English if you find it difficult in any
way to understand we have failed

487
00:38:21,569 --> 00:38:26,869
help us make it even easier to
understand we will fail if we make this

488
00:38:26,869 --> 00:38:34,109
complex if people outside a community
can't understand we fail

489
00:38:34,109 --> 00:38:38,058
we need to provide people with the
information they need to protect

490
00:38:38,059 --> 00:38:40,009
themselves and their privacy

491
00:38:40,009 --> 00:38:42,910
one of the first things that came out of
our Privacy border on the questions that

492
00:38:42,910 --> 00:38:46,940
was raised was so you show somebody all
of their information you've got all

493
00:38:46,940 --> 00:38:51,150
their information what do they know
about it so we've made a change the new

494
00:38:51,150 --> 00:38:54,739
version will currently working on is
going to the first thing it does before

495
00:38:54,739 --> 00:38:58,930
it tells the security owner of the tool
that they have someone's data it tells

496
00:38:58,930 --> 00:39:04,980
the data zona so if they pull my title
for example I would get an email saying

497
00:39:04,980 --> 00:39:12,589
hi this is another neighbor your company
your boss has decided that protecting

498
00:39:12,589 --> 00:39:17,609
you is important would you like to see
all your data the first person and the

499
00:39:17,609 --> 00:39:21,890
only real person who is entitled to see
all of their data in this tool is the

500
00:39:21,890 --> 00:39:28,019
owner of that data we hope to show that
the extent of what was available where

501
00:39:28,019 --> 00:39:32,470
we found it from there's no magic here
there's no secret source and we hope to

502
00:39:32,470 --> 00:39:36,379
give them the option of changing that
give them the link to the Facebook page

503
00:39:36,380 --> 00:39:39,690
where they can change the privacy
options give them the link to some

504
00:39:39,690 --> 00:39:46,239
guidance on how to do this better we
want to give people an option of success

505
00:39:46,239 --> 00:39:50,269
and that has to be continuous it has to
be available to everyone and it has to

506
00:39:50,269 --> 00:39:55,640
be tightly controlled and this is this
even technically possible because it

507
00:39:55,640 --> 00:40:01,609
turns out this place is relatively
challenging I started writing this with

508
00:40:01,609 --> 00:40:09,650
the typical Kiwi actor Jude of how hard
can it be quite when you're dealing with

509
00:40:09,650 --> 00:40:13,589
a lot of different systems and different
integration points you've got complexity

510
00:40:13,589 --> 00:40:23,369
we're talking about the scale of data
that is really immense now processing

511
00:40:23,369 --> 00:40:29,470
large sets of data or big data as they
like to call it these days isn't hard

512
00:40:29,470 --> 00:40:33,238
doing that in a way you could actually
visualize it on a screen and a human

513
00:40:33,239 --> 00:40:38,489
being can actually deal with it and
understand it is terrifying I can

514
00:40:38,489 --> 00:40:40,859
talking to a lot of you on this
conference today and

515
00:40:40,859 --> 00:40:45,239
one of the startling things I always get
surprised by it but with american

516
00:40:45,239 --> 00:40:50,359
companies is that companies are
considered themselves small have 50,000

517
00:40:50,359 --> 00:40:56,369
people in them we're talking a scale we
cannot visualize simply we need to do

518
00:40:56,369 --> 00:41:01,559
some work on it it turns out we also
learned there's a reason why compromise

519
00:41:01,559 --> 00:41:05,970
gmail accounts have a really high market
value that's because it's sort of

520
00:41:05,970 --> 00:41:09,578
dubious creating them and I really hard
to maintain you have to maintain

521
00:41:09,579 --> 00:41:14,339
convincing aliases for to like this this
is something that Ava itself will help

522
00:41:14,339 --> 00:41:20,328
you with you would need to manage this
if you all actually asked and no that's

523
00:41:20,329 --> 00:41:26,069
that's why you making money this faces
hard it's hard to manage we have a quite

524
00:41:26,069 --> 00:41:30,308
cracked we're trying hard but we haven't
cracked it and we don't just email

525
00:41:30,309 --> 00:41:32,769
account we need LinkedIn profiles
Twitter profiles and they need to be

526
00:41:32,769 --> 00:41:36,700
active in convincing because it's all
very well compromising someone who is

527
00:41:36,700 --> 00:41:40,519
careless enough they just looked at an
empty profiling believed it but what if

528
00:41:40,519 --> 00:41:46,660
it looks convincing by the way nobody
nobody on the planet has any more time

529
00:41:46,660 --> 00:41:49,390
for a more appliances in their
organization

530
00:41:49,390 --> 00:41:53,828
a study proved that it takes between two
or three skilled individuals to actually

531
00:41:53,829 --> 00:41:58,269
run an appliance in their organization
so if we were to add another one UD two

532
00:41:58,269 --> 00:42:01,649
or three people who actually understood
how people ticked you could communicate

533
00:42:01,650 --> 00:42:05,509
with other human beings which nothing
personal I'm in the security space we're

534
00:42:05,509 --> 00:42:11,460
really bad at it so we need unicorns
demand the appliance like this so this

535
00:42:11,460 --> 00:42:15,390
is hard how do we make this usable to
people who want security people in a way

536
00:42:15,390 --> 00:42:20,400
that non-secure people under security
things I want to make a little redundant

537
00:42:20,400 --> 00:42:28,019
sorry again so as well as a research
project like a citizen finished is

538
00:42:28,019 --> 00:42:30,910
unfinished but working you can tell
things from Google Apps for Business she

539
00:42:30,910 --> 00:42:34,739
can pull things in Active Directory and
its rapidly evolving we've got an active

540
00:42:34,739 --> 00:42:35,960
community and we want more

541
00:42:35,960 --> 00:42:39,900
there is basically now testing in the
other is basic Twitter testing in that

542
00:42:39,900 --> 00:42:44,299
but we need more testing of it we need
continuous integration we need a road

543
00:42:44,299 --> 00:42:48,700
map we have been bootstrapping initially
in at times when my newborn daughter was

544
00:42:48,700 --> 00:42:53,270
teeny tiny it was written in an hour
long chunks now we have a real team

545
00:42:53,270 --> 00:42:57,600
and we are refactoring making it into a
sensible proper engineered application

546
00:42:57,600 --> 00:43:03,799
but this text I'm like a machine with
the appliances many organizations we

547
00:43:03,800 --> 00:43:06,770
spoke to you really want to do this but
they don't know how to do it themselves

548
00:43:06,770 --> 00:43:11,080
and I think we're going to have an
emerging space come thru of security

549
00:43:11,080 --> 00:43:15,490
culture is a change now if you come to
this event in three years that spend a

550
00:43:15,490 --> 00:43:20,810
whole is full of this service don't buy
a magic box please do not buy a magic

551
00:43:20,810 --> 00:43:25,810
box if you cannot see what this is doing
to people if you cannot engage with them

552
00:43:25,810 --> 00:43:31,630
on an ethical debate walk away we want
to integrate already integrated with

553
00:43:31,630 --> 00:43:34,520
Google by Google people have been trying
to contact you for a while

554
00:43:34,520 --> 00:43:39,340
Facebook Twitter Linkedin slack get hurt
if you can name a place where your

555
00:43:39,340 --> 00:43:40,710
people are hanging out

556
00:43:40,710 --> 00:43:47,820
sharing information we want to be there
we don't we want to integrate properly

557
00:43:47,820 --> 00:43:51,390
we want to work with trusted security
teams for these organizations but we're

558
00:43:51,390 --> 00:43:54,950
having difficulty reaching you you don't
answer your email

559
00:43:54,950 --> 00:44:00,589
case hi we should talk there's plenty of
room for contribution here we are

560
00:44:00,590 --> 00:44:03,620
growing a team slowly but like I said
we're bootstrapped we don't have any

561
00:44:03,620 --> 00:44:08,940
crazy funding funding but we have an
ethics for the needs people we need

562
00:44:08,940 --> 00:44:12,380
develop as we need people who do
documentation we need sociologists if

563
00:44:12,380 --> 00:44:18,340
you know it ain't osceola gist please
send them my way and most of all we want

564
00:44:18,340 --> 00:44:25,330
volunteer I volunteer organizations to
come and do safe consensual Sheila

565
00:44:25,330 --> 00:44:31,470
security science scale I want big
organizations to be brave enough to come

566
00:44:31,470 --> 00:44:37,310
and show how they're made I wanted to
show in an anonymized way how your

567
00:44:37,310 --> 00:44:41,500
people connect to each other what would
your grass look like what were you

568
00:44:41,500 --> 00:44:45,970
surprised by your findings because when
we start having this debate when we have

569
00:44:45,970 --> 00:44:50,250
this discussion a people start getting
more secure and it's gonna take leaders

570
00:44:50,250 --> 00:44:55,930
big organizations to do this we can have
the ideas but without the support of

571
00:44:55,930 --> 00:45:00,990
those without him being brave and open
to being vulnerable we're never gonna

572
00:45:00,990 --> 00:45:03,750
get anywhere as a community

573
00:45:03,750 --> 00:45:07,370
we have a problem with people it's big

574
00:45:07,370 --> 00:45:11,990
we have more people in our organizations
than we know what to do with literally

575
00:45:11,990 --> 00:45:18,609
insecurity cents for every senator Lee
Sejal for product you can use it it does

576
00:45:18,610 --> 00:45:21,880
work you can contribute to it you could
deploy it to stay with the doctor

577
00:45:21,880 --> 00:45:27,680
scripts but the road ahead is really
hard we need to be able to protect our

578
00:45:27,680 --> 00:45:32,230
people that's a genuine need but we have
to do it ethically with privacy in mind

579
00:45:32,230 --> 00:45:35,980
and we're gonna have to sell security to
our entire organization for the first

580
00:45:35,980 --> 00:45:41,610
time in our history we have never had to
do this faithful if you want to learn

581
00:45:41,610 --> 00:45:45,290
more about Eva this is all of its
contact it also has a website there is a

582
00:45:45,290 --> 00:45:48,930
read the docs things got a whole get
involved page in many places to come and

583
00:45:48,930 --> 00:45:50,210
talk to us

584
00:45:50,210 --> 00:45:56,090
email address or even answer it a
Twitter

585
00:45:56,090 --> 00:46:06,780
it easy you don't have to be technical
if anyone has any questions though any

586
00:46:06,780 --> 00:46:11,260
part of this concerns you or any part of
this you think needs raising loudly in a

587
00:46:11,260 --> 00:46:14,940
room full of people who share your
concerns your time there's a microphone

588
00:46:14,940 --> 00:46:19,280
just there we have four minutes and 20
seconds according to the clock and if

589
00:46:19,280 --> 00:46:29,600
not I'll be around after its thank you
very much

590
00:46:29,600 --> 00:46:44,220
questions I know how are you oh wow so
in a trial that you've done so far

591
00:46:44,220 --> 00:46:48,910
or if you haven't had any actionable
data from the data such as you had to

592
00:46:48,910 --> 00:46:53,390
work with how would you envision
reacting to the Intel but you drive from

593
00:46:53,390 --> 00:46:59,779
the store without going back to security
awareness training so the one thing that

594
00:46:59,780 --> 00:47:03,360
we would like to see his reaction is
some kind of gamification

595
00:47:03,360 --> 00:47:07,510
instead of us telling people how to do
something

596
00:47:07,510 --> 00:47:10,370
the best way for people to engage with
the process and know what to do is for

597
00:47:10,370 --> 00:47:14,980
them to kind of discover it so we want
to make it so that as a team you know

598
00:47:14,980 --> 00:47:18,530
what areas you know have been
problematic and you can look at so much

599
00:47:18,530 --> 00:47:23,510
as we can suggest options in but I want
them to as a group go well for us what

600
00:47:23,510 --> 00:47:27,310
works what would we do hear how can we
protect our little group I want to

601
00:47:27,310 --> 00:47:31,420
actually push the decisions of water
remediation down to the little positive

602
00:47:31,420 --> 00:47:36,230
people because I think if we try and
dictate as we have done historically we

603
00:47:36,230 --> 00:47:45,070
will get the same resistance we
currently have

604
00:47:45,070 --> 00:47:56,980
first I want to applaud your bravery in
doing this this is absolutely amazing

605
00:47:56,980 --> 00:48:04,720
and as a human I would love to see that
data about my own connections to people

606
00:48:04,720 --> 00:48:11,640
in my organization and I think when
users see you and they can see the type

607
00:48:11,640 --> 00:48:18,170
of data that anyone can drive from these
services through social engineering that

608
00:48:18,170 --> 00:48:23,320
they would really see the value in it I
don't actually have a question I just

609
00:48:23,320 --> 00:48:27,640
wanted to tell you about I thought this
was amazing and incredibly incredibly

610
00:48:27,640 --> 00:48:30,390
hard though thank you

611
00:48:30,390 --> 00:48:35,490
if I do nothing else I want actual real
people not us with special word of it

612
00:48:35,490 --> 00:48:40,399
with a broken and I wanted real normal
everyday people to be able to see this

613
00:48:40,400 --> 00:48:44,020
and do something about it cuz if they
can't see it they generally don't know

614
00:48:44,020 --> 00:48:48,480
where to begin ok

615
00:48:48,480 --> 00:48:52,520
stunned silence so thank you thank you
very much

