1
00:00:00,000 --> 00:00:04,940
and without further ado I would like to
introduce this afternoon session deep

2
00:00:04,940 --> 00:00:15,049
learning on disassembly data please
welcome Andrew Davis and Matt will again

3
00:00:15,049 --> 00:00:20,740
thank you so I'm at will

4
00:00:20,740 --> 00:00:29,140
Sandra Davis we are are the science team
a company called silence company at all

5
00:00:29,140 --> 00:00:37,380
bases about description of her silence
is it's the lvad so our work focuses on

6
00:00:37,380 --> 00:00:49,550
and machine learning for the purpose of
Asian research about the skies here just

7
00:00:49,550 --> 00:00:55,709
outside the research word graduate is
difficult but we have products so people

8
00:00:55,710 --> 00:00:59,910
are familiar with silence I don't want
you confused with this being a

9
00:00:59,910 --> 00:01:08,460
commercial product we have so just
before him a little bit of because black

10
00:01:08,460 --> 00:01:15,720
hat so scary but he first got my way out
there so just meet rising report this

11
00:01:15,720 --> 00:01:26,130
year by malware about the carpet second
example is a unique organizations and to

12
00:01:26,130 --> 00:01:32,000
consider debt so what this means is that
over the last decade or so the volume

13
00:01:32,000 --> 00:01:36,540
all where that's out there now continue
to grow and that caused a problem

14
00:01:36,540 --> 00:01:42,479
because you just can scale and the
traditional way that we have or so in

15
00:01:42,479 --> 00:01:47,170
the old days while the mariel days you
may be company without a signature and

16
00:01:47,170 --> 00:01:52,159
then back to the people you know twenty
thirty years ago and so to call

17
00:01:52,159 --> 00:01:57,219
attention to our time and date see some
of the techniques being used but the

18
00:01:57,219 --> 00:02:00,820
main problem is if you're going to have
a human in the loop to about half hour

19
00:02:00,820 --> 00:02:06,750
are you file you know where he just
can't spell that up so our goal and and

20
00:02:06,750 --> 00:02:09,288
this recharge talk about that

21
00:02:09,288 --> 00:02:16,260
that is we want to find alternate ways
that can detect and do it quickly and

22
00:02:16,260 --> 00:02:25,480
accurately for this talk to see give you
all over the road map to mention or

23
00:02:25,480 --> 00:02:30,018
there are focused on artificial
intelligence machine learning so we're

24
00:02:30,019 --> 00:02:33,609
gonna give a brief overview of what that
actually entails I know someone you

25
00:02:33,609 --> 00:02:40,060
working today I here in this room right
now so you just sit tight we'll get some

26
00:02:40,060 --> 00:02:45,209
good stuff later but if you want it is
so you understand the context of what's

27
00:02:45,209 --> 00:02:50,340
going on then we'll talk about this
research is focused on Tuesday morning

28
00:02:50,340 --> 00:02:55,569
which is a subset of machine learning
that has sort of grown in recent years

29
00:02:55,569 --> 00:03:01,220
to has shown steady art effectiveness
and and various applications outside

30
00:03:01,220 --> 00:03:07,209
security and most of all we applied that
to security space here and that the fun

31
00:03:07,209 --> 00:03:12,470
part is going to a demo so we're gonna
go the internet download a bunch of

32
00:03:12,470 --> 00:03:19,180
brand new malware that voted today to
our total and see how am I told us to

33
00:03:19,180 --> 00:03:26,530
get an idea of the actual effectiveness
would have in the real world and so it

34
00:03:26,530 --> 00:03:31,000
had increased my colleague Andrew Davis
and he'll walk you through the research

35
00:03:31,000 --> 00:03:47,829
you done for the people who have been to
the other machine learning talks here so

36
00:03:47,829 --> 00:03:57,720
far just sort of get into his hands on
this stuff right so basically you were

37
00:03:57,720 --> 00:04:02,030
trying to addresses and have been
telling us something good in other words

38
00:04:02,030 --> 00:04:05,430
we don't get PDF we get something an
email attachment or something like that

39
00:04:05,430 --> 00:04:10,019
and poorly click on and we want to know
that certain content from services but

40
00:04:10,019 --> 00:04:13,669
it turns out that telling get things
from bad things is a very classic

41
00:04:13,669 --> 00:04:18,349
application of pattern recognition and
machine learning a lot of other people

42
00:04:18,349 --> 00:04:20,548
like people uses machine learning

43
00:04:20,548 --> 00:04:24,620
search results as fuck is going to is
really cool sophisticated algorithms to

44
00:04:24,620 --> 00:04:29,120
automatically detect faces and edges so
there's a lot of good use machine

45
00:04:29,120 --> 00:04:33,610
learning an industry so if we have these
very large databases of nowhere and we

46
00:04:33,610 --> 00:04:37,139
know what we're looking at you know if
it's good if it's that we put these

47
00:04:37,139 --> 00:04:42,669
things we put these things to work for
supervised learning we need for meeting

48
00:04:42,669 --> 00:04:46,400
gradients right we need input data which
in this case is going to be a whole

49
00:04:46,400 --> 00:04:50,739
bunch of the pilots a binary is things
like that we need something called

50
00:04:50,740 --> 00:04:54,960
future engineering which is a way to
sort of take this wrong information

51
00:04:54,960 --> 00:04:59,799
executables or whatever and led his
country into something the model can

52
00:04:59,800 --> 00:05:04,069
understand and of course we need a
predictive model models job is to look

53
00:05:04,069 --> 00:05:08,190
at a whole bunch of it up and then learn
how it can tell between good and then we

54
00:05:08,190 --> 00:05:12,490
also need associated labels for every
single sample you need to wait to tell

55
00:05:12,490 --> 00:05:16,819
the model that hey this things bad you
should try and call a bad or anything is

56
00:05:16,819 --> 00:05:25,289
good so you should try so rampant in
Italia can be a lot of things right and

57
00:05:25,289 --> 00:05:28,360
the stalker going to cover mostly
executable code so we're going to use

58
00:05:28,360 --> 00:05:32,120
Windows PCs in particular that's not
necessarily confined to that you could

59
00:05:32,120 --> 00:05:38,590
also use my sexy could use Linux Els
there are all sorts of executable but

60
00:05:38,590 --> 00:05:42,659
she could travel along you can also use
his modeling techniques for docking is

61
00:05:42,659 --> 00:05:47,699
right where documents trying to do
something you could see if her some

62
00:05:47,699 --> 00:05:52,789
malicious code in the PDF or you can
also see if Excel macros trying to be

63
00:05:52,789 --> 00:05:58,659
something that's in addition you can
also use a great big scripts script

64
00:05:58,659 --> 00:06:04,319
dataset of hung out where you can try to
model I thought you could try to model

65
00:06:04,319 --> 00:06:08,500
bash scripts see shell scripts Ruby
scripts whatever you want basically as

66
00:06:08,500 --> 00:06:15,440
long as you have nothing but you can
probably trying to prove their labels

67
00:06:15,440 --> 00:06:19,379
labels going to tell them out of what
the sample is and in our case it's going

68
00:06:19,379 --> 00:06:23,879
to be a very very granular just good vs
bad decision right but if you wanted to

69
00:06:23,879 --> 00:06:25,920
do some been several attacks you could
also

70
00:06:25,920 --> 00:06:31,180
so have labels let's say you want to try
to model to detect something banker or

71
00:06:31,180 --> 00:06:32,320
tramadol

72
00:06:32,320 --> 00:06:35,820
second this is probably a keylogger

73
00:06:35,820 --> 00:06:51,430
more advanced analytics that we're going
to be as good as your input features so

74
00:06:51,430 --> 00:06:54,560
as a motivating example let's say we
have a case for trying to break some new

75
00:06:54,560 --> 00:06:58,400
form of cash right this captures going
to be 10 images you may have seen

76
00:06:58,400 --> 00:07:02,679
something like this for each one has a
cat or dog and presumably if you're not

77
00:07:02,680 --> 00:07:08,230
a bot have no idea what kind of dog is
just gonna choose randomly and captures

78
00:07:08,230 --> 00:07:13,130
and get on with your trying to do what
they were trying to break the same right

79
00:07:13,130 --> 00:07:18,050
so what we would do instead of dealing
with the image which may be very

80
00:07:18,050 --> 00:07:22,600
complicated cats wide variety of what
stocks a wide variety of looks what you

81
00:07:22,600 --> 00:07:26,210
doing studies you'd write something to
sort of the problem into smaller chunks

82
00:07:26,210 --> 00:07:31,900
right she would have think it tells you
ok as the subject i'm looking at very if

83
00:07:31,900 --> 00:07:36,520
so you know sort of the true false thing
or is this subject up five years for

84
00:07:36,520 --> 00:07:42,580
example or what is the subjects
approximate mass so as you can see none

85
00:07:42,580 --> 00:07:46,200
of these features are by themselves
necessarily discriminate of something

86
00:07:46,200 --> 00:07:50,849
scary it could either be thinks cat that
weird looking dog on the side they're

87
00:07:50,850 --> 00:07:55,140
lucky here that's not necessarily
completely productive as to whether or

88
00:07:55,140 --> 00:07:59,700
not it's a cat or dog so what model it
do is it would take these different

89
00:07:59,700 --> 00:08:00,930
pieces of evidence

90
00:08:00,930 --> 00:08:04,400
find ways to sort of reason about it
automatically so they could tell you if

91
00:08:04,400 --> 00:08:13,150
the things the dog and then you could
break up shop let's talk about the kinds

92
00:08:13,150 --> 00:08:16,190
of features that would use for
executables so there are a number of

93
00:08:16,190 --> 00:08:20,300
number of machine learning based
approaches for texting while we're out

94
00:08:20,300 --> 00:08:24,260
there so maybe what they would do as
they look at file size for example our

95
00:08:24,260 --> 00:08:29,630
trust under the radar in a lot of
situations it's very small that's not

96
00:08:29,630 --> 00:08:33,350
necessarily true in every single case
you may have a very small pockets not

97
00:08:33,350 --> 00:08:37,159
doing anything malicious so again these
features are necessarily by themselves

98
00:08:37,159 --> 00:08:39,419
completely productive

99
00:08:39,419 --> 00:08:44,480
streams so drunk he you know you can and
streams against your file and extract

100
00:08:44,480 --> 00:08:48,820
all the strings that you see if the
files doing something like including a

101
00:08:48,820 --> 00:08:52,860
bunch of base 64 encoded strings
includes a whole bunch of jurors looking

102
00:08:52,860 --> 00:08:56,930
host names for things like that simple
maybe try to do something that has to do

103
00:08:56,930 --> 00:09:01,709
you also have this idea held in grams
and grams away teacher in a

104
00:09:01,709 --> 00:09:08,279
variable-length thing and to fix things
right so if we take the example has a

105
00:09:08,279 --> 00:09:12,260
variable in this case we have a word
that's three letters long and in the

106
00:09:12,260 --> 00:09:16,319
case of one gram we're going to turn it
into any six dimensional vector in other

107
00:09:16,320 --> 00:09:21,660
words we have something $0.26 that
particular word betrayal on Dec been a

108
00:09:21,660 --> 00:09:26,980
bit and everything else you can also
have two grams instead of a victory it

109
00:09:26,980 --> 00:09:30,360
happened it reeks of things and you
would light up the CA been as well as

110
00:09:30,360 --> 00:09:36,649
the 18th grandstand to scale
exponentially so you have to go and you

111
00:09:36,649 --> 00:09:41,360
need 26 squared storage if you have
three Grammy 26 cube and it just gets

112
00:09:41,360 --> 00:09:44,290
worse and worse oh eight grams kind of
become prohibitive as he starts

113
00:09:44,290 --> 00:09:49,490
increasing in numbers like nine or ten
you can also use interviewed sections so

114
00:09:49,490 --> 00:09:53,810
you look at all your section and the
section has very high entropy that means

115
00:09:53,810 --> 00:09:57,099
it probably doesn't contain lunch
executable probably packed or something

116
00:09:57,100 --> 00:10:01,740
like that and again being necessarily
indicative of whether or not it's doing

117
00:10:01,740 --> 00:10:05,959
something that but what the other
evidence like what the file sizes and

118
00:10:05,959 --> 00:10:09,729
industries that contains invalid learn
how to discriminate between goodnight

119
00:10:09,730 --> 00:10:16,220
samples what is the model doing then
model is going to take something near

120
00:10:16,220 --> 00:10:20,209
future space in other words the thing
that you engineer at the binary to go

121
00:10:20,209 --> 00:10:23,899
into its going to try and draw a line
between the get samples and the bad

122
00:10:23,899 --> 00:10:27,579
samples so the whole feature engineering
us to come up with a way that you can

123
00:10:27,579 --> 00:10:31,870
make about stuff into this feature space
and they call the good stuff into this

124
00:10:31,870 --> 00:10:36,139
sudden features they going to do is
going to try and learn this dividing

125
00:10:36,139 --> 00:10:40,190
line between your good stuff that stuff
there a lot of models out there was

126
00:10:40,190 --> 00:10:44,300
someone I can think of this night as you
may have seen night is an application to

127
00:10:44,300 --> 00:10:47,660
expand detection

128
00:10:47,660 --> 00:10:49,000
as does

129
00:10:49,000 --> 00:10:52,560
seems that everything what if your
features are completely independent and

130
00:10:52,560 --> 00:10:56,699
it's a very small easy to train model
you could maybe but naive Bayes

131
00:10:56,700 --> 00:11:01,610
classifier on a really really
low-powered network switch to you know

132
00:11:01,610 --> 00:11:06,810
filter out spending all stuff like that
and you have more complex right you can

133
00:11:06,810 --> 00:11:11,050
have your workforce models like rain
forest k nearest neighbors just a

134
00:11:11,050 --> 00:11:15,650
support vector machines is there sort of
off the shelf models that work well in a

135
00:11:15,650 --> 00:11:19,660
lot of general cases and if you want to
perform a good baseline performance

136
00:11:19,660 --> 00:11:23,880
right to take her data through one of
these workhorse models you can sort of

137
00:11:23,880 --> 00:11:28,710
get an idea of how are your model and we
have more complex models such as going

138
00:11:28,710 --> 00:11:31,590
to be subject to talk their cult hero
networks

139
00:11:31,590 --> 00:11:35,400
networks are nice because he can sort of
tune the complexity of the model right

140
00:11:35,400 --> 00:11:38,170
make it learned really really cool
things and I'll show you some

141
00:11:38,170 --> 00:11:46,689
interesting things saying the whole
point of the model is to learn sort of

142
00:11:46,690 --> 00:11:49,890
separating region between the good stuff
and about stuff or whatever you're

143
00:11:49,890 --> 00:12:03,810
trying to do this you have to train the
model so the lion may start off so the

144
00:12:03,810 --> 00:12:08,380
decision by her master offering
something like this in overtime as it

145
00:12:08,380 --> 00:12:12,600
starts like more samples the decision to
enter all sort of figure out how to best

146
00:12:12,600 --> 00:12:17,160
get that line around so that it can
divide between good and bad so the whole

147
00:12:17,160 --> 00:12:21,709
purpose of this is to generalize right
at the local can only tell us things

148
00:12:21,710 --> 00:12:25,150
that it knows about samples at the scene
already that's not very useful already

149
00:12:25,150 --> 00:12:30,069
have signatures right so the whole point
is to generalize to unseen samples so

150
00:12:30,070 --> 00:12:33,670
when you heat in a completely new novel
piece of malware if you have to get

151
00:12:33,670 --> 00:12:36,569
enough model it's going to be able to
tell you straight away whether it's good

152
00:12:36,570 --> 00:12:45,250
or that some animations for you what
we're seeing here is a model called

153
00:12:45,250 --> 00:12:48,560
logistic regression logistic regression
is gonna have the assumption that

154
00:12:48,560 --> 00:12:53,010
whatever feature space you're operating
in your data is linearly separable and

155
00:12:53,010 --> 00:12:56,430
if it's not linearly separable than this
line that it draws isn't going to

156
00:12:56,430 --> 00:12:59,770
perfectly discriminate things but you
know a lot of cases you can get some

157
00:12:59,770 --> 00:13:04,689
reasonable accuracy out of it so as I
was saying before the initial conditions

158
00:13:04,690 --> 00:13:09,130
sort of draws the line you know
horizontally and vertically this

159
00:13:09,130 --> 00:13:11,980
particular models being trained with
something called stochastic gradient

160
00:13:11,980 --> 00:13:14,810
descent or in this case is just great in
the senate because I'm using all the

161
00:13:14,810 --> 00:13:19,189
samples and every single time the line
moves a little bit because the model has

162
00:13:19,190 --> 00:13:23,500
said ok here on my heirs and here's how
I should move the lines that are better

163
00:13:23,500 --> 00:13:27,480
classify things on the next edition does
this again and again and again until

164
00:13:27,480 --> 00:13:32,280
finally love until it settles into local
optimum other words the performance of

165
00:13:32,280 --> 00:13:36,600
the model is going to be the best place
in the Premier space finally gets there

166
00:13:36,600 --> 00:13:40,459
it's discriminating these red and blue
glasses with actors even ninety-nine

167
00:13:40,459 --> 00:13:47,619
percent failure modes right like I was
saying feature engineering is vitally

168
00:13:47,620 --> 00:13:52,910
important and remodeling logistic
regression if your teachers are able to

169
00:13:52,910 --> 00:13:57,459
not only your lease up on this example
it's not going to do is all right so as

170
00:13:57,459 --> 00:14:00,709
you can see from this noise problem
there's no dividing line that you can

171
00:14:00,709 --> 00:14:04,180
come up with little perfectly separate
these two classes you know you could

172
00:14:04,180 --> 00:14:09,219
have maybe something curbed the logistic
regression is going to give you so you

173
00:14:09,220 --> 00:14:15,740
can see it as sort of a meddling
accuracy of like 88.6% so we're going to

174
00:14:15,740 --> 00:14:18,800
do is we're going to get a more
complicated model and does this

175
00:14:18,800 --> 00:14:23,430
animation goes also to explain what's
going on so the network has the ability

176
00:14:23,430 --> 00:14:27,500
to sort of Twister outing and toward the
original so that it is linearly

177
00:14:27,500 --> 00:14:31,230
separable and higher parts of the model
that's not to say that no other models

178
00:14:31,230 --> 00:14:35,280
can do things like support vector
machines and Brenda Morris W him up on

179
00:14:35,280 --> 00:14:38,920
your decision boundaries but you know
this is still really full visualization

180
00:14:38,920 --> 00:14:43,969
because he can see exactly how it sort
of sliding spacer and in a way that it

181
00:14:43,970 --> 00:14:47,290
packs all the red stuff over here and
all the blue stuff you know sort of goes

182
00:14:47,290 --> 00:14:52,199
to the corners of the teachers Vegas
pretty cool to see so when the model

183
00:14:52,200 --> 00:14:54,360
gets to the point of logistic regression

184
00:14:54,360 --> 00:14:58,310
it says I have a little something sort
of you know mostly separate thread in

185
00:14:58,310 --> 00:14:59,239
blue

186
00:14:59,240 --> 00:15:03,339
ok if I start thinking that decision
boundary down then I can perform better

187
00:15:03,339 --> 00:15:18,370
and you can see this ones getting 100%
accuracy doing the job only during its

188
00:15:18,370 --> 00:15:30,950
important it is very very hard need
people who know people who really know

189
00:15:30,950 --> 00:15:34,750
what they're doing they people at a very
long history and reverse engineering

190
00:15:34,750 --> 00:15:39,290
need people who know the file format
since I now need to know all sorts of

191
00:15:39,290 --> 00:15:39,719
things

192
00:15:39,720 --> 00:15:44,870
engineering well as I saw this really
fragile interplay between implementing

193
00:15:44,870 --> 00:15:50,040
the teachers in a way that's you know
but three sets a very gradual process so

194
00:15:50,040 --> 00:15:53,290
maybe we should ask ourselves if there
are ways around feature engineer in

195
00:15:53,290 --> 00:15:57,019
other words some magical other than that
we just don't get into any gives us get

196
00:15:57,019 --> 00:16:01,320
our predictions so otherwise your own
future engineering yeah I would say so

197
00:16:01,320 --> 00:16:06,180
if you have a whole lot of data you have
a whole lot of computing power and take

198
00:16:06,180 --> 00:16:10,099
advantage of these fences and deporting
representation learning algorithms

199
00:16:10,100 --> 00:16:17,899
usually do quite well I'm gonna get into
deep learning like i said im ambush you

200
00:16:17,899 --> 00:16:19,170
within that straight away

201
00:16:19,170 --> 00:16:22,990
going to get the whole bunch of really
cool many examples maybe convince you

202
00:16:22,990 --> 00:16:32,180
that if learning it's a complex model
that you know our detection so this is

203
00:16:32,180 --> 00:16:35,329
sort of that turnaround plan for neural
networks this was a thing that happened

204
00:16:35,329 --> 00:16:39,479
in 2010 it was the first case of neural
network sort of working much much much

205
00:16:39,480 --> 00:16:43,930
better than the sort of existing
solutions and computer vision so

206
00:16:43,930 --> 00:16:47,390
hopefully we can see the labels piling
up here

207
00:16:47,390 --> 00:16:50,560
classifying things like mites and
container ships motor scooters and

208
00:16:50,560 --> 00:16:54,739
leopards in fact this challenge there
are 1000 upper classes so the things

209
00:16:54,740 --> 00:17:01,350
that need to be able to you know say
what it is is very wide and varied so

210
00:17:01,350 --> 00:17:06,130
what's really cool about this is that
would end up with something like might

211
00:17:06,130 --> 00:17:11,350
also has a couple of additional outputs
so these models here is models are

212
00:17:11,349 --> 00:17:14,829
evaluated on how all the guests this
copy of accuracy so as long as the

213
00:17:14,829 --> 00:17:19,569
correct label is in the top five
predictions accounts so it up with

214
00:17:19,569 --> 00:17:24,069
something like might you can see that
the other labels are very committed rape

215
00:17:24,069 --> 00:17:28,129
you have black widow we have coverage we
have take exception starfish everything

216
00:17:28,130 --> 00:17:31,240
is pretty closely related so in a sense
this model may be learning something

217
00:17:31,240 --> 00:17:34,390
about the world right it saying the
lights are very similar to these other

218
00:17:34,390 --> 00:17:40,450
buggy things container ships are very
similar to live and scooters and mopeds

219
00:17:40,450 --> 00:17:45,340
and it's doing this completely uninstall
it has our input pixels in the upper

220
00:17:45,340 --> 00:17:51,459
levels as well as learning from thats
evolution of this was automatic

221
00:17:51,460 --> 00:17:55,710
captioning historically been going on
for about a year so the idea of

222
00:17:55,710 --> 00:18:00,440
automatic captions there's this huge
data set of input images in the labels

223
00:18:00,440 --> 00:18:05,900
for these images are the objects are
looking at labels are a human human made

224
00:18:05,900 --> 00:18:10,480
I guess annotation of the image of the
model is your training it to look at an

225
00:18:10,480 --> 00:18:16,180
input and then and replicate the caption
so you can see examples like men in

226
00:18:16,180 --> 00:18:19,730
black that's playing a guitar or a
construction worker in Orange City does

227
00:18:19,730 --> 00:18:23,870
working on the really cool thing to
point out about this is that this model

228
00:18:23,870 --> 00:18:26,750
has never seen these images before it's
the very first time and other

229
00:18:26,750 --> 00:18:30,350
construction worker and an orange safety
vest working on route and I'll putting

230
00:18:30,350 --> 00:18:34,740
the correct thing there some kinda weird
ones like a boy is doing backflip is

231
00:18:34,740 --> 00:18:42,540
doing backflips not in a week or so tell
you about these models so I kinda

232
00:18:42,540 --> 00:18:46,360
sitting on a couch with remote control
that looks like a rat in the middle

233
00:18:46,360 --> 00:18:49,879
class and a woman holding a teddy bear
in front of a mirror I don't see any

234
00:18:49,880 --> 00:18:54,960
teddy bears and seniors have no idea
what's coming up on his horses standing

235
00:18:54,960 --> 00:18:57,980
in the middle of a room there's no force
whatsoever in this model is just getting

236
00:18:57,980 --> 00:19:05,860
it done on fairly there's some
disagreement with his balls and other

237
00:19:05,860 --> 00:19:10,370
really cool thing is that work it's a
special deep network that has recurrent

238
00:19:10,370 --> 00:19:13,729
connections model time series data

239
00:19:13,730 --> 00:19:17,260
supplied to the objective language
modeling language modeling you're going

240
00:19:17,260 --> 00:19:20,700
to look at the last let's say 10 or so
characters are going to see some history

241
00:19:20,700 --> 00:19:24,490
of characters objective of the model is
to put the next character that's likely

242
00:19:24,490 --> 00:19:29,890
to the so the whole bunch of shakespeare
into this model and a completely

243
00:19:29,890 --> 00:19:35,630
memorized things like and second senator
to do and it's also coming up with

244
00:19:35,630 --> 00:19:38,850
things that are very structurally
shakespearian right so it's like strain

245
00:19:38,850 --> 00:19:42,929
words like that ended so it's really
interesting to see it sort of mimicking

246
00:19:42,930 --> 00:19:47,790
shakespeare of course like on a local
level it's you know looking a lot like

247
00:19:47,790 --> 00:19:50,980
Shakespeare but on a global level it's
not really coming up in overall story

248
00:19:50,980 --> 00:19:56,210
play it's just helping shakespearian
gibberish they're kinda funny wellness

249
00:19:56,210 --> 00:20:00,830
program like this you can see it's
talking about angel investors start up

250
00:20:00,830 --> 00:20:05,090
things like that are actually stochastic
there there's a tab ramos to them so you

251
00:20:05,090 --> 00:20:10,949
can sort of making up more predictable
things by changing how samples and it

252
00:20:10,950 --> 00:20:14,380
was so funny thing about the program
blog posts if you make the model super

253
00:20:14,380 --> 00:20:18,100
to deterministic get stuck in a loop of
talking about startups I think it says

254
00:20:18,100 --> 00:20:24,290
something like about the story about the
sort of just turns into a burger and the

255
00:20:24,290 --> 00:20:25,750
final one is

256
00:20:25,750 --> 00:20:29,530
networks trained on Linux kernel source
so in this case you can see that it's

257
00:20:29,530 --> 00:20:35,470
doing a very good job of balancing curly
braces balancing parentheses you know it

258
00:20:35,470 --> 00:20:40,550
Warner dereferencing has and has about
trucks there is kind of a funny thing

259
00:20:40,550 --> 00:20:42,300
where it's returning 0 non-static

260
00:20:42,300 --> 00:20:46,600
but you know we can model a little bit
of slack that's again this is gibberish

261
00:20:46,600 --> 00:20:50,820
the if you try to compile this nothing
will happen this likely but it's really

262
00:20:50,820 --> 00:20:54,960
cool see that it cannot but feel like if
you're just had me these functions are

263
00:20:54,960 --> 00:21:03,110
totally devoted think at some level
sequin bad I'm going to introduce what's

264
00:21:03,110 --> 00:21:06,620
going on sort of mathematical in a deep
neural network when you get from doctor

265
00:21:06,620 --> 00:21:12,649
to not put label so what I have on the
left side here is a set of features the

266
00:21:12,650 --> 00:21:14,640
top note is going to be file size

267
00:21:14,640 --> 00:21:17,870
next is going to be section one
interview lets a section to interview

268
00:21:17,870 --> 00:21:21,139
second tranche B and we have a whole
bunch of other features which I have a

269
00:21:21,140 --> 00:21:25,250
list and we have a final feature like
you know is packed with UPS or something

270
00:21:25,250 --> 00:21:27,059
like that but we're going

271
00:21:27,059 --> 00:21:32,090
to do is we're going to head that is
actor we're going to do a matrix-vector

272
00:21:32,090 --> 00:21:37,178
multiplication right that turns into
another vector now we're going to buy a

273
00:21:37,179 --> 00:21:42,269
nonlinearity in other words just some
function everything was all posts and

274
00:21:42,269 --> 00:21:46,110
we're going to do that again with the
previous hidden layer into another

275
00:21:46,110 --> 00:21:49,379
weight matrix we're going to fight this
process again and again until he finally

276
00:21:49,379 --> 00:21:52,789
get to the output learn so you can start
to think of it as just a whole bunch of

277
00:21:52,789 --> 00:21:58,740
repetitive operations of pictures and
nonlinearities yes actually comes up

278
00:21:58,740 --> 00:22:05,659
with a really powerful other thing that
we unfortunately have to go through the

279
00:22:05,659 --> 00:22:09,759
idea of convolution so all these really
cool image recognition algorithms you

280
00:22:09,759 --> 00:22:13,360
something called convolutional neural
networks so I'm sharing a fully

281
00:22:13,360 --> 00:22:17,928
connected network so no matter how he
sort of commute isn't but it's going to

282
00:22:17,929 --> 00:22:21,619
happen right it doesn't matter if the
file size comes first of all sides come

283
00:22:21,619 --> 00:22:26,080
second you can sort of shop these things
are however with image data if you're to

284
00:22:26,080 --> 00:22:33,029
shuffle the pixels around you lose the
meaning of what the energy right so we

285
00:22:33,029 --> 00:22:37,450
do to deal with us as we instead of
using matrix matrix multiplications and

286
00:22:37,450 --> 00:22:42,960
you later use convolutions competition
basically going to be taking an input

287
00:22:42,960 --> 00:22:46,419
and then you have something called a
convolutional kernel that sort of steps

288
00:22:46,419 --> 00:22:49,779
over it so everything thrown every
single column will have this competition

289
00:22:49,779 --> 00:22:53,149
and so what it's doing

290
00:22:53,149 --> 00:23:00,239
medically as a cane since my laser
pointers in iran also like to have an

291
00:23:00,240 --> 00:23:04,600
input image here we're going to have her
come aleutian kernel here every single

292
00:23:04,600 --> 00:23:05,908
axle

293
00:23:05,909 --> 00:23:13,919
02 the score tied together so it is your
times for your time 00 time 03 2011

294
00:23:13,919 --> 00:23:19,149
times you're at one time so on and so
forth until I get to overlapping pixels

295
00:23:19,149 --> 00:23:24,699
and we're going to at all those up and
he felt response for that particular

296
00:23:24,700 --> 00:23:28,820
pixel is going to be negative so you
copy that over to help manage are going

297
00:23:28,820 --> 00:23:31,529
to do it again for this pixel again for
this pixel again for those pics all

298
00:23:31,529 --> 00:23:39,230
except for the entire and what are these
competitions doing exactly what's really

299
00:23:39,230 --> 00:23:40,010
general operate

300
00:23:40,010 --> 00:23:44,730
you can use them for edge detection so
in this case we have competition that's

301
00:23:44,730 --> 00:23:49,280
going to look at a tough pixel by pixel
x1 pixel that's going to be a waiting

302
00:23:49,280 --> 00:23:54,360
for right on +1 +1 +1 going to subtract
out the center pixel with the same way

303
00:23:54,360 --> 00:23:58,770
negative for what you get a sort of like
rising falling had an idea of where the

304
00:23:58,770 --> 00:24:01,990
legislation image so if you're trying to
do a classifier that it's a

305
00:24:01,990 --> 00:24:06,560
distinguishes between men and women
could maybe it's the edge here to come

306
00:24:06,560 --> 00:24:10,700
up with a useful features like I said
it's really general operation you can

307
00:24:10,700 --> 00:24:16,680
also use of your boring so in this
example we have are you doing here just

308
00:24:16,680 --> 00:24:20,270
taking the average of the neighborhood
of pixels yes says the effects when you

309
00:24:20,270 --> 00:24:27,800
look at the image blurring exam season
here on that works so we're going to do

310
00:24:27,800 --> 00:24:33,409
that we're going to have a ton of weight
matrices we're going to have these

311
00:24:33,410 --> 00:24:37,170
competition and competition finals are
going to be completely learned from the

312
00:24:37,170 --> 00:24:43,050
data compilations followed by the moment
while I was talking about when did this

313
00:24:43,050 --> 00:24:48,500
a few times then we have something later
objective is to look at a whole bunch of

314
00:24:48,500 --> 00:24:52,760
let's say two by two neighborhoods of
pixels and do something like that the

315
00:24:52,760 --> 00:24:57,550
next pixel for all of them so in that
case you can turn a 64 of 64 engine to

316
00:24:57,550 --> 00:25:01,500
32 by 32 image that has the effect of
sort of reducing the dimensionality

317
00:25:01,500 --> 00:25:06,180
helpfully three way too much interesting
data you do this again and again until

318
00:25:06,180 --> 00:25:09,630
you get to the output layer and then if
the competition filters have been

319
00:25:09,630 --> 00:25:12,770
learned while in the fully connected
there has been learned while they can

320
00:25:12,770 --> 00:25:15,500
tell the difference between cars and
trucks and airplanes and ships sources

321
00:25:15,500 --> 00:25:22,960
so how do we interpret these models
right so I'm showing you here is the

322
00:25:22,960 --> 00:25:27,140
first player in other words the first
set of filters bounces but you can see

323
00:25:27,140 --> 00:25:30,350
it's doing it sort of figuring out you
know the lay press the image the dark

324
00:25:30,350 --> 00:25:35,510
arts the image and maybe coming up with
such detectors things like that

325
00:25:35,510 --> 00:25:39,350
run it through the rest of the model but
you tend to see his starts picking up

326
00:25:39,350 --> 00:25:42,679
objects right so instead of just
considering the light parts of the

327
00:25:42,680 --> 00:25:46,320
engine dark arts the image may be
combining that information together into

328
00:25:46,320 --> 00:25:49,379
a sort of like what does it look like or
what does it

329
00:25:49,380 --> 00:25:52,830
windshield look like or what does a
trunk look like that's combining all the

330
00:25:52,830 --> 00:25:55,540
stuff together to come up with model
that can tell the difference

331
00:25:55,540 --> 00:26:04,770
worse showing here is the final output
layer so we're basically taking on to

332
00:26:04,770 --> 00:26:10,900
say the eaves and then just everything
on the card image what you see is he see

333
00:26:10,900 --> 00:26:14,770
it's picking up really highly right here
so this may be you know I filter that's

334
00:26:14,770 --> 00:26:19,139
really sensitive to detecting windows
and cars maybe that's because you have

335
00:26:19,140 --> 00:26:22,560
other things that seem to be looking at
the cargo hold as a whole this one here

336
00:26:22,560 --> 00:26:25,540
that looks like it's looking at a
headline and grow its combining all this

337
00:26:25,540 --> 00:26:28,610
information together to come up with
something that can discriminate between

338
00:26:28,610 --> 00:26:38,229
parents and so how do I is all the stuff
from our detection going to discuss what

339
00:26:38,230 --> 00:26:43,020
we're going to do is we're going to
disassemble a p/e are going to turn it

340
00:26:43,020 --> 00:26:47,420
into a list of instructions right so
we're going to have human readable

341
00:26:47,420 --> 00:26:53,540
newmont X and we're going to turn it
into just the hexadecimal representation

342
00:26:53,540 --> 00:26:58,170
that's all we're doing here so take this
55 the thing that corresponds to the

343
00:26:58,170 --> 00:27:03,020
push our VP we're going to just put it
in your information down here so this is

344
00:27:03,020 --> 00:27:06,980
going to be the binary representation 55
we're putting this out eight bytes

345
00:27:06,980 --> 00:27:12,010
because x86 instructions are variable
and this one is 53 so you can see it's

346
00:27:12,010 --> 00:27:17,270
only differing by one but this is 488
950 we're just going to do this to every

347
00:27:17,270 --> 00:27:22,100
single instruction and so we have an
image that is 64 pixels wide other words

348
00:27:22,100 --> 00:27:26,110
64 bits number of its instruction and
it's going to be however many

349
00:27:26,110 --> 00:27:29,610
instructions we have an executable d
right that's all told him it was going

350
00:27:29,610 --> 00:27:34,709
to be you know we're going to do is
we're going to take these jobs and

351
00:27:34,710 --> 00:27:38,240
recognition algorithms that work really
well with object recognition and apply

352
00:27:38,240 --> 00:27:42,410
them directly to our direction so we're
going to have a big data that one does

353
00:27:42,410 --> 00:27:46,830
peds we have an advanced me know which
ones are good or bad

354
00:27:46,830 --> 00:27:50,250
going to turn them into these sorts of
images and we're going to throw three

355
00:27:50,250 --> 00:27:55,210
models but it says it will be done so
you can see it sort of the spatial

356
00:27:55,210 --> 00:27:59,870
structure and the instructions you can
see sort of repeating sets

357
00:27:59,870 --> 00:28:08,360
Stephen Wolfram cellular automata never
seen those are starting to get a little

358
00:28:08,360 --> 00:28:12,669
noisy sometimes but there's still 20
eighties patterns in the chaos right now

359
00:28:12,670 --> 00:28:18,280
the one unfortunate thing about this
model and the thing that we had to

360
00:28:18,280 --> 00:28:22,690
figure out was the fact that the object
her mission other times they're always

361
00:28:22,690 --> 00:28:27,460
taken a fixed image sides so you have a
512 by 512 imaging you wanna classify it

362
00:28:27,460 --> 00:28:33,940
only works with 64 64 images at stake
here and put in a pop-up high tops

363
00:28:33,940 --> 00:28:38,610
president sides it needs to be done to
the other as far as I know that there's

364
00:28:38,610 --> 00:28:42,850
no way for their there's no compression
thing you can do directly to be teased

365
00:28:42,850 --> 00:28:44,199
that makes sense right

366
00:28:44,200 --> 00:28:48,040
you could maybe try to get instructions
that out to some axle way that's going

367
00:28:48,040 --> 00:28:53,940
to waste a lot of memory but we do
instead is behind this idea sort of only

368
00:28:53,940 --> 00:28:57,040
feeding what the model thinks is
important to the final fully connected

369
00:28:57,040 --> 00:29:01,500
we're so in this case the model sort of
learns which instructions and needs to

370
00:29:01,500 --> 00:29:06,480
consider the call something good done
here is a sort of visualized so we have

371
00:29:06,480 --> 00:29:11,000
read these sequences of instructions
that the little things are important and

372
00:29:11,000 --> 00:29:15,120
white or the sequences that are
unfortunately I haven't done a lot of

373
00:29:15,120 --> 00:29:18,330
data science and these images I think
you really useful to reverse engineer

374
00:29:18,330 --> 00:29:24,389
and they could maybe get them you know
sort of respondents executable or

375
00:29:24,390 --> 00:29:29,720
something like that

376
00:29:29,720 --> 00:29:32,590
disassembly is really a problem that
great it's a very interesting thing

377
00:29:32,590 --> 00:29:36,820
there's no way that you tend to an
executable and extract out every single

378
00:29:36,820 --> 00:29:40,730
instruction right there gonna be some
things that you jump into conditionally

379
00:29:40,730 --> 00:29:42,669
anime not grab that

380
00:29:42,669 --> 00:29:46,379
so I'm going to extract all the
executable code that we can it's

381
00:29:46,379 --> 00:29:50,879
difficult for other difficult things
that information can be buried elsewhere

382
00:29:50,879 --> 00:29:55,219
in the executable you can have packed
examples

383
00:29:55,220 --> 00:29:59,090
up he skated examples they need to come
up with to do with this right because

384
00:29:59,090 --> 00:30:02,820
the model just working on the
disassembly data is going to happen

385
00:30:02,820 --> 00:30:06,980
visibility into the pack part of the
excuse that said there may be regular

386
00:30:06,980 --> 00:30:11,269
tees and now we're an hour maybe doing
something that makes a reverse engineer

387
00:30:11,269 --> 00:30:15,989
have to try really hard time Pakistan
not information they give you all you

388
00:30:15,989 --> 00:30:21,859
need to call something good or bad also
this this model only really applies taxi

389
00:30:21,859 --> 00:30:27,759
to executable so really cool to come up
with ways to apply this to scripts I

390
00:30:27,759 --> 00:30:31,350
think it would also be interesting to
start applying this model to envy and

391
00:30:31,350 --> 00:30:38,289
almost immediately start applying this
model to construct a plan to see sharps

392
00:30:38,289 --> 00:30:42,549
intermediate representation as long as
he had enough input samples this

393
00:30:42,549 --> 00:30:46,129
approach probably went pretty well
they're interesting thing I'd like to

394
00:30:46,129 --> 00:30:51,408
look into the question of whether or not
turning on all by its attractive because

395
00:30:51,409 --> 00:30:56,419
if they have to simply did it take like
20 megabyte he has a whole bunch of

396
00:30:56,419 --> 00:31:01,509
images or something like that or not and
when you disassemble it up with you know

397
00:31:01,509 --> 00:31:06,619
702 disassembly permission for the
disassembly model it's going to be very

398
00:31:06,619 --> 00:31:11,459
small and great compact and easy to
train if it's raining on girl gets much

399
00:31:11,460 --> 00:31:15,369
more difficult because you have to
consider every single by Nick can be

400
00:31:15,369 --> 00:31:26,119
very very large for something he's going
to get to the demo before I saw this

401
00:31:26,119 --> 00:31:32,379
talk I downloaded 100 samples from
virustotal and also the quarry using

402
00:31:32,379 --> 00:31:39,668
this particular on any samples that are
less than three large they just throw it

403
00:31:39,669 --> 00:31:45,440
away they were first seen three days ago
and later I P exe because that's what

404
00:31:45,440 --> 00:31:49,369
our model is trained on has more than 20
positive so the industry as a whole

405
00:31:49,369 --> 00:31:53,970
thing's pretty nasty when we just have
attacking here that the PD's corrupt

406
00:31:53,970 --> 00:32:02,290
because we don't want to disassemble it
we're going to cancer can see how the

407
00:32:02,290 --> 00:32:07,149
small compares to industry we're going
to do some stuff that result samples

408
00:32:07,150 --> 00:32:11,310
that are not not for example if we
disassemble a.net sample the only one on

409
00:32:11,310 --> 00:32:16,050
one instruction so there's not much
useful stuff tomorrow we're going to

410
00:32:16,050 --> 00:32:20,280
converted into thing that Julia
programming language I'm gonna distant

411
00:32:20,280 --> 00:32:25,570
understand and then we're going to score
it going to run a smile on the data that

412
00:32:25,570 --> 00:32:30,129
I don't correspond to the stalk and
we'll see how it does have no idea

413
00:32:30,130 --> 00:32:50,330
alright so what we're seeing here is
we're seeing a calc how many times a ok

414
00:32:50,330 --> 00:32:53,689
looking at the model's output
probability right so you feeling a

415
00:32:53,690 --> 00:32:56,280
sample then he gets on top of
probabilities to other announcement

416
00:32:56,280 --> 00:33:05,420
where 0 that's probably good if it's one
of the things up saying that we have a

417
00:33:05,420 --> 00:33:25,180
lot of protections while so the one on
the right is your number

418
00:33:25,180 --> 00:33:28,600
the interesting thing to point out about
this is that there have been very few

419
00:33:28,600 --> 00:33:32,399
development hours that went into this
project right and it's comparing

420
00:33:32,400 --> 00:33:36,250
favorably with the rest of industry
right it's picking things out

421
00:33:36,250 --> 00:33:42,940
not a super impressive but this model
can run a whole lot of samples and sort

422
00:33:42,940 --> 00:33:46,220
of filter things done for years and
years and look at is pretty interesting

423
00:33:46,220 --> 00:34:11,380
what's now to see how industry did these
scans various of these samples right I'm

424
00:34:11,380 --> 00:34:15,340
going to look at all the query results
from virus so and then an itemized the

425
00:34:15,340 --> 00:34:44,909
vendors and then we'll see where we fall

426
00:34:44,909 --> 00:34:52,659
so I can see but the scan so far not all
of them have completed as I talk more

427
00:34:52,659 --> 00:34:57,119
scans will go and we'll see how it ends
up falling roughly into them it's a

428
00:34:57,119 --> 00:35:02,359
little bit lower than half or somewhere
here under 54 is doing slightly better

429
00:35:02,359 --> 00:35:16,119
than go ahead and three takeaways from
the stock basically a true disassembly

430
00:35:16,119 --> 00:35:26,970
did in 2009 this stuff while the scans
are going astray taken questions you

431
00:35:26,970 --> 00:35:30,490
don't happen to ask the question you
don't have a chance to ask your question

432
00:35:30,490 --> 00:35:31,470
you can contact us

433
00:35:31,470 --> 00:35:35,950
machine learning and silence dot com in
the same questions they're like to give

434
00:35:35,950 --> 00:35:38,930
a shout out to Derek suring Gabriel
acevedo without them there have been at

435
00:35:38,930 --> 00:35:41,009
it for this project and it wouldn't
happen

436
00:35:41,010 --> 00:35:48,710
extra plug we are hiring so check out
silence dot com company careers and if

437
00:35:48,710 --> 00:35:59,810
you'd be interested in

438
00:35:59,810 --> 00:36:13,820
can you so by next generation networks
used to it and I was under the

439
00:36:13,820 --> 00:36:27,100
impression that learning revert to using
much more layers is that was attacked as

440
00:36:27,100 --> 00:36:32,140
I guess it depends on how you that
that's more than maybe let's say one had

441
00:36:32,140 --> 00:36:37,870
Larry call it the more sophisticated
models like the Google not is up to like

442
00:36:37,870 --> 00:36:44,150
twenty two layers which actually is
doing some sort of like crazy thing yeah

443
00:36:44,150 --> 00:36:51,280
it was a pretty wide range for the
definition he would call this particular

444
00:36:51,280 --> 00:36:56,180
case we have to competition winners all
the way to fully connected leaders nazi

445
00:36:56,180 --> 00:37:10,419
party but so my question is with the
earlier and you hers as well using so

446
00:37:10,420 --> 00:37:14,910
the blockbuster use letters as the
criminals and you're using just the

447
00:37:14,910 --> 00:37:16,609
opposite series my

448
00:37:16,610 --> 00:37:24,110
using like the STV your code or words
for the generation text asking why we're

449
00:37:24,110 --> 00:37:27,880
not using things like asked his yeah why
why you're not using asked he's in the

450
00:37:27,880 --> 00:37:33,500
blockbuster earlier uses letters rather
than words as the things operate on ok

451
00:37:33,500 --> 00:37:39,400
you can certainly figure out a way it's
is sort of leverage STDs and there are

452
00:37:39,400 --> 00:37:42,620
some models that sort of work like
Unilever these bottles that were

453
00:37:42,620 --> 00:37:47,150
countries structures that would be an
interesting line of work

454
00:37:47,150 --> 00:37:50,930
research their million different ways
you can go

455
00:37:50,930 --> 00:38:08,200
and it's just one particular direction I
didn't do as far as training we think

456
00:38:08,200 --> 00:38:14,078
about those about 1.6 million samples
going on 9/8 about 90% for training and

457
00:38:14,079 --> 00:38:19,200
10% for validation so somewhere in the
neighborhood of several thousand says

458
00:38:19,200 --> 00:38:30,109
maybe one or two hundred thousand I
dunno what percentage of samples your

459
00:38:30,109 --> 00:38:36,558
child classifier actually been I'm
versus militias that I have its 50 split

460
00:38:36,559 --> 00:38:42,160
I think it was slightly less than fifty
50 something like sixty 49 train the

461
00:38:42,160 --> 00:38:46,868
model I get a split between getting that
doesn't weren't unfairly biased when

462
00:38:46,869 --> 00:38:53,069
will it mean the reason I ask is if you
i mean obviously those proportions are

463
00:38:53,069 --> 00:38:57,790
like a lot different than you would find
in an enterprise network so I mean you

464
00:38:57,790 --> 00:39:00,980
could just make a sensor that always
says this is malicious

465
00:39:00,980 --> 00:39:05,920
Gatorade percent of the time which would
look better than some in tomorrow's

466
00:39:05,920 --> 00:39:11,480
really realistic yeah that's very true
the whole idea of how our input

467
00:39:11,480 --> 00:39:15,510
distribution and training differs from
him but distribution in like a likely

468
00:39:15,510 --> 00:39:23,690
situation like machine learning-based a
few questions that's really hard to

469
00:39:23,690 --> 00:39:30,339
grapple with great because the
distribution is really hard thing yeah I

470
00:39:30,339 --> 00:39:35,319
guess I'm just wondering if you have you
tried running like you know maybe 10,000

471
00:39:35,319 --> 00:39:44,740
911 malicious and see if I can say as
far as our production goes it's not

472
00:39:44,740 --> 00:39:53,250
super false-positive you soon

473
00:39:53,250 --> 00:39:58,050
training set of 1.6 million samples it's
obvious that they

474
00:39:58,050 --> 00:40:05,100
manually analyzed so you may not have
that much confidence how do you protect

475
00:40:05,100 --> 00:40:13,810
against just repeating the mistakes of
existing question we have observed that

476
00:40:13,810 --> 00:40:19,100
there is like a particular amount of
little boys right so you know somewhere

477
00:40:19,100 --> 00:40:23,400
in the neighborhood of 1 percent on
their labels are kind of like not very

478
00:40:23,400 --> 00:40:26,970
good so there is a problem

479
00:40:26,970 --> 00:40:30,770
fortunately a lot of models are fairly
resilient to that other words you don't

480
00:40:30,770 --> 00:40:34,140
have to worry too much about label noise
until you start getting into the regime

481
00:40:34,140 --> 00:40:38,850
in like 5 10 20 percent so as long as a
little said she got her kind of ok your

482
00:40:38,850 --> 00:40:46,000
mother's going to work very well so how
do you tell which unfortunately that's

483
00:40:46,000 --> 00:40:50,630
sort of getting into the range of trade
secrets as a lot of work that goes into

484
00:40:50,630 --> 00:41:03,620
that too much of her time

