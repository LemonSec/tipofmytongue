1
00:00:00,000 --> 00:00:05,190
you are increased you currently in the
Jasmine Wynne for Internet scale malware

2
00:00:05,190 --> 00:00:17,789
analysis with Sakura hand if Hamas lingo
and jobs while George Webster will be

3
00:00:17,789 --> 00:00:22,100
discussed in Internet scale in our
analysis so during the talk printer

4
00:00:22,100 --> 00:00:26,840
briefly discuss who we are kind of the
motivation the parliamentary CEO Irene

5
00:00:26,840 --> 00:00:29,769
discuss the framework which we believe
will help solve this problem and

6
00:00:29,769 --> 00:00:34,290
alleviate it will then be discussing the
two different implementations and

7
00:00:34,290 --> 00:00:39,180
discuss what we're gonna be trying to do
with this in the future so here we have

8
00:00:39,180 --> 00:00:44,710
used the director replied that assigns
is that no better he's also a co-author

9
00:00:44,710 --> 00:00:49,539
a binary pig which is a feature
extraction for large-scale static

10
00:00:49,539 --> 00:00:54,760
analysis we also have Thomas lingo is a
PhD student at the University of

11
00:00:54,760 --> 00:00:58,920
Connecticut he's a senior security
researcher at me better and he's a

12
00:00:58,920 --> 00:01:04,040
creator of dracula which is pretty much
for large-scale dynamic analysis through

13
00:01:04,040 --> 00:01:08,520
virtual machine introspection and then
you have made and George Webster my PhD

14
00:01:08,520 --> 00:01:13,250
student at the Technische Universitaet
Munich and I'm researching the cognitive

15
00:01:13,250 --> 00:01:19,119
bias and cyber times so we really have
permit fees and is he wanted to create a

16
00:01:19,119 --> 00:01:23,100
system that really incorporated the
full-scale the analytics life cycle and

17
00:01:23,100 --> 00:01:28,020
we wanted to do so across multiple teams
so the system be very fast we need to be

18
00:01:28,020 --> 00:01:32,030
scalable we want to just be resilient
and wanted to be flexible and more

19
00:01:32,030 --> 00:01:35,670
flexible I mean we want to be able to
incorporate new analytic methods and

20
00:01:35,670 --> 00:01:42,369
techniques pretty much with the kids so
what we did was we first we develop

21
00:01:42,369 --> 00:01:47,610
scholar in scholar is just basically an
architectural blueprint for saying this

22
00:01:47,610 --> 00:01:51,229
is how we need to design our system this
is what we need to create redundant

23
00:01:51,229 --> 00:01:55,950
totem which is a scalable static
analysis implementation and then we said

24
00:01:55,950 --> 00:01:59,670
hey we need to take dracula for dynamic
analysis figure out how to tie this hole

25
00:01:59,670 --> 00:02:04,079
into the system together and directive
is done with the hypervisor and it needs

26
00:02:04,079 --> 00:02:07,179
no and St John and it's quite nice

27
00:02:07,180 --> 00:02:12,070
so to discuss the problem as really the
current state of affairs and as you guys

28
00:02:12,070 --> 00:02:16,700
are all aware its absolute like a
tsunami and this is for multiple reasons

29
00:02:16,700 --> 00:02:22,670
discussed shortly but really it's
because we can't keep up so in 2012

30
00:02:22,670 --> 00:02:28,320
McAfee stated that we receive 200,000
unique samples a day however in May in

31
00:02:28,320 --> 00:02:33,420
2015 virustotal saying that we're
exceeding one million samples of day and

32
00:02:33,420 --> 00:02:36,880
this isn't even talk about the historic
town of a tree house and trying to

33
00:02:36,880 --> 00:02:38,850
process all that information as well

34
00:02:38,850 --> 00:02:44,690
furthermore tools absolute disjointed
they're pretty much one wonders trying

35
00:02:44,690 --> 00:02:48,140
to solve the problem for what they need
to do at that time

36
00:02:48,140 --> 00:02:50,540
not really looking at how do you take
this into the big picture of things

37
00:02:50,540 --> 00:02:54,970
there's also heavy reliance on the
individual analyst and a single person

38
00:02:54,970 --> 00:02:58,090
to try to tie it all together and figure
out what's really going on

39
00:02:58,090 --> 00:03:02,940
furthermore our tools only focus on the
binaries came up from the anti-virus

40
00:03:02,940 --> 00:03:08,250
community but the problem is you have
multi-stage droppers you have many more

41
00:03:08,250 --> 00:03:14,820
malware polymorphism and really had a
pretty nu nu sample is absolutely dirt

42
00:03:14,820 --> 00:03:19,959
cheap and it's just you can't
furthermore you got your defensive tools

43
00:03:19,959 --> 00:03:24,780
are focused on that signature so these
binaries that can keep up with you got

44
00:03:24,780 --> 00:03:30,830
the defense of tools our signatures for
those buying areas so she gets North AV

45
00:03:30,830 --> 00:03:36,390
products they are rules you just really
can't keep up so

46
00:03:36,390 --> 00:03:41,309
the current state of affairs is getting
even worse with the rise of the actors

47
00:03:41,310 --> 00:03:45,150
organized crime you got nation states
and these guys are very sophisticated

48
00:03:45,150 --> 00:03:50,000
they're very smart they don't know what
they're doing and now they have a lot of

49
00:03:50,000 --> 00:03:55,020
resources so now we're no longer sit
back here you really have teams that are

50
00:03:55,020 --> 00:03:58,700
dealing with sophisticated tools you got
a large scale infrastructure that's very

51
00:03:58,700 --> 00:03:59,769
complex

52
00:03:59,770 --> 00:04:03,630
analyst telling them what to do how to
do it where to do it and you'll see how

53
00:04:03,630 --> 00:04:08,570
financial networks that are moving money
around so what this really means is

54
00:04:08,570 --> 00:04:16,089
reverse engineer he's really not enough
so we really need to get pretty much

55
00:04:16,089 --> 00:04:17,539
going back to the initial

56
00:04:17,540 --> 00:04:22,160
analytical ice I can say we need to
focus on the 5 W's we need to focus on

57
00:04:22,160 --> 00:04:27,780
who's behind the action what are their
goals whereas the infrastructure when do

58
00:04:27,780 --> 00:04:32,330
they operate wire they conducted this
operation and most importantly how do we

59
00:04:32,330 --> 00:04:40,340
stop the activity so nicely really in
the age of big data and we need to

60
00:04:40,340 --> 00:04:43,299
figure out how to leverage your defense
of tools to actually take advantage of

61
00:04:43,300 --> 00:04:48,050
somebody's taking advantage of this data
every house and we need to use multiple

62
00:04:48,050 --> 00:04:51,850
tools and different techniques to do is
when things not going to do it for us to

63
00:04:51,850 --> 00:04:55,979
use machine learning to do graphical
representation we also need to do

64
00:04:55,979 --> 00:05:01,039
reverse engineering across what we got
so as we SAT there we went to the

65
00:05:01,040 --> 00:05:03,510
problem and said really got two ways to
go for it

66
00:05:03,510 --> 00:05:07,969
one is respect but we currently have
gonna get failure or we probably have it

67
00:05:07,970 --> 00:05:11,560
or to try to figure out something else
try to go a different direction maybe

68
00:05:11,560 --> 00:05:16,910
have some success so in order to try to
go to the success path what we did was

69
00:05:16,910 --> 00:05:22,860
we created scholar and solid is really a
micro services framework is made to

70
00:05:22,860 --> 00:05:27,229
conduct the full lifecycle 15 the
instruction needed so we wanted to

71
00:05:27,229 --> 00:05:30,960
support hundreds of millions of objects
allowed to automatically expand into

72
00:05:30,960 --> 00:05:34,190
public and private infrastructure pretty
much the cloud

73
00:05:34,190 --> 00:05:37,170
we also want to deprive the
infrastructure to not only gather all

74
00:05:37,170 --> 00:05:40,770
the features that we mean but also to
private infrastructure to then do

75
00:05:40,770 --> 00:05:45,880
something with that data we also want to
support third parties are doing as virus

76
00:05:45,880 --> 00:05:52,350
total right connector places that can
bring the stuff into the system and even

77
00:05:52,350 --> 00:05:55,480
though the tools are destroyed in that
doesn't mean that they're not valuable

78
00:05:55,480 --> 00:05:59,290
in the not important so every right to
really want to be able to incorporate

79
00:05:59,290 --> 00:06:05,490
all that stuff back into the systems so
when we look at scholar be you really

80
00:06:05,490 --> 00:06:09,650
broke the system down into three core
components and he's put into the

81
00:06:09,650 --> 00:06:17,380
transfer lair your planner and then your
services so the goal of the service

82
00:06:17,380 --> 00:06:22,520
reform an individual task independently
of each other kind of an atomic nature

83
00:06:22,520 --> 00:06:29,979
and we wanted them to interact with the
plan next for the planner we went into

84
00:06:29,980 --> 00:06:33,740
scheduled to services execution and
figure out if something's gone wrong

85
00:06:33,740 --> 00:06:38,500
with the service thing needs to be
restarted restarted and then kind of

86
00:06:38,500 --> 00:06:41,760
manage all that together but doing in a
smart way what's actually figures out

87
00:06:41,760 --> 00:06:47,860
how do we do this best so we're not just
wasting our cycles furthermore we want

88
00:06:47,860 --> 00:06:52,030
to plan our concern to transport layer
that can actually move everything around

89
00:06:52,030 --> 00:06:55,250
between the planners and do the same to
schedule the way to kind of make it so

90
00:06:55,250 --> 00:07:01,080
we can't really lose data so what can I
say colin is pretty much the big picture

91
00:07:01,080 --> 00:07:05,250
and with the big picture there's five
main themes you got your gateway their

92
00:07:05,250 --> 00:07:05,960
stories

93
00:07:05,960 --> 00:07:11,539
investigation or interrogation and their
presentation themes and a stalker really

94
00:07:11,540 --> 00:07:17,200
wanna talk about the investigation and
the interrogation levels so with the

95
00:07:17,200 --> 00:07:22,550
interrogation planner the goal here is
to figure out when you receive a sample

96
00:07:22,550 --> 00:07:26,630
when you receive an IP address and
domain what is it and what information

97
00:07:26,630 --> 00:07:33,090
can you get from it so this really
focuses on just one object be whatever

98
00:07:33,090 --> 00:07:37,560
it is it's agnostic but how do you do
the static analysis performed the

99
00:07:37,560 --> 00:07:41,930
dynamic analysis get information from
third parties and kind of put everything

100
00:07:41,930 --> 00:07:42,630
together

101
00:07:42,630 --> 00:07:47,610
so what say you got a sample that's what
this whole point to track your for

102
00:07:47,610 --> 00:07:54,800
dynamic analysis and stole or whatever
have you next to you get a huge amount

103
00:07:54,800 --> 00:07:58,750
of data and you got a lot of features
that are generated from this so what do

104
00:07:58,750 --> 00:08:03,230
you do with all the data to display it
what do you work with it from there we

105
00:08:03,230 --> 00:08:08,470
have the investigation planner this is
broken down into two parts the first

106
00:08:08,470 --> 00:08:13,850
american dad as he need a ride and
infrastructure to figure out what's

107
00:08:13,850 --> 00:08:18,170
going on in this incorporates machine
learning and static analysis to say hey

108
00:08:18,170 --> 00:08:22,270
how do we cluster stuff together do we
see any patterns are crossed out that we

109
00:08:22,270 --> 00:08:27,340
have behavior how is everything
functioning so how do we do that on that

110
00:08:27,340 --> 00:08:32,640
level next year dealing with humans and
our human Ellis are very good so we

111
00:08:32,640 --> 00:08:37,189
wanted to be able to say what do we do
and how do we tried it started to these

112
00:08:37,190 --> 00:08:41,200
people in a way that makes sense for
that individual under way that makes

113
00:08:41,200 --> 00:08:45,770
sense for the person I created it so you
want to be able to provide services that

114
00:08:45,770 --> 00:08:51,610
comprise an API interface plug into a
web portal so if you had to say I don't

115
00:08:51,610 --> 00:08:56,500
Pro you can just provide a service that
price the data you need entire pro you

116
00:08:56,500 --> 00:09:00,610
had multi just add a little of service
that provides an API said neither data

117
00:09:00,610 --> 00:09:04,670
can be displayed on multi the goal here
is to display the data in a way that's

118
00:09:04,670 --> 00:09:08,479
best for the analyst best for the end
user and could tie into your existing

119
00:09:08,480 --> 00:09:17,310
tools so we really did we created a
framework and the framework provides a

120
00:09:17,310 --> 00:09:23,339
general overview so going for him is
talk we're gonna pride kind of two

121
00:09:23,340 --> 00:09:28,170
different house and implementation the
first is gonna be static analysis and

122
00:09:28,170 --> 00:09:32,750
then the second gonna be the dynamic
analysis piece to start talking about

123
00:09:32,750 --> 00:09:36,710
the static analysis implementation
handed off to sack and he's going to

124
00:09:36,710 --> 00:09:39,620
discuss sternum

125
00:09:39,620 --> 00:09:45,990
so tom is the first plan that we
implemented effectively controls how we

126
00:09:45,990 --> 00:09:49,850
consume work what work needs to be done
and how we monitor the work that needs

127
00:09:49,850 --> 00:09:54,320
to be performed totem can be thought of
both has the planner the thing that

128
00:09:54,320 --> 00:09:58,830
coordinates all the individual elements
of work and all we need to do as well as

129
00:09:58,830 --> 00:10:04,570
the static analysis components which
directly plug into it so total

130
00:10:04,570 --> 00:10:09,720
represents our static analysis process
for very large file data sets right now

131
00:10:09,720 --> 00:10:15,230
no veto which is where I'm working
receives mid meddling six figures worth

132
00:10:15,230 --> 00:10:17,900
of our everyday for those of you from a
large TV you're one of the

133
00:10:17,900 --> 00:10:20,939
infrastructure owners I'm sure that's
not what you would consider to be

134
00:10:20,940 --> 00:10:24,620
extremely large amounts of malware but
that's what we get in a screening

135
00:10:24,620 --> 00:10:28,080
process on a daily basis and we
evaluated a number of different Open

136
00:10:28,080 --> 00:10:33,080
Source Matters zoo and instrumentation
engines to try and figure out of

137
00:10:33,080 --> 00:10:35,630
anything that's already existing out
there would work for us and what we

138
00:10:35,630 --> 00:10:40,020
found was more or less nothing out there
right now is able to consume streaming

139
00:10:40,020 --> 00:10:44,380
amounts of data at the volumes that we
needed for the kind of analytics that we

140
00:10:44,380 --> 00:10:49,040
need to perform the other thing that we
started noticing as well in the process

141
00:10:49,040 --> 00:10:52,910
of doing a handful of directed
operations over the course of this last

142
00:10:52,910 --> 00:10:58,029
year was that a lot of our partners in
the EV industry or in the larger larger

143
00:10:58,029 --> 00:11:02,620
security industry some of them had
serious problems being able to run

144
00:11:02,620 --> 00:11:07,810
historical signatures are historical
analytics against their malware store

145
00:11:07,810 --> 00:11:13,089
obviously anyone's going to have issues
running any kind of analytic against 200

146
00:11:13,089 --> 00:11:17,400
300 million our samples but we were
finding that they probably couldn't even

147
00:11:17,400 --> 00:11:21,790
go back more than a week or two in many
cases and so will we identified was we

148
00:11:21,790 --> 00:11:25,939
needed to develop some way to allow us
not just to ingest the ongoing sense now

149
00:11:25,940 --> 00:11:30,040
that we have right now but to also be
able to apply new analytics and new

150
00:11:30,040 --> 00:11:34,529
findings against historical ourselves
that we have because if you can't look

151
00:11:34,529 --> 00:11:39,189
back what good are your models at the
end of the day in addition to that we

152
00:11:39,190 --> 00:11:43,540
identified a handful of other design
requirements that we had we need to be

153
00:11:43,540 --> 00:11:48,400
able to have dynamically to find jobs
and by that I mean let's say abuse of

154
00:11:48,400 --> 00:11:50,959
power comes in we know for whatever
various reasons

155
00:11:50,960 --> 00:11:55,290
we only need to run against one or two
different analytics whereas another

156
00:11:55,290 --> 00:11:58,949
piece of malware that we collect my
needs to run against seven or eight or

157
00:11:58,950 --> 00:12:05,010
even nine any arbitrary number that we
have you can't set up a system that has

158
00:12:05,010 --> 00:12:10,439
one particular path of execution through
the overall analytic stream you need to

159
00:12:10,440 --> 00:12:14,980
be able to wrap things dynamically you
effectively have these small graphs that

160
00:12:14,980 --> 00:12:19,820
God created that you're able to say okay
if this result as such and such you run

161
00:12:19,820 --> 00:12:24,390
against this other analytic and then
finally we need to be able to

162
00:12:24,390 --> 00:12:28,110
dynamically scale the system with the
other thing that we found when

163
00:12:28,110 --> 00:12:31,910
interacting with other people in the
large amount of community was when doing

164
00:12:31,910 --> 00:12:37,040
static analysis we found a lot of people
who would size clusters based on either

165
00:12:37,040 --> 00:12:42,709
of these spike that they get on every
single day when our comes in sizes

166
00:12:42,710 --> 00:12:48,470
against some known quantity that they'd
be getting every day on average and and

167
00:12:48,470 --> 00:12:53,710
respectively this leads to either you
have an underutilized cluster or a

168
00:12:53,710 --> 00:12:57,350
cluster that you have to continuously
resize every single time you go up

169
00:12:57,350 --> 00:13:00,710
another 10 or 20 percent in your average
number of malware samples you collected

170
00:13:00,710 --> 00:13:05,520
day so we implemented it along the same
time as we began to define the stalled

171
00:13:05,520 --> 00:13:08,550
framework and we have we've ended up
with an asynchronous and easily

172
00:13:08,550 --> 00:13:13,140
extendable system that lets a scale very
well be resilient to failures in a

173
00:13:13,140 --> 00:13:19,069
distributed environment so calling back
to the graphics although a bit earlier

174
00:13:19,070 --> 00:13:22,990
between the transport planner and
service layers this is how we

175
00:13:22,990 --> 00:13:27,850
implemented it in terms of totem our
transport layer is handled by RabbitMQ

176
00:13:27,850 --> 00:13:32,480
the transport layer is where we load new
samples into or at least tell the system

177
00:13:32,480 --> 00:13:36,690
that there are new samples that need to
be process we're using RabbitMQ for a

178
00:13:36,690 --> 00:13:40,490
handful of reasons and then they're all
very practical at the end of the day

179
00:13:40,490 --> 00:13:44,880
it's very well understood well supported
system every major languages bindings

180
00:13:44,880 --> 00:13:49,560
for most the bindings are actually very
good I'd imagine that probably a third

181
00:13:49,560 --> 00:13:52,689
to half the people in here have probably
used heard of it in some way at some

182
00:13:52,690 --> 00:13:53,730
point in time

183
00:13:53,730 --> 00:13:58,430
this allows us to asynchronously load
malware hold it for work and then have

184
00:13:58,430 --> 00:14:02,599
new workers join there are a couple of
very nice things about rabbit aside from

185
00:14:02,600 --> 00:14:05,389
the fact that it's easy to understand
and easy to work with

186
00:14:05,389 --> 00:14:10,410
probably the biggest one of it is it's
very easy to scale the system as a whole

187
00:14:10,410 --> 00:14:16,980
right now we're capable of ingesting
probably north of 7,000 malware samples

188
00:14:16,980 --> 00:14:22,889
a second during our current deployment
which is more than fast enough for our

189
00:14:22,889 --> 00:14:28,250
average streaming process what we're
able to do with that is quickly in just

190
00:14:28,250 --> 00:14:31,339
a large amount of malware but when we
come to stay just where we need to

191
00:14:31,339 --> 00:14:36,190
ingest even further not only can we add
on more submitters to the system we're

192
00:14:36,190 --> 00:14:39,370
capable of horizontally scaling rabbit
itself

193
00:14:39,370 --> 00:14:42,589
got high availability for those of you
who need some kind of a

194
00:14:42,589 --> 00:14:46,320
high-availability system and that you're
also able to distribute the ques

195
00:14:46,320 --> 00:14:50,579
themselves at you can have dedicated
nodes working on a single queue and all

196
00:14:50,579 --> 00:14:53,949
sorts of other fun things the other
piece of functionality that we really

197
00:14:53,949 --> 00:14:58,500
rely on very heavily inside of rabbit is
that has got a very deep routing

198
00:14:58,500 --> 00:15:04,100
topology system it's very easy to insert
various ways to route samples through

199
00:15:04,100 --> 00:15:08,819
RabbitMQ well being able to maintain a
level of persistence in the system in

200
00:15:08,819 --> 00:15:12,219
the event that we lose arabinose in the
event you lose a worker we never

201
00:15:12,220 --> 00:15:16,220
actually lose any kind of meaningful
work we always remember that there was

202
00:15:16,220 --> 00:15:20,589
several jobs that works you that we need
to process our needs to be pushed

203
00:15:20,589 --> 00:15:25,649
through we never actually lose any kind
of maintain state the next part of the

204
00:15:25,649 --> 00:15:32,440
chain really then is the plan which the
totem worker itself its largest

205
00:15:32,440 --> 00:15:35,190
collection of State overall in the
system it manages RabbitMQ

206
00:15:35,190 --> 00:15:40,199
communications it organizes verifies
invalidates results once they've come in

207
00:15:40,199 --> 00:15:44,029
it ensures that downloads of the
individual malware samples themselves

208
00:15:44,029 --> 00:15:48,699
happen happen up speed and it does all
the communication with the individual

209
00:15:48,699 --> 00:15:53,709
analytical services overall this is our
major workhorse

210
00:15:53,710 --> 00:15:58,430
it's got a lot of interesting properties
if any any single worker fails messages

211
00:15:58,430 --> 00:16:03,949
are persistent desk if a particular set
of analytics fails about halfway through

212
00:16:03,950 --> 00:16:08,470
the analytical setting that succeeded
betsy realized out gets stored for

213
00:16:08,470 --> 00:16:13,620
database you see you later and anything
that failed will simply get bundled back

214
00:16:13,620 --> 00:16:17,050
up and read cute again in this keeps us
from having to do multiple

215
00:16:17,050 --> 00:16:21,790
retransmissions or retransmissions in
different areas all for the same set of

216
00:16:21,790 --> 00:16:26,040
analytics in this seriously cuts down on
the amount of network traffic that we

217
00:16:26,040 --> 00:16:32,760
have overall speedup we have finally we
got the services themselves they are

218
00:16:32,760 --> 00:16:39,980
based off of base basic restful wrappers
around known tools or things that are

219
00:16:39,980 --> 00:16:43,040
developed internally to to the consumer

220
00:16:43,040 --> 00:16:47,050
we made this decision for a couple of
reasons yes HSDPA is not the fastest

221
00:16:47,050 --> 00:16:49,920
thing out there and yes you can
definitely have implemented using a

222
00:16:49,920 --> 00:16:53,280
Prada bus rapid Rover even threat or
something along those lines more

223
00:16:53,280 --> 00:16:57,860
traditional IPC system but one of the
things that we quickly found was our

224
00:16:57,860 --> 00:17:02,420
initial beta testers really enjoyed the
fact that they were able to take any

225
00:17:02,420 --> 00:17:06,589
code that they currently had in a
language they currently developed things

226
00:17:06,589 --> 00:17:11,109
and and they were very easily able to
integrate it with totem anything that

227
00:17:11,109 --> 00:17:15,530
speaks a basic rest communication
protocol will will be useful

228
00:17:15,530 --> 00:17:19,300
you can be easily communicate with the
service internally as well as a

229
00:17:19,300 --> 00:17:22,389
community with external services

230
00:17:22,390 --> 00:17:29,260
we've seen some room branch internal to
the office that allows us to get a

231
00:17:29,260 --> 00:17:33,980
little bit of extra speed but ultimately
transference speed between local nodes

232
00:17:33,980 --> 00:17:39,960
as it's not necessarily a problem so a
couple of the things that I thought were

233
00:17:39,960 --> 00:17:43,830
important about owning that we should
probably drill down on the total system

234
00:17:43,830 --> 00:17:47,820
as a whole message centric there is no
shared state between workers so while

235
00:17:47,820 --> 00:17:49,909
you have a distributed workforce warm

236
00:17:49,910 --> 00:17:54,390
workers know about any other worker in
the group this makes things a lot

237
00:17:54,390 --> 00:17:58,920
simpler for implementers both myself as
well as anyone who would be implementing

238
00:17:58,920 --> 00:18:00,060
this inside of there

239
00:18:00,060 --> 00:18:04,450
own local environment you don't have to
worry about maintaining any kind of

240
00:18:04,450 --> 00:18:08,540
concurrent state you don't have to worry
about having any kind of consensus you

241
00:18:08,540 --> 00:18:13,000
don't have to worry about where anything
is if a worker dies this allows us to

242
00:18:13,000 --> 00:18:17,400
keep our workers as very expendable
notes and because of the fact that our

243
00:18:17,400 --> 00:18:21,310
jobs our individual messages each one
comprised of a single element of

244
00:18:21,310 --> 00:18:25,610
analytical work were able to serialize a
single message we don't have to ship

245
00:18:25,610 --> 00:18:30,040
individual binaries across the wire we
don't have to ship anything at any

246
00:18:30,040 --> 00:18:34,360
particular weird way you're only sending
a handful of bites at any given time and

247
00:18:34,360 --> 00:18:37,719
all of that structure and that really
speeds up the ability to load new

248
00:18:37,720 --> 00:18:41,900
samples and perform analysis at scale
we've seen a couple of other systems

249
00:18:41,900 --> 00:18:47,420
that are in the streaming space that do
things using either 0 NQ or a handful of

250
00:18:47,420 --> 00:18:52,180
other systems that do directed
transference of malware samples

251
00:18:52,180 --> 00:18:57,910
themselves across the distributed cloud
and that so useful way of handling

252
00:18:57,910 --> 00:19:02,160
things if you're guaranteed to be inside
a local network at all times but we

253
00:19:02,160 --> 00:19:05,880
don't have that guarantee one of the
things that we're doing is we have a

254
00:19:05,880 --> 00:19:10,530
hybrid system for processing power 99
percent of all the samples that we have

255
00:19:10,530 --> 00:19:13,670
we're perfectly comfortable with
processing them inside of AWS another

256
00:19:13,670 --> 00:19:17,740
cloud provider we only get a handful of
samples at any given time which

257
00:19:17,740 --> 00:19:21,010
absolutely have to be maintained within
the control of our our local

258
00:19:21,010 --> 00:19:21,980
environments

259
00:19:21,980 --> 00:19:25,550
one of the nicer things about owning
this allows us to scale material across

260
00:19:25,550 --> 00:19:29,389
a hybrid environments samples and he
just a local samples that need to be run

261
00:19:29,390 --> 00:19:34,570
a dynamic analysis system can stay in
our automatically routed to local notes

262
00:19:34,570 --> 00:19:38,879
whereas other notes sitting out in the
cloud or sitting in in any kind of

263
00:19:38,880 --> 00:19:41,670
distributed environment will
automatically consume messages that are

264
00:19:41,670 --> 00:19:44,910
more appropriate for them so long as a
total workers capable of communicating

265
00:19:44,910 --> 00:19:50,220
with RabbitMQ note in this case or any
kind of distributed file system we have

266
00:19:50,220 --> 00:19:54,930
a HTTP load balancer that sits in front
of a distributed reacts yes cluster

267
00:19:54,930 --> 00:20:00,380
you're able to begin processing at the
end of the day deployment for any

268
00:20:00,380 --> 00:20:05,480
individual node takes on the order of
maybe five 10 seconds all told

269
00:20:05,480 --> 00:20:09,220
we're overall very resilient to failures
as you have to be in any kind of

270
00:20:09,220 --> 00:20:14,480
distributed environment we take best
effort guarantees to be able to transfer

271
00:20:14,480 --> 00:20:17,940
your message not lose work and and and
generally function normally

272
00:20:17,940 --> 00:20:21,000
right now we're at at least once

273
00:20:21,000 --> 00:20:24,799
processing system which means that there
are sometimes instances where if you

274
00:20:24,799 --> 00:20:29,168
kill a worker a specific job might be
completed twice these are fairly rare

275
00:20:29,169 --> 00:20:32,500
circumstances but we can't guarantee
really any better than that at the

276
00:20:32,500 --> 00:20:35,970
moment that's not a major concern for us
at the end of the day most of these

277
00:20:35,970 --> 00:20:39,590
static analyses that we do are
relatively time independent and

278
00:20:39,590 --> 00:20:43,610
everything that we load into our back
and DVDs gets timestamps we know if

279
00:20:43,610 --> 00:20:48,629
there has been a secondary secondary run
due to some he'll component failure but

280
00:20:48,630 --> 00:20:52,630
at the end of the day it allows us to
very easily make sure that we have never

281
00:20:52,630 --> 00:20:57,380
lost any particular element of work and
finally because the fact that each

282
00:20:57,380 --> 00:21:01,540
individual message can be see realized
as a set up individual components of

283
00:21:01,540 --> 00:21:07,139
analytics if we go through 456 analytics
in the seventh or eighth one failed for

284
00:21:07,140 --> 00:21:11,190
any arbitrary reason we see realized out
anything that succeeded

285
00:21:11,190 --> 00:21:16,880
we retain anything that failed and weary
cue it all over again obviously as

286
00:21:16,880 --> 00:21:20,650
anyone who's familiar with some of the
distributed systems work making that's

287
00:21:20,650 --> 00:21:26,390
backed foreign front with Q's is is
fairly loosely coupled architecture we

288
00:21:26,390 --> 00:21:28,830
found this is very very helpful for us

289
00:21:28,830 --> 00:21:33,159
failures we found even in our worst
scenarios might stop processing but at

290
00:21:33,160 --> 00:21:37,440
no point is the fact that we need to run
particular samples ever actually

291
00:21:37,440 --> 00:21:40,910
compromise that we've ever failed to
deliver a message regardless of how many

292
00:21:40,910 --> 00:21:46,590
workers we actually kill this is useful
for us it allows us to run things inside

293
00:21:46,590 --> 00:21:51,889
of a WSN spot that says we don't have
any real guarantees which seriously cuts

294
00:21:51,890 --> 00:21:56,850
down on the amount of cost that is
ultimately incurred and they definitely

295
00:21:56,850 --> 00:22:00,580
allows us to add new workers and very
diverse environments very easily because

296
00:22:00,580 --> 00:22:03,610
we never really concerned that something
like become deadlocked or something

297
00:22:03,610 --> 00:22:08,309
might stop or or cause some kind of
cascading failure one of the things that

298
00:22:08,309 --> 00:22:11,940
I got asked to log when originally
designed system and demoing it to people

299
00:22:11,940 --> 00:22:13,600
was what are we doing

300
00:22:13,600 --> 00:22:16,740
for our language selection you know what
what is everyone going to have to learn

301
00:22:16,740 --> 00:22:19,910
to be able to work with this obviously
for the analytics were more or less

302
00:22:19,910 --> 00:22:25,799
language agnostic but totem itself the
planner and the monitoring layer is

303
00:22:25,799 --> 00:22:30,440
implemented in a JVM languages scholar
we chose that for a couple of reasons I

304
00:22:30,440 --> 00:22:33,320
know that there are a number of systems
out there that are using Python or other

305
00:22:33,320 --> 00:22:38,600
systems right now but we chose something
that that moves away from Python 443

306
00:22:38,600 --> 00:22:43,360
major reasons one I want to be able to
have easy seamless concurrency without

307
00:22:43,360 --> 00:22:47,780
having to fight the gill every 10
minutes as I get really second that I

308
00:22:47,780 --> 00:22:50,860
wanted to be able to have type safety
internally so that way of someone who's

309
00:22:50,860 --> 00:22:54,469
implementing a new analytic wants to
ensure that data is heavily vetted

310
00:22:54,470 --> 00:22:59,049
before moving on to the database system
or enforce a scheme on one particular

311
00:22:59,049 --> 00:23:03,879
area they'd be able to do so and in the
case for people who don't want to

312
00:23:03,880 --> 00:23:06,900
enforce scheme is workable just
serializing things blindly to JSON

313
00:23:06,900 --> 00:23:11,630
without any kind of major issue and then
finally we wanted to have a system

314
00:23:11,630 --> 00:23:15,590
that's relatively approachable what
people may not like job I'm not

315
00:23:15,590 --> 00:23:19,918
personally an enormous benefit myself
but it's very understandable syntax I'm

316
00:23:19,919 --> 00:23:24,120
scholar syntax is not necessarily
substantially different and especially

317
00:23:24,120 --> 00:23:28,649
in what we open source today we've gone
through some fairly substantial means to

318
00:23:28,650 --> 00:23:31,860
make sure that everything is very clear
and very approachable so no one who's

319
00:23:31,860 --> 00:23:36,340
looking at it should be you know if you
passed level 1 and level 2 CIS class or

320
00:23:36,340 --> 00:23:39,110
even been in the industry for a year or
two you should be able to immediately

321
00:23:39,110 --> 00:23:44,750
understand what's going on so as I
mentioned before scale of something of a

322
00:23:44,750 --> 00:23:47,130
pain and one of the things we've
unfortunately not been able to open

323
00:23:47,130 --> 00:23:51,770
source yet is our dynamic are dynamic
scaling system we're capable of

324
00:23:51,770 --> 00:23:55,600
monitoring all of totem figuring out
what our level of Lodi is based on

325
00:23:55,600 --> 00:23:59,439
analytics that needs to be broader
what's stored currently in the cube or

326
00:23:59,440 --> 00:24:02,520
the number of analytics that we
currently have up compared to what we

327
00:24:02,520 --> 00:24:07,440
could be launching any given time and
we've got a system right now that allows

328
00:24:07,440 --> 00:24:10,490
us to monitor the material and
dynamically launch more notes whenever

329
00:24:10,490 --> 00:24:14,679
we have a fairly large amount of samples
that need to be wrapped obviously this

330
00:24:14,679 --> 00:24:17,880
does little for us in the event that
we've got a lot we've were primarily

331
00:24:17,880 --> 00:24:19,580
working on samples I need to remain

332
00:24:19,580 --> 00:24:25,730
house but that's far edge case in our
environment as I mentioned before and

333
00:24:25,730 --> 00:24:28,490
has two should be fairly clear by now
total speed really comes from the

334
00:24:28,490 --> 00:24:33,460
ability to join workers dynamically to
an existing workload so we've we've

335
00:24:33,460 --> 00:24:37,470
generated early on we generated a large
number of performance metrics and these

336
00:24:37,470 --> 00:24:42,030
are some of the smaller sample sets
compared against scripts now comparing

337
00:24:42,030 --> 00:24:45,750
things again scripts maybe a little
unfair most because Chris is a single

338
00:24:45,750 --> 00:24:50,740
node system is completely monolithic so
with this was less a comparison of raw

339
00:24:50,740 --> 00:24:54,460
speed and more comparison of what
happens when you begin trying to analyze

340
00:24:54,460 --> 00:24:59,230
things under load inside of it creates
number one is obviously slower than

341
00:24:59,230 --> 00:25:04,110
total assets stands issues with
underlying language and and concurrency

342
00:25:04,110 --> 00:25:08,199
model but the bigger thing that we found
his when you begin loading Chris in any

343
00:25:08,200 --> 00:25:12,980
meaningful fashion any amount of load on
one section of it may be at the ingest

344
00:25:12,980 --> 00:25:16,900
or be at the database loading portions
are being the analytics themselves

345
00:25:16,900 --> 00:25:21,480
causes that load to be distributed all
other portions of the system and what we

346
00:25:21,480 --> 00:25:25,010
found was asked we tried to load more
and more samples and allow them to run

347
00:25:25,010 --> 00:25:29,090
concurrently we found very quickly that
we saw increasing numbers of air and we

348
00:25:29,090 --> 00:25:35,090
highlighted that here towards the 50,000
sample range which is not a large number

349
00:25:35,090 --> 00:25:39,649
of samples by any means we start to
secrets begin falling over and those

350
00:25:39,650 --> 00:25:43,870
errors there are errors that caused an
unrecoverable state for that particular

351
00:25:43,870 --> 00:25:48,790
sample forced to be recuse or you meant
that we weren't able to load data or

352
00:25:48,790 --> 00:25:53,030
perform the finalized analytic and
whereas with totem both 43 workers a

353
00:25:53,030 --> 00:25:58,270
hundred workers while our speed stayed
more or less stable we never actually

354
00:25:58,270 --> 00:26:03,790
saw those any any individual errors in
another test even when we would try to

355
00:26:03,790 --> 00:26:08,300
load the system as much as we possibly
could even the worst failure scenarios

356
00:26:08,300 --> 00:26:12,030
had individual analytics possibly
failing but those would simply those

357
00:26:12,030 --> 00:26:16,070
individual portions of a job we get
really cute and reprocessed at the end

358
00:26:16,070 --> 00:26:20,820
so well even if you have a misbehaving
job you have overall system that helps

359
00:26:20,820 --> 00:26:25,300
lower the system will still continue
behaving and it will complete anything

360
00:26:25,300 --> 00:26:28,610
that is capable of completing all the
way to the bitter end

361
00:26:28,610 --> 00:26:34,590
so this graph which is not terribly
readable at the moment represents two

362
00:26:34,590 --> 00:26:38,928
sets of total deployments that are
running right now that are running in

363
00:26:38,929 --> 00:26:43,410
our production environment against a
million our symbols of peace to run

364
00:26:43,410 --> 00:26:49,030
1,000,000 malware samples against 100
total nodes sitting on AWS enlarges

365
00:26:49,030 --> 00:26:55,570
which works out to being I think 400 600
course I can't remember off the top of

366
00:26:55,570 --> 00:26:56,540
my head

367
00:26:56,540 --> 00:27:02,020
works into just under two hours and this
was running for three separate analytics

368
00:27:02,020 --> 00:27:06,129
for every single sample those analytics
were called virustotal to check to see

369
00:27:06,130 --> 00:27:11,280
if he knew anything about it which was
an external API call that goes over

370
00:27:11,280 --> 00:27:19,629
HTTPS there was the application of the
exchanges fully our rule set against

371
00:27:19,630 --> 00:27:23,140
each individual sample we were
generously provided access to your

372
00:27:23,140 --> 00:27:28,080
assets and finally we did a number of
various hashing techniques against each

373
00:27:28,080 --> 00:27:33,809
binary MT 5 shah's feature hashing just
as an example of what you can do some

374
00:27:33,809 --> 00:27:38,080
balls 1 million individual samples we've
got three million overall sets of

375
00:27:38,080 --> 00:27:43,710
analytics I could run and it took us
just under two hours more like an hour

376
00:27:43,710 --> 00:27:49,179
and 45 minutes or so to process one
million samples with a hundred spot

377
00:27:49,179 --> 00:27:56,510
instances on AWS so internally we've
been able to implement a large array of

378
00:27:56,510 --> 00:28:00,340
analytics services and we've currently
got Chris services parody internal to

379
00:28:00,340 --> 00:28:04,270
know that we've got clear support for
third-party services such as virustotal

380
00:28:04,270 --> 00:28:09,299
or anything else you may want to do an
external call to and we support resource

381
00:28:09,299 --> 00:28:12,760
extraction for a number of different
techniques right now for the open source

382
00:28:12,760 --> 00:28:16,000
release for releasing a handful of these
at the moment we're not able to open

383
00:28:16,000 --> 00:28:18,790
source all of them but now that it's an
open source project should be able to

384
00:28:18,790 --> 00:28:24,418
develop these again in an external
environment finally we're looking into

385
00:28:24,419 --> 00:28:27,600
support fairly soon going through a
party tikka to do

386
00:28:27,600 --> 00:28:32,699
content parsing for office HTML
JavaScript files which should be a

387
00:28:32,700 --> 00:28:35,750
useful thing for a lot of individuals
who are working with more of these

388
00:28:35,750 --> 00:28:37,650
textual base documents

389
00:28:37,650 --> 00:28:41,140
we've even got a handful of more
experimental things that are running

390
00:28:41,140 --> 00:28:46,040
internally we've managed to integrate a
handful of radar instances radar to

391
00:28:46,040 --> 00:28:49,260
finance from earlier with the
open-source disassembler we've been able

392
00:28:49,260 --> 00:28:53,980
to do that and begin pulling down some
automated assembly obviously that's not

393
00:28:53,980 --> 00:28:57,700
a perfect solution but it's something
that we found to be useful in getting to

394
00:28:57,700 --> 00:29:03,500
be seen a handful of other analytics
that we're developing going forward so

395
00:29:03,500 --> 00:29:08,080
obviously thats planning layer the
organization layer and the statically

396
00:29:08,080 --> 00:29:12,760
are the last thing that we have today to
talk about is the dynamic analysis later

397
00:29:12,760 --> 00:29:20,490
track of which is going to be presented
by Tomas was against the drug will sit

398
00:29:20,490 --> 00:29:25,870
in the investigation earlier hope this
called framework and let's look at that

399
00:29:25,870 --> 00:29:29,689
morning the film so the best way to
describe drug agent less dynamic

400
00:29:29,690 --> 00:29:33,910
analysis system and by that I mean that
you don't have to install any special

401
00:29:33,910 --> 00:29:37,080
software between the sandbox within the
region machine that you want to run the

402
00:29:37,080 --> 00:29:41,639
malware in this is important because one
of the first things I do when they want

403
00:29:41,640 --> 00:29:47,010
to thwart analysis is look at the
environment they want and if they can't

404
00:29:47,010 --> 00:29:48,570
find out process

405
00:29:48,570 --> 00:29:52,669
existing the malware itself to shut down
so if you don't have anything that's

406
00:29:52,670 --> 00:29:57,240
fingerprint the ball you are much more
likely to actually be able to analyze

407
00:29:57,240 --> 00:30:01,720
matter successfully so it is open source
it has been out since last October and

408
00:30:01,720 --> 00:30:05,780
is built on my library which is also an
open source library which is effectively

409
00:30:05,780 --> 00:30:10,520
a wraparound virtual machine
introspection subsystem so well you

410
00:30:10,520 --> 00:30:14,889
might sell these hypervisor agnostic for
now drug paraphernalia relies on Zambia

411
00:30:14,890 --> 00:30:20,990
my sub system which is very robust three
main components that I found most

412
00:30:20,990 --> 00:30:25,820
important about drug stealth capability
that I already mention wondering is

413
00:30:25,820 --> 00:30:28,929
purely performed through the hypervisor
using that you don't need relation

414
00:30:28,930 --> 00:30:32,080
extension so you really don't have any
special software installed in the

415
00:30:32,080 --> 00:30:36,800
sandbox furthermore it is very scalable
so using both young bride memory and

416
00:30:36,800 --> 00:30:41,080
copy on write best so we can spend on
pool deirdre machines in second termmore

417
00:30:41,080 --> 00:30:44,409
only allocate resources for those
virtual machines that are absolutely

418
00:30:44,410 --> 00:30:47,789
necessary so you can scale up the number
of sessions run

419
00:30:47,789 --> 00:30:52,669
hardware furthermore you have full
access to all your hard drive the future

420
00:30:52,669 --> 00:30:57,779
machine PCB registers the memory or even
the disk so you really have a complete

421
00:30:57,779 --> 00:31:03,479
view of what's happening between the
trees that what we have been able to

422
00:31:03,479 --> 00:31:06,340
deal with actually my jaw system caused
that happened within that virtual

423
00:31:06,340 --> 00:31:10,999
machine was really can trap whatever we
want it in that system so for example

424
00:31:10,999 --> 00:31:14,330
you also traveled heap allocations
within the Beatles colonel and also

425
00:31:14,330 --> 00:31:20,099
threw up on all the scheduling events
that happen only problem with that is if

426
00:31:20,099 --> 00:31:23,499
you really don't have any agent is how
do you actually start them out here some

427
00:31:23,499 --> 00:31:27,720
cool it's quite straightforward you have
the completion sitting at the end of

428
00:31:27,720 --> 00:31:31,440
your tradition that started on your
behalf but they don't have an agent you

429
00:31:31,440 --> 00:31:35,769
don't want to have some server running
it because then that server itself could

430
00:31:35,769 --> 00:31:41,129
be back to you know red flag for malware
to look for so instead of up to double

431
00:31:41,129 --> 00:31:45,728
up as a way to hijack any existing
process within the regime to start them

432
00:31:45,729 --> 00:31:46,559
out or something

433
00:31:46,559 --> 00:31:50,809
health so let's get that actually

434
00:31:50,809 --> 00:31:55,059
them away but it's probably going to be
easier to follow so here I have 14

435
00:31:55,059 --> 00:31:59,428
points for running Windows 7 virtual
machine and what I can assure you is

436
00:31:59,429 --> 00:32:02,859
that how to actually hijacked that
process the task manager that's running

437
00:32:02,859 --> 00:32:08,099
to start arbitrary executions so again
you have full access to virtual machine

438
00:32:08,099 --> 00:32:11,668
so you can actually reconstruct what's
happening inside so I just listed all

439
00:32:11,669 --> 00:32:15,889
the processes that are within that
machine using standard memory forensic

440
00:32:15,889 --> 00:32:19,728
techniques so this is the same
techniques that would use here are just

441
00:32:19,729 --> 00:32:26,190
running on like virtual machine so the
way we going to hijack the processes by

442
00:32:26,190 --> 00:32:31,649
trapping events when that process gets
returned from kernel mode to user mode

443
00:32:31,649 --> 00:32:35,619
to actually start calculator on a beach
house so as you can see from an external

444
00:32:35,619 --> 00:32:39,418
perspective using the hypervisor I was
able to inject a brand-new processed

445
00:32:39,419 --> 00:32:43,700
into that virtual machine without having
anything bought standard processes

446
00:32:43,700 --> 00:32:48,409
running in that machine so again I don't
rely on task manager it could have been

447
00:32:48,409 --> 00:32:52,769
any other process like Internet Explorer
and be bad but be effectively have an

448
00:32:52,769 --> 00:32:56,720
external sheltered at virtual machine
can actually pass arbitrary

449
00:32:56,720 --> 00:33:00,440
it's like having a terminal to the
machine so I just passed the command to

450
00:33:00,440 --> 00:33:05,230
start up Internet Explorer and send it
to a website as you can see it's quite

451
00:33:05,230 --> 00:33:08,960
fast and it also tells you a lot of
information about the process of

452
00:33:08,960 --> 00:33:12,330
actually getting ejected so you get the
PID that's right I D and all the

453
00:33:12,330 --> 00:33:16,610
information that you identified this new
process that got the injected and you

454
00:33:16,610 --> 00:33:19,928
can really change together as many
commands as you want

455
00:33:19,929 --> 00:33:24,130
so and so just like the stuff I just
made a copy paste it here it's a long

456
00:33:24,130 --> 00:33:27,990
one so what I gotta do here is actually
start up the man died txt to download

457
00:33:27,990 --> 00:33:34,320
process monitor from Sysinternals unzip
it and started off automatically and it

458
00:33:34,320 --> 00:33:46,830
will come and injective zip is
downloading extracted and it's running

459
00:33:46,830 --> 00:33:51,860
so that you really have very effective
external shouted machine

460
00:33:51,860 --> 00:33:54,918
the only thing we don't inject right now
is keyboard and mouse offense but that

461
00:33:54,919 --> 00:34:00,200
can also be done so once you actually
injected the matter some pool the other

462
00:34:00,200 --> 00:34:03,280
thing you want to do is actually start
monitoring so this is still down four

463
00:34:03,280 --> 00:34:08,339
points for and the way he actually
achieve monitoring of the machine is

464
00:34:08,339 --> 00:34:12,139
that they are going to be injecting
break points into the kernel and my

465
00:34:12,139 --> 00:34:14,780
break when they meet the standard break
points that you would use when you're

466
00:34:14,780 --> 00:34:18,480
debugging this offer accepted computer
designed to actually threw up all those

467
00:34:18,480 --> 00:34:23,320
break points into the hypervisor
extensions are configured that the

468
00:34:23,320 --> 00:34:27,080
breakpoints feel trapped in the diaper
miser so we can actually monitored 24

469
00:34:27,080 --> 00:34:32,549
execution on the Windows kernel so still
I have you know standard process least

470
00:34:32,550 --> 00:34:36,700
things are also going to show the kernel
modules listed so you really have a

471
00:34:36,699 --> 00:34:39,310
complete view of what's what's happening
you get into the machine and what's

472
00:34:39,310 --> 00:34:43,609
what's there so yeah this is the biggest
turn all those are all the kernel

473
00:34:43,609 --> 00:34:47,299
modules loaded and what I gonna do is
actually going to start up a screen

474
00:34:47,300 --> 00:34:50,540
session because the output is going to
be very verbose and it's not gonna be

475
00:34:50,540 --> 00:34:55,300
able to be able to actually read it so I
gonna be dripping in sweat it out but

476
00:34:55,300 --> 00:34:58,460
later so now what you actually see here
is all those break points have been

477
00:34:58,460 --> 00:35:02,450
injected into the Windows kernel and
this is the live execution of Windows

478
00:35:02,450 --> 00:35:07,390
running on the right and once I start
moving the mouse right you see things

479
00:35:07,390 --> 00:35:11,930
speeding on quite considerably but I
mean it's not designed for humans to

480
00:35:11,930 --> 00:35:16,710
really understand what's happening in
there it's like watching the matrix so

481
00:35:16,710 --> 00:35:21,099
what they are going to do is actually
going out with for some more meaningful

482
00:35:21,099 --> 00:35:22,480
things to look for

483
00:35:22,480 --> 00:35:26,220
first I just gonna grab for the
instruction pointer if these are going

484
00:35:26,220 --> 00:35:29,200
to be the actual functions that are
getting called beating the Bengals

485
00:35:29,200 --> 00:35:32,160
colonel where r break points are
injected and this is how you actually

486
00:35:32,160 --> 00:35:35,960
are able to monitor system so we don't
actually trapping all the system call

487
00:35:35,960 --> 00:35:39,420
instruction you're trippin on the
functions that get called but a system

488
00:35:39,420 --> 00:35:45,380
issue so these are old system calls that
Windows is executing right now but the

489
00:35:45,380 --> 00:35:48,020
other thing that I'm also tripping on
its heap allocations and heap

490
00:35:48,020 --> 00:35:51,369
allocations are very useful features
because that's really allows you to

491
00:35:51,369 --> 00:35:53,619
reconstruct a lot of things about what's
happening

492
00:35:53,619 --> 00:35:58,670
machine so for example as you can see a
lot of things happening if the machine

493
00:35:58,670 --> 00:36:03,039
is idle and start moving the mouse
around you'll see a lot of Iowa

494
00:36:03,039 --> 00:36:07,759
locations may be reading maybe you can
see there is these are just coordinate

495
00:36:07,759 --> 00:36:11,599
structures that hold their timeouts is
moving but some of the other things that

496
00:36:11,599 --> 00:36:15,839
are very useful from the kernel here
that you can look for his file objects

497
00:36:15,839 --> 00:36:19,640
for example you want to see what files
are being accessed machine and you can

498
00:36:19,640 --> 00:36:25,509
do that by watching for file object all
locations so I just write some

499
00:36:25,509 --> 00:36:28,999
personalization thing on the Windows
desktop and these are all the files that

500
00:36:28,999 --> 00:36:33,339
are actually getting access buy windows
and a dead this list just purely looking

501
00:36:33,339 --> 00:36:36,720
at the memory and the execution of the
machine so I don't have anything

502
00:36:36,720 --> 00:36:41,808
watching the filesystem excess itself
those trying to advocate the structures

503
00:36:41,809 --> 00:36:45,740
before it actually access from the file
system there's a lot of things getting

504
00:36:45,740 --> 00:36:50,269
access just a simple thing like this so
this is quite amazing and as you can

505
00:36:50,269 --> 00:36:54,180
imagine this is very useful when you're
analyzing want to identify what files

506
00:36:54,180 --> 00:36:58,239
have been touched what the you know what
amounted doing because you actually see

507
00:36:58,239 --> 00:37:02,440
all the files that have been opened and
this is not something that can really

508
00:37:02,440 --> 00:37:07,730
mess with this is really the internal
Windows kernel trying to open file so

509
00:37:07,730 --> 00:37:11,859
unless the military is implementing its
own file system access mechanism and

510
00:37:11,859 --> 00:37:16,348
allocation mechanism effectively loading
another operating system within the

511
00:37:16,349 --> 00:37:19,819
operating system you can really trust so
I just created a text file on the

512
00:37:19,819 --> 00:37:23,579
desktop and as you can see it shows up
in the log as well so this is really

513
00:37:23,579 --> 00:37:29,660
really nice tool to have a lot of really
awesome thing about northrop's really

514
00:37:29,660 --> 00:37:34,308
cloud ready so everything that is
required to run drug has been ends and

515
00:37:34,309 --> 00:37:38,519
some sense for 13 be she's been really
is about two years ago

516
00:37:38,519 --> 00:37:43,508
4426 I have to reverse the entire reveal
myself system moves and so ends on four

517
00:37:43,509 --> 00:37:50,069
points 6 it has been optimized and a
bunch of really cool stuff have been

518
00:37:50,069 --> 00:37:54,960
merged into 16 the first RC's going to
be cut in two weeks and I'm 416 is going

519
00:37:54,960 --> 00:37:59,079
to be released later this year the only
thing that's stopping us from running

520
00:37:59,079 --> 00:38:03,839
drunk and a cloud-like on Amazon is the
fact that most of the cloud providers

521
00:38:03,839 --> 00:38:05,450
don't enable distinct

522
00:38:05,450 --> 00:38:10,520
security modules which is really what
many baluster rhonda system securely on

523
00:38:10,520 --> 00:38:15,000
on a cloud deployment varied there might
be other users on the system sold access

524
00:38:15,000 --> 00:38:18,820
and security modules with an evil ass
desegregated be systems from each other

525
00:38:18,820 --> 00:38:22,490
and unfortunately most cloud providers
don't enable that either it always has

526
00:38:22,490 --> 00:38:28,578
been hymns and four years now and I
really cool thing about Xander is that

527
00:38:28,579 --> 00:38:32,579
he's running with arms offers on arms
chipset so you can actually analyze

528
00:38:32,579 --> 00:38:37,890
mobile malware like Android malware so
actually implemented for some 4.6 basic

529
00:38:37,890 --> 00:38:42,170
$0.03 gave it was therefore designed
using the arm to stage Beijing mechanism

530
00:38:42,170 --> 00:38:45,550
so you can actually monitor memory
accesses that are happening on ARM chips

531
00:38:45,550 --> 00:38:49,140
so you actually going to be able to
analyze mobile malware be the system as

532
00:38:49,140 --> 00:38:56,480
well but it's still a work in progress
and current status of trouble he's

533
00:38:56,480 --> 00:39:00,640
actually that it's still not complete so
it's not a drop-in replacement record we

534
00:39:00,640 --> 00:39:05,618
can just use this and forgot about it
but we are very much hoping to get this

535
00:39:05,619 --> 00:39:09,180
up to that stage so right that this is
really just an academic prototype they

536
00:39:09,180 --> 00:39:13,129
treated for my view ceases to show that
this is actually possible to do and as

537
00:39:13,130 --> 00:39:17,470
you can see it's quite stable definitely
needs community involvement so it is

538
00:39:17,470 --> 00:39:24,000
open source so if you like to submit
batch is something bugging boards and

539
00:39:24,000 --> 00:39:29,300
there are many new things that will be
very very nice to have for drug turf so

540
00:39:29,300 --> 00:39:33,520
for example in values are releasing the
new chipset that people have this thing

541
00:39:33,520 --> 00:39:37,069
called me to tell you she was Asian
exceptions which will be very useful to

542
00:39:37,069 --> 00:39:41,890
have for drug turf as well actually had
a chance to review the creativity first

543
00:39:41,890 --> 00:39:46,160
open source implementation for days for
which we have always known for 16 as

544
00:39:46,160 --> 00:39:51,109
well as I don't wanna miss also the one
that I'm very excited and they also want

545
00:39:51,109 --> 00:39:56,270
to get KVM so setting up sign is sharp
learning curve so I'm a rare that a lot

546
00:39:56,270 --> 00:39:59,890
of people who just want to use it on KVM
and this will be a lot simpler so we

547
00:39:59,890 --> 00:40:04,290
definitely want to get this or a similar
substance done to KVM as well so we

548
00:40:04,290 --> 00:40:10,540
could actually wrong drug KVM so I get
the big picture again so this has been

549
00:40:10,540 --> 00:40:14,480
all the investigation clear and the
future is really the interrogation what

550
00:40:14,480 --> 00:40:15,800
to do with the beethoven

551
00:40:15,800 --> 00:40:21,170
have generated a ton of data so some of
the others from drug traffickers

552
00:40:21,170 --> 00:40:26,790
hundreds of megabytes of logs what do
you do with that data analyzing just a

553
00:40:26,790 --> 00:40:31,310
minor itself I'm gonna get you much as
george sad miners themselves or to cheap

554
00:40:31,310 --> 00:40:36,120
you should not just the binaries
themself we really want to answer to 5

555
00:40:36,120 --> 00:40:42,060
W's and the best way to do that is to
create complex is on this day we are

556
00:40:42,060 --> 00:40:47,390
very durable as they do what we're
hoping to do is use big data and I've

557
00:40:47,390 --> 00:40:51,540
extols the mind that they determine how
well he actually relates identify

558
00:40:51,540 --> 00:40:57,880
families and relationships champion
actors who is behind the structure it's

559
00:40:57,880 --> 00:41:01,370
a lot more effective way to shut down
Mallory's you shut down the

560
00:41:01,370 --> 00:41:04,250
infrastructure instead of trying to
clean up all the miners that are out

561
00:41:04,250 --> 00:41:14,670
there and also available to as many
places as possible so we definitely need

562
00:41:14,670 --> 00:41:17,830
to have a grief for humans when they
want to look at these data like for

563
00:41:17,830 --> 00:41:21,730
example the drug about what this pretty
much unusable as a human it's way too

564
00:41:21,730 --> 00:41:26,390
verbose and you can't really get much
out of it so it has to be structured as

565
00:41:26,390 --> 00:41:29,650
well for humans as well as for machine
learning algorithms and this is

566
00:41:29,650 --> 00:41:34,240
something that they want to do as we go
forward also retaining historical data

567
00:41:34,240 --> 00:41:38,720
set so we want to keep as much as
possible but as we go forward that there

568
00:41:38,720 --> 00:41:44,299
is going to be a massive industry has to
remain searchable and that is going to

569
00:41:44,300 --> 00:41:50,130
be a challenge that I'm very happy to
announce the open source release so this

570
00:41:50,130 --> 00:41:54,370
is a brand new system released by the
weather so this is what I wrote and this

571
00:41:54,370 --> 00:42:00,520
is what we have so the three components
of them that are getting their service

572
00:42:00,520 --> 00:42:04,370
in our index components Toshiba father
and the transfer framework for the

573
00:42:04,370 --> 00:42:08,859
analysis part and as I said drug has
been open source and if you remain open

574
00:42:08,860 --> 00:42:14,080
source under hoping to go forward and
develop both of these systems and what

575
00:42:14,080 --> 00:42:17,400
they're really saying today is still
Akbar served at the integrated drug

576
00:42:17,400 --> 00:42:23,640
candidate and former you also have a
boot so it means a criminal matter of

577
00:42:23,640 --> 00:42:26,140
soapy sign up for a boot 1064

578
00:42:26,140 --> 00:42:29,680
we have a bunch of other things that you
love to talk to you about so please join

579
00:42:29,680 --> 00:42:35,519
us and just to recap what we have show
you here is we created a blueprint to

580
00:42:35,519 --> 00:42:41,109
create large-scale malware analysis
frameworks systems using to school and

581
00:42:41,109 --> 00:42:46,098
we created two systems static analysis
component returned them that can analyze

582
00:42:46,099 --> 00:42:50,099
hundreds or thousands assembles in
minutes as well as a drug-free system

583
00:42:50,099 --> 00:42:54,210
beaches di provider based dynamic
analysis systems so both of these

584
00:42:54,210 --> 00:42:58,430
systems are open source links are up
there please go and grab them they're

585
00:42:58,430 --> 00:43:03,598
actually get up and do that I thank you
for coming and we will take any

586
00:43:03,599 --> 00:43:04,619
questions you have

587
00:43:04,619 --> 00:43:09,930
so there are microphones in each land so
if you have any questions should thank

588
00:43:09,930 --> 00:43:35,299
you

589
00:43:35,300 --> 00:43:52,250
colonel but you can really inject break
points on a very physical memory which

590
00:43:52,250 --> 00:43:56,990
correspond to userspace applications as
well the only thing you need for that is

591
00:43:56,990 --> 00:43:58,890
really break points

592
00:43:58,890 --> 00:44:02,379
locations for two break points to be
placed so if you don't have the debug

593
00:44:02,380 --> 00:44:06,310
information portal process not
necessarily wanna know where to place

594
00:44:06,310 --> 00:44:09,130
those brake lines that he'll be
meaningful but for example if you know

595
00:44:09,130 --> 00:44:14,310
that a process loads libraries that you
have information for you can definitely

596
00:44:14,310 --> 00:44:19,700
monitor dole's usages for the user space
processes well for now I'm not doing

597
00:44:19,700 --> 00:44:25,180
that but it is definitely possible and
you use the split page technique said

598
00:44:25,180 --> 00:44:29,779
the reeds are different than in the
execution yes so essentially the

599
00:44:29,780 --> 00:44:33,230
breakpoints are protected DVD
permissions

600
00:44:33,230 --> 00:44:37,130
machine priced from those memory
locations to determine if their break

601
00:44:37,130 --> 00:44:41,620
points I actually trap those excesses to
the hypervisor and I can just remove the

602
00:44:41,620 --> 00:44:45,410
break point and tell whatever processes
running machine that there is nothing

603
00:44:45,410 --> 00:44:48,569
there and this was one of the very first
things that they had to do because

604
00:44:48,570 --> 00:44:54,990
Windows actually blue screens when you
just inject break points into it so that

605
00:44:54,990 --> 00:44:58,290
was I don't bother very first thing we
have to do to actually just not press

606
00:44:58,290 --> 00:45:03,130
the system so it's actually visible so
you can scan the physical memory from

607
00:45:03,130 --> 00:45:10,530
the machine but you will not find
anything thanks

608
00:45:10,530 --> 00:45:24,130
two questions are you handling 64 bit
Mauer on 64 bit OS is yes supports both

609
00:45:24,130 --> 00:45:30,210
32 and 64 bit Windows users face
component is doesn't really matter cuz

610
00:45:30,210 --> 00:45:35,570
I'm really trippin the curtain itself so
yeah I can do the same both 32 and 64

611
00:45:35,570 --> 00:45:42,120
bit and we need to your dynamic has seen
how long is your test run for the bangs

612
00:45:42,120 --> 00:45:47,740
for my test that I did I usually run
malware 41 minutes but it's an arbitrary

613
00:45:47,740 --> 00:45:52,109
number so you really have no idea how
long you have to run him out here for so

614
00:45:52,110 --> 00:45:56,890
I'm not doing any time in manipulation
here to like you know try to escape

615
00:45:56,890 --> 00:46:00,940
sleeping now they're anything like that
so this is just you know if you want to

616
00:46:00,940 --> 00:46:05,570
run a four-year you can I find it for 60
seconds if I see something interesting

617
00:46:05,570 --> 00:46:10,840
but it's it's an arbitrary number there
is no solution for determining how long

618
00:46:10,840 --> 00:46:13,870
you need to run malware before you
actually observe anything malicious

619
00:46:13,870 --> 00:46:22,819
that's that's an open research problem
thank you thank you again for coming

