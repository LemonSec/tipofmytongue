1
00:00:00,000 --> 00:00:06,240
welcome to my cat 2015 you there will be
a reception tonight in the business call

2
00:00:06,240 --> 00:00:12,889
at 5:30 p.m. Business Hall is located in
Shoreline a room party awards take place

3
00:00:12,889 --> 00:00:23,460
tonight in Mandalay BCD at 6 p.m. and
you are in lagoon k for how to hack

4
00:00:23,460 --> 00:00:29,099
government technology as policymakers
with Tara mcsweeney and ash currants or

5
00:00:29,099 --> 00:00:36,050
Tommy oh thank you and then of course as
in every public speaking type of

6
00:00:36,050 --> 00:00:40,250
situation make sure your phones are on
vibrate no matter how cool you think

7
00:00:40,250 --> 00:00:50,700
your own ringtone is it really do that
for me with that great for everyone

8
00:00:50,700 --> 00:01:04,720
information how is she on the back of
some sort of talk US government

9
00:01:04,720 --> 00:01:14,650
technologists as policymakers and
technologists and EC had a ride april's

10
00:01:14,650 --> 00:01:20,780
I've worked for Press Washington Post on
their own arguments I worked at the wall

11
00:01:20,780 --> 00:01:25,020
street journal in a series called what
they know it was a dive into privacy and

12
00:01:25,020 --> 00:01:33,899
security online and today we're gonna
give you a brief talk with me I'm

13
00:01:33,900 --> 00:01:37,710
commissioner at the Federal Trade
Commission and as you can probably tell

14
00:01:37,710 --> 00:01:41,179
from the difference between our two
pictures I'm the kind of lawyer a

15
00:01:41,180 --> 00:01:47,090
policymaker that needs help from people
like sean is a cool technologists so my

16
00:01:47,090 --> 00:01:48,320
background is

17
00:01:48,320 --> 00:01:55,610
TCD OJ White House the hill that kind of
thing I am NOT a technologist and mostly

18
00:01:55,610 --> 00:02:01,770
I learned from technologists in order to
do my work just didn't know about the

19
00:02:01,770 --> 00:02:05,850
disclaimer on the bottom of this fired a
shot and I worked for the Federal Trade

20
00:02:05,850 --> 00:02:11,790
Commission FTC but so do lots of other
people as well and so and therefore

21
00:02:11,790 --> 00:02:16,400
other commissioners in addition to to me
they don't always agree with everything

22
00:02:16,400 --> 00:02:20,050
we say so today we're here speaking on
behalf of ourselves about our

23
00:02:20,050 --> 00:02:24,790
experiences working together and why
technologists matter and should be very

24
00:02:24,790 --> 00:02:32,170
influential role in law enforcement and
policy-making also I said so today the

25
00:02:32,170 --> 00:02:39,230
stock is a technology policy what do we
mean by tech policy what are the big

26
00:02:39,230 --> 00:02:45,290
debate right now and why do encounter a
wider technologists matter you guys and

27
00:02:45,290 --> 00:02:50,950
me this is an attack talk or not
dropping any ideas where time out some

28
00:02:50,950 --> 00:02:58,420
vulnerabilities birth of the human and
process kind not exploits and to start

29
00:02:58,420 --> 00:03:09,738
something on the side of the truck
series of shows when you purchase a

30
00:03:09,739 --> 00:03:18,770
message and I and i wanna say that this
is the theme is senator ted stevens to

31
00:03:18,770 --> 00:03:24,410
quote from the 2006 net neutrality
debate and me included it here because

32
00:03:24,410 --> 00:03:30,220
it's kind of funny and because it's sort
of tees up nicely the fundamental point

33
00:03:30,220 --> 00:03:34,200
that we're trying to make which is that
when people are making decisions about

34
00:03:34,200 --> 00:03:38,630
laws that relate to technology they need
technologists to help them understand

35
00:03:38,630 --> 00:03:43,940
what the impact is on the technology and
how it's working and to be fair he was

36
00:03:43,940 --> 00:03:52,359
actually totally wrong it's more troops
than trucks or adding also so there are

37
00:03:52,360 --> 00:03:58,239
a number of policy issues that have huge
technology components that are being

38
00:03:58,239 --> 00:04:02,239
debated in Washington right now and this
is a certain word cloud that includes a

39
00:04:02,239 --> 00:04:06,440
lot of them from privacy policy to
cross-border data flows the right to be

40
00:04:06,440 --> 00:04:07,359
forgotten

41
00:04:07,359 --> 00:04:11,780
data security consumer data security the
Internet of Things automotive security

42
00:04:11,780 --> 00:04:17,640
today in the senate he said permission
sharing I'm leavin out that we have

43
00:04:17,640 --> 00:04:24,110
different groups touring car and medical
devices we talked earlier this morning

44
00:04:24,110 --> 00:04:30,550
about CFA and it's great to see that
this community and I've kind of been

45
00:04:30,550 --> 00:04:34,520
bringing more policy related
presentations just because it's

46
00:04:34,520 --> 00:04:42,049
affecting all of us but I want to start
here at the FTC because every day you

47
00:04:42,050 --> 00:04:46,229
take the lead in making sure that
Americans their hard-earned money and

48
00:04:46,229 --> 00:04:51,270
the privacy are protected especially
when they go online and these days

49
00:04:51,270 --> 00:04:53,240
that's pretty much where

50
00:04:53,240 --> 00:04:58,690
manager bank accounts pay our bills
handling everything from medical records

51
00:04:58,690 --> 00:05:08,509
two movie tickets controlling our homes
houses from smartphones secret service

52
00:05:08,509 --> 00:05:11,240
does not let me do that

53
00:05:11,240 --> 00:05:17,690
but I know other people do so this is a
president at the FTC earlier this year

54
00:05:17,690 --> 00:05:21,080
just as a historical note he was the
first president since franklin roosevelt

55
00:05:21,080 --> 00:05:26,520
to visit the FTC and she was talking
about a bunch of the issues that we

56
00:05:26,520 --> 00:05:30,710
focus on at the Trade Commission as it
released to protecting consumers data

57
00:05:30,710 --> 00:05:35,310
security and privacy especially as we
are increasingly connected and the

58
00:05:35,310 --> 00:05:39,669
Internet of Things kind of comes online
I'm so so he was talking about his

59
00:05:39,669 --> 00:05:43,000
agenda to get teased up nicely

60
00:05:43,000 --> 00:05:46,780
huge focused in washington at the
highest levels on these kinds of issues

61
00:05:46,780 --> 00:05:51,969
and to bring him access that pretty much
everything we do online is is online now

62
00:05:51,970 --> 00:05:55,970
so as a society if you're all the
interactions that congress will be

63
00:05:55,970 --> 00:06:03,550
involved in also have some sort of nine
additional component so consumers are

64
00:06:03,550 --> 00:06:08,690
moving from the brick-and-mortar world
into the wired one end and when it's a

65
00:06:08,690 --> 00:06:13,659
couple of things up front you know for
those of us that having been steeped in

66
00:06:13,659 --> 00:06:18,340
this that you s approach to privacy and
consumer privacy is this kind of

67
00:06:18,340 --> 00:06:23,130
alphabet soup it's a sector based
approach it protects certain kinds of

68
00:06:23,130 --> 00:06:24,229
information

69
00:06:24,229 --> 00:06:31,159
health information financial information
children under 13 and then relies mostly

70
00:06:31,159 --> 00:06:32,800
on enforcement

71
00:06:32,800 --> 00:06:36,229
to protect privacy promises that are
being made to consumers in the

72
00:06:36,229 --> 00:06:41,699
commercial sector importantly the focus
of this talk is on protecting consumer

73
00:06:41,699 --> 00:06:45,800
privacy and data security in the
commercial sector the private sector

74
00:06:45,800 --> 00:06:50,889
we're not talking about today protecting
consumer privacy and security from the

75
00:06:50,889 --> 00:06:53,949
government that's a different part of
the government the National I work in

76
00:06:53,949 --> 00:06:58,830
order to focus on what the FTC has
jurisdiction on this kind of runs

77
00:06:58,830 --> 00:07:04,400
through a bunch of those laws do not
call askance fan hit by tee I'll be

78
00:07:04,400 --> 00:07:10,810
which is the family education records
Protection Act may not be as obvious to

79
00:07:10,810 --> 00:07:14,250
many in the room but that's actually an
underpinning of this whole student data

80
00:07:14,250 --> 00:07:18,169
privacy debate that's going on
telecommunications act and a bunch of

81
00:07:18,169 --> 00:07:22,159
different state laws on the state level
of course we also see different

82
00:07:22,159 --> 00:07:25,759
approaches not only to protecting
student data but also to the kinds of

83
00:07:25,759 --> 00:07:30,490
notifications that consumers are
supposed to receive if their information

84
00:07:30,490 --> 00:07:34,969
was breached the other laws that we
don't really have the preacher don't

85
00:07:34,969 --> 00:07:42,639
have at the federal level the FTC

86
00:07:42,639 --> 00:07:46,729
buyer here why are we talking to you
about all of these technology policy

87
00:07:46,729 --> 00:07:51,568
issues and how did it come to be that we
have technology as it as a primary focus

88
00:07:51,569 --> 00:07:57,210
of protecting consumers couple of things
one sec just celebrated the 200th

89
00:07:57,210 --> 00:08:01,138
birthday it was created by Woodrow
Wilson he's the guy on the left it was

90
00:08:01,139 --> 00:08:06,090
primarily organized to combat the
economic power of the trust at the

91
00:08:06,090 --> 00:08:10,128
beginning of the 20th century in America
for those of you that our students have

92
00:08:10,129 --> 00:08:14,229
economic history the trust controlled by
a very small number of people they

93
00:08:14,229 --> 00:08:18,219
controlled most of the economy was a
problem this is sort of an antitrust

94
00:08:18,219 --> 00:08:21,699
problem in the Trade Commission was
created to work with the Department of

95
00:08:21,699 --> 00:08:27,819
Justice to protect consumers from unfair
competition in the marketplace but as

96
00:08:27,819 --> 00:08:31,320
our mission has evolved we also protect
now

97
00:08:31,320 --> 00:08:37,020
consumers from unfair deceptive acts and
practices which has made us memorialized

98
00:08:37,020 --> 00:08:44,860
white hat in protecting consumer privacy
and data security there's the FTC Act

99
00:08:44,860 --> 00:08:46,970
keep going

100
00:08:46,970 --> 00:08:51,690
that's basically our authority it's
relatively broad and we've been using it

101
00:08:51,690 --> 00:08:55,970
in the last 25 years particularly to
bring consumer data security and privacy

102
00:08:55,970 --> 00:09:01,410
cases but we protect consumers from a
range of different kinds of products and

103
00:09:01,410 --> 00:09:06,890
advertising practices and things like
that so I don't think about us maybe it

104
00:09:06,890 --> 00:09:14,600
ought to CSU the Federal Trade marketed
in the United States it was kathleen

105
00:09:14,600 --> 00:09:22,530
least undergarments yes the camp in the
interim government the where but lose

106
00:09:22,530 --> 00:09:27,610
weight and and and have less so you like
this does not work

107
00:09:27,610 --> 00:09:37,380
yeah it's a real product and so we bring
cases like this against products and

108
00:09:37,380 --> 00:09:42,980
advertising practices things that don't
work a lot of them are Waverly did scams

109
00:09:42,980 --> 00:09:46,250
and other things like that will cause
its kind of the low tech consumer

110
00:09:46,250 --> 00:09:50,690
protection and very important part of
our mission and our mission also

111
00:09:50,690 --> 00:09:55,970
involves technology and so imagine 14
when we were none of this was high-tech

112
00:09:55,970 --> 00:10:01,570
this was you know telecom was just kind
of kicking off my phone calls one of our

113
00:10:01,570 --> 00:10:08,860
first cases was not an accounting
machine basically a school computer your

114
00:10:08,860 --> 00:10:15,060
body case essentially about the fact
that it did not do what it claimed and

115
00:10:15,060 --> 00:10:17,709
there again technology was a key
component because we have to understand

116
00:10:17,710 --> 00:10:21,790
what accounting machines were supposed
to do what claims were made and then

117
00:10:21,790 --> 00:10:30,630
case against the counting machines in
the name of the company and technologies

118
00:10:30,630 --> 00:10:33,810
always been a part of our work so this
is i think in the sixties or seventies

119
00:10:33,810 --> 00:10:35,270
recreate it

120
00:10:35,270 --> 00:10:43,230
example systems to automatically measure
tar in cigarettes he has said he became

121
00:10:43,230 --> 00:10:49,620
the FTC method for measuring tar and
it's a century building tools building

122
00:10:49,620 --> 00:10:54,690
in this case this cigarette smoking
machine which kind of reminds me of

123
00:10:54,690 --> 00:10:58,330
oscars droid army talk where you
essentially were a bunch of droids and

124
00:10:58,330 --> 00:11:04,660
test their output and cigarettes but
it's it's to describe how we do a lot of

125
00:11:04,660 --> 00:11:10,010
building and tools and technology
related matters to even historically

126
00:11:10,010 --> 00:11:16,660
alright so cigarettes caffeinated
undergarments why do we need

127
00:11:16,660 --> 00:11:20,410
technologists well the fact is as
consumers have moved the

128
00:11:20,410 --> 00:11:24,790
brick-and-mortar world into the wired
and connected one they have been

129
00:11:24,790 --> 00:11:30,910
experiencing a bunch of different kinds
of practices around their privacy and

130
00:11:30,910 --> 00:11:37,959
their data security and so FTC 2.0 or
FCC at 100 is an agency that has

131
00:11:37,960 --> 00:11:40,550
increasingly focused part of its mission

132
00:11:40,550 --> 00:11:45,359
protecting consumers and we do that
primarily through enforcement actions

133
00:11:45,360 --> 00:11:49,320
this light is a snapshot of some of the
enforcement cases we brought against

134
00:11:49,320 --> 00:11:54,700
major tech companies in the last five
years they involve consumer security and

135
00:11:54,700 --> 00:11:59,890
privacy and have been deeply informed by
technologists like a scan and we've been

136
00:11:59,890 --> 00:12:04,790
expanding our our technological
capabilities in order to understand when

137
00:12:04,790 --> 00:12:09,610
promises are being made to consumers
whether they're being kept and really be

138
00:12:09,610 --> 00:12:14,960
able to carefully evaluate data security
practices in the industry and we're

139
00:12:14,960 --> 00:12:17,200
going to spend a little time going
through some of these cases because they

140
00:12:17,200 --> 00:12:22,810
really are and the underpinning of how
we're shaping a lot of the data security

141
00:12:22,810 --> 00:12:28,050
and privacy practices using our
enforcement tool

142
00:12:28,050 --> 00:12:36,500
this is a big area for us and
essentially deception is when consumers

143
00:12:36,500 --> 00:12:42,840
are marketed and she was a certain way
and rely on that marketing and making

144
00:12:42,840 --> 00:12:47,340
their decision to buy the product but
then are misled and we can we can bring

145
00:12:47,340 --> 00:12:52,230
a case in this case involved consumers
being told that they could have

146
00:12:52,230 --> 00:12:56,840
unlimited plans or keep unlimited data
plans when in fact they were going to be

147
00:12:56,840 --> 00:13:01,310
throttled after certain thresholds are
reached so we said that was deceptive

148
00:13:01,310 --> 00:13:07,209
this case is actually currently in
litigation and so that this is a case

149
00:13:07,210 --> 00:13:08,270
but again

150
00:13:08,270 --> 00:13:11,930
understanding underpinnings the
technical underpinnings critical to this

151
00:13:11,930 --> 00:13:15,060
case right so the staff had to
understand the difference between

152
00:13:15,060 --> 00:13:21,550
network management and congestion
tolling have to understand example when

153
00:13:21,550 --> 00:13:29,209
network routing works and telco world
which means that just samurai seven are

154
00:13:29,210 --> 00:13:34,500
some of these obscure non IP protocols
kind of a very different world and it

155
00:13:34,500 --> 00:13:40,130
also has to essentially get into what
our practices in the space where other

156
00:13:40,130 --> 00:13:44,100
companies doing what are what is the
norm and try to differentiate whether

157
00:13:44,100 --> 00:13:52,380
this practice was harmful to consumers
so this is again

158
00:13:52,380 --> 00:13:56,810
situation in which we are taking a look
at privacy promises that are made to

159
00:13:56,810 --> 00:14:02,270
consumers and whether the company is
actually upheld them in this situation

160
00:14:02,270 --> 00:14:06,350
privacy promise was that Gmail users
their information was going to be used

161
00:14:06,350 --> 00:14:10,760
for Gmail and it was then used to
populate buzz in a mini lab too

162
00:14:10,760 --> 00:14:14,370
complicated case but suffice it to say
people weren't really given sufficient

163
00:14:14,370 --> 00:14:19,180
notice about how that was going to work
many of you may recall us in this case

164
00:14:19,180 --> 00:14:23,250
we resolved it with a consent order
which is a relatively common way that we

165
00:14:23,250 --> 00:14:28,980
can resolve cases it puts Google under
order with us for twenty years we have

166
00:14:28,980 --> 00:14:30,310
with in that order

167
00:14:30,310 --> 00:14:35,479
independent auditor comes every two
years to do privacy policy adding and

168
00:14:35,480 --> 00:14:39,360
for the first time this was a first for
the FEC required the company to

169
00:14:39,360 --> 00:14:45,050
implement a comprehensive privacy policy
for consumers and users and radio this

170
00:14:45,050 --> 00:14:46,209
work this later

171
00:14:46,210 --> 00:14:52,180
2012 google also engaged in a practice
regarding

172
00:14:52,180 --> 00:14:57,819
second version of Safari browser
settings and so when there are no and

173
00:14:57,820 --> 00:15:03,820
that was to be in violation of their
consent agreement and so it's called

174
00:15:03,820 --> 00:15:08,490
contempt and legal terms it's a good
tool for us and so then we can bring

175
00:15:08,490 --> 00:15:17,940
actual damages and extracting money from
the entity that's how I 30 works again

176
00:15:17,940 --> 00:15:24,709
privacy promises Facebook another case
in which we were looking at whether the

177
00:15:24,709 --> 00:15:28,109
representations Facebook had made to
users about how they could restrict

178
00:15:28,110 --> 00:15:32,800
their information were actually true men
in this case relatively importantly

179
00:15:32,800 --> 00:15:37,599
there was a retroactive change that
Facebook implemented and when they

180
00:15:37,600 --> 00:15:42,660
change that he said that was also unfair
to consumers that if they had decided

181
00:15:42,660 --> 00:15:46,800
their permission was going to be handled
a certain way and then you changed your

182
00:15:46,800 --> 00:15:50,719
policy about how that information is
going to be handled without giving

183
00:15:50,720 --> 00:15:54,910
people sufficient controller twice at
that point or notice that that's an

184
00:15:54,910 --> 00:15:59,920
unfair practice again in this case we
brought the case and have been

185
00:15:59,920 --> 00:16:02,010
underwater again for twenty years

186
00:16:02,010 --> 00:16:08,120
comprehensive privacy policy is a part
of that audits exacta 2010 so remember

187
00:16:08,120 --> 00:16:13,200
Facebook for example make claims about
what information you can make public or

188
00:16:13,200 --> 00:16:19,050
private but in fact if you recall apps
would have access to information

189
00:16:19,050 --> 00:16:23,969
regardless of what the user settings
were and so and so it involved things

190
00:16:23,970 --> 00:16:28,310
like probing the API or developing
software to demonstrate what information

191
00:16:28,310 --> 00:16:33,329
is accessible and involve things like we
made a claim regarding deletion of

192
00:16:33,330 --> 00:16:37,339
photos so when you add delete a photo on
Facebook in fact it would still remain

193
00:16:37,339 --> 00:16:42,200
in the city and cash so people could
still excessive you have things like

194
00:16:42,200 --> 00:16:46,600
sharing data with advertisers and so if
people knew how

195
00:16:46,600 --> 00:16:53,470
refer headers work and how Facebook IDs
will be transmitted to third parties

196
00:16:53,470 --> 00:16:58,880
those key those key concepts had to be
conveyed and and they were they became a

197
00:16:58,880 --> 00:17:04,319
core component of the case that the
counter there the technical Council what

198
00:17:04,319 --> 00:17:12,938
we used to allege some of the violations
no me this is a relatively recent case

199
00:17:12,939 --> 00:17:18,309
this case involved a company whose tech
allows users and consumers to be tracked

200
00:17:18,309 --> 00:17:22,500
through their MAC address in retail
locations they had made a promise though

201
00:17:22,500 --> 00:17:26,990
that they would allow consumers to opt
out in retail locations that were using

202
00:17:26,990 --> 00:17:30,820
the technology and that they would
provide notice at retail locations of

203
00:17:30,820 --> 00:17:36,418
the technology but they didn't actually
required the retailers who are using the

204
00:17:36,419 --> 00:17:40,940
tack to provide that notice where that
opt out so we said that that was a

205
00:17:40,940 --> 00:17:43,120
broken promise and that was deception

206
00:17:43,120 --> 00:17:48,760
some critical concepts that were being
debated in this case between staff and

207
00:17:48,760 --> 00:17:55,309
council and run around things like
everyone knows what WiFi signals are but

208
00:17:55,309 --> 00:18:01,539
things around what our wifi headers
sources wifi content packet data there

209
00:18:01,539 --> 00:18:06,030
were claims about many of the companies
in the space of the Titans space make

210
00:18:06,030 --> 00:18:11,260
claims around and in the end so they
would argue that they used cryptography

211
00:18:11,260 --> 00:18:17,309
to make the MAC addresses anonymous in
fact effectively their housing market

212
00:18:17,309 --> 00:18:23,740
dresses but if people know it's it's the
kind of the manufacturer so there's not

213
00:18:23,740 --> 00:18:30,600
a lot of variation you can essentially
it something like 23832 brute force

214
00:18:30,600 --> 00:18:33,959
which is something you can do on a
standard laptop these days

215
00:18:33,960 --> 00:18:38,530
generator rainbow tables so we had to
rate their like this a perfect example

216
00:18:38,530 --> 00:18:43,879
of how you can help me understand what
the heck is going on when we're making

217
00:18:43,880 --> 00:18:48,320
an online course the decision because I
now know what he's talking about but I

218
00:18:48,320 --> 00:18:50,860
guarantee you at the beginning of that
process

219
00:18:50,860 --> 00:18:57,629
I had no idea and so these claims are
understanding these claims and the

220
00:18:57,630 --> 00:19:01,360
validity and what the enormous like
everyone here probably understands that

221
00:19:01,360 --> 00:19:04,270
you can download a rainbow table or
reverse a house pretty easily especially

222
00:19:04,270 --> 00:19:10,000
one that's expects but but a lot of the
policy makers don't realize and and they

223
00:19:10,000 --> 00:19:13,840
just go by the claims that the companies
can make until they prove otherwise

224
00:19:13,840 --> 00:19:18,020
and so this is why it's critical to
demonstrate and show data and even my

225
00:19:18,020 --> 00:19:21,540
show that I can hey I can reverse the
house as a couple of these key concepts

226
00:19:21,540 --> 00:19:25,570
that became part of the case and again
this is a very interesting technology

227
00:19:25,570 --> 00:19:30,260
right this is promiscuous wi-fi sniffing
of your devices as you move around

228
00:19:30,260 --> 00:19:36,020
move around in this conference right and
so there's a persistent trail of where

229
00:19:36,020 --> 00:19:40,129
you been over time by someone you don't
even know and to disable it

230
00:19:40,130 --> 00:19:45,030
yes they are disabled wifi are there are
companies that use GSM so so you're him

231
00:19:45,030 --> 00:19:48,899
see your tendency to track you as you
move about and so this is a very kind of

232
00:19:48,900 --> 00:19:55,700
privacy in the area anyway so it's
important to get it right now this is

233
00:19:55,700 --> 00:20:00,350
part of the FTC is ongoing work and I'm
sure we'll see more and more of this in

234
00:20:00,350 --> 00:20:05,010
coming years to make sure that apps are
being marketed truthfully to consumers

235
00:20:05,010 --> 00:20:11,379
and in this case our beef was with
concept of the fact of morality that the

236
00:20:11,380 --> 00:20:15,250
promise that these messages would
disappear when in fact that was that was

237
00:20:15,250 --> 00:20:18,080
not necessarily the case at all

238
00:20:18,080 --> 00:20:21,720
we also want to be sort of looking at
the at the

239
00:20:21,720 --> 00:20:25,770
talk more carefully also looked
carefully at the security promises that

240
00:20:25,770 --> 00:20:30,270
were made to consumers as well this is a
really great area where outside

241
00:20:30,270 --> 00:20:35,639
researchers also inform policy right so
there is i think in 2013 the scruffy

242
00:20:35,640 --> 00:20:40,810
beard guys demonstrated the limitations
and a number of ephemeral messaging out

243
00:20:40,810 --> 00:20:45,280
and everyone here kind of probably can
understand how data flows and when you

244
00:20:45,280 --> 00:20:49,090
do it unless there's some really need
crypto happening it's not actually

245
00:20:49,090 --> 00:20:55,179
deleted but it takes the agency kind of
researchers like you know how I learned

246
00:20:55,180 --> 00:21:00,310
or highlight some of these facts and so
there's a number of cases we only cover

247
00:21:00,310 --> 00:21:05,270
a few but there's a number of cases
around CSS his case against the US

248
00:21:05,270 --> 00:21:08,900
history sniffing this is when you know
your links change colors advertisers

249
00:21:08,900 --> 00:21:12,790
would be able to terminate your browser
when it's a blue or purple drank and

250
00:21:12,790 --> 00:21:16,240
identify what other web sites you
visited right and so that's a neat

251
00:21:16,240 --> 00:21:21,130
hacking technique those demonstrating
some these conferences but advertisers

252
00:21:21,130 --> 00:21:24,530
were in fact engaged in it and that
again that informs us of what to look

253
00:21:24,530 --> 00:21:27,830
for and what are some of the state of
the art we also looked at five cookies

254
00:21:27,830 --> 00:21:31,260
we have a number of technical cases that
were very much

255
00:21:31,260 --> 00:21:35,810
first alerted we do our due diligence
and we dwelled event but highlighting

256
00:21:35,810 --> 00:21:43,260
this is critical in this space and we
also take a look at security practices

257
00:21:43,260 --> 00:21:49,110
well and so folks remember the Carrier
IQ above a few years ago where the

258
00:21:49,110 --> 00:21:52,520
researcher had identified kind of a
third party

259
00:21:52,520 --> 00:21:59,870
longer on a forum that was his claims
tracking users cutting keystrokes I

260
00:21:59,870 --> 00:22:06,260
think it was HTC phones we we brought a
case against HTC for essentially

261
00:22:06,260 --> 00:22:10,340
not taking reasonable steps to secure
the software developer for phones and

262
00:22:10,340 --> 00:22:15,310
part of it was that the integrated a
couple of features including carry argue

263
00:22:15,310 --> 00:22:19,360
in their own lager in a way that for
example broke the Android permission

264
00:22:19,360 --> 00:22:26,840
model completely allowed side loading or
unloading of unsigned code then they

265
00:22:26,840 --> 00:22:31,980
ship with debug equals yes which
essentially allowed to basically like a

266
00:22:31,980 --> 00:22:36,300
bunch of extraneous data logger and then
they use denying that he types listener

267
00:22:36,300 --> 00:22:38,280
so any other app on the phone

268
00:22:38,280 --> 00:22:43,800
successfully connect and pull data from
bloggers kind of them again

269
00:22:43,800 --> 00:22:46,870
circumventing the permission model and
that the apps and rock so did a bunch of

270
00:22:46,870 --> 00:22:51,570
kind of what we would consider in this
dumb things and we brought a case

271
00:22:51,570 --> 00:22:57,139
against them for for failure to take
reasonable security steps to make it

272
00:22:57,140 --> 00:23:01,700
legal to hear about unfairness and what
it means in in a legal context though

273
00:23:01,700 --> 00:23:05,740
this is one of those places where the
technology can tell us all about how

274
00:23:05,740 --> 00:23:08,530
things are working and where the where
the problems are from their perspective

275
00:23:08,530 --> 00:23:13,530
but then as a lawyer we have to fit into
what our legal authority actually is so

276
00:23:13,530 --> 00:23:14,139
for us

277
00:23:14,140 --> 00:23:19,820
unfair nurses and after practice that
causes or is likely to cause substantial

278
00:23:19,820 --> 00:23:23,820
injury to consumers which is not
reasonably avoidable by consumers

279
00:23:23,820 --> 00:23:28,550
themselves and not outweighed by
countervailing benefits I'm so basically

280
00:23:28,550 --> 00:23:32,960
that leads us to do this sort of
reasonableness standard that were

281
00:23:32,960 --> 00:23:37,620
applying to consumer data security cases
should note this is currently in

282
00:23:37,620 --> 00:23:41,239
litigation said we'll see how the
authority involves but this is how we've

283
00:23:41,240 --> 00:23:47,370
been using it and it really important
piece of that for us is that we are we

284
00:23:47,370 --> 00:23:52,179
really strongly believe in being tech
neutral we don't dictate the kind of

285
00:23:52,180 --> 00:23:57,910
technology people ought to be using but
what we do say is the best practices

286
00:23:57,910 --> 00:24:02,540
here's what we believe are reasonable
and you know take your pick great have

287
00:24:02,540 --> 00:24:04,139
security by design

288
00:24:04,140 --> 00:24:08,290
have good processes and procedures in
place you doing the basic thing

289
00:24:08,290 --> 00:24:15,379
things that the industry perceives as
sort of basic reasonable security cases

290
00:24:15,380 --> 00:24:19,670
against makers Credit Karma and branding

291
00:24:19,670 --> 00:24:24,780
findings the ticketing up out there lets
you check your credit scores for

292
00:24:24,780 --> 00:24:28,940
essentially the scent disabling
certification right so they would

293
00:24:28,940 --> 00:24:31,810
collecting credit card information and
other personal information check your

294
00:24:31,810 --> 00:24:37,960
record scores but they had essentially
rendered tell us an effective because

295
00:24:37,960 --> 00:24:42,320
they were you know and that's a hot
topic we know that our talks today is

296
00:24:42,320 --> 00:24:47,830
about Saudi or tomorrow is absurd
validation issues there you know it's

297
00:24:47,830 --> 00:24:54,090
hot it's something that happens and here
we we we allege that the this practice

298
00:24:54,090 --> 00:24:58,709
especially when it relates to credit
card information is unreasonable and

299
00:24:58,710 --> 00:25:04,030
again in these cases we're looking at
the injury here to the consumers that

300
00:25:04,030 --> 00:25:08,860
we're hoping to avoid our security flaws
that introduced vulnerabilities to

301
00:25:08,860 --> 00:25:12,780
sensitive consumer information he needs
to be seen seen in these cases as well

302
00:25:12,780 --> 00:25:18,080
as about a case against train that goes
on the more recent cases and one of our

303
00:25:18,080 --> 00:25:25,639
first foray in the IOT which everyone
knows here this is essentially a camera

304
00:25:25,640 --> 00:25:31,610
maker in a remote camera maker that how
to secure view capability that allowed

305
00:25:31,610 --> 00:25:36,309
individuals to connect to their camera
in there they advertise it as being safe

306
00:25:36,309 --> 00:25:41,120
to monitor baby monitor in a hospital or
even in banking environments but in fact

307
00:25:41,120 --> 00:25:47,260
they had done it in a way where one they
don't have any security program so we

308
00:25:47,260 --> 00:25:51,250
don't win a Super perfect security but
we like that but companies that make

309
00:25:51,250 --> 00:25:56,130
claims about security have some
functionality and here they were not

310
00:25:56,130 --> 00:25:59,010
paying attention to vulnerability
disclosures from researchers they were

311
00:25:59,010 --> 00:26:02,879
not passing an airline the cameras to be
remotely accessible if you know the IP

312
00:26:02,880 --> 00:26:07,140
address of the camera even if the user
it's you know set the option off you can

313
00:26:07,140 --> 00:26:11,799
just pull them off the street from the
IP IP address again here from a legal

314
00:26:11,799 --> 00:26:14,760
perspective we have deception you're
making claims about the security of your

315
00:26:14,760 --> 00:26:19,090
product that don't turn out to be true
we have unfairness this consumer injury

316
00:26:19,090 --> 00:26:22,260
and a problem here the injuries a little
bit different than the kids are just

317
00:26:22,260 --> 00:26:25,809
talking about because it's actually the
sort of intrusion into people's personal

318
00:26:25,809 --> 00:26:30,678
homes and personalize the live feed of
their baby can being you on the public

319
00:26:30,679 --> 00:26:34,910
Internet and available to somebody is is
a kind of injury that were concerned

320
00:26:34,910 --> 00:26:42,330
about us when we talk about its ok scott
designer and this is a company that was

321
00:26:42,330 --> 00:26:49,350
making a century software for companies
that provide rent-to-own laptops it's

322
00:26:49,350 --> 00:26:56,309
essentially was iraq was a remote remote
access tool that took screenshots webcam

323
00:26:56,309 --> 00:27:00,080
photos every two minutes keystroke
loggers it was designed to not be

324
00:27:00,080 --> 00:27:06,620
detectable by AV and it was you know in
some cases Detective Mode call Detective

325
00:27:06,620 --> 00:27:10,030
Mode that the company's going to be a
bit with their activated for people that

326
00:27:10,030 --> 00:27:15,418
relate to pay their laptop payments and
in some cases they took pictures of

327
00:27:15,419 --> 00:27:18,900
children individuals that fully clothed
and couples engaged in sexual activities

328
00:27:18,900 --> 00:27:23,230
which is somewhat invasive we would
argue

329
00:27:23,230 --> 00:27:31,919
wanna get your laptop back yeah yeah
somewhat invasive as I can and I think

330
00:27:31,919 --> 00:27:40,710
you know from a consumer perspective
that's just creepy and what's this

331
00:27:40,710 --> 00:27:46,760
community no longer that's basically TSR
that is not going to hide from AV and

332
00:27:46,760 --> 00:27:51,510
that takes its this webcam and screen
shots at the right right so we know this

333
00:27:51,510 --> 00:27:56,460
in this community but it's being sold to
consumers now and no disclosure and

334
00:27:56,460 --> 00:27:59,600
companies were in fact using this
functionality is it was about they could

335
00:27:59,600 --> 00:28:10,899
push enforcement authority right and
that is that's why we spend a little

336
00:28:10,900 --> 00:28:14,480
time going through some of these cases
because they are very important in

337
00:28:14,480 --> 00:28:19,830
shaping tech policy and keeping privacy
policies and security policies that the

338
00:28:19,830 --> 00:28:23,559
companies that we especially has under
order but also folks in the industry

339
00:28:23,559 --> 00:28:27,980
that are looking at what we're doing but
the other way in which we really tried

340
00:28:27,980 --> 00:28:32,660
to shape policy is an and also by the
way inform our enforcement and ourselves

341
00:28:32,660 --> 00:28:36,790
about what the right policy ought to be
his by holding workshops and putting

342
00:28:36,790 --> 00:28:40,710
together reports of things like that so
recently in the last year we've been

343
00:28:40,710 --> 00:28:45,210
looking at IOT obviously due to
discrimination health and fitness

344
00:28:45,210 --> 00:28:49,549
wearables so this is one of those gaps I
think information for a lot of people

345
00:28:49,549 --> 00:28:54,470
they say no hip and they started their
health information is in the day here

346
00:28:54,470 --> 00:28:58,590
I'm using us like us- consumers is
protected sort of because they're

347
00:28:58,590 --> 00:29:01,620
familiar with all the HIPAA process for
being in the doctor's office or whatnot

348
00:29:01,620 --> 00:29:05,610
but they don't necessarily think of the
fact that if they're generating their

349
00:29:05,610 --> 00:29:10,559
own health information on a wearable
it's not protected necessarily at all so

350
00:29:10,559 --> 00:29:15,200
there you need to look at whatever the
practices of the company that you are

351
00:29:15,200 --> 00:29:19,410
sharing your information with and and
understand it so that's what what that's

352
00:29:19,410 --> 00:29:20,370
about

353
00:29:20,370 --> 00:29:25,299
we're also looking in the fall across
device tracking in a workshop that

354
00:29:25,299 --> 00:29:32,668
encourage all of you to comment on our
participate in a technology that tries

355
00:29:32,669 --> 00:29:37,119
to essentially identify when if you see
him in your mobile phone and then you

356
00:29:37,119 --> 00:29:41,299
later by on your desktop and tablet that
can attribute the add to the same person

357
00:29:41,299 --> 00:29:46,929
and do some conversion metrics or
provide right compensation to their

358
00:29:46,929 --> 00:29:51,929
identity of the person the referral for
the idea for the purchase but the

359
00:29:51,929 --> 00:29:55,299
technology is really interesting so
there's a sign in services when you're

360
00:29:55,299 --> 00:30:00,749
logged in to search the same source on
both devices that service knows you're

361
00:30:00,749 --> 00:30:01,679
the same user

362
00:30:01,679 --> 00:30:04,820
there's a lot of probabilistic
techniques I try to monitor either

363
00:30:04,820 --> 00:30:09,629
location or the same IP address or
things like the browsing behavior you

364
00:30:09,629 --> 00:30:14,049
browse the same types of sites with
brother fingerprinting as well

365
00:30:14,049 --> 00:30:17,249
to identify the same user and it breaks
a lot of our contacts

366
00:30:17,249 --> 00:30:23,489
boundaries of like this devices for the
specific devices for work uses are

367
00:30:23,489 --> 00:30:28,909
surprising uses for example a company
that begins right so so they're at

368
00:30:28,909 --> 00:30:34,210
libraries that essentially an ultrasonic
audio sounds from one phone at the

369
00:30:34,210 --> 00:30:37,739
library on the other phone is listening
on the mic and then a tribute to those

370
00:30:37,739 --> 00:30:42,340
two devices as related to this workshop
we want to try to understand some of the

371
00:30:42,340 --> 00:30:45,769
technologies that are you some of the
techniques water the consumer choices

372
00:30:45,769 --> 00:30:49,929
that they have what is the notice given
to consumers and what are the tradeoffs

373
00:30:49,929 --> 00:30:55,210
that snowfall if you want if you're
interested in it you can harm that PC

374
00:30:55,210 --> 00:31:00,020
web page for precise tracking or you can
Internet

375
00:31:00,020 --> 00:31:07,490
so you can hit me up as well have
contact information at the end so we're

376
00:31:07,490 --> 00:31:16,770
still on this like doing so we also put
out best practices guide to things like

377
00:31:16,770 --> 00:31:20,900
that we have a new start with security
initiative and a new guide out that's

378
00:31:20,900 --> 00:31:27,090
based on all of the FTC enforcement in
on consumer data security and all of the

379
00:31:27,090 --> 00:31:31,060
best practices and lessons learned from
those cases there's more than fifty of

380
00:31:31,060 --> 00:31:36,399
them we that guy is currently available
and we're going to be having different

381
00:31:36,400 --> 00:31:40,940
workshops and convening around the
country starting in the fall

382
00:31:40,940 --> 00:31:44,740
those are the first couple are
chairwoman will be in San Francisco in

383
00:31:44,740 --> 00:31:48,850
September I'll be in Austin in November
and we're gonna have more after that and

384
00:31:48,850 --> 00:31:54,790
then there's Tec Tec contact information
between us on our blog publish things

385
00:31:54,790 --> 00:31:59,290
like what are some best practices like
with regards developments

386
00:31:59,290 --> 00:32:04,210
concepts like the principle of least
privilege how to handle permissions

387
00:32:04,210 --> 00:32:10,360
properly we try to try to identify key
areas that are pitfalls are key best

388
00:32:10,360 --> 00:32:14,090
practices that companies and startups
can consider their buildings happen

389
00:32:14,090 --> 00:32:21,169
again this is where this community and
other others help really inform what are

390
00:32:21,170 --> 00:32:26,520
what are those practices so again I
encourage you to engage with us and do

391
00:32:26,520 --> 00:32:30,580
what you're doing to continue to push
companies to prioritize privacy and

392
00:32:30,580 --> 00:32:36,399
security as one of the key facets when
they're developing new stuff finally the

393
00:32:36,400 --> 00:32:39,900
other one of the other tools that we've
been using the last couple of years

394
00:32:39,900 --> 00:32:45,160
relatively effectively that harnesses
the real force para technologists are

395
00:32:45,160 --> 00:32:49,380
contests so few years ago congress
passed a law that allows us now run

396
00:32:49,380 --> 00:32:54,600
contest to solve problems that have been
tricky for us one of them has been the

397
00:32:54,600 --> 00:32:58,980
scourge of robocalls many of you may
have gotten these phone calls either on

398
00:32:58,980 --> 00:33:03,600
your mobile phone or if you still have
one on landline and these are you know

399
00:33:03,600 --> 00:33:07,439
when you have a robot voice this is
Rachel from customer service I'm calling

400
00:33:07,440 --> 00:33:11,740
because you've won whatever you get
these calls even if you're on the Do Not

401
00:33:11,740 --> 00:33:15,500
Call list which by the way we operate
with the SEC what's really annoying

402
00:33:15,500 --> 00:33:18,210
right because if you're on the Do Not
Call list you're not supposed to be

403
00:33:18,210 --> 00:33:22,860
getting these kinds of calls and the
fact is the robot can sort of you know

404
00:33:22,860 --> 00:33:29,129
undermine the whole system so we created
a series of contests a contest that have

405
00:33:29,130 --> 00:33:35,980
already provided new consumer facing
tools to block robo calls have provided

406
00:33:35,980 --> 00:33:40,620
us with new law enforcement tools better
honey pot so that we are better able to

407
00:33:40,620 --> 00:33:45,110
detect them and this week we're running
so these are some of the major was last

408
00:33:45,110 --> 00:33:49,040
year this route this year running
community strength back to this is

409
00:33:49,040 --> 00:33:55,020
contest that's been in several phases
the final phases and DEF CON Saturday

410
00:33:55,020 --> 00:33:58,900
where we are going to be taking a look
at a couple of new tools that are being

411
00:33:58,900 --> 00:34:04,640
created that will allow consumers not
only to hopefully capture the so-called

412
00:34:04,640 --> 00:34:08,750
number but then search of forward it
seamlessly into better her honey pot and

413
00:34:08,750 --> 00:34:10,739
better technology for us and

414
00:34:10,739 --> 00:34:15,868
so we're trying to provide new tools to
help deal with this problem even though

415
00:34:15,869 --> 00:34:20,899
we already have law enforcement
authority that is meant to address it

416
00:34:20,899 --> 00:34:28,259
technology has a tradition for robo
calls and automated dialers is very hard

417
00:34:28,260 --> 00:34:34,700
now you can you can use cloud services
and so sometimes you need a third

418
00:34:34,699 --> 00:34:39,149
technology added and so these contests
are building tools and and techniques

419
00:34:39,149 --> 00:34:43,409
combined in combination with our law
enforcement authority to combat these

420
00:34:43,409 --> 00:34:48,470
issues right I'm sure you will receive
10 your most important to your grandmas

421
00:34:48,469 --> 00:34:55,388
received one and maybe submit her
information which is a big issue the

422
00:34:55,389 --> 00:35:01,430
other thing that we're doing is helped
set up this internal in-house research

423
00:35:01,430 --> 00:35:05,520
group called the office of technology
research and investigation at the time

424
00:35:05,520 --> 00:35:10,660
but it essentially we try to look at new
emerging technologies and do your own

425
00:35:10,660 --> 00:35:18,100
research on measurement our own analysis
to obtain turns out here today that are

426
00:35:18,100 --> 00:35:25,190
working with us in the front row and
where they had to sit there and we're

427
00:35:25,190 --> 00:35:31,500
continuing to bring additional resources
and house we're hiring and then

428
00:35:31,500 --> 00:35:36,859
something issues we're looking at TV
connected cars this idea of transparency

429
00:35:36,859 --> 00:35:43,000
which another not really off the time
but this issue around algorithms right

430
00:35:43,000 --> 00:35:47,310
and so so my past work was to show
example companies charging consumers

431
00:35:47,310 --> 00:35:50,420
different prices for things based on
where they were located and what other

432
00:35:50,420 --> 00:35:55,730
websites they visit and and ultimately
trying to get an idea of what are the

433
00:35:55,730 --> 00:36:00,109
practices in all of the other times we
interact with on a daily basis

434
00:36:00,109 --> 00:36:04,220
one of the ways they used to highlight
this issue is for example how many use

435
00:36:04,220 --> 00:36:09,910
Google Maps today or some sort of
napping hands people it's an authorized

436
00:36:09,910 --> 00:36:14,569
service we use but do we have any idea
to know whether the algorithm is giving

437
00:36:14,570 --> 00:36:18,880
us the best route to a place or whether
it's routing ice in front of a store

438
00:36:18,880 --> 00:36:19,559
that gives

439
00:36:19,559 --> 00:36:23,339
money or a billboard that has
essentially provided them some service

440
00:36:23,339 --> 00:36:27,150
don't pick on Google and other companies
that every other than that you interact

441
00:36:27,150 --> 00:36:31,079
with you have a way to know what the
underlying code is doing and what the

442
00:36:31,079 --> 00:36:34,539
biases are and that's an area that I'm
very interested in and that we're gonna

443
00:36:34,539 --> 00:36:38,759
be trying to do in this research shop
will have some info about how to engage

444
00:36:38,759 --> 00:36:43,549
with us can I just because I think it's
a really it's the point that we're

445
00:36:43,549 --> 00:36:46,319
really trying to underscore here which
is that we have this hundred year old

446
00:36:46,319 --> 00:36:49,479
authority in this 100 year old
institution that's meant to protect

447
00:36:49,479 --> 00:36:54,930
consumers and what we've been trying to
do is make sure that we can modernize

448
00:36:54,930 --> 00:36:58,959
ourselves and keep pace with where
consumers actually are and stay on top

449
00:36:58,959 --> 00:37:02,140
of the issues that are actually
confronting them which is why the role

450
00:37:02,140 --> 00:37:06,469
of technologists like ash can have
really expanded within the FTC why we

451
00:37:06,469 --> 00:37:16,029
have it here I you guys do and and why
we are here making a plug for your help

452
00:37:16,029 --> 00:37:20,029
debate so these are all that we decided
we were like getting so focused on our

453
00:37:20,029 --> 00:37:22,829
little world that we wanted to make sure
that we didn't lose sight of the fact

454
00:37:22,829 --> 00:37:27,289
that technology can and should play a
vital role in a number of these big

455
00:37:27,289 --> 00:37:32,640
debates that are currently happening in
DCD the security of course today in the

456
00:37:32,640 --> 00:37:41,359
senate cyber I don't even know the
status of the past today on information

457
00:37:41,359 --> 00:37:46,259
sharing that's again the miners and it's
not a lot of technologists were engaged

458
00:37:46,259 --> 00:37:50,729
on what that would specifics are in and
how the language is written is gonna

459
00:37:50,729 --> 00:37:56,049
affect all of us both from the side of
information sharing as well as consumers

460
00:37:56,049 --> 00:38:00,140
and so is a critical debates that
happening right now many of which many

461
00:38:00,140 --> 00:38:01,920
of you know and many have

462
00:38:01,920 --> 00:38:07,480
many of these you may not be aware of
but it's important to essentially be

463
00:38:07,480 --> 00:38:13,049
mindful of them and really engage on any
of them yeah and so you know many people

464
00:38:13,049 --> 00:38:19,359
play quite fun right but there's another
call of duty right which is essentially

465
00:38:19,359 --> 00:38:27,160
making yourself heard providing input
engaging in his policy debates right so

466
00:38:27,160 --> 00:38:32,609
it's not always fun although you know
telling a bunch of high-powered

467
00:38:32,609 --> 00:38:36,950
attorneys or pasta makers they're
completely wrong about something is

468
00:38:36,950 --> 00:38:42,029
pretty fun sometimes ultimately though
if you you know the reason of why you

469
00:38:42,030 --> 00:38:47,329
should do this isn't the pay isn't the
you know the status but ultimately if

470
00:38:47,329 --> 00:38:48,970
you don't do this

471
00:38:48,970 --> 00:38:53,240
other people well right people that out
I don't pick on a particular senator the

472
00:38:53,240 --> 00:38:57,160
people that India see that out
themselves as the phone caucus people

473
00:38:57,160 --> 00:39:01,230
that don't have a smartphone taught the
fact that they don't use email

474
00:39:01,230 --> 00:39:05,839
have no real understanding of Internet
protocols but that are writing laws that

475
00:39:05,839 --> 00:39:10,640
will affect each and every one of you
and so that's essentially kind of the

476
00:39:10,640 --> 00:39:16,730
call to duty yeah Katy just tune out
everything that we just there's some

477
00:39:16,730 --> 00:39:20,619
takeaways for you and they basically
underscore these points right which is

478
00:39:20,619 --> 00:39:24,980
technologists matter and they should
help inform our lives and our policy

479
00:39:24,980 --> 00:39:31,020
making in our law enforcement we
definitely have an open door and listen

480
00:39:31,020 --> 00:39:37,980
when we hear about research so we really
need your help and we'd like you to come

481
00:39:37,980 --> 00:39:41,470
up with so far

482
00:39:41,470 --> 00:39:49,899
contact information later I got smashed
a crafty Chicago style GRI I'm tech SEC

483
00:39:49,900 --> 00:39:57,000
she's TMC sweeney FTC and I do an
underscore this this kind of second part

484
00:39:57,000 --> 00:40:01,000
of your work has impact one other piece
to to be mindful others as I said so

485
00:40:01,000 --> 00:40:05,510
many of our investigations and are even
our policy is informed by this community

486
00:40:05,510 --> 00:40:10,510
but we also have this one restriction
which is that we cannot disclose ongoing

487
00:40:10,510 --> 00:40:12,030
with criminally can't wear like

488
00:40:12,030 --> 00:40:17,580
it's a criminal liability to disclose
the existence of an ongoing

489
00:40:17,580 --> 00:40:23,819
investigation so oftentimes things to me
or engage in our cases take one to two

490
00:40:23,820 --> 00:40:27,600
years sometimes right and so we will not
be able to come to you to ask questions

491
00:40:27,600 --> 00:40:32,620
or to get more information but we do
hear you and it's very valuable stuff

492
00:40:32,620 --> 00:40:37,770
example I worked at the FTC is the first
technologies in 2010 and in between

493
00:40:37,770 --> 00:40:40,590
there have been doing a bunch of other
stuff and I recently joined but in that

494
00:40:40,590 --> 00:40:43,060
middle time I would come across research
or I would

495
00:40:43,060 --> 00:40:47,029
myself to research that I knew would be
of interest to the FTC inside right up

496
00:40:47,030 --> 00:40:50,310
in a blog sometimes we get some press
coverage but I was always very sure that

497
00:40:50,310 --> 00:40:53,900
marianne to like write the FAQ and
methodology of how to reproduce

498
00:40:53,900 --> 00:40:58,850
reproduce this in isolation and what are
the steps and what are the trends pieces

499
00:40:58,850 --> 00:41:03,100
that someone like the FTC on AG might be
interesting because it's something that

500
00:41:03,100 --> 00:41:07,270
we can't go back to you and say hey we
have your script that used to like fine

501
00:41:07,270 --> 00:41:12,259
that's a possibility right so that's
just a point I want to make as we do

502
00:41:12,260 --> 00:41:16,280
hear you we just can't often reach out
and engage in the same way although

503
00:41:16,280 --> 00:41:20,600
we're going to be starting a series of
workshops and conversations with the

504
00:41:20,600 --> 00:41:24,670
community more broadly to have a
dialogue less about enforcement of

505
00:41:24,670 --> 00:41:28,950
individual matters but to help educate I
said what's going on and so we have

506
00:41:28,950 --> 00:41:35,129
about six minutes last we were gonna
have to buy sins and if not a mussel

507
00:41:35,130 --> 00:41:38,720
happy to talk about some of the kind of
tips and tricks on talking to policy

508
00:41:38,720 --> 00:41:41,439
makers we can do a little bit of both

509
00:41:41,440 --> 00:41:45,730
so I'm hoping that first night there are
many questions I'm happy to talk you

510
00:41:45,730 --> 00:41:47,180
through some of the

511
00:41:47,180 --> 00:41:52,140
what I've observed as ways to engage in
policy effectively as it takes sometimes

512
00:41:52,140 --> 00:41:57,160
we're bad at focusing or presenting
things in the language that is important

513
00:41:57,160 --> 00:42:02,069
after you get asked him steps you can
practice on me and see if i understand

514
00:42:02,070 --> 00:42:08,380
anything that you told me so high I'm
Andrew Conway from club mark we provide

515
00:42:08,380 --> 00:42:13,950
spam filtering services for a number of
large ISPs and since a lot of consumer

516
00:42:13,950 --> 00:42:18,629
fraud starts with an email message we
have a lot of a lot of visibility into

517
00:42:18,630 --> 00:42:24,250
that and we have on occasion shared
information with the FTC and as you

518
00:42:24,250 --> 00:42:28,290
point out we never hear and I think back
until you know sometimes a couple of

519
00:42:28,290 --> 00:42:33,490
years later there's an indictment which
is great I do I don't have one criticism

520
00:42:33,490 --> 00:42:38,810
I would say in that you know consent
order is fine against a big company like

521
00:42:38,810 --> 00:42:43,700
a Google whether you just want them to
fix the problem but for the smaller

522
00:42:43,700 --> 00:42:49,830
operators who are genuinely malicious
mostly the FTC enforcement consists of

523
00:42:49,830 --> 00:42:55,069
making give the money back and there are
no criminal penalties that there is

524
00:42:55,070 --> 00:43:01,330
nothing punitive about that you gave the
example of the diet clothing and you

525
00:43:01,330 --> 00:43:05,040
know a friend of mine posted something
about diet loading completely different

526
00:43:05,040 --> 00:43:12,029
diet clothing on Facebook just this week
so it's you know maybe suggest that you

527
00:43:12,030 --> 00:43:16,290
look for loss of their breaking that
involve criminal penalties and if that

528
00:43:16,290 --> 00:43:20,550
is not within the reach of the FTC then
find someone in the department of

529
00:43:20,550 --> 00:43:24,490
justice or the secret service for wire
fraud who can who can maybe put these

530
00:43:24,490 --> 00:43:28,950
people in prison because that's the only
thing even if you stop one individual if

531
00:43:28,950 --> 00:43:32,720
there's nothing punitive going on or get
others coming in to fill that ecological

532
00:43:32,720 --> 00:43:36,200
nation a really important point

533
00:43:36,200 --> 00:43:39,200
and when I should have underscored at
the beginning which is the FTC has civil

534
00:43:39,200 --> 00:43:43,598
authority we don't have criminal
authority we do work very carefully both

535
00:43:43,599 --> 00:43:47,640
with our state partners and with our
federal law enforcement partners when we

536
00:43:47,640 --> 00:43:53,129
detect criminal activity and we can
preferred over to doj as well but as you

537
00:43:53,130 --> 00:43:56,400
point out this is kind of a game of
whack-a-mole people who want to scam

538
00:43:56,400 --> 00:44:00,089
people will constantly find ways to do
that right and I use all the

539
00:44:00,089 --> 00:44:06,509
technological capabilities available to
them to conduct their skin so we can get

540
00:44:06,510 --> 00:44:10,579
consumers their money back if we can get
the money and it hasn't all been spent a

541
00:44:10,579 --> 00:44:14,869
lot of time that has been we can keep
those guys on your order if they break

542
00:44:14,869 --> 00:44:19,150
in order again and we do have them for
contempt that's that's a penalty started

543
00:44:19,150 --> 00:44:24,349
crying then but our legal authorities
are are limited and that way we have to

544
00:44:24,349 --> 00:44:28,329
sort of do our our our process but I
think it's an important way and we do

545
00:44:28,329 --> 00:44:41,380
get to see stuff down or sometimes your
questions to you earlier mentioned be

546
00:44:41,380 --> 00:44:46,400
TRENDnet security cameras not following
appropriate practices in the World God

547
00:44:46,400 --> 00:44:52,210
basically many different brands that are
bringing in and selling insecure like

548
00:44:52,210 --> 00:44:57,470
his result by Swanand Lorax at Costco
and they have the same problems that you

549
00:44:57,470 --> 00:45:01,220
mentioned obviously the PCs Enforcement
Administration it was ineffective

550
00:45:01,220 --> 00:45:09,560
because each team problems that were
income net savings now china cameras are

551
00:45:09,560 --> 00:45:17,569
still happening and being resold public
so how do you get to see what is the

552
00:45:17,569 --> 00:45:21,829
best way as we can bring this to the
attention and I know that we're getting

553
00:45:21,829 --> 00:45:25,349
traction because it really does seem
like a united we throw things that give

554
00:45:25,349 --> 00:45:29,670
us an email that is you know it take it
up to you see which doesn't seem like a

555
00:45:29,670 --> 00:45:34,240
way to reach out to you said the legal
thing earlier but we can track you know

556
00:45:34,240 --> 00:45:39,430
what their complaints about this
particular thing

557
00:45:39,430 --> 00:45:44,910
so if you have a complaint system and we
do have a ticket he is actually my email

558
00:45:44,910 --> 00:45:48,609
but I like the answer is yes it's a

559
00:45:48,609 --> 00:45:53,839
the pipeline ensure the supply chain
issue is a huge issue and IOT we

560
00:45:53,839 --> 00:45:59,170
released a report last year or this year
on the state of IOT and called for

561
00:45:59,170 --> 00:46:05,230
things like many factors to look at this
supply chain and we do we do you know

562
00:46:05,230 --> 00:46:09,849
we've rounded things we branded software
hardware and a concern and we do

563
00:46:09,849 --> 00:46:13,460
brandeis investigations we can go out to
all of them but we try to either

564
00:46:13,460 --> 00:46:20,559
enforcement authority or policy
authority tried to highlight or take

565
00:46:20,559 --> 00:46:24,490
action against some of these problems
that you mentioned which is common

566
00:46:24,490 --> 00:46:30,129
chipset routers or devices or not
because I'm asking about the retailers

567
00:46:30,130 --> 00:46:35,880
are going up the companies which isn't
always possible because their country

568
00:46:35,880 --> 00:46:40,540
does your PC have the authority to try
to win you have something that's clearly

569
00:46:40,540 --> 00:46:45,720
insecure they've taken action against
before do you have the authority to go

570
00:46:45,720 --> 00:46:50,529
after the people who are rebranding or
who are selling yeah yeah if there's a

571
00:46:50,530 --> 00:46:53,700
contractual relationship and their
rebranding and things like that then yes

572
00:46:53,700 --> 00:47:00,669
China but the company is in Aus and we
can in fact take action against the

573
00:47:00,670 --> 00:47:03,780
company and its brand intense and
engaging with consumers and selling the

574
00:47:03,780 --> 00:47:08,930
device to consumers but I also
underscore and your plane in IIT space

575
00:47:08,930 --> 00:47:13,440
in our report flags flags and also for
legislators on the hill right there is a

576
00:47:13,440 --> 00:47:17,819
wide range of security practices and not
everybody is getting the memo to really

577
00:47:17,819 --> 00:47:20,450
designed with security in mind

578
00:47:20,450 --> 00:47:24,759
and they aren't aware of the FTC or its
enforcement capabilities then we can go

579
00:47:24,760 --> 00:47:28,950
after everything a person so we are
aware of the fact that they're gonna be

580
00:47:28,950 --> 00:47:32,399
a lot of these consumer-facing products
that do have security issues associated

581
00:47:32,400 --> 00:47:37,410
with him when reason we want to get the
benefit of your health and I think it's

582
00:47:37,410 --> 00:47:42,170
another one that you know we put on the
list of hot policy debates that we think

583
00:47:42,170 --> 00:47:47,010
that everybody should be hearing about
rate we also called for a comprehensive

584
00:47:47,010 --> 00:47:52,560
data security legislation in our report
and tell us what to do right so it is

585
00:47:52,560 --> 00:47:57,880
the pipeline issue supply chain issues i
od devices is huge we have only two more

586
00:47:57,880 --> 00:48:02,369
minutes so I don't take the three
questions that are just go ahead and

587
00:48:02,369 --> 00:48:10,170
asset and we'll try to answer all in
succession so glad I left if you wanted

588
00:48:10,170 --> 00:48:14,020
to be a technology are there

589
00:48:14,020 --> 00:48:21,470
buzzwords or like how did you get into
this the plane like to do that so yeah

590
00:48:21,470 --> 00:48:36,419
and expression under a bushel and it is
open source tools on nonprofits

591
00:48:36,420 --> 00:48:40,970
medical devices that are coming out and
I know something or share your

592
00:48:40,970 --> 00:48:52,040
information like records I was curious
about you know I know you guys are

593
00:48:52,040 --> 00:48:56,180
looking more into I guess connected
vehicles I saw it listed up there and in

594
00:48:56,180 --> 00:49:00,819
light of what happened with the Jeep
Cherokee is their urgency to maybe in

595
00:49:00,819 --> 00:49:07,880
quirements or what is that he sees
position or responsibility there

596
00:49:07,880 --> 00:49:16,559
so in terms of how to get into the space
I mean really it's publish you know

597
00:49:16,559 --> 00:49:22,970
start you would be amazed how start Dec
is for people that know what they're

598
00:49:22,970 --> 00:49:27,269
talking about but the key is that can
also talk to policymakers had a whole

599
00:49:27,269 --> 00:49:30,649
kind of slide on some of the key issues
of understanding where they're coming

600
00:49:30,650 --> 00:49:34,819
from in the debate being able to use
simple language not all of the details

601
00:49:34,819 --> 00:49:39,490
but figuring out what the crux of the
pivot point in terms of being able to

602
00:49:39,490 --> 00:49:44,839
voice things and not simple but accurate
finding metaphors that you know

603
00:49:44,839 --> 00:49:51,420
consistent that will really work that
resemble are historically used them all

604
00:49:51,420 --> 00:49:55,460
and whether it's a phone booth whether
its public space but that are maintained

605
00:49:55,460 --> 00:50:00,130
in the technology as well and then there
are you don't wanna come to the FTC

606
00:50:00,130 --> 00:50:07,150
there are groups doing policy at a local
level two so I'll budget the state AG's

607
00:50:07,150 --> 00:50:11,009
a drain on technologists and house is
not great keyword except maybe tech

608
00:50:11,009 --> 00:50:16,299
policy and privacy and security but I'm
hiring for this for example so I am

609
00:50:16,299 --> 00:50:21,509
hiring research coordinator people are
interested in working doing conducting

610
00:50:21,509 --> 00:50:26,980
research at the FTC definitely email me
or cherry page but there is nothing like

611
00:50:26,980 --> 00:50:32,180
this in a box we fit right we're not
lawyers were not like CSIT guys were not

612
00:50:32,180 --> 00:50:35,970
fixing your desktop with this weird
category of thing and there's not a

613
00:50:35,970 --> 00:50:40,740
really good resource as I know how that
addresses that draws these people and so

614
00:50:40,740 --> 00:50:46,368
it's a lot of organic mouth but come see
me or talk to CDT other other

615
00:50:46,369 --> 00:50:52,839
organizations Joe home has made the same
the need for technologists so so just

616
00:50:52,839 --> 00:50:57,490
try to engage in ways you can and try to
be out there said he had not happened

617
00:50:57,490 --> 00:51:01,868
jurisdiction answer is we don't but I be
happy to have congress fix that for us

618
00:51:01,869 --> 00:51:09,200
and connected car yes these are things
that will kill people with your car

619
00:51:09,200 --> 00:51:10,230
start

620
00:51:10,230 --> 00:51:15,869
we are very interested in area you know
there's a lot of other agencies involved

621
00:51:15,869 --> 00:51:22,320
there's also a lot of US troops there

622
00:51:22,320 --> 00:51:25,510
industry groups that are involved and so
we're trying to take a survey to

623
00:51:25,510 --> 00:51:29,810
understand what the state of the system
is what things like cars and runs things

624
00:51:29,810 --> 00:51:43,970
that can hit in the head a bad thing I
would add to that you know it's a really

625
00:51:43,970 --> 00:51:47,100
interesting evolution what's happening
in the connected car space from the

626
00:51:47,100 --> 00:51:50,799
privacy and security perspective over
the last year you have the industry

627
00:51:50,800 --> 00:51:56,420
coming together you have them getting
some privacy self reg that's interesting

628
00:51:56,420 --> 00:51:57,250
to look at

629
00:51:57,250 --> 00:52:01,320
doesn't really touch this sort of public
safety security vulnerability problem

630
00:52:01,320 --> 00:52:06,800
that you're talking about and I you know
I think they're now looking at and more

631
00:52:06,800 --> 00:52:12,190
aware and increasingly aware of that as
an issue that they're going to need to

632
00:52:12,190 --> 00:52:18,180
tackle certainly we're gonna continue to
want to work carefully on

633
00:52:18,180 --> 00:52:27,259
protecting consumers security and safety
in the IOT space required perfect

634
00:52:27,260 --> 00:52:35,280
security required process and reasonable
security and this analysis has a number

635
00:52:35,280 --> 00:52:44,340
of factors harm to consumers the
benefits so we're still trying to really

636
00:52:44,340 --> 00:52:49,940
engage so the more were informed the
better and so I think we're done thank

637
00:52:49,940 --> 00:52:51,780
you very much for coming and if you want

