1
00:00:01,700 --> 00:00:04,810
[Music]

2
00:00:07,460 --> 00:00:10,019
hello black hat and thank you for

3
00:00:10,019 --> 00:00:12,960
joining us on our talk on leveraging the

4
00:00:12,960 --> 00:00:14,400
endpoint security framework for

5
00:00:14,400 --> 00:00:17,520
Behavioral detections I'm Jaren Bradley

6
00:00:17,520 --> 00:00:19,380
I'm here presenting with my co-worker

7
00:00:19,380 --> 00:00:22,080
Matt benyo we both work at jamf threat

8
00:00:22,080 --> 00:00:24,480
Labs where we focus on finding new ways

9
00:00:24,480 --> 00:00:27,240
to detect malicious activity on Mac OS

10
00:00:27,240 --> 00:00:30,599
devices over the past few years this has

11
00:00:30,599 --> 00:00:32,520
meant leaning pretty heavily into the

12
00:00:32,520 --> 00:00:34,380
apple and Point Security framework and

13
00:00:34,380 --> 00:00:36,420
today we wanted to share a bit about

14
00:00:36,420 --> 00:00:38,340
where we've found success with

15
00:00:38,340 --> 00:00:40,800
monitoring for applications that are

16
00:00:40,800 --> 00:00:43,800
behaving in ways that they shouldn't be

17
00:00:43,800 --> 00:00:46,020
so if you're here there's a good chance

18
00:00:46,020 --> 00:00:47,520
that you probably know a thing or two

19
00:00:47,520 --> 00:00:49,200
about the endpoint security framework

20
00:00:49,200 --> 00:00:51,719
but regardless of your level of exposure

21
00:00:51,719 --> 00:00:53,879
we're going to take a step back and put

22
00:00:53,879 --> 00:00:56,399
it into context so what is the endpoint

23
00:00:56,399 --> 00:00:58,559
security framework

24
00:00:58,559 --> 00:01:00,660
so if you're building an endpoint

25
00:01:00,660 --> 00:01:02,160
security tool for an operating system

26
00:01:02,160 --> 00:01:04,920
you really need two basic things the

27
00:01:04,920 --> 00:01:07,380
first is a source of information about

28
00:01:07,380 --> 00:01:09,180
events that are happening in the

29
00:01:09,180 --> 00:01:10,740
operating system that feeds into your

30
00:01:10,740 --> 00:01:13,020
analysis and detections

31
00:01:13,020 --> 00:01:16,080
and the second is the ability to act on

32
00:01:16,080 --> 00:01:19,200
detections to exert Authority that could

33
00:01:19,200 --> 00:01:21,540
be killing a process or preventing a

34
00:01:21,540 --> 00:01:24,119
file from being deleted or modified and

35
00:01:24,119 --> 00:01:25,140
so on

36
00:01:25,140 --> 00:01:27,659
and historically the kernel the heart of

37
00:01:27,659 --> 00:01:28,979
the operating system is the place where

38
00:01:28,979 --> 00:01:30,840
we would go to access this data and

39
00:01:30,840 --> 00:01:32,580
exert this Authority

40
00:01:32,580 --> 00:01:34,799
so until recently if you're developing

41
00:01:34,799 --> 00:01:36,720
an endpoint security tool for Mac OS

42
00:01:36,720 --> 00:01:39,420
you'd build a kernel extension and you

43
00:01:39,420 --> 00:01:42,060
had at your disposal to do so the open

44
00:01:42,060 --> 00:01:44,280
BSM audit Trail for your event

45
00:01:44,280 --> 00:01:47,640
information you had the chaos kernel

46
00:01:47,640 --> 00:01:49,439
programming interface for your controls

47
00:01:49,439 --> 00:01:51,840
which was a bit limited and there's also

48
00:01:51,840 --> 00:01:53,759
the mandatory Access Control framework

49
00:01:53,759 --> 00:01:55,920
which had the controls that vendors are

50
00:01:55,920 --> 00:01:58,860
looking for but it was unsupported

51
00:01:58,860 --> 00:02:01,140
undocumented and ostensibly off limits

52
00:02:01,140 --> 00:02:02,880
to anyone but Apple

53
00:02:02,880 --> 00:02:05,159
so the thing is even by Apple's

54
00:02:05,159 --> 00:02:07,200
admission kernel extensions are

55
00:02:07,200 --> 00:02:10,139
difficult to develop and maintain and

56
00:02:10,139 --> 00:02:11,760
ultimately they can create new security

57
00:02:11,760 --> 00:02:14,220
vulnerabilities because even a minor bug

58
00:02:14,220 --> 00:02:17,819
can lead to things like kernel panics

59
00:02:17,819 --> 00:02:20,400
so these limitations really have served

60
00:02:20,400 --> 00:02:23,459
as a big obstacle to innovation in Mac

61
00:02:23,459 --> 00:02:25,680
OS security so

62
00:02:25,680 --> 00:02:27,780
in an effort to secure their kernel to

63
00:02:27,780 --> 00:02:29,220
give security vendors what they need to

64
00:02:29,220 --> 00:02:32,340
build Tools in 10.15 apple introduced

65
00:02:32,340 --> 00:02:35,040
the endpoint security framework

66
00:02:35,040 --> 00:02:37,080
and in doing so they are effectively

67
00:02:37,080 --> 00:02:39,840
serving up in user space and event info

68
00:02:39,840 --> 00:02:42,959
Rich event information source and the

69
00:02:42,959 --> 00:02:45,780
controls to act on detections all

70
00:02:45,780 --> 00:02:47,400
without adding any additional

71
00:02:47,400 --> 00:02:49,319
instability in the kernel

72
00:02:49,319 --> 00:02:50,940
so instead of

73
00:02:50,940 --> 00:02:53,280
kernel extensions vendors can now build

74
00:02:53,280 --> 00:02:56,160
system extensions that exist in user

75
00:02:56,160 --> 00:02:57,540
space

76
00:02:57,540 --> 00:02:59,879
and the way this works is that when an

77
00:02:59,879 --> 00:03:01,140
event occurs

78
00:03:01,140 --> 00:03:03,239
the kernel sends information to all of

79
00:03:03,239 --> 00:03:05,220
the third-party system extensions that

80
00:03:05,220 --> 00:03:07,379
are subscribed to a particular event

81
00:03:07,379 --> 00:03:09,660
things like process creates and exits

82
00:03:09,660 --> 00:03:11,819
file creates unlinks Mount events that

83
00:03:11,819 --> 00:03:13,440
type of stuff

84
00:03:13,440 --> 00:03:16,379
most ESF events come in two different

85
00:03:16,379 --> 00:03:18,360
varieties you have notification events

86
00:03:18,360 --> 00:03:20,099
and you have authorization events they

87
00:03:20,099 --> 00:03:22,019
both deliver the same information but

88
00:03:22,019 --> 00:03:24,720
notify events are simply meant to inform

89
00:03:24,720 --> 00:03:26,580
so they let the system extension know

90
00:03:26,580 --> 00:03:28,500
that Something's Happened and the system

91
00:03:28,500 --> 00:03:30,599
extension can use that information in

92
00:03:30,599 --> 00:03:32,400
whatever way it sees fit maybe it pops

93
00:03:32,400 --> 00:03:35,099
an alert to a console or maybe it's

94
00:03:35,099 --> 00:03:37,500
forwarding data to a Sim

95
00:03:37,500 --> 00:03:40,379
by contrast authorization events

96
00:03:40,379 --> 00:03:43,920
actually hold up activity at the kernel

97
00:03:43,920 --> 00:03:46,440
so the extension evaluates event data

98
00:03:46,440 --> 00:03:48,480
with its detection logic and determines

99
00:03:48,480 --> 00:03:51,780
whether this process should proceed

100
00:03:51,780 --> 00:03:54,120
when an event fails the system extension

101
00:03:54,120 --> 00:03:56,519
checks the system extension sends the

102
00:03:56,519 --> 00:03:58,140
deny response and the operation is

103
00:03:58,140 --> 00:04:00,599
terminated now of course this is just a

104
00:04:00,599 --> 00:04:02,040
visual representation for illustration

105
00:04:02,040 --> 00:04:04,379
as the window for all this to occur is

106
00:04:04,379 --> 00:04:06,420
incredibly brief to maintain performance

107
00:04:06,420 --> 00:04:09,500
and user experience

108
00:04:09,599 --> 00:04:11,519
so static detections have been around

109
00:04:11,519 --> 00:04:13,560
since the early days of antivirus and

110
00:04:13,560 --> 00:04:15,060
they continue to stick around because

111
00:04:15,060 --> 00:04:17,160
they're an effective means of detecting

112
00:04:17,160 --> 00:04:20,220
malware based on the way the auth events

113
00:04:20,220 --> 00:04:22,260
work ESF complements static base

114
00:04:22,260 --> 00:04:24,900
blocking very nicely while the execution

115
00:04:24,900 --> 00:04:27,120
of event is on hold a third-party

116
00:04:27,120 --> 00:04:28,919
extension can quickly scan it decide

117
00:04:28,919 --> 00:04:31,800
whether or not to allow it to execute

118
00:04:31,800 --> 00:04:33,360
um so what are the some of the static

119
00:04:33,360 --> 00:04:35,220
behaviors that can be scanned in this

120
00:04:35,220 --> 00:04:36,720
small time window well it can be a

121
00:04:36,720 --> 00:04:38,639
variety of things but if we're going to

122
00:04:38,639 --> 00:04:40,020
prevent something we better be really

123
00:04:40,020 --> 00:04:42,600
sure that it's uh not something I should

124
00:04:42,600 --> 00:04:44,340
be allowed to run because once again the

125
00:04:44,340 --> 00:04:46,259
last thing we want to do is ruin the

126
00:04:46,259 --> 00:04:48,900
user's Mac OS experience so for this

127
00:04:48,900 --> 00:04:50,759
reason uh traditional kind of indicators

128
00:04:50,759 --> 00:04:53,580
of compromise work really well team IDs

129
00:04:53,580 --> 00:04:55,560
or developers that have been identified

130
00:04:55,560 --> 00:04:58,860
as malicious in the past uh is a is an

131
00:04:58,860 --> 00:05:00,780
easy thing to quickly look up and block

132
00:05:00,780 --> 00:05:03,540
file hashes you know file Fingerprints

133
00:05:03,540 --> 00:05:06,120
of known malware and then of course Yara

134
00:05:06,120 --> 00:05:08,400
rules work fantastic as well allowing us

135
00:05:08,400 --> 00:05:10,860
to scan for byte byte patterns or

136
00:05:10,860 --> 00:05:14,040
strings and and blocking if we see ones

137
00:05:14,040 --> 00:05:15,780
that we don't like there's of course

138
00:05:15,780 --> 00:05:17,580
other options such as machine learning

139
00:05:17,580 --> 00:05:19,680
algorithms but again ultimately whatever

140
00:05:19,680 --> 00:05:21,840
you end up testing against needs to

141
00:05:21,840 --> 00:05:24,900
return a result almost instantly

142
00:05:24,900 --> 00:05:27,780
so this leads naturally to the focus of

143
00:05:27,780 --> 00:05:29,699
our talk which is behavioral detections

144
00:05:29,699 --> 00:05:31,860
and this idea of a behavioral detection

145
00:05:31,860 --> 00:05:34,620
has been around for a while and they've

146
00:05:34,620 --> 00:05:36,780
increased in value as security vendors

147
00:05:36,780 --> 00:05:39,479
have really refined uh developing a

148
00:05:39,479 --> 00:05:41,280
baseline of what normal application

149
00:05:41,280 --> 00:05:43,080
activity looks like as opposed to things

150
00:05:43,080 --> 00:05:45,720
that are more suspicious or nefarious

151
00:05:45,720 --> 00:05:47,880
so the downside to this type of a

152
00:05:47,880 --> 00:05:49,680
detection is that they tend to have a

153
00:05:49,680 --> 00:05:51,539
higher false positive ratio because

154
00:05:51,539 --> 00:05:53,280
we're looking at a broader pattern of

155
00:05:53,280 --> 00:05:54,780
activity as opposed to something more

156
00:05:54,780 --> 00:05:57,180
objective like a file hash

157
00:05:57,180 --> 00:06:00,120
but when these are executed correctly

158
00:06:00,120 --> 00:06:02,280
it's a worthy trade-off because it

159
00:06:02,280 --> 00:06:04,080
allows us to identify things like

160
00:06:04,080 --> 00:06:06,479
malware that we haven't seen before or

161
00:06:06,479 --> 00:06:08,520
activity patterns that really haven't

162
00:06:08,520 --> 00:06:10,740
been seen before

163
00:06:10,740 --> 00:06:12,840
so to give an example

164
00:06:12,840 --> 00:06:15,060
um we'll call this one a fake file

165
00:06:15,060 --> 00:06:16,320
extension and we'll start with something

166
00:06:16,320 --> 00:06:19,199
really straightforward here so in this

167
00:06:19,199 --> 00:06:21,539
example a user goes to finder in their

168
00:06:21,539 --> 00:06:24,139
temp directory and they discover

169
00:06:24,139 --> 00:06:28,020
a PDF called a DOT PDF now a single

170
00:06:28,020 --> 00:06:30,180
letter PDF in the temp file is probably

171
00:06:30,180 --> 00:06:32,880
weird enough to detect on on its own but

172
00:06:32,880 --> 00:06:35,580
we can take a closer look at this and

173
00:06:35,580 --> 00:06:37,740
when they examine this file they would

174
00:06:37,740 --> 00:06:40,740
discover that this is actually a Mako

175
00:06:40,740 --> 00:06:42,479
executable

176
00:06:42,479 --> 00:06:43,880
so

177
00:06:43,880 --> 00:06:46,020
masquerading file extensions using

178
00:06:46,020 --> 00:06:47,460
contradictory file extensions in this

179
00:06:47,460 --> 00:06:48,840
way is one of the oldest tricks in the

180
00:06:48,840 --> 00:06:51,600
book uh attackers will use this method

181
00:06:51,600 --> 00:06:53,160
to try and blend in with the user's

182
00:06:53,160 --> 00:06:55,740
files or the operating system and

183
00:06:55,740 --> 00:06:57,419
somewhat ironically these kind of cheap

184
00:06:57,419 --> 00:06:59,759
evasive maneuvers lead to some of our

185
00:06:59,759 --> 00:07:01,139
best detections because they're hard to

186
00:07:01,139 --> 00:07:04,699
justify in a benign context

187
00:07:05,460 --> 00:07:07,680
so as you can see all we really did here

188
00:07:07,680 --> 00:07:09,539
was take the behavior of a file being

189
00:07:09,539 --> 00:07:12,000
created or written to Temp and perform

190
00:07:12,000 --> 00:07:14,039
some additional checks to determine if

191
00:07:14,039 --> 00:07:15,900
it was actually of any interest so truth

192
00:07:15,900 --> 00:07:17,580
be told like benyo said some of these

193
00:07:17,580 --> 00:07:19,740
might be interesting by themselves for

194
00:07:19,740 --> 00:07:21,840
instance a PDF extension on an

195
00:07:21,840 --> 00:07:23,880
executable it's probably a detection by

196
00:07:23,880 --> 00:07:26,400
itself but if we want to take additional

197
00:07:26,400 --> 00:07:29,340
kind of odd behaviors like oh this is

198
00:07:29,340 --> 00:07:31,860
this is in the temp directory or this

199
00:07:31,860 --> 00:07:33,660
has a single letter file name these are

200
00:07:33,660 --> 00:07:35,220
all just kind of strange things if we

201
00:07:35,220 --> 00:07:37,020
want to further kind of enhance and

202
00:07:37,020 --> 00:07:38,639
tighten up detections we could look for

203
00:07:38,639 --> 00:07:40,740
multiple things like this to create one

204
00:07:40,740 --> 00:07:42,900
detection

205
00:07:42,900 --> 00:07:44,819
we'll demonstrate a slightly more

206
00:07:44,819 --> 00:07:46,979
in-depth example of one of these

207
00:07:46,979 --> 00:07:49,020
detections with something we call p-list

208
00:07:49,020 --> 00:07:50,880
disguised as Apple

209
00:07:50,880 --> 00:07:54,360
so inside of the system Library launch

210
00:07:54,360 --> 00:07:57,060
agents directory a launch agent is

211
00:07:57,060 --> 00:07:59,400
something that will run generally run at

212
00:07:59,400 --> 00:08:01,740
startup on the system when your system

213
00:08:01,740 --> 00:08:05,280
boots and here we have what a launch

214
00:08:05,280 --> 00:08:06,720
agent should look like

215
00:08:06,720 --> 00:08:09,840
This one belongs to the Mac OS diagnose

216
00:08:09,840 --> 00:08:12,479
agent we actually tell this by simply

217
00:08:12,479 --> 00:08:13,919
looking at the file name Apple

218
00:08:13,919 --> 00:08:16,680
encourages developers to follow suit and

219
00:08:16,680 --> 00:08:18,840
name all launch agents and daemons using

220
00:08:18,840 --> 00:08:21,419
a reverse domain name notation so by

221
00:08:21,419 --> 00:08:24,379
looking at the file called

222
00:08:24,379 --> 00:08:27,240
com.apple.diagnose agent.plist we should

223
00:08:27,240 --> 00:08:29,520
immediately know that this P list is

224
00:08:29,520 --> 00:08:31,199
part of the operating system and belongs

225
00:08:31,199 --> 00:08:33,539
to Apple so a long time ago malware

226
00:08:33,539 --> 00:08:35,159
authors caught on to this fact as well

227
00:08:35,159 --> 00:08:36,839
so they began calling their malicious

228
00:08:36,839 --> 00:08:39,500
demons and

229
00:08:39,500 --> 00:08:41,120
agents.com.apple.fill in the blank

230
00:08:41,120 --> 00:08:43,679
causing those agents to blend in with

231
00:08:43,679 --> 00:08:46,819
the operating system as well

232
00:08:47,220 --> 00:08:50,040
so if we look inside this file we see

233
00:08:50,040 --> 00:08:52,320
that this agent will launch this

234
00:08:52,320 --> 00:08:54,540
diagnose helper this is an uh this

235
00:08:54,540 --> 00:08:56,820
executable is an apple binary and

236
00:08:56,820 --> 00:09:01,160
properly signed by Apple as it should be

237
00:09:01,680 --> 00:09:03,959
so let's take a look at how this can be

238
00:09:03,959 --> 00:09:07,019
counterfeited or abused by attackers so

239
00:09:07,019 --> 00:09:09,480
what we'll be looking for is in the user

240
00:09:09,480 --> 00:09:12,720
launch agents or launch demons directory

241
00:09:12,720 --> 00:09:14,700
an addition of a new plist that's the

242
00:09:14,700 --> 00:09:16,440
first thing we detect on but then we

243
00:09:16,440 --> 00:09:19,320
look to see are they using a com.apple

244
00:09:19,320 --> 00:09:21,959
identifier in the file name and truth be

245
00:09:21,959 --> 00:09:23,820
told we could stop right here if there's

246
00:09:23,820 --> 00:09:25,620
something that's outside of the sit

247
00:09:25,620 --> 00:09:28,740
protected system launch agents directory

248
00:09:28,740 --> 00:09:30,959
and it's in the users folder that's

249
00:09:30,959 --> 00:09:32,459
probably suspicious enough to take a

250
00:09:32,459 --> 00:09:34,140
look at but we have found some false

251
00:09:34,140 --> 00:09:36,540
positives that hit this so we can refine

252
00:09:36,540 --> 00:09:38,459
this detection by doing some additional

253
00:09:38,459 --> 00:09:40,560
checks so what we do is we look at that

254
00:09:40,560 --> 00:09:44,220
P list and we scope in on the executable

255
00:09:44,220 --> 00:09:46,620
that this intends to run at login and

256
00:09:46,620 --> 00:09:48,000
that's going to give us a path so we can

257
00:09:48,000 --> 00:09:50,580
go to the executable at that path and we

258
00:09:50,580 --> 00:09:54,120
can run a code signing check and if this

259
00:09:54,120 --> 00:09:57,060
is something that's using a com.apple p

260
00:09:57,060 --> 00:09:59,399
list we should hope or expect that this

261
00:09:59,399 --> 00:10:01,260
is an executable that's also owned by

262
00:10:01,260 --> 00:10:04,260
Apple and in this case the code signing

263
00:10:04,260 --> 00:10:06,420
information comes back is unsigned and

264
00:10:06,420 --> 00:10:07,920
that is highly suspicious something that

265
00:10:07,920 --> 00:10:09,959
we can confidently trigger a detection

266
00:10:09,959 --> 00:10:12,240
on for further analysis

267
00:10:12,240 --> 00:10:14,640
so this has been a really reliable

268
00:10:14,640 --> 00:10:16,920
detection over the years it is worth

269
00:10:16,920 --> 00:10:19,380
pointing out though that when this these

270
00:10:19,380 --> 00:10:21,360
days when we see this triggered it's

271
00:10:21,360 --> 00:10:23,220
generally one of the newer Espionage

272
00:10:23,220 --> 00:10:25,200
focused applications this is something

273
00:10:25,200 --> 00:10:27,360
that adware used to do a lot but I think

274
00:10:27,360 --> 00:10:29,100
that they spend so much time in the

275
00:10:29,100 --> 00:10:30,899
trenches and they've been caught by so

276
00:10:30,899 --> 00:10:32,279
many different security products using

277
00:10:32,279 --> 00:10:33,720
this technique that's something that

278
00:10:33,720 --> 00:10:36,680
they've moved away from

279
00:10:37,140 --> 00:10:39,420
so so far we've talked quite a bit about

280
00:10:39,420 --> 00:10:41,100
different behaviors and checks to

281
00:10:41,100 --> 00:10:43,200
perform with file activity let's get

282
00:10:43,200 --> 00:10:44,940
into a bit of background on what

283
00:10:44,940 --> 00:10:46,740
suspicious process activity looks like

284
00:10:46,740 --> 00:10:48,959
so we're going to give an example here

285
00:10:48,959 --> 00:10:51,660
by showing off a single exec event let's

286
00:10:51,660 --> 00:10:53,100
say that you're maybe a threat Hunter

287
00:10:53,100 --> 00:10:56,160
you're in Splunk and you encounter a

288
00:10:56,160 --> 00:10:58,980
process execution events in this example

289
00:10:58,980 --> 00:11:01,200
we're just demoing with a simple cut

290
00:11:01,200 --> 00:11:02,519
command

291
00:11:02,519 --> 00:11:04,380
so for those that aren't familiar with

292
00:11:04,380 --> 00:11:06,600
the cut command it's generally used to

293
00:11:06,600 --> 00:11:08,160
splice data passed to it from another

294
00:11:08,160 --> 00:11:10,380
command by itself it really tells us

295
00:11:10,380 --> 00:11:12,899
absolutely nothing we're going to show

296
00:11:12,899 --> 00:11:14,700
here how we can use other fields in this

297
00:11:14,700 --> 00:11:17,040
event to get the context of what's

298
00:11:17,040 --> 00:11:20,120
happening on the system

299
00:11:21,180 --> 00:11:23,040
so next we'll use the parent process ID

300
00:11:23,040 --> 00:11:24,959
and grab the process that ran the cut

301
00:11:24,959 --> 00:11:27,360
command it it's primarily a tool meant

302
00:11:27,360 --> 00:11:29,399
to be used within a shell so it comes as

303
00:11:29,399 --> 00:11:32,519
no surprise that the parent is zsh in

304
00:11:32,519 --> 00:11:34,920
this case where we really start to gain

305
00:11:34,920 --> 00:11:37,620
some useful context here is when we take

306
00:11:37,620 --> 00:11:39,959
this same event and we look up the

307
00:11:39,959 --> 00:11:42,000
responsible PID which in this case

308
00:11:42,000 --> 00:11:45,660
points to terminal dot app as we can see

309
00:11:45,660 --> 00:11:48,240
this process ID starts to paint a better

310
00:11:48,240 --> 00:11:50,579
picture so far we've determined that the

311
00:11:50,579 --> 00:11:52,560
user opened a terminal their shell of

312
00:11:52,560 --> 00:11:55,560
choice is the default zsh and they

313
00:11:55,560 --> 00:11:58,380
executed cut however as I stated earlier

314
00:11:58,380 --> 00:12:01,140
this still there's still more to this

315
00:12:01,140 --> 00:12:04,019
picture and cut by itself isn't super

316
00:12:04,019 --> 00:12:05,940
helpful to us but at least we know that

317
00:12:05,940 --> 00:12:07,620
this was likely a user because it was

318
00:12:07,620 --> 00:12:10,140
executed through a terminal GUI

319
00:12:10,140 --> 00:12:11,640
application

320
00:12:11,640 --> 00:12:14,220
but uh by taking the process group ID

321
00:12:14,220 --> 00:12:16,740
value in this event we can determine

322
00:12:16,740 --> 00:12:19,380
what the process group ID leader of this

323
00:12:19,380 --> 00:12:20,640
command was

324
00:12:20,640 --> 00:12:24,720
this PID value is fairly uh fairly well

325
00:12:24,720 --> 00:12:25,800
known

326
00:12:25,800 --> 00:12:26,459
um

327
00:12:26,459 --> 00:12:27,839
but it gets less attention than it

328
00:12:27,839 --> 00:12:30,300
deserves in fret hunting not only can we

329
00:12:30,300 --> 00:12:32,880
grab what process was at the front of a

330
00:12:32,880 --> 00:12:34,800
set of piped commands in this case

331
00:12:34,800 --> 00:12:37,560
system profiler but we can also perform

332
00:12:37,560 --> 00:12:40,079
a search to see all processes that share

333
00:12:40,079 --> 00:12:42,060
this same process group ID essentially

334
00:12:42,060 --> 00:12:44,399
rebuilding the exact command that was

335
00:12:44,399 --> 00:12:46,800
executed so this approach can't always

336
00:12:46,800 --> 00:12:49,079
be taken as we're demoing an example

337
00:12:49,079 --> 00:12:50,579
here where a standard job control

338
00:12:50,579 --> 00:12:53,100
behavior is in place but overall this is

339
00:12:53,100 --> 00:12:54,300
a pretty good way to go about getting

340
00:12:54,300 --> 00:12:56,760
the context of how a group of commands

341
00:12:56,760 --> 00:12:59,279
was executed in this case we can see

342
00:12:59,279 --> 00:13:01,019
that the executed command was one that

343
00:13:01,019 --> 00:13:03,000
gets used to grab a Serial ID of the

344
00:13:03,000 --> 00:13:06,779
device it's run on and it gets used by

345
00:13:06,779 --> 00:13:09,240
both legitimate apps and scripts as well

346
00:13:09,240 --> 00:13:12,860
as some malware performing Recon

347
00:13:13,579 --> 00:13:17,040
a session is a collection of process

348
00:13:17,040 --> 00:13:19,260
groups and a session ID points us to the

349
00:13:19,260 --> 00:13:21,120
process that's in control of those

350
00:13:21,120 --> 00:13:22,560
groups and this is where we can kind of

351
00:13:22,560 --> 00:13:24,779
go and get some additional context of

352
00:13:24,779 --> 00:13:27,600
what actually ran inside the terminal

353
00:13:27,600 --> 00:13:30,000
so in this case it belongs to the login

354
00:13:30,000 --> 00:13:32,880
process which the terminal runs upon

355
00:13:32,880 --> 00:13:36,420
execution before the shell is chosen

356
00:13:36,420 --> 00:13:38,519
so from a single event that shows a

357
00:13:38,519 --> 00:13:40,139
simple cut command occurring we were

358
00:13:40,139 --> 00:13:42,240
able to use all the PID fields to

359
00:13:42,240 --> 00:13:44,399
determine the exact context of what's

360
00:13:44,399 --> 00:13:46,680
happening and then with some simple

361
00:13:46,680 --> 00:13:48,540
lookups we can even sort out the command

362
00:13:48,540 --> 00:13:52,260
history that ran here in this terminal

363
00:13:52,260 --> 00:13:54,360
so let's take a look at an attack

364
00:13:54,360 --> 00:13:56,459
behavior that can be uncovered using

365
00:13:56,459 --> 00:13:57,720
some of these techniques that we just

366
00:13:57,720 --> 00:13:59,820
discussed

367
00:13:59,820 --> 00:14:01,740
so in this particular demonstration

368
00:14:01,740 --> 00:14:04,860
we're looking at a popular form of a

369
00:14:04,860 --> 00:14:07,380
living off the land technique so in this

370
00:14:07,380 --> 00:14:10,139
technique the attacker will host a

371
00:14:10,139 --> 00:14:12,959
script on their server and they will

372
00:14:12,959 --> 00:14:14,579
curl that down on the victim machine but

373
00:14:14,579 --> 00:14:17,519
pipe it directly to an interpreter on

374
00:14:17,519 --> 00:14:19,079
the system

375
00:14:19,079 --> 00:14:20,579
the reason that this is an attractive

376
00:14:20,579 --> 00:14:22,800
technique is because in doing so no

377
00:14:22,800 --> 00:14:25,260
malicious files exist on the disk

378
00:14:25,260 --> 00:14:27,120
therefore you can really sidestep most

379
00:14:27,120 --> 00:14:30,180
static detections this way as the script

380
00:14:30,180 --> 00:14:33,680
really only exists in memory

381
00:14:33,720 --> 00:14:36,720
now while this doesn't create files it's

382
00:14:36,720 --> 00:14:39,060
not entirely untraceable if you have

383
00:14:39,060 --> 00:14:40,920
that URL and the server still up you

384
00:14:40,920 --> 00:14:42,540
could go for example this is the Mythic

385
00:14:42,540 --> 00:14:43,980
agent that would be hosted on This

386
00:14:43,980 --> 00:14:46,740
Server by Cody Thomas that's still

387
00:14:46,740 --> 00:14:48,000
available but you're creating that extra

388
00:14:48,000 --> 00:14:50,399
step and really going to sidestep any

389
00:14:50,399 --> 00:14:52,920
detections aren't looking for this type

390
00:14:52,920 --> 00:14:56,420
of a technique specifically

391
00:14:56,940 --> 00:14:59,579
so if we now look for applescript which

392
00:14:59,579 --> 00:15:01,019
is The Interpreter in this case being

393
00:15:01,019 --> 00:15:02,639
run and we check for it in the process

394
00:15:02,639 --> 00:15:03,660
history

395
00:15:03,660 --> 00:15:06,660
we'll see that it's running with no

396
00:15:06,660 --> 00:15:08,639
arguments it's just running as Osa

397
00:15:08,639 --> 00:15:10,940
script

398
00:15:11,100 --> 00:15:14,399
so to use ESF data to track this type of

399
00:15:14,399 --> 00:15:16,680
activity what we would look for is the

400
00:15:16,680 --> 00:15:18,720
execution of The Interpreter in this

401
00:15:18,720 --> 00:15:21,480
case Osa script or apple script and if

402
00:15:21,480 --> 00:15:23,459
you look down below in the command you

403
00:15:23,459 --> 00:15:25,680
would see that it has no path to a

404
00:15:25,680 --> 00:15:27,720
script no additional commands which is a

405
00:15:27,720 --> 00:15:29,820
pretty good giveaway that whatever is

406
00:15:29,820 --> 00:15:31,920
running this the script was piped

407
00:15:31,920 --> 00:15:34,740
directly to The Interpreter in this way

408
00:15:34,740 --> 00:15:37,800
so the way that we can start to uncover

409
00:15:37,800 --> 00:15:40,320
this of what piped to Osa script is by

410
00:15:40,320 --> 00:15:42,720
looking at that process group ID so if

411
00:15:42,720 --> 00:15:44,579
we follow that process group ID we see

412
00:15:44,579 --> 00:15:46,680
that it leads us

413
00:15:46,680 --> 00:15:48,959
to the curl command

414
00:15:48,959 --> 00:15:51,420
and once we have this link we are

415
00:15:51,420 --> 00:15:53,279
confident that this type of a living off

416
00:15:53,279 --> 00:15:54,899
the land technique was being used at

417
00:15:54,899 --> 00:15:56,699
least to the point of popping an alert

418
00:15:56,699 --> 00:15:59,719
for further analysis

419
00:15:59,760 --> 00:16:01,680
so let's walk through another sample

420
00:16:01,680 --> 00:16:03,480
that drives home the use case of once

421
00:16:03,480 --> 00:16:05,459
again the process group ID

422
00:16:05,459 --> 00:16:08,160
uh Spotlight is functionality on Mac OS

423
00:16:08,160 --> 00:16:10,320
that indexes files and documents as

424
00:16:10,320 --> 00:16:12,959
they're created it does this by indexing

425
00:16:12,959 --> 00:16:15,779
it does this indexing by taking keywords

426
00:16:15,779 --> 00:16:18,360
uh found in those documents and making

427
00:16:18,360 --> 00:16:21,000
them easily findable in a search so when

428
00:16:21,000 --> 00:16:23,459
you press command and spacebar you can

429
00:16:23,459 --> 00:16:25,199
punch in a keyword and easily find the

430
00:16:25,199 --> 00:16:27,180
document you were looking for even if

431
00:16:27,180 --> 00:16:28,680
you can't remember where you saved it

432
00:16:28,680 --> 00:16:30,839
this is a super useful feature I use it

433
00:16:30,839 --> 00:16:32,940
all the time but any feature that's

434
00:16:32,940 --> 00:16:35,459
useful for us is generally also useful

435
00:16:35,459 --> 00:16:37,980
for an attacker

436
00:16:37,980 --> 00:16:40,560
so mdfind is the command line equivalent

437
00:16:40,560 --> 00:16:43,800
of using this Spotlight functionality so

438
00:16:43,800 --> 00:16:45,420
an attacker can easily search for

439
00:16:45,420 --> 00:16:47,279
different keywords and attempts to try

440
00:16:47,279 --> 00:16:49,500
and find files on the hard drive that

441
00:16:49,500 --> 00:16:51,120
contain these keywords such as maybe

442
00:16:51,120 --> 00:16:54,180
password routing and account or

443
00:16:54,180 --> 00:16:56,579
confidential

444
00:16:56,579 --> 00:16:59,040
so an attacker once on the system might

445
00:16:59,040 --> 00:17:00,720
use a command that looks something like

446
00:17:00,720 --> 00:17:03,120
this where basically they run mdfind

447
00:17:03,120 --> 00:17:04,859
they get a list of files back that

448
00:17:04,859 --> 00:17:06,780
contain the word confidential and then

449
00:17:06,780 --> 00:17:08,459
they take each one of those files and

450
00:17:08,459 --> 00:17:11,099
pipe them immediately to an archive and

451
00:17:11,099 --> 00:17:12,839
now they just have to X fill that

452
00:17:12,839 --> 00:17:16,079
archive and they have a giant archive

453
00:17:16,079 --> 00:17:19,399
full of confidential files

454
00:17:21,240 --> 00:17:23,699
so in order to detect this happening

455
00:17:23,699 --> 00:17:26,040
what we would look for is the execution

456
00:17:26,040 --> 00:17:28,620
of one of the built-in archive Tools in

457
00:17:28,620 --> 00:17:31,380
this example it's tar so then the next

458
00:17:31,380 --> 00:17:34,080
question is we ask what is the process

459
00:17:34,080 --> 00:17:36,900
group idea of this tar execution and in

460
00:17:36,900 --> 00:17:39,360
this case following this process group

461
00:17:39,360 --> 00:17:43,080
ID would lead us naturally to MD find

462
00:17:43,080 --> 00:17:45,480
and when this link has been made we can

463
00:17:45,480 --> 00:17:48,299
be reasonably confident that tar was run

464
00:17:48,299 --> 00:17:50,640
at a string of commands that started

465
00:17:50,640 --> 00:17:52,740
with mdfine and this technique was

466
00:17:52,740 --> 00:17:54,840
likely being used to the point where we

467
00:17:54,840 --> 00:17:57,419
can pop an alert for further analysis

468
00:17:57,419 --> 00:17:59,700
it's worth pointing out though that this

469
00:17:59,700 --> 00:18:01,980
technique while interesting is limited

470
00:18:01,980 --> 00:18:05,760
to what's available uh outside of the

471
00:18:05,760 --> 00:18:08,460
full disk aspect asset aspect of the

472
00:18:08,460 --> 00:18:10,620
transparent transparency consent and

473
00:18:10,620 --> 00:18:12,720
controls there's still some useful

474
00:18:12,720 --> 00:18:14,760
things we'll get a little bit more into

475
00:18:14,760 --> 00:18:19,340
TCC in one of our advanced detections

476
00:18:19,980 --> 00:18:21,480
so we've talked a bit about what we'd

477
00:18:21,480 --> 00:18:23,520
call Standard detections now we'd like

478
00:18:23,520 --> 00:18:24,780
to get in some detections that require

479
00:18:24,780 --> 00:18:27,360
significantly more checks to determine

480
00:18:27,360 --> 00:18:31,280
applications uh behaving Anonymous

481
00:18:31,280 --> 00:18:34,080
anonymously all three detections we'll

482
00:18:34,080 --> 00:18:35,880
talk about here were developed after we

483
00:18:35,880 --> 00:18:38,100
discovered or learned about a zero day

484
00:18:38,100 --> 00:18:41,160
vulnerability and then we went and found

485
00:18:41,160 --> 00:18:43,919
a way to detect those vulnerability if

486
00:18:43,919 --> 00:18:46,020
those vulnerabilities were ever abused

487
00:18:46,020 --> 00:18:47,760
so everything we'll cover here has since

488
00:18:47,760 --> 00:18:49,160
been patched

489
00:18:49,160 --> 00:18:51,780
but we still wanted to make sure before

490
00:18:51,780 --> 00:18:53,280
those patches occurred that we were

491
00:18:53,280 --> 00:18:55,260
detecting them should it happen

492
00:18:55,260 --> 00:18:57,179
so the first we're going to touch on is

493
00:18:57,179 --> 00:18:59,940
a gatekeeper bypass from a while back so

494
00:18:59,940 --> 00:19:03,000
a number of different bypasses have come

495
00:19:03,000 --> 00:19:04,919
to lights over the course of this year

496
00:19:04,919 --> 00:19:07,140
revolving around file quarantine and

497
00:19:07,140 --> 00:19:08,940
gatekeeper these are both security

498
00:19:08,940 --> 00:19:11,460
features built into Mac OS that exist to

499
00:19:11,460 --> 00:19:13,740
help users ensure they're only running

500
00:19:13,740 --> 00:19:16,440
code that's properly been signed by a

501
00:19:16,440 --> 00:19:19,559
trusted developer and notarized in this

502
00:19:19,559 --> 00:19:21,360
slide we see that a user is downloaded

503
00:19:21,360 --> 00:19:24,179
and ran an app called toxic.app this

504
00:19:24,179 --> 00:19:25,500
would result

505
00:19:25,500 --> 00:19:26,520
um

506
00:19:26,520 --> 00:19:29,460
uh in this gatekeeper prompt uh of

507
00:19:29,460 --> 00:19:31,320
something like this primarily because

508
00:19:31,320 --> 00:19:33,240
the app is completely unsigned and

509
00:19:33,240 --> 00:19:35,880
therefore untrusted

510
00:19:35,880 --> 00:19:38,039
so last year Cedric Owens discovered a

511
00:19:38,039 --> 00:19:39,840
method that allowed apps to incorrectly

512
00:19:39,840 --> 00:19:41,520
pass gatekeeper checks he actually did

513
00:19:41,520 --> 00:19:43,559
talk about this here at black hat

514
00:19:43,559 --> 00:19:45,539
um so we created a detection when we

515
00:19:45,539 --> 00:19:47,640
heard about this vulnerability and soon

516
00:19:47,640 --> 00:19:49,620
discovered a variant of the Slayer

517
00:19:49,620 --> 00:19:53,100
malware abusing it in the wild

518
00:19:53,100 --> 00:19:55,740
so before abusing this bypass Slayer

519
00:19:55,740 --> 00:19:57,240
developers had to convince you to

520
00:19:57,240 --> 00:19:59,460
override gatekeeper because they didn't

521
00:19:59,460 --> 00:20:01,620
want to sign the malware they would

522
00:20:01,620 --> 00:20:04,020
convince users to override gatekeeper by

523
00:20:04,020 --> 00:20:05,940
literally providing instructions for the

524
00:20:05,940 --> 00:20:08,100
override process within their installer

525
00:20:08,100 --> 00:20:09,900
graphics

526
00:20:09,900 --> 00:20:11,280
so this simply consists of

527
00:20:11,280 --> 00:20:13,320
right-clicking the application selecting

528
00:20:13,320 --> 00:20:15,240
open rather than double clicking on it

529
00:20:15,240 --> 00:20:17,340
it seems very basic but we see users

530
00:20:17,340 --> 00:20:19,160
fall for this all the time

531
00:20:19,160 --> 00:20:21,900
we do see that this still results in

532
00:20:21,900 --> 00:20:24,179
some prompts informing the user that

533
00:20:24,179 --> 00:20:25,559
this app was downloaded from the

534
00:20:25,559 --> 00:20:27,660
internet but ultimately they're given

535
00:20:27,660 --> 00:20:30,059
the option to go forward with it if

536
00:20:30,059 --> 00:20:31,620
they'd like to when right clicking on

537
00:20:31,620 --> 00:20:33,918
the app

538
00:20:33,960 --> 00:20:35,880
so that's what the old Slayer malware

539
00:20:35,880 --> 00:20:37,740
installer looked like here's what the

540
00:20:37,740 --> 00:20:40,500
Slayer malware with gatekeeper with the

541
00:20:40,500 --> 00:20:42,900
gatekeeper bypass embedded in it looked

542
00:20:42,900 --> 00:20:43,559
like

543
00:20:43,559 --> 00:20:45,480
uh it's just a simple double click on

544
00:20:45,480 --> 00:20:47,400
the downloaded application and it's game

545
00:20:47,400 --> 00:20:49,260
over for the user they didn't have to

546
00:20:49,260 --> 00:20:51,660
write click the application nor click

547
00:20:51,660 --> 00:20:54,360
through various prompt warnings uh this

548
00:20:54,360 --> 00:20:55,740
completely unsigned malware would

549
00:20:55,740 --> 00:20:57,480
execute and perform a bunch of

550
00:20:57,480 --> 00:20:59,460
background activities while the user was

551
00:20:59,460 --> 00:21:01,980
none the wiser

552
00:21:01,980 --> 00:21:03,840
an additional note to make here is that

553
00:21:03,840 --> 00:21:06,299
although this looked like a PKG

554
00:21:06,299 --> 00:21:07,919
installer it was actually just a

555
00:21:07,919 --> 00:21:10,559
weaponized application that used a PKG

556
00:21:10,559 --> 00:21:13,260
icon but how did the bypass actually

557
00:21:13,260 --> 00:21:16,679
work it worked in cases where an

558
00:21:16,679 --> 00:21:18,539
application did not contain an

559
00:21:18,539 --> 00:21:20,580
info.plist file

560
00:21:20,580 --> 00:21:23,940
uh and it used a script as its primary

561
00:21:23,940 --> 00:21:26,039
payload so if these two things were true

562
00:21:26,039 --> 00:21:28,080
it would be given a stamp of approval

563
00:21:28,080 --> 00:21:30,120
from the gatekeeper Security check and

564
00:21:30,120 --> 00:21:33,360
it would be allowed to execute

565
00:21:33,360 --> 00:21:35,880
so let's rewind a little bit and think

566
00:21:35,880 --> 00:21:36,780
about

567
00:21:36,780 --> 00:21:38,820
how we could actually detect this so

568
00:21:38,820 --> 00:21:41,340
first of all when an application is

569
00:21:41,340 --> 00:21:43,260
launched by double clicking it sends a

570
00:21:43,260 --> 00:21:45,000
message to launch D which then goes on

571
00:21:45,000 --> 00:21:46,980
to open the application so that's the

572
00:21:46,980 --> 00:21:48,960
thing that we would look for is launch D

573
00:21:48,960 --> 00:21:51,360
being the parent process now obviously

574
00:21:51,360 --> 00:21:53,760
most of the processes are running on the

575
00:21:53,760 --> 00:21:56,220
system have a parent of launch D but by

576
00:21:56,220 --> 00:21:57,780
including this in the detection we can

577
00:21:57,780 --> 00:22:01,559
reduce false positives so our next check

578
00:22:01,559 --> 00:22:03,840
is to be checking to ensure that we're

579
00:22:03,840 --> 00:22:05,340
actually dealing with an application

580
00:22:05,340 --> 00:22:08,039
bundle this can be done by analyzing the

581
00:22:08,039 --> 00:22:09,720
command line while the app was double

582
00:22:09,720 --> 00:22:10,799
clicked

583
00:22:10,799 --> 00:22:13,980
but what we can do very easily is look

584
00:22:13,980 --> 00:22:16,080
for this Telltale string in the command

585
00:22:16,080 --> 00:22:19,380
line arguments of dot app slash contents

586
00:22:19,380 --> 00:22:22,440
slash Mac OS if we see this string we're

587
00:22:22,440 --> 00:22:24,600
confident that we're dealing with an

588
00:22:24,600 --> 00:22:27,199
application

589
00:22:29,940 --> 00:22:32,460
so next we're going to ensure that the

590
00:22:32,460 --> 00:22:34,679
process that was running was actually a

591
00:22:34,679 --> 00:22:36,720
built-in interpreter so what we did was

592
00:22:36,720 --> 00:22:39,000
we essentially looked for any of the

593
00:22:39,000 --> 00:22:40,919
built-in interpreters at the time there

594
00:22:40,919 --> 00:22:42,120
were a couple more that have since been

595
00:22:42,120 --> 00:22:43,740
deprecated but these are all the ones

596
00:22:43,740 --> 00:22:45,659
that are available and in the Slayer

597
00:22:45,659 --> 00:22:47,460
example it was actually bash that was

598
00:22:47,460 --> 00:22:49,700
running

599
00:22:51,299 --> 00:22:53,340
so the next thing we'll do is we want to

600
00:22:53,340 --> 00:22:55,140
make sure since a requirement of this

601
00:22:55,140 --> 00:22:56,940
bypass was that the executable was a

602
00:22:56,940 --> 00:22:59,039
script we'll look at the executable to

603
00:22:59,039 --> 00:23:00,480
ensure that it wasn't some type of a

604
00:23:00,480 --> 00:23:02,039
macho binary that it was actually a

605
00:23:02,039 --> 00:23:03,960
script so you could do this via API

606
00:23:03,960 --> 00:23:06,000
check magic bytes whatever your

607
00:23:06,000 --> 00:23:09,020
particular flavor is

608
00:23:10,860 --> 00:23:13,080
and then lastly we want to make sure

609
00:23:13,080 --> 00:23:14,700
that we're catching this at the moment

610
00:23:14,700 --> 00:23:16,679
that it's being looked at by gatekeeper

611
00:23:16,679 --> 00:23:18,120
and for this we relied on a particular

612
00:23:18,120 --> 00:23:20,820
Quirk of Gatekeepers so to mitigate a

613
00:23:20,820 --> 00:23:23,640
different vulnerability when you double

614
00:23:23,640 --> 00:23:24,960
click on an application that's in

615
00:23:24,960 --> 00:23:27,900
something like a DMG gatekeeper will

616
00:23:27,900 --> 00:23:30,419
actually move that to a randomized file

617
00:23:30,419 --> 00:23:32,520
path to prevent it from accessing

618
00:23:32,520 --> 00:23:35,159
external resources and this particular

619
00:23:35,159 --> 00:23:39,960
feature is called app translocation

620
00:23:39,960 --> 00:23:42,539
so that's what we'll look for to ensure

621
00:23:42,539 --> 00:23:44,340
that this is happening at the moment of

622
00:23:44,340 --> 00:23:46,140
a gatekeeper inspection that will

623
00:23:46,140 --> 00:23:49,740
incorrectly pass checks

624
00:23:49,740 --> 00:23:51,659
so let's take a quick look at what all

625
00:23:51,659 --> 00:23:53,940
this looks like from an ESF perspective

626
00:23:53,940 --> 00:23:56,220
notice here that we can almost do all

627
00:23:56,220 --> 00:23:58,140
the checks required once again by

628
00:23:58,140 --> 00:24:00,539
pivoting around on a single exec event

629
00:24:00,539 --> 00:24:02,580
so the first thing we're going to do is

630
00:24:02,580 --> 00:24:05,220
check that the parent is launch d

631
00:24:05,220 --> 00:24:07,140
uh next we're going to take a look at

632
00:24:07,140 --> 00:24:09,059
the command line arguments and make sure

633
00:24:09,059 --> 00:24:13,380
a application is referenced within them

634
00:24:13,380 --> 00:24:15,059
uh instead of checking the command line

635
00:24:15,059 --> 00:24:17,580
arguments we could also check the script

636
00:24:17,580 --> 00:24:20,640
field that ESF provides on execution uh

637
00:24:20,640 --> 00:24:22,980
but uh in this case we do see that the

638
00:24:22,980 --> 00:24:24,780
application is referenced inside the

639
00:24:24,780 --> 00:24:26,880
command line arguments so next we'll

640
00:24:26,880 --> 00:24:29,159
grab the path of the executable being

641
00:24:29,159 --> 00:24:31,440
exact to see if it matches an

642
00:24:31,440 --> 00:24:33,000
interpreter language which in this case

643
00:24:33,000 --> 00:24:36,419
it does we see that it's been Bash

644
00:24:36,419 --> 00:24:38,460
and then we will take the application

645
00:24:38,460 --> 00:24:40,620
from the command line arguments and

646
00:24:40,620 --> 00:24:43,140
check to ensure that it's not a macho as

647
00:24:43,140 --> 00:24:45,240
of course for this bypass we only care

648
00:24:45,240 --> 00:24:47,400
about scripts because that's all that

649
00:24:47,400 --> 00:24:48,960
worked

650
00:24:48,960 --> 00:24:52,080
so finally as mentioned before uh we're

651
00:24:52,080 --> 00:24:54,000
going to check that this app is being

652
00:24:54,000 --> 00:24:56,039
analyzed by gatekeeper as we only want

653
00:24:56,039 --> 00:24:57,720
to trigger at the time that the

654
00:24:57,720 --> 00:25:00,480
gatekeeper bypass is occurring so you

655
00:25:00,480 --> 00:25:02,159
can actually use a script as your main

656
00:25:02,159 --> 00:25:04,080
payload in an application Apple does

657
00:25:04,080 --> 00:25:06,419
allow for that uh but when when

658
00:25:06,419 --> 00:25:07,980
something like this happens we want to

659
00:25:07,980 --> 00:25:10,260
trigger on this at the time of bypasses

660
00:25:10,260 --> 00:25:12,240
if the user still continues to want to

661
00:25:12,240 --> 00:25:13,799
run this in the future that's that's up

662
00:25:13,799 --> 00:25:16,100
to them

663
00:25:18,120 --> 00:25:19,980
so this is the detection we put into

664
00:25:19,980 --> 00:25:21,360
action when we heard the zero day

665
00:25:21,360 --> 00:25:23,580
existed and almost immediately as we

666
00:25:23,580 --> 00:25:25,380
pushed it out we detected the Slayer

667
00:25:25,380 --> 00:25:28,380
malware uh dropper triggering in various

668
00:25:28,380 --> 00:25:30,240
environments which tells us malicious

669
00:25:30,240 --> 00:25:32,880
authors do see value in evading these

670
00:25:32,880 --> 00:25:34,799
gatekeeper checks and do see value in

671
00:25:34,799 --> 00:25:36,480
not having to take the time to sign code

672
00:25:36,480 --> 00:25:38,640
or pay for any type of you know code

673
00:25:38,640 --> 00:25:41,360
signing fee

674
00:25:41,580 --> 00:25:43,799
so next we're going to touch on a TCC

675
00:25:43,799 --> 00:25:45,840
bypass which we hinted at a little bit

676
00:25:45,840 --> 00:25:48,360
earlier as we showed

677
00:25:48,360 --> 00:25:52,080
um earlier TCC is uh is kind of a

678
00:25:52,080 --> 00:25:54,000
feature where users can grant specific

679
00:25:54,000 --> 00:25:56,640
applications permissions to do specific

680
00:25:56,640 --> 00:25:59,279
things such as capture keyboard input

681
00:25:59,279 --> 00:26:02,460
record the mic or record the screen so

682
00:26:02,460 --> 00:26:04,140
when an application attempts to perform

683
00:26:04,140 --> 00:26:07,020
an action such as record the screen the

684
00:26:07,020 --> 00:26:08,820
user is prompted asking if they want to

685
00:26:08,820 --> 00:26:12,779
approve this action for the application

686
00:26:12,779 --> 00:26:14,580
so perhaps one of the more concerning

687
00:26:14,580 --> 00:26:16,080
times where we've seen this prompt

688
00:26:16,080 --> 00:26:18,720
bypassed was in the Wild by the XCS set

689
00:26:18,720 --> 00:26:21,659
malware zero day usage isn't new for

690
00:26:21,659 --> 00:26:23,340
this malware in fact it was using two

691
00:26:23,340 --> 00:26:25,400
other zero days at the time as well

692
00:26:25,400 --> 00:26:27,480
specifically we're going to focus in on

693
00:26:27,480 --> 00:26:29,820
the Zero date it would attempt to use in

694
00:26:29,820 --> 00:26:32,039
order to gain screen sharing permissions

695
00:26:32,039 --> 00:26:34,440
uh the malware would start by looking

696
00:26:34,440 --> 00:26:36,840
for a list of various applications that

697
00:26:36,840 --> 00:26:39,360
already exist on the system and likely

698
00:26:39,360 --> 00:26:42,240
hold that screen recording permission in

699
00:26:42,240 --> 00:26:43,740
the malware code it referred to these

700
00:26:43,740 --> 00:26:46,260
applications as donor apps

701
00:26:46,260 --> 00:26:48,299
among these applications was of course

702
00:26:48,299 --> 00:26:50,760
Zoom since at this point many users have

703
00:26:50,760 --> 00:26:53,159
had installed zoom on on their systems

704
00:26:53,159 --> 00:26:55,320
to remotely share their screens and for

705
00:26:55,320 --> 00:26:57,000
that purpose it would have the screen

706
00:26:57,000 --> 00:26:59,220
sharing permission already uh what the

707
00:26:59,220 --> 00:27:01,380
app malware authors discovered is that

708
00:27:01,380 --> 00:27:03,419
if they placed an application bundle

709
00:27:03,419 --> 00:27:06,179
within an already existing application

710
00:27:06,179 --> 00:27:07,260
bundle

711
00:27:07,260 --> 00:27:09,020
we'll call this

712
00:27:09,020 --> 00:27:11,220
update.app in this case they could

713
00:27:11,220 --> 00:27:13,559
actually piggyback off the permissions

714
00:27:13,559 --> 00:27:16,980
of that the existing bundle held

715
00:27:16,980 --> 00:27:19,140
so if we go back to the TCC settings

716
00:27:19,140 --> 00:27:20,880
this is effectively what would now be

717
00:27:20,880 --> 00:27:22,980
taking place however the piggybacking

718
00:27:22,980 --> 00:27:26,000
application would gain the permissions

719
00:27:26,000 --> 00:27:28,320
it would gain the permissions but it

720
00:27:28,320 --> 00:27:30,360
would not show up in this list of

721
00:27:30,360 --> 00:27:33,960
software as able to do so so uh now all

722
00:27:33,960 --> 00:27:35,460
the attacker had to do was record the

723
00:27:35,460 --> 00:27:37,200
screen and no prompts would be displayed

724
00:27:37,200 --> 00:27:40,260
to the user I think an important

725
00:27:40,260 --> 00:27:42,360
takeaway here is that many don't think

726
00:27:42,360 --> 00:27:43,980
anyone's going to take the time on Mac

727
00:27:43,980 --> 00:27:46,860
OS to bypass these type of restrictions

728
00:27:46,860 --> 00:27:49,919
when in fact malware has already taken

729
00:27:49,919 --> 00:27:51,360
the time to try and find ways around

730
00:27:51,360 --> 00:27:54,240
this to remain more stealthy this was

731
00:27:54,240 --> 00:27:56,880
all also done via applescript malware by

732
00:27:56,880 --> 00:27:59,220
the way which uh some some might argue

733
00:27:59,220 --> 00:28:02,640
makes this even more impressive

734
00:28:02,640 --> 00:28:05,400
so when this malware runs it will

735
00:28:05,400 --> 00:28:07,559
trigger an endpoint security framework

736
00:28:07,559 --> 00:28:09,000
exec event

737
00:28:09,000 --> 00:28:11,520
and the way that we would detect this is

738
00:28:11,520 --> 00:28:13,080
to look for that application being

739
00:28:13,080 --> 00:28:15,720
opened and we'd look at the path to

740
00:28:15,720 --> 00:28:17,279
First determine that we're dealing with

741
00:28:17,279 --> 00:28:18,840
an application

742
00:28:18,840 --> 00:28:20,580
and the next thing we'll check to see is

743
00:28:20,580 --> 00:28:23,700
to see is that application nested inside

744
00:28:23,700 --> 00:28:25,860
of another application

745
00:28:25,860 --> 00:28:27,779
now keep in mind Zoom is just the

746
00:28:27,779 --> 00:28:29,760
example here in theory it could be any

747
00:28:29,760 --> 00:28:31,919
application that had the desired TCC

748
00:28:31,919 --> 00:28:34,640
permissions

749
00:28:35,340 --> 00:28:38,520
so now that we have an outer app and an

750
00:28:38,520 --> 00:28:40,080
inner application we can start to treat

751
00:28:40,080 --> 00:28:42,059
those as two separate things and it's

752
00:28:42,059 --> 00:28:43,440
worth pointing out that it's totally

753
00:28:43,440 --> 00:28:45,179
legal for developers to do this it's

754
00:28:45,179 --> 00:28:46,860
it's a normal behavior to put one app

755
00:28:46,860 --> 00:28:49,679
inside of another application however we

756
00:28:49,679 --> 00:28:51,299
would expect that the signing

757
00:28:51,299 --> 00:28:52,919
information of those two applications

758
00:28:52,919 --> 00:28:55,980
would match so that's how we were able

759
00:28:55,980 --> 00:28:58,799
to look for this being done illicitly so

760
00:28:58,799 --> 00:29:00,960
you check the donor application give it

761
00:29:00,960 --> 00:29:02,760
a code signing check in this case it's

762
00:29:02,760 --> 00:29:04,799
the Zoom app it's a price surprise it's

763
00:29:04,799 --> 00:29:07,799
signed by Zoom legitimately so then next

764
00:29:07,799 --> 00:29:09,539
we want to check the inner application

765
00:29:09,539 --> 00:29:12,360
and we should expect that also to be

766
00:29:12,360 --> 00:29:14,279
signed by Zoom if this is a legitimate

767
00:29:14,279 --> 00:29:17,220
update app and in the case of the XCS at

768
00:29:17,220 --> 00:29:19,799
malware it came back as signed ad hoc

769
00:29:19,799 --> 00:29:23,220
which was a huge red flag

770
00:29:23,220 --> 00:29:25,620
so that's the detection we're looking

771
00:29:25,620 --> 00:29:28,679
for an application being executed we're

772
00:29:28,679 --> 00:29:30,600
looking for that application to be

773
00:29:30,600 --> 00:29:32,399
nested inside of another application

774
00:29:32,399 --> 00:29:35,100
then we check the outer application

775
00:29:35,100 --> 00:29:36,899
signing information and see that it's

776
00:29:36,899 --> 00:29:39,480
legitimate and for the inner application

777
00:29:39,480 --> 00:29:41,000
when we check that signing information

778
00:29:41,000 --> 00:29:43,440
if it's illegitimate we'd see one of

779
00:29:43,440 --> 00:29:45,600
three cases a mismatched team ID that

780
00:29:45,600 --> 00:29:47,580
doesn't match the outer app signed ad

781
00:29:47,580 --> 00:29:49,799
hoc or not signed at all and if those

782
00:29:49,799 --> 00:29:51,960
conditions are met we confidently pop an

783
00:29:51,960 --> 00:29:55,399
alert for further analysis

784
00:29:55,799 --> 00:29:58,740
so let's talk about one last gatekeeper

785
00:29:58,740 --> 00:30:00,659
bypass that we were able to detect and

786
00:30:00,659 --> 00:30:02,460
this vulnerability was actually found by

787
00:30:02,460 --> 00:30:05,640
jamf's own for Dao seljuki and he was

788
00:30:05,640 --> 00:30:07,980
attributed on a cve when this was

789
00:30:07,980 --> 00:30:09,840
patched by Apple

790
00:30:09,840 --> 00:30:11,640
so to understand this particular bypass

791
00:30:11,640 --> 00:30:13,679
we first have to quickly break down some

792
00:30:13,679 --> 00:30:16,260
of the basics of how Safari works so

793
00:30:16,260 --> 00:30:18,779
when Safari is used to download a file

794
00:30:18,779 --> 00:30:20,279
especially something like a zip file

795
00:30:20,279 --> 00:30:22,260
with an application in it you may have

796
00:30:22,260 --> 00:30:24,419
noticed that it hits the downloads

797
00:30:24,419 --> 00:30:26,159
folder and is almost instantaneously

798
00:30:26,159 --> 00:30:28,020
unzipped this is the default behavior

799
00:30:28,020 --> 00:30:31,500
and this is part of a feature in Safari

800
00:30:31,500 --> 00:30:33,539
called open safe files for downloading

801
00:30:33,539 --> 00:30:36,059
it's what Apple deems to save files and

802
00:30:36,059 --> 00:30:37,320
probably part of the thinking around

803
00:30:37,320 --> 00:30:38,820
this is something like an application

804
00:30:38,820 --> 00:30:40,919
while it feels like a file is actually a

805
00:30:40,919 --> 00:30:43,919
directory bundle and can't be downloaded

806
00:30:43,919 --> 00:30:45,960
directly so often you'll see

807
00:30:45,960 --> 00:30:47,640
applications that are zipped up in this

808
00:30:47,640 --> 00:30:49,799
way and using this Auto unzip feature

809
00:30:49,799 --> 00:30:52,140
kind of abstracts that away so it feels

810
00:30:52,140 --> 00:30:56,480
uh more logical to an end user

811
00:30:57,840 --> 00:31:01,380
so if we quickly rewind uh once again

812
00:31:01,380 --> 00:31:03,179
and then watch all of this in slow

813
00:31:03,179 --> 00:31:05,159
motion using the endpoint security

814
00:31:05,159 --> 00:31:08,220
framework what we would actually see is

815
00:31:08,220 --> 00:31:10,799
that after the archive download occurs

816
00:31:10,799 --> 00:31:13,559
Through Safari the Safari sandbox is

817
00:31:13,559 --> 00:31:15,600
actually what's responsible for creating

818
00:31:15,600 --> 00:31:17,940
a temporary directory and then handling

819
00:31:17,940 --> 00:31:19,980
the unzipping of that archive into that

820
00:31:19,980 --> 00:31:22,020
directory

821
00:31:22,020 --> 00:31:24,720
so the Safari sandbox then takes the

822
00:31:24,720 --> 00:31:26,520
quarantine extended attribute and

823
00:31:26,520 --> 00:31:28,559
applies it to the newly unzipped

824
00:31:28,559 --> 00:31:29,880
application

825
00:31:29,880 --> 00:31:31,559
this part's actually very important

826
00:31:31,559 --> 00:31:33,360
because when an application is opened

827
00:31:33,360 --> 00:31:34,799
for the first time its extended

828
00:31:34,799 --> 00:31:37,380
attributes are checked by the system if

829
00:31:37,380 --> 00:31:39,299
this quarantine extended attribute is on

830
00:31:39,299 --> 00:31:41,820
the opened application the system knows

831
00:31:41,820 --> 00:31:42,899
that it needs to be checked by

832
00:31:42,899 --> 00:31:46,699
gatekeeper upon its first launch

833
00:31:47,159 --> 00:31:49,140
so while we're browsing the internet in

834
00:31:49,140 --> 00:31:50,820
search of malware we encountered a

835
00:31:50,820 --> 00:31:53,220
Gaming website that was hosting games in

836
00:31:53,220 --> 00:31:56,640
application form via zip archives so

837
00:31:56,640 --> 00:31:58,620
after we downloaded these games we

838
00:31:58,620 --> 00:32:00,539
noticed that they were somehow bypassing

839
00:32:00,539 --> 00:32:03,000
Gatekeepers prompts despite being

840
00:32:03,000 --> 00:32:05,760
completely unsigned so after further

841
00:32:05,760 --> 00:32:07,919
investigation we actually noticed that

842
00:32:07,919 --> 00:32:09,659
the extended attribute was not being

843
00:32:09,659 --> 00:32:11,700
placed on the application directory

844
00:32:11,700 --> 00:32:14,580
itself it was only being applied to the

845
00:32:14,580 --> 00:32:16,980
recursive contents under that app and as

846
00:32:16,980 --> 00:32:19,380
it turns out gatekeeper only cares about

847
00:32:19,380 --> 00:32:21,179
whether that application has a

848
00:32:21,179 --> 00:32:25,260
quarantine mark on it or not

849
00:32:25,260 --> 00:32:28,020
so we notice that this wasn't actually

850
00:32:28,020 --> 00:32:29,940
happening if we downloaded the

851
00:32:29,940 --> 00:32:32,580
application via another browser and then

852
00:32:32,580 --> 00:32:35,039
unzipped it manually all the quarantine

853
00:32:35,039 --> 00:32:37,440
attributes would appear as expected in

854
00:32:37,440 --> 00:32:39,179
in this type of scenario

855
00:32:39,179 --> 00:32:41,159
so this told us the issue lied somewhere

856
00:32:41,159 --> 00:32:44,820
in the Safari Auto unzipper itself

857
00:32:44,820 --> 00:32:46,620
not only that but we also noticed that

858
00:32:46,620 --> 00:32:48,480
if we used Apple's built-in ditto

859
00:32:48,480 --> 00:32:51,059
command to unzip our own archive it

860
00:32:51,059 --> 00:32:53,039
would also result in the same quarantine

861
00:32:53,039 --> 00:32:55,559
bug this told us the bug likely goes

862
00:32:55,559 --> 00:32:57,240
much deeper on the operating system

863
00:32:57,240 --> 00:32:59,340
somewhere as it was affecting at least

864
00:32:59,340 --> 00:33:03,439
two different unarchiving Technologies

865
00:33:03,720 --> 00:33:06,480
so as it uh as it turned out this issue

866
00:33:06,480 --> 00:33:08,159
existed within the bill of materials

867
00:33:08,159 --> 00:33:10,500
functionality a bill of materials is

868
00:33:10,500 --> 00:33:12,779
think of it like a receipt for all files

869
00:33:12,779 --> 00:33:15,000
that maybe an installer or archive

870
00:33:15,000 --> 00:33:17,640
leaves on the system logically this

871
00:33:17,640 --> 00:33:19,559
receipt technology ties really well to

872
00:33:19,559 --> 00:33:22,440
PKG installers uh however Mac OS also

873
00:33:22,440 --> 00:33:25,320
builds references builds and references

874
00:33:25,320 --> 00:33:29,279
uh a bomb for zip files as well it's

875
00:33:29,279 --> 00:33:32,519
just not very well documented anywhere

876
00:33:32,519 --> 00:33:35,640
so upon unarchiving the application from

877
00:33:35,640 --> 00:33:38,519
a normal zip file the bomb seen on the

878
00:33:38,519 --> 00:33:41,279
right here will keep track of each file

879
00:33:41,279 --> 00:33:43,620
that gets unarchived the unarchiving

880
00:33:43,620 --> 00:33:46,500
logic then goes through each file uh in

881
00:33:46,500 --> 00:33:48,000
the bomb and applies the quarantine

882
00:33:48,000 --> 00:33:50,580
attribute fittingly

883
00:33:50,580 --> 00:33:53,460
so one big thing we noticed analyzing a

884
00:33:53,460 --> 00:33:55,500
normal zipped application in a hex

885
00:33:55,500 --> 00:33:57,720
editor is that the first zip file header

886
00:33:57,720 --> 00:34:00,600
starts at the root application directory

887
00:34:00,600 --> 00:34:03,000
the quarantine attribute would always be

888
00:34:03,000 --> 00:34:06,720
applied as expected in this case but the

889
00:34:06,720 --> 00:34:08,339
zip files we are downloading from the

890
00:34:08,339 --> 00:34:10,679
internet were unknowingly bypassing

891
00:34:10,679 --> 00:34:12,199
gatekeeper

892
00:34:12,199 --> 00:34:14,820
and on the other hand they were missing

893
00:34:14,820 --> 00:34:17,580
this root level header

894
00:34:17,580 --> 00:34:19,619
and instead they started at the

895
00:34:19,619 --> 00:34:23,540
applications contents directory

896
00:34:24,659 --> 00:34:27,000
so if we take one of these modified zip

897
00:34:27,000 --> 00:34:30,119
files and remove the top level header

898
00:34:30,119 --> 00:34:32,280
we see here that when the bomb gets

899
00:34:32,280 --> 00:34:35,040
parsed once again on the right

900
00:34:35,040 --> 00:34:37,020
the application root directory would be

901
00:34:37,020 --> 00:34:39,300
missing from the bomb however the

902
00:34:39,300 --> 00:34:41,699
application would continue to unzip and

903
00:34:41,699 --> 00:34:44,418
operate normally

904
00:34:44,520 --> 00:34:46,500
but when the copy quarantine function

905
00:34:46,500 --> 00:34:48,659
gets referenced and it references the

906
00:34:48,659 --> 00:34:50,159
bill of materials to apply the

907
00:34:50,159 --> 00:34:52,440
quarantine attributes it ends up missing

908
00:34:52,440 --> 00:34:54,480
the app directory itself since the bill

909
00:34:54,480 --> 00:34:56,460
of materials at this point was out of

910
00:34:56,460 --> 00:34:58,080
sync

911
00:34:58,080 --> 00:35:00,119
so using the endpoint security framework

912
00:35:00,119 --> 00:35:01,920
again is our foundation how do we go

913
00:35:01,920 --> 00:35:04,320
about detecting this occurring

914
00:35:04,320 --> 00:35:07,020
so we start by looking for a file rename

915
00:35:07,020 --> 00:35:08,520
event we're looking for that moment when

916
00:35:08,520 --> 00:35:10,740
the Safari sandbox broker is moving from

917
00:35:10,740 --> 00:35:12,900
its temp file the new application back

918
00:35:12,900 --> 00:35:15,000
to the downloads folder

919
00:35:15,000 --> 00:35:16,800
then we ensure that it's actually the

920
00:35:16,800 --> 00:35:18,960
Safari sandbox broker that's taking the

921
00:35:18,960 --> 00:35:21,200
action

922
00:35:21,300 --> 00:35:24,000
and then we make we make sure that it's

923
00:35:24,000 --> 00:35:25,440
actually an application that's in

924
00:35:25,440 --> 00:35:28,640
question that's being moved

925
00:35:29,400 --> 00:35:31,500
then we make sure that the original

926
00:35:31,500 --> 00:35:34,859
location is the temporary directory that

927
00:35:34,859 --> 00:35:36,660
the sandbox broker creates when it's

928
00:35:36,660 --> 00:35:38,339
unzipping the file and moving it back to

929
00:35:38,339 --> 00:35:40,440
downloads and then finally we do an

930
00:35:40,440 --> 00:35:42,720
extended attribute lookup to ensure that

931
00:35:42,720 --> 00:35:44,280
the quarantine attribute was actually

932
00:35:44,280 --> 00:35:46,820
applied

933
00:35:47,640 --> 00:35:50,220
so this detection is interesting because

934
00:35:50,220 --> 00:35:51,960
by looking over the shoulder of the

935
00:35:51,960 --> 00:35:53,460
built-in security and ensuring that it's

936
00:35:53,460 --> 00:35:55,740
doing its job as expected we can

937
00:35:55,740 --> 00:35:58,320
generically detect when a gatekeeper

938
00:35:58,320 --> 00:36:00,300
bypass has occurred even if we don't

939
00:36:00,300 --> 00:36:01,920
know what the technique is all we're

940
00:36:01,920 --> 00:36:03,240
looking for is an application that's

941
00:36:03,240 --> 00:36:05,640
being downloaded by the Safari sandbox

942
00:36:05,640 --> 00:36:07,380
broker and yet somehow came away without

943
00:36:07,380 --> 00:36:09,240
a quarantine attribute and really I

944
00:36:09,240 --> 00:36:10,800
think this highlights the beauty of

945
00:36:10,800 --> 00:36:13,020
these behavioral detections because they

946
00:36:13,020 --> 00:36:15,480
can allow us to pick up on techniques

947
00:36:15,480 --> 00:36:19,280
that we haven't even uncovered yet

948
00:36:20,280 --> 00:36:22,560
so that kind of wraps up our talk uh

949
00:36:22,560 --> 00:36:24,660
what we show today is simply one piece

950
00:36:24,660 --> 00:36:26,640
of tooling that feeds off events

951
00:36:26,640 --> 00:36:28,619
provided by the endpoint security

952
00:36:28,619 --> 00:36:31,320
framework but what's great about ESF is

953
00:36:31,320 --> 00:36:32,820
that Apple can focus on providing

954
00:36:32,820 --> 00:36:35,520
visibility into the operating system and

955
00:36:35,520 --> 00:36:37,320
developers can get the power to decide

956
00:36:37,320 --> 00:36:38,400
what should be done with this

957
00:36:38,400 --> 00:36:40,800
information and build detections engines

958
00:36:40,800 --> 00:36:42,300
as well as anything else they can think

959
00:36:42,300 --> 00:36:44,820
of more than anything it's just nice to

960
00:36:44,820 --> 00:36:47,880
have these events that we use come from

961
00:36:47,880 --> 00:36:50,040
that that used to come from various

962
00:36:50,040 --> 00:36:52,920
complex sources now be streamlined in an

963
00:36:52,920 --> 00:36:54,839
organized fashion from Apple so we can

964
00:36:54,839 --> 00:36:57,119
focus on using the events rather than

965
00:36:57,119 --> 00:36:58,740
having to worry about creating them

966
00:36:58,740 --> 00:37:01,560
ourselves and that's what we had thanks

967
00:37:01,560 --> 00:37:04,500
so much for having us

968
00:37:04,500 --> 00:37:06,740
foreign

969
00:37:11,200 --> 00:37:14,310
[Music]

