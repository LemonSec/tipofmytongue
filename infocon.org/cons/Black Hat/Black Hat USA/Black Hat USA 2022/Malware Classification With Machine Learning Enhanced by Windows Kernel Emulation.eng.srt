1
00:00:01,700 --> 00:00:04,810
[Music]

2
00:00:07,519 --> 00:00:11,820
hey everyone uh yeah uh today we will

3
00:00:11,820 --> 00:00:13,799
build we'll be talking about malware

4
00:00:13,799 --> 00:00:15,960
classification through machine learning

5
00:00:15,960 --> 00:00:19,020
specifically how we enhance like known

6
00:00:19,020 --> 00:00:21,180
techniques with a kernel emulation

7
00:00:21,180 --> 00:00:22,920
telemetry

8
00:00:22,920 --> 00:00:26,100
so brief roadmap is that we touch on

9
00:00:26,100 --> 00:00:27,779
let's say known techniques in a public

10
00:00:27,779 --> 00:00:31,740
space that based mostly on a static

11
00:00:31,740 --> 00:00:35,160
analysis of malware file then we touch

12
00:00:35,160 --> 00:00:38,940
briefly our limitations and why this is

13
00:00:38,940 --> 00:00:41,219
not does not provide a full picture to

14
00:00:41,219 --> 00:00:44,460
the ml algorithm and then yeah we will

15
00:00:44,460 --> 00:00:47,460
transit to a hybrid approach and we will

16
00:00:47,460 --> 00:00:49,620
cover specifically techniques behind

17
00:00:49,620 --> 00:00:52,980
like AI modeling embeddings and 1D

18
00:00:52,980 --> 00:00:55,559
convolutions because I assume since

19
00:00:55,559 --> 00:00:57,539
applicability of AI to security is

20
00:00:57,539 --> 00:00:59,219
building a wall problem you need to know

21
00:00:59,219 --> 00:01:02,520
security and AI I assume not much

22
00:01:02,520 --> 00:01:04,559
background in AI Technologies all over

23
00:01:04,559 --> 00:01:06,720
cover them briefly

24
00:01:06,720 --> 00:01:10,020
uh disclaimer due to affiliation uh

25
00:01:10,020 --> 00:01:12,479
since I'm like a software engineer in

26
00:01:12,479 --> 00:01:14,460
Microsoft This research doesn't

27
00:01:14,460 --> 00:01:17,340
represent functionality of mde just in

28
00:01:17,340 --> 00:01:20,280
case there will be correlations it's a

29
00:01:20,280 --> 00:01:23,640
separate team work and yeah so far we

30
00:01:23,640 --> 00:01:26,460
know it doesn't reflect any models used

31
00:01:26,460 --> 00:01:29,600
in FB it's more of a like public

32
00:01:29,600 --> 00:01:32,580
research we we are contributing to the

33
00:01:32,580 --> 00:01:36,540
known techniques in this domain

34
00:01:36,540 --> 00:01:37,200
um

35
00:01:37,200 --> 00:01:40,200
starting with the what we know how how

36
00:01:40,200 --> 00:01:42,920
ml works for malware classification

37
00:01:42,920 --> 00:01:46,560
already a long time ago right for AI

38
00:01:46,560 --> 00:01:49,680
research five years back is is huge time

39
00:01:49,680 --> 00:01:51,899
there was released a great work by

40
00:01:51,899 --> 00:01:54,659
researchers and endgame originally which

41
00:01:54,659 --> 00:01:56,880
later was acquired by elastic they they

42
00:01:56,880 --> 00:01:58,619
now maintain this project it's called

43
00:01:58,619 --> 00:02:02,220
Amber and it basically describes a way

44
00:02:02,220 --> 00:02:05,159
to extract features from a PE file

45
00:02:05,159 --> 00:02:08,780
portable executable file as a byte blob

46
00:02:08,780 --> 00:02:12,300
it's open source you can take a look and

47
00:02:12,300 --> 00:02:16,140
it it captures around a dozen types that

48
00:02:16,140 --> 00:02:18,599
that can extract valuable information

49
00:02:18,599 --> 00:02:21,239
from feed P file like section info

50
00:02:21,239 --> 00:02:24,840
Imports info entropies byte histograms

51
00:02:24,840 --> 00:02:26,160
Etc

52
00:02:26,160 --> 00:02:28,280
uh however

53
00:02:28,280 --> 00:02:31,920
this has its own limitations in fact

54
00:02:31,920 --> 00:02:34,620
this feature extraction scheme works

55
00:02:34,620 --> 00:02:36,860
really well if we

56
00:02:36,860 --> 00:02:39,300
apply it to the general

57
00:02:39,300 --> 00:02:41,879
let's say malware threat landscape

58
00:02:41,879 --> 00:02:44,760
however there are ways to circumvent how

59
00:02:44,760 --> 00:02:46,680
this works one of them is adversarial

60
00:02:46,680 --> 00:02:50,280
machine learning which came to the like

61
00:02:50,280 --> 00:02:53,340
uh acknowledgment of the field from from

62
00:02:53,340 --> 00:02:57,420
computer vision uh back in 2014 uh the

63
00:02:57,420 --> 00:02:59,580
evasion attacks were presented a little

64
00:02:59,580 --> 00:03:02,000
bit earlier there was with any attacks

65
00:03:02,000 --> 00:03:06,900
and how it basically works it's that we

66
00:03:06,900 --> 00:03:10,920
modify an input through an ml model in

67
00:03:10,920 --> 00:03:13,019
some like clever way we generate

68
00:03:13,019 --> 00:03:15,959
perturbations and it completely screws

69
00:03:15,959 --> 00:03:19,800
up how ml model behaves in this example

70
00:03:19,800 --> 00:03:22,440
that was presented in an original paper

71
00:03:22,440 --> 00:03:25,140
we see how like seemingly random noise

72
00:03:25,140 --> 00:03:27,239
can completely circumvent the

73
00:03:27,239 --> 00:03:30,180
functionality of image classifier back

74
00:03:30,180 --> 00:03:32,360
then this

75
00:03:32,360 --> 00:03:35,940
applies to the ml World in malware as

76
00:03:35,940 --> 00:03:36,959
well

77
00:03:36,959 --> 00:03:40,019
for instance there is a group in in a

78
00:03:40,019 --> 00:03:42,180
university of Cavalieri published an

79
00:03:42,180 --> 00:03:45,599
attack of section injection and like

80
00:03:45,599 --> 00:03:47,940
when you add

81
00:03:47,940 --> 00:03:51,840
I run like benign sections to uh already

82
00:03:51,840 --> 00:03:54,720
packed malware already compiled malware

83
00:03:54,720 --> 00:03:58,319
it in fact evades static classifiers uh

84
00:03:58,319 --> 00:04:00,840
with that with a high Invasion ratio the

85
00:04:00,840 --> 00:04:01,920
second problem with the static

86
00:04:01,920 --> 00:04:05,099
classifiers are Packers and uh four

87
00:04:05,099 --> 00:04:07,260
static classifier packed software and

88
00:04:07,260 --> 00:04:11,580
like mid 9 B9 were in malware seems sort

89
00:04:11,580 --> 00:04:13,860
of the same because a lot of properties

90
00:04:13,860 --> 00:04:16,560
that static classifiers extract uh

91
00:04:16,560 --> 00:04:19,880
become ubiquitous amongst the the

92
00:04:19,880 --> 00:04:22,620
malware distribution

93
00:04:22,620 --> 00:04:25,800
so where we can go from here like at

94
00:04:25,800 --> 00:04:27,960
this stage of ml applicability at least

95
00:04:27,960 --> 00:04:30,479
in a public space we know that vendors

96
00:04:30,479 --> 00:04:33,900
do some Dynamic analysis in a closed

97
00:04:33,900 --> 00:04:36,060
proprietary form but public knowledge

98
00:04:36,060 --> 00:04:38,460
and public white papers that has mostly

99
00:04:38,460 --> 00:04:40,740
static applicability with the dynamic

100
00:04:40,740 --> 00:04:43,500
ones limited to a few thousand samples

101
00:04:43,500 --> 00:04:47,460
in a in a prototype way where we do move

102
00:04:47,460 --> 00:04:50,759
from this look on on malware sample in a

103
00:04:50,759 --> 00:04:53,240
static analysis tools like PE Studio

104
00:04:53,240 --> 00:04:57,360
what does human analysts it performs

105
00:04:57,360 --> 00:04:59,360
Dynamic analysis right through debuggers

106
00:04:59,360 --> 00:05:02,040
through detonation of malware in a

107
00:05:02,040 --> 00:05:05,100
controlled environment we absorb spawn

108
00:05:05,100 --> 00:05:08,400
processes we absorb common lines and

109
00:05:08,400 --> 00:05:10,759
API calls

110
00:05:10,759 --> 00:05:13,400
registry access file system access

111
00:05:13,400 --> 00:05:16,380
network connections all this provides

112
00:05:16,380 --> 00:05:18,240
additional insights into functionality

113
00:05:18,240 --> 00:05:21,300
of malware most of this stuff is usually

114
00:05:21,300 --> 00:05:24,020
embedded within

115
00:05:24,020 --> 00:05:27,600
bytes but it can be obfuscated it can be

116
00:05:27,600 --> 00:05:31,380
yeah it is extracted during the runtime

117
00:05:31,380 --> 00:05:33,180
and

118
00:05:33,180 --> 00:05:35,460
Here Comes

119
00:05:35,460 --> 00:05:37,759
or ability to apply

120
00:05:37,759 --> 00:05:41,639
Dynamic analysis to ml world we

121
00:05:41,639 --> 00:05:44,580
uh consider using emulators for this why

122
00:05:44,580 --> 00:05:48,240
because detonating malware in VM is

123
00:05:48,240 --> 00:05:51,060
costly you cannot do this for quantities

124
00:05:51,060 --> 00:05:53,759
beneficial for deep learning you need to

125
00:05:53,759 --> 00:05:56,280
revert contaminated environment you need

126
00:05:56,280 --> 00:05:59,340
to boot up again the full uh like

127
00:05:59,340 --> 00:06:01,979
operating system kernel it takes time it

128
00:06:01,979 --> 00:06:04,199
takes computational resources and

129
00:06:04,199 --> 00:06:06,419
luckily we have a great emulator thanks

130
00:06:06,419 --> 00:06:08,880
to demand the end team research and

131
00:06:08,880 --> 00:06:10,740
development they're doing great job

132
00:06:10,740 --> 00:06:12,560
maintaining Speakeasy development

133
00:06:12,560 --> 00:06:15,600
developing it and it basically allows to

134
00:06:15,600 --> 00:06:18,900
acquire Dynamic Telemetry just in four

135
00:06:18,900 --> 00:06:21,720
lines of code in fact their own data

136
00:06:21,720 --> 00:06:23,460
science team does research in this

137
00:06:23,460 --> 00:06:25,620
direction some insights are are

138
00:06:25,620 --> 00:06:28,560
published in cameras last year so if you

139
00:06:28,560 --> 00:06:30,720
are interested in their work you can

140
00:06:30,720 --> 00:06:33,600
take a look in this reference uh so what

141
00:06:33,600 --> 00:06:35,639
we get from a speakeasy emulation

142
00:06:35,639 --> 00:06:38,160
basically the same information just

143
00:06:38,160 --> 00:06:40,440
purely in Python

144
00:06:40,440 --> 00:06:42,840
yeah network connections

145
00:06:42,840 --> 00:06:46,800
register access file access and like we

146
00:06:46,800 --> 00:06:49,380
can get even data that is written to the

147
00:06:49,380 --> 00:06:52,680
files and of course API calls

148
00:06:52,680 --> 00:06:55,080
uh that's that's only like tip of the

149
00:06:55,080 --> 00:06:57,180
iceberg there are memory segments again

150
00:06:57,180 --> 00:07:01,080
memory segment content and

151
00:07:01,080 --> 00:07:03,360
uh yeah pretty pretty great tool not

152
00:07:03,360 --> 00:07:06,419
only for uh automated analysis with a

153
00:07:06,419 --> 00:07:08,479
model but for manual too

154
00:07:08,479 --> 00:07:11,699
uh and what we do with this data we

155
00:07:11,699 --> 00:07:14,460
basically present this model which

156
00:07:14,460 --> 00:07:17,400
emulates PE

157
00:07:17,400 --> 00:07:19,440
portable executable files from different

158
00:07:19,440 --> 00:07:22,199
points of view first of all we preserve

159
00:07:22,199 --> 00:07:25,319
Amber static features because they are

160
00:07:25,319 --> 00:07:27,840
great we don't know what discard what we

161
00:07:27,840 --> 00:07:30,300
know in this direction they are there

162
00:07:30,300 --> 00:07:33,800
they do a great work in in general

163
00:07:33,800 --> 00:07:36,840
malware distribution however we add

164
00:07:36,840 --> 00:07:38,460
additional arms

165
00:07:38,460 --> 00:07:41,580
uh one arm focuses on API calls

166
00:07:41,580 --> 00:07:44,099
basically we extract a sequence of API

167
00:07:44,099 --> 00:07:46,979
calls from the emulation report which is

168
00:07:46,979 --> 00:07:49,680
the closest way let's say uh

169
00:07:49,680 --> 00:07:51,960
to represent what malware does on the

170
00:07:51,960 --> 00:07:54,060
system

171
00:07:54,060 --> 00:07:54,960
um

172
00:07:54,960 --> 00:07:57,900
in addition to that we take a look on

173
00:07:57,900 --> 00:08:00,900
where malware uh course not malware but

174
00:08:00,900 --> 00:08:03,960
any PE file were located in a system at

175
00:08:03,960 --> 00:08:05,639
the moment of execution

176
00:08:05,639 --> 00:08:08,520
so we collect this data from in the wild

177
00:08:08,520 --> 00:08:12,720
and use to analyze our system as a

178
00:08:12,720 --> 00:08:14,819
contextual parameter because there is a

179
00:08:14,819 --> 00:08:17,520
behavioral pattern of of portable

180
00:08:17,520 --> 00:08:19,199
executable and there is a contextual

181
00:08:19,199 --> 00:08:22,139
part that represents environment

182
00:08:22,139 --> 00:08:26,099
uh all the those three arms basically

183
00:08:26,099 --> 00:08:29,460
work as a feature extractors that

184
00:08:29,460 --> 00:08:32,580
squeeze out the most valuable uh parts

185
00:08:32,580 --> 00:08:34,860
of their input data through the learning

186
00:08:34,860 --> 00:08:38,458
process and in a in the end provide

187
00:08:38,458 --> 00:08:42,000
those cold representations in an AI

188
00:08:42,000 --> 00:08:46,100
World they squeeze out uh

189
00:08:46,100 --> 00:08:49,140
128 dimensional representations of of

190
00:08:49,140 --> 00:08:53,580
their data and provided to the late

191
00:08:53,580 --> 00:08:56,700
model we call it meta model which

192
00:08:56,700 --> 00:08:59,459
actually performs the classification it

193
00:08:59,459 --> 00:09:02,880
takes input from from all three arms and

194
00:09:02,880 --> 00:09:04,560
basically tells from those

195
00:09:04,560 --> 00:09:06,420
representations whether this is a

196
00:09:06,420 --> 00:09:09,320
malware on or B9 wire

197
00:09:09,320 --> 00:09:12,779
uh the data set we used to evaluate this

198
00:09:12,779 --> 00:09:17,339
model looks like this it's around the

199
00:09:17,339 --> 00:09:19,500
training set and validation sets consist

200
00:09:19,500 --> 00:09:21,360
around 100

201
00:09:21,360 --> 00:09:24,180
000 samples uh more of than 300

202
00:09:24,180 --> 00:09:26,100
gigabytes of data

203
00:09:26,100 --> 00:09:28,860
and the test set was collected three

204
00:09:28,860 --> 00:09:31,680
months after acquisition of training set

205
00:09:31,680 --> 00:09:35,940
to evaluate how model performs in the

206
00:09:35,940 --> 00:09:39,000
evasive like evolving thread landscape

207
00:09:39,000 --> 00:09:42,480
and consists roughly of 27 and a half

208
00:09:42,480 --> 00:09:46,080
thousands of of samples

209
00:09:46,080 --> 00:09:48,959
uh the labels were assigned by

210
00:09:48,959 --> 00:09:50,640
professional threat intelligence team

211
00:09:50,640 --> 00:09:54,120
using manual and automated tools and the

212
00:09:54,120 --> 00:09:56,339
single label clean represents a benign

213
00:09:56,339 --> 00:09:58,980
software and all other labels are are

214
00:09:58,980 --> 00:10:00,540
malicious it's

215
00:10:00,540 --> 00:10:02,220
it's not

216
00:10:02,220 --> 00:10:03,180
um

217
00:10:03,180 --> 00:10:06,480
like data set doesn't generalize well

218
00:10:06,480 --> 00:10:09,420
across all malware times types it's not

219
00:10:09,420 --> 00:10:12,300
so crucial for analysis of model uh

220
00:10:12,300 --> 00:10:14,339
because yeah we will we will focus only

221
00:10:14,339 --> 00:10:16,440
on these labels just to analyze how

222
00:10:16,440 --> 00:10:18,180
model works but of course there are

223
00:10:18,180 --> 00:10:20,040
other types of malware which were not

224
00:10:20,040 --> 00:10:23,100
included and if you want to consider

225
00:10:23,100 --> 00:10:25,019
those ideas to build a more General

226
00:10:25,019 --> 00:10:26,120
model

227
00:10:26,120 --> 00:10:28,680
don't select the specific label select

228
00:10:28,680 --> 00:10:30,080
as much as possible

229
00:10:30,080 --> 00:10:32,339
data you can get

230
00:10:32,339 --> 00:10:35,279
uh clean clean labels are relatively

231
00:10:35,279 --> 00:10:38,279
more like uh volumetric to the malware

232
00:10:38,279 --> 00:10:41,360
to balance both both

233
00:10:41,360 --> 00:10:43,800
types of data

234
00:10:43,800 --> 00:10:46,500
uh we passed this data set through an

235
00:10:46,500 --> 00:10:49,740
emulator which presumably would uh like

236
00:10:49,740 --> 00:10:51,839
require a lot of resources to pass

237
00:10:51,839 --> 00:10:54,480
through the VMS but yeah The Demolator

238
00:10:54,480 --> 00:10:57,480
with that in relatively fast emulators

239
00:10:57,480 --> 00:11:00,839
are not perfect they uh

240
00:11:00,839 --> 00:11:04,680
create or or emulate only a subpart of

241
00:11:04,680 --> 00:11:07,260
actual kernel some API calls are not

242
00:11:07,260 --> 00:11:10,079
present or are not implemented therefore

243
00:11:10,079 --> 00:11:12,899
some of the emulation is error knows

244
00:11:12,899 --> 00:11:15,779
however as we observed emulation error

245
00:11:15,779 --> 00:11:19,380
rates are not that prevailing and there

246
00:11:19,380 --> 00:11:23,540
were still pretty good for our analysis

247
00:11:23,640 --> 00:11:24,180
um

248
00:11:24,180 --> 00:11:26,820
where do we head from that we have a

249
00:11:26,820 --> 00:11:30,000
file path and we have an APA call as a

250
00:11:30,000 --> 00:11:33,720
API call sequence uh both problems are

251
00:11:33,720 --> 00:11:36,959
basically the same from the ml modeling

252
00:11:36,959 --> 00:11:39,720
point of view those are these like

253
00:11:39,720 --> 00:11:42,120
sequences first one is encoded as a

254
00:11:42,120 --> 00:11:45,540
utf-8 bytes and form a vector of

255
00:11:45,540 --> 00:11:46,560
integers

256
00:11:46,560 --> 00:11:49,740
uh API calls can be recorded with them

257
00:11:49,740 --> 00:11:52,560
just artificial label map to like where

258
00:11:52,560 --> 00:11:54,480
specific API call represents the

259
00:11:54,480 --> 00:11:56,240
specific integer

260
00:11:56,240 --> 00:11:58,980
therefore we get basically the same

261
00:11:58,980 --> 00:12:00,720
input data of course representing

262
00:12:00,720 --> 00:12:03,380
different information

263
00:12:03,380 --> 00:12:06,060
then these sequences are passed to the

264
00:12:06,060 --> 00:12:08,940
embedding layer what is embeddings what

265
00:12:08,940 --> 00:12:12,959
are embeddings uh those come to the AI

266
00:12:12,959 --> 00:12:15,300
technology World from NLP natural

267
00:12:15,300 --> 00:12:17,700
language processing where

268
00:12:17,700 --> 00:12:21,300
we've seen that embedded tokens when

269
00:12:21,300 --> 00:12:24,140
they are expanded into

270
00:12:24,140 --> 00:12:26,519
embedded Vector space basically what it

271
00:12:26,519 --> 00:12:29,700
does it takes a narrow sequence and

272
00:12:29,700 --> 00:12:33,019
represents into more wider dimensional

273
00:12:33,019 --> 00:12:37,500
space and those expanded values have

274
00:12:37,500 --> 00:12:40,019
interesting properties for example after

275
00:12:40,019 --> 00:12:42,839
training similar tokens appear in a

276
00:12:42,839 --> 00:12:45,060
similar region similar regions of this

277
00:12:45,060 --> 00:12:46,800
expanded Vector space for instance

278
00:12:46,800 --> 00:12:50,160
cities body parts yeah feelings reside

279
00:12:50,160 --> 00:12:52,980
in the same area so these later layers

280
00:12:52,980 --> 00:12:54,620
can grasp

281
00:12:54,620 --> 00:12:56,820
approximate meaning of the token

282
00:12:56,820 --> 00:12:59,420
independent of a token appearance

283
00:12:59,420 --> 00:13:01,860
presumably something similar happens in

284
00:13:01,860 --> 00:13:05,660
for instance API call space where

285
00:13:05,660 --> 00:13:08,279
sequence of API calls that can be used

286
00:13:08,279 --> 00:13:12,740
to inject uh shell code in a threat

287
00:13:12,740 --> 00:13:15,839
there are different ways to do this they

288
00:13:15,839 --> 00:13:18,240
they can be research that they could

289
00:13:18,240 --> 00:13:20,279
reside in the similar Vector space in

290
00:13:20,279 --> 00:13:22,079
the expanded embeddings this is just

291
00:13:22,079 --> 00:13:24,060
speculation we didn't verify that it's

292
00:13:24,060 --> 00:13:26,940
not that straightforward to do but uh

293
00:13:26,940 --> 00:13:29,600
presumably something like that happens

294
00:13:29,600 --> 00:13:32,600
then embedded

295
00:13:32,600 --> 00:13:35,220
values are passed to next layer which is

296
00:13:35,220 --> 00:13:38,060
convolutions convolutional layer

297
00:13:38,060 --> 00:13:40,860
those come from the computer vision

298
00:13:40,860 --> 00:13:44,220
domain convolutions were used

299
00:13:44,220 --> 00:13:48,060
to extract features from the images for

300
00:13:48,060 --> 00:13:50,880
instance this filter in the middle is

301
00:13:50,880 --> 00:13:53,399
Will extract the vertical lines from an

302
00:13:53,399 --> 00:13:57,420
image and the model then performs actual

303
00:13:57,420 --> 00:14:00,060
convolution of the filter over the input

304
00:14:00,060 --> 00:14:02,459
data those are two-dimensional

305
00:14:02,459 --> 00:14:05,279
convolutions we use one-dimensional one

306
00:14:05,279 --> 00:14:07,440
because they are applied over the one

307
00:14:07,440 --> 00:14:09,839
dimension of the input sequence when I

308
00:14:09,839 --> 00:14:11,339
think about one-dimensional convolutions

309
00:14:11,339 --> 00:14:13,019
the thing that comes to my mind is

310
00:14:13,019 --> 00:14:16,260
heartbeat where a one-dimensional

311
00:14:16,260 --> 00:14:18,300
convolutional layer could could easily

312
00:14:18,300 --> 00:14:20,579
grasp the pattern that is represented in

313
00:14:20,579 --> 00:14:24,120
the heartbeats something similar is done

314
00:14:24,120 --> 00:14:26,940
in a file path for instance inputs where

315
00:14:26,940 --> 00:14:29,120
one dimensional convolutions could get

316
00:14:29,120 --> 00:14:33,060
like gram n grams like dot exe or C

317
00:14:33,060 --> 00:14:36,839
backslash win which may lighter be used

318
00:14:36,839 --> 00:14:40,680
by by later layers for actual decision

319
00:14:40,680 --> 00:14:43,320
boundary between benignware and

320
00:14:43,320 --> 00:14:48,199
malicious uh soft malicious samples

321
00:14:48,199 --> 00:14:52,260
those later layers are purple ones in in

322
00:14:52,260 --> 00:14:54,660
the in the architecture are basically

323
00:14:54,660 --> 00:14:58,260
fully connected a neural network which I

324
00:14:58,260 --> 00:15:00,600
assume like everyone almost heard

325
00:15:00,600 --> 00:15:03,480
nowadays those are just neurons that

326
00:15:03,480 --> 00:15:05,940
that build a non-linear function between

327
00:15:05,940 --> 00:15:08,100
an input and an output

328
00:15:08,100 --> 00:15:10,620
in fact we use the fully connected

329
00:15:10,620 --> 00:15:13,800
neural network as our meta model 2 and

330
00:15:13,800 --> 00:15:17,279
this is a way to to build either complex

331
00:15:17,279 --> 00:15:19,620
decision boundary or extract valuable

332
00:15:19,620 --> 00:15:23,180
data from input to the output

333
00:15:23,240 --> 00:15:26,699
and those are the results of our model

334
00:15:26,699 --> 00:15:31,199
uh to emphasize again this is done on

335
00:15:31,199 --> 00:15:32,699
the data that collected three months

336
00:15:32,699 --> 00:15:36,060
after the training and how to read this

337
00:15:36,060 --> 00:15:38,120
heat map

338
00:15:38,120 --> 00:15:41,459
x axis represent a false positive rate

339
00:15:41,459 --> 00:15:45,480
which means how many samples we fire

340
00:15:45,480 --> 00:15:48,240
uh how many benign samples we fire

341
00:15:48,240 --> 00:15:51,360
alongside with the 100

342
00:15:51,360 --> 00:15:53,420
000 malicious samples

343
00:15:53,420 --> 00:15:57,360
and in production you will not be

344
00:15:57,360 --> 00:15:59,820
allowed to push any ml model that that

345
00:15:59,820 --> 00:16:02,399
brings alongside false false alarms

346
00:16:02,399 --> 00:16:03,899
because the most precious time we have

347
00:16:03,899 --> 00:16:06,420
is a human analyst time and we are not

348
00:16:06,420 --> 00:16:09,500
allowed to to like spare their analysis

349
00:16:09,500 --> 00:16:11,519
on on

350
00:16:11,519 --> 00:16:14,459
false alarms uh therefore we will focus

351
00:16:14,459 --> 00:16:18,180
on for instance this column which which

352
00:16:18,180 --> 00:16:21,180
represents re really really low false

353
00:16:21,180 --> 00:16:23,339
positive requirements that we give to

354
00:16:23,339 --> 00:16:25,620
the model we we can deploy multiple

355
00:16:25,620 --> 00:16:28,740
models that are are super accurate in

356
00:16:28,740 --> 00:16:30,779
their predictions but have low detection

357
00:16:30,779 --> 00:16:33,480
rates this basically resembles what we

358
00:16:33,480 --> 00:16:35,519
have in rule based or signature based

359
00:16:35,519 --> 00:16:37,079
approach they fire only on specific

360
00:16:37,079 --> 00:16:40,500
cases but led through many other

361
00:16:40,500 --> 00:16:42,839
examples

362
00:16:42,839 --> 00:16:46,440
so what we have here if we look on

363
00:16:46,440 --> 00:16:49,620
separate models or arms

364
00:16:49,620 --> 00:16:51,959
then we still see that Amber is the King

365
00:16:51,959 --> 00:16:54,600
right because it extracts so many

366
00:16:54,600 --> 00:16:59,040
properties from the static static byte

367
00:16:59,040 --> 00:17:02,519
blob and again it's a sort of a state of

368
00:17:02,519 --> 00:17:05,400
the art as we know right now there is no

369
00:17:05,400 --> 00:17:07,980
question it's a great tool how to apply

370
00:17:07,980 --> 00:17:10,199
and get a quick win for a classification

371
00:17:10,199 --> 00:17:13,140
we see surprisingly poor performance of

372
00:17:13,140 --> 00:17:16,799
emulation on API calls right and these

373
00:17:16,799 --> 00:17:19,799
points us that we still can improve this

374
00:17:19,799 --> 00:17:23,099
component and yeah we will touch this in

375
00:17:23,099 --> 00:17:24,359
a minute

376
00:17:24,359 --> 00:17:27,299
but the most astonishing thing from our

377
00:17:27,299 --> 00:17:28,919
point of view is

378
00:17:28,919 --> 00:17:32,820
that combination of separate modules not

379
00:17:32,820 --> 00:17:35,220
only improves performance like

380
00:17:35,220 --> 00:17:37,440
cumulatively that we use them

381
00:17:37,440 --> 00:17:40,320
independently just together but

382
00:17:40,320 --> 00:17:43,260
we see this emerged

383
00:17:43,260 --> 00:17:46,620
pattern of meta models ability to give

384
00:17:46,620 --> 00:17:48,900
additional value to this input data for

385
00:17:48,900 --> 00:17:51,000
instance here we see file paths and

386
00:17:51,000 --> 00:17:54,200
demolition only give us like 43 percent

387
00:17:54,200 --> 00:17:57,059
samples are detected if if we use them

388
00:17:57,059 --> 00:17:59,160
together or even less if there's no

389
00:17:59,160 --> 00:18:01,320
samples overlap but if we use them

390
00:18:01,320 --> 00:18:04,140
together and apply meta model on top we

391
00:18:04,140 --> 00:18:07,140
we boost that up to 77 so it's like over

392
00:18:07,140 --> 00:18:10,919
30 percent uh rather than using them

393
00:18:10,919 --> 00:18:13,200
separately and it's even better than

394
00:18:13,200 --> 00:18:15,419
this like state of the art wide

395
00:18:15,419 --> 00:18:18,120
extraction by the Ember itself like at

396
00:18:18,120 --> 00:18:19,220
least by 20

397
00:18:19,220 --> 00:18:22,260
just from file pass and just from the

398
00:18:22,260 --> 00:18:25,080
API call sequence so we we already can

399
00:18:25,080 --> 00:18:28,559
catch 77 of data and

400
00:18:28,559 --> 00:18:31,860
this is something that we usually maybe

401
00:18:31,860 --> 00:18:34,020
don't see don't see from a male point of

402
00:18:34,020 --> 00:18:36,539
view that it can build heuristics that

403
00:18:36,539 --> 00:18:39,780
we even don't we are not aware of just

404
00:18:39,780 --> 00:18:42,960
give a data just different type of of

405
00:18:42,960 --> 00:18:45,299
properties just different type of like

406
00:18:45,299 --> 00:18:48,539
angles and it will figure out valuable

407
00:18:48,539 --> 00:18:50,940
components for it in this case it

408
00:18:50,940 --> 00:18:53,160
probably takes some part of file path

409
00:18:53,160 --> 00:18:56,580
and some appearance of a few API calls

410
00:18:56,580 --> 00:18:59,340
and sees that those are representative

411
00:18:59,340 --> 00:19:03,000
for Mar for malware whereas the benign

412
00:19:03,000 --> 00:19:04,440
were with the same

413
00:19:04,440 --> 00:19:07,380
API calls don't have this part of file

414
00:19:07,380 --> 00:19:09,240
pass or something like that

415
00:19:09,240 --> 00:19:10,980
and of course when using them three

416
00:19:10,980 --> 00:19:13,740
together we get a fairly good detection

417
00:19:13,740 --> 00:19:15,840
rate with such low false positive

418
00:19:15,840 --> 00:19:18,419
requirement only one uh false triggering

419
00:19:18,419 --> 00:19:21,960
in so much like 100 000 samples so this

420
00:19:21,960 --> 00:19:24,419
model already in this like prototype-ish

421
00:19:24,419 --> 00:19:26,880
way could be deployed in production as

422
00:19:26,880 --> 00:19:29,039
one of the uh

423
00:19:29,039 --> 00:19:31,860
like parts to the to the other thing

424
00:19:31,860 --> 00:19:35,100
solution for for manual analysts it

425
00:19:35,100 --> 00:19:36,179
still has

426
00:19:36,179 --> 00:19:39,900
like 14 of true negatives but they can

427
00:19:39,900 --> 00:19:41,880
be captured by other means right we need

428
00:19:41,880 --> 00:19:46,440
to lap over our our detections but

429
00:19:46,440 --> 00:19:50,220
um yeah uh brief note on how adversarial

430
00:19:50,220 --> 00:19:52,200
malware behaves

431
00:19:52,200 --> 00:19:53,940
uh

432
00:19:53,940 --> 00:19:56,820
this is how we read this graph it

433
00:19:56,820 --> 00:19:59,280
it displays two models let's focus only

434
00:19:59,280 --> 00:20:01,440
on like orange bars which represent

435
00:20:01,440 --> 00:20:02,640
Amber model

436
00:20:02,640 --> 00:20:07,980
and the Y scale is logarithmic so when

437
00:20:07,980 --> 00:20:10,679
we we construct it and like adversarial

438
00:20:10,679 --> 00:20:13,799
malware data set from from our test set

439
00:20:13,799 --> 00:20:17,100
and we've seen that more than

440
00:20:17,100 --> 00:20:20,039
a thousand samples were evasive on just

441
00:20:20,039 --> 00:20:22,440
pure model itself when we added

442
00:20:22,440 --> 00:20:23,820
emulation

443
00:20:23,820 --> 00:20:27,860
only 100 of those 1000 samples State

444
00:20:27,860 --> 00:20:31,640
evasive so like the 90 drop of equation

445
00:20:31,640 --> 00:20:34,140
rate of those attacks we know

446
00:20:34,140 --> 00:20:36,299
specifically we tested section injection

447
00:20:36,299 --> 00:20:37,080
attack

448
00:20:37,080 --> 00:20:39,539
and when we apply the file path as well

449
00:20:39,539 --> 00:20:42,600
the basically the attack yielded

450
00:20:42,600 --> 00:20:45,199
unsuccessful

451
00:20:46,140 --> 00:20:50,580
therefore we we proved kind of that if

452
00:20:50,580 --> 00:20:52,940
adver adversaries wants to use

453
00:20:52,940 --> 00:20:55,860
techniques in in adversarial

454
00:20:55,860 --> 00:20:58,380
um machine learning World they should

455
00:20:58,380 --> 00:21:00,539
adapt some

456
00:21:00,539 --> 00:21:03,660
some perturbations that

457
00:21:03,660 --> 00:21:07,320
fool the dynamic parts of the complex

458
00:21:07,320 --> 00:21:09,360
heuristic

459
00:21:09,360 --> 00:21:13,380
uh some ideas on future work again as we

460
00:21:13,380 --> 00:21:15,840
can see emulation part is only a

461
00:21:15,840 --> 00:21:18,360
prototypish the performance is

462
00:21:18,360 --> 00:21:20,340
relatively bad if you compare directly

463
00:21:20,340 --> 00:21:22,919
with the with other models under low

464
00:21:22,919 --> 00:21:26,340
false positive requirements uh we can

465
00:21:26,340 --> 00:21:28,740
consider how to improve API call model

466
00:21:28,740 --> 00:21:31,559
itself but we can add a lot of more data

467
00:21:31,559 --> 00:21:34,440
that were we what we were talking about

468
00:21:34,440 --> 00:21:36,720
previously network connections registry

469
00:21:36,720 --> 00:21:40,440
manipulations file system this all these

470
00:21:40,440 --> 00:21:43,440
these parts of report can be modeled

471
00:21:43,440 --> 00:21:45,299
and

472
00:21:45,299 --> 00:21:48,299
not to monopolize or like approach on

473
00:21:48,299 --> 00:21:51,000
this we publish the emulation data sets

474
00:21:51,000 --> 00:21:53,280
publicly so if you want just go to the

475
00:21:53,280 --> 00:21:56,039
repo and grab them play with them those

476
00:21:56,039 --> 00:22:00,720
are Json reports of both data sets uh we

477
00:22:00,720 --> 00:22:03,480
unfortunately cannot publish B samples

478
00:22:03,480 --> 00:22:05,460
due to privacy policy but emulation

479
00:22:05,460 --> 00:22:09,179
reports are anonymized so yeah if you

480
00:22:09,179 --> 00:22:12,059
wanna play in this direction just just

481
00:22:12,059 --> 00:22:15,500
feel free you have data now

482
00:22:15,500 --> 00:22:17,760
additional sources of contextual

483
00:22:17,760 --> 00:22:19,799
awareness can be used as

484
00:22:19,799 --> 00:22:22,919
as like filling the epistemic Gap that

485
00:22:22,919 --> 00:22:25,140
we have there are parts of information

486
00:22:25,140 --> 00:22:29,159
that we can add for model to to to be

487
00:22:29,159 --> 00:22:32,159
valuable to segregate those 14 that it

488
00:22:32,159 --> 00:22:34,500
still is not able to catch for instance

489
00:22:34,500 --> 00:22:36,059
parent processes

490
00:22:36,059 --> 00:22:38,580
this data is hard to acquire maybe in

491
00:22:38,580 --> 00:22:40,860
some cases but from for a Security

492
00:22:40,860 --> 00:22:44,700
operation centers or yeah threat Hunters

493
00:22:44,700 --> 00:22:47,280
it's easy data and you can try to model

494
00:22:47,280 --> 00:22:49,679
it as well another one is the mark of

495
00:22:49,679 --> 00:22:51,900
the web and download source of course if

496
00:22:51,900 --> 00:22:54,120
you know or like digital forensic

497
00:22:54,120 --> 00:22:56,400
Specialists here will point you that you

498
00:22:56,400 --> 00:22:59,039
can grab this info from ads streams for

499
00:22:59,039 --> 00:23:02,340
every file right and you can use this as

500
00:23:02,340 --> 00:23:05,940
a part of heuristic really valuable part

501
00:23:05,940 --> 00:23:09,480
so those are just some ideas that if you

502
00:23:09,480 --> 00:23:12,600
are inspired and want to continue uh he

503
00:23:12,600 --> 00:23:14,760
those are promising directions from our

504
00:23:14,760 --> 00:23:16,620
point of view

505
00:23:16,620 --> 00:23:20,159
a few takeaways

506
00:23:20,159 --> 00:23:23,640
first of all AI allows to Model Behavior

507
00:23:23,640 --> 00:23:26,159
we see it rarely at least in public

508
00:23:26,159 --> 00:23:28,919
research of course this is done

509
00:23:28,919 --> 00:23:31,020
proprietary almost every vendor right

510
00:23:31,020 --> 00:23:33,120
now does this in their back end

511
00:23:33,120 --> 00:23:36,059
but like scientific knowledge is is

512
00:23:36,059 --> 00:23:38,159
really poor in this direction there is

513
00:23:38,159 --> 00:23:40,980
no models that you can take and directly

514
00:23:40,980 --> 00:23:43,500
use pre-trained models but we see that

515
00:23:43,500 --> 00:23:46,980
this can be done and this yields are are

516
00:23:46,980 --> 00:23:48,299
known techniques

517
00:23:48,299 --> 00:23:51,720
and the benefit behind the modeling

518
00:23:51,720 --> 00:23:53,820
behavior that it can be applied to much

519
00:23:53,820 --> 00:23:56,159
wider set of data for instance not only

520
00:23:56,159 --> 00:23:59,280
P files as a byte blobs can be used for

521
00:23:59,280 --> 00:24:01,440
analysis which is the case with static

522
00:24:01,440 --> 00:24:04,260
techniques but data like sysmon or odd

523
00:24:04,260 --> 00:24:06,840
can be modeled as well which is which

524
00:24:06,840 --> 00:24:10,559
represents much wider spectrum of

525
00:24:10,559 --> 00:24:12,419
security practitioners again security

526
00:24:12,419 --> 00:24:14,580
operations center you don't need to be

527
00:24:14,580 --> 00:24:17,520
security vendor which is in the case in

528
00:24:17,520 --> 00:24:19,620
in P data sets this is usually security

529
00:24:19,620 --> 00:24:21,900
vendors that do this research with the

530
00:24:21,900 --> 00:24:24,480
behavior it's every one of us socks

531
00:24:24,480 --> 00:24:26,400
around the world that that can benefit

532
00:24:26,400 --> 00:24:28,860
from Models like this

533
00:24:28,860 --> 00:24:33,840
uh second ml you basically you just need

534
00:24:33,840 --> 00:24:36,720
give it data and it figures itself the

535
00:24:36,720 --> 00:24:38,820
valuable part

536
00:24:38,820 --> 00:24:40,980
um it's it's the pipeline that you need

537
00:24:40,980 --> 00:24:43,740
to build and as we've seen

538
00:24:43,740 --> 00:24:46,320
ml finds valuable components if you

539
00:24:46,320 --> 00:24:49,980
provide it uh different angles of of the

540
00:24:49,980 --> 00:24:54,059
same question in that case uh yeah the

541
00:24:54,059 --> 00:24:56,419
this performance boost that we've seen

542
00:24:56,419 --> 00:24:58,980
by combining file path and emulation

543
00:24:58,980 --> 00:25:02,340
models is from our point of view is is

544
00:25:02,340 --> 00:25:04,679
great and it's in fact is not artifact

545
00:25:04,679 --> 00:25:07,320
of this specific data set we've seen

546
00:25:07,320 --> 00:25:08,940
this behavioral across validation

547
00:25:08,940 --> 00:25:11,940
training contested so the same pattern

548
00:25:11,940 --> 00:25:14,159
emerging in every piece of data that we

549
00:25:14,159 --> 00:25:15,659
tested

550
00:25:15,659 --> 00:25:19,559
and last but not least what we wanted to

551
00:25:19,559 --> 00:25:22,020
remind everyone when we speak about ml

552
00:25:22,020 --> 00:25:24,480
applicability to security problems ml is

553
00:25:24,480 --> 00:25:26,039
not a silver bullet it will not replace

554
00:25:26,039 --> 00:25:29,400
you tomorrow and like human Specialists

555
00:25:29,400 --> 00:25:31,440
were will be out of work

556
00:25:31,440 --> 00:25:33,900
it's a tool that we can use and apply

557
00:25:33,900 --> 00:25:37,020
basically AI is a software it's we are

558
00:25:37,020 --> 00:25:40,500
far from intelligent agents that do work

559
00:25:40,500 --> 00:25:43,200
by themselves it is a tool that you can

560
00:25:43,200 --> 00:25:45,600
put is any other type of code or

561
00:25:45,600 --> 00:25:48,299
Automation and use it in addition to the

562
00:25:48,299 --> 00:25:50,640
tools you have right now like rule-based

563
00:25:50,640 --> 00:25:53,000
approach is not like

564
00:25:53,000 --> 00:25:55,980
substituted by by AI techniques it's an

565
00:25:55,980 --> 00:25:58,200
additional way to do your work more

566
00:25:58,200 --> 00:26:01,020
efficiently and you cannot with the

567
00:26:01,020 --> 00:26:04,260
small models you you don't need uh yeah

568
00:26:04,260 --> 00:26:07,260
you just just Implement one arm from for

569
00:26:07,260 --> 00:26:08,700
example this approach and it will

570
00:26:08,700 --> 00:26:12,200
already can can be a better

571
00:26:12,200 --> 00:26:16,080
detection way for you for to to identify

572
00:26:16,080 --> 00:26:17,640
some some things that you need to

573
00:26:17,640 --> 00:26:19,440
identify

574
00:26:19,440 --> 00:26:22,140
yeah acknowledgments to the many teams

575
00:26:22,140 --> 00:26:25,140
that did research that made the

576
00:26:25,140 --> 00:26:26,820
foundations for this work for instance

577
00:26:26,820 --> 00:26:29,580
again Monday and they do a great job for

578
00:26:29,580 --> 00:26:32,100
maintaining Speak Easy and their data

579
00:26:32,100 --> 00:26:34,320
science team does similar research and

580
00:26:34,320 --> 00:26:36,659
game for for original worker member

581
00:26:36,659 --> 00:26:41,039
sofas AI team showed that fall pass in

582
00:26:41,039 --> 00:26:43,380
fact improve Amber so we were influenced

583
00:26:43,380 --> 00:26:45,720
by them and guys from kagler University

584
00:26:45,720 --> 00:26:48,080
done the adversarial machine

585
00:26:48,080 --> 00:26:50,760
learning library that is easy to use

586
00:26:50,760 --> 00:26:52,320
thanks to them and the people who

587
00:26:52,320 --> 00:26:54,840
support it yeah that's it now it's the

588
00:26:54,840 --> 00:26:57,620
time for questions

589
00:26:58,080 --> 00:27:00,260
foreign

590
00:27:04,800 --> 00:27:07,899
[Music]

