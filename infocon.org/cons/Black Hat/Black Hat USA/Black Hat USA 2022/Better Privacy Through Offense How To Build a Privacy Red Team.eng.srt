1
00:00:01,630 --> 00:00:04,810
[Music]

2
00:00:07,639 --> 00:00:10,679
good morning black hat uh my name is

3
00:00:10,679 --> 00:00:12,420
Scott Denali I'm a privacy engineering

4
00:00:12,420 --> 00:00:14,160
manager at meta and I support something

5
00:00:14,160 --> 00:00:16,139
called the Privacy red team which

6
00:00:16,139 --> 00:00:18,000
coincidentally is what the topic of this

7
00:00:18,000 --> 00:00:19,859
conversation is all about

8
00:00:19,859 --> 00:00:21,060
the way we're going to kick things off

9
00:00:21,060 --> 00:00:23,160
is by making the case more broadly for

10
00:00:23,160 --> 00:00:25,260
offensive privacy before diving into the

11
00:00:25,260 --> 00:00:26,460
question that I'm sure you're all here

12
00:00:26,460 --> 00:00:28,019
to hear the answer to which is what is

13
00:00:28,019 --> 00:00:29,400
the difference between a security and

14
00:00:29,400 --> 00:00:31,439
privacy red team we'll talk about what

15
00:00:31,439 --> 00:00:33,000
we did at meta to build a privacy red

16
00:00:33,000 --> 00:00:35,280
team give you some ideas for operations

17
00:00:35,280 --> 00:00:36,899
that you might want to perform if you're

18
00:00:36,899 --> 00:00:38,579
thinking about building privacy red team

19
00:00:38,579 --> 00:00:39,840
and then wrap up with some final

20
00:00:39,840 --> 00:00:40,800
thoughts

21
00:00:40,800 --> 00:00:42,719
but before we do all that I want to

22
00:00:42,719 --> 00:00:44,340
level set a bit and give you an idea of

23
00:00:44,340 --> 00:00:46,320
what this talk is and is not about

24
00:00:46,320 --> 00:00:48,300
so primarily what we want to do here is

25
00:00:48,300 --> 00:00:49,860
start a conversation within this

26
00:00:49,860 --> 00:00:52,739
community about offensive privacy I know

27
00:00:52,739 --> 00:00:53,879
there are others in the audience that

28
00:00:53,879 --> 00:00:54,960
I've talked to that are from different

29
00:00:54,960 --> 00:00:56,879
companies you either have or are planned

30
00:00:56,879 --> 00:00:58,860
to start a privacy red team and I think

31
00:00:58,860 --> 00:01:00,600
it's time we Elevate this convert this

32
00:01:00,600 --> 00:01:02,340
conversation to something community-wide

33
00:01:02,340 --> 00:01:04,260
versus one-on-one

34
00:01:04,260 --> 00:01:06,119
more to the point if you're an

35
00:01:06,119 --> 00:01:07,439
organization or you work for an

36
00:01:07,439 --> 00:01:08,760
organization that currently has an

37
00:01:08,760 --> 00:01:11,340
internal security red team this talk

38
00:01:11,340 --> 00:01:12,840
might be a blueprint for how you build

39
00:01:12,840 --> 00:01:15,479
an internal privacy red team if you

40
00:01:15,479 --> 00:01:17,520
contract external red team Services well

41
00:01:17,520 --> 00:01:18,780
this might be a blueprint for another

42
00:01:18,780 --> 00:01:21,720
type of service to ask for if you offer

43
00:01:21,720 --> 00:01:24,119
red team Services then this might be a

44
00:01:24,119 --> 00:01:25,680
new type of service offering that you

45
00:01:25,680 --> 00:01:27,180
might want to provide

46
00:01:27,180 --> 00:01:28,799
but all in all what we're trying to do

47
00:01:28,799 --> 00:01:31,020
here is give an understanding of how we

48
00:01:31,020 --> 00:01:33,119
think privacy rate teaming fits into

49
00:01:33,119 --> 00:01:35,220
holistic privacy program

50
00:01:35,220 --> 00:01:36,780
but we're definitely not going to do

51
00:01:36,780 --> 00:01:38,820
here is pitch you anything I'm not here

52
00:01:38,820 --> 00:01:40,140
to sell anything

53
00:01:40,140 --> 00:01:41,520
we're also not going to talk about any

54
00:01:41,520 --> 00:01:43,979
other aspect of meta Beyond privacy red

55
00:01:43,979 --> 00:01:45,659
teaming

56
00:01:45,659 --> 00:01:46,920
and throughout this talk you're going to

57
00:01:46,920 --> 00:01:49,020
hear me say things like privacy this or

58
00:01:49,020 --> 00:01:51,240
security that I very much understand

59
00:01:51,240 --> 00:01:52,799
that these are overlapping fields in

60
00:01:52,799 --> 00:01:53,759
fact we're going to talk about that

61
00:01:53,759 --> 00:01:55,979
pretty soon but the point here is it's

62
00:01:55,979 --> 00:01:57,299
hard for me to keep caviar on everything

63
00:01:57,299 --> 00:01:59,159
I say so don't take anything I say is an

64
00:01:59,159 --> 00:02:00,780
absolute

65
00:02:00,780 --> 00:02:03,180
and lastly circling back to the first

66
00:02:03,180 --> 00:02:05,340
point you may agree or disagree and

67
00:02:05,340 --> 00:02:06,540
partner and hold with what I'm going to

68
00:02:06,540 --> 00:02:07,740
say here just remember it's a

69
00:02:07,740 --> 00:02:09,959
conversation I want your feedback I want

70
00:02:09,959 --> 00:02:12,420
to hear what you have to say about it

71
00:02:12,420 --> 00:02:13,980
all right now let's dive in and make the

72
00:02:13,980 --> 00:02:16,140
case for offensive privacy we're at

73
00:02:16,140 --> 00:02:18,060
black hat which means you all really

74
00:02:18,060 --> 00:02:20,520
well understand how offense helps your

75
00:02:20,520 --> 00:02:22,020
security program and I want to make the

76
00:02:22,020 --> 00:02:23,760
same case for how offense can help your

77
00:02:23,760 --> 00:02:25,860
privacy program and when I do that in

78
00:02:25,860 --> 00:02:28,020
two very specific ways the first is

79
00:02:28,020 --> 00:02:29,340
through some experiences you may have

80
00:02:29,340 --> 00:02:32,700
had and the second is conceptually

81
00:02:32,700 --> 00:02:35,280
so if you're a current red team or a pen

82
00:02:35,280 --> 00:02:36,959
tester you might have been in an

83
00:02:36,959 --> 00:02:39,180
operation and came across some pii or

84
00:02:39,180 --> 00:02:40,860
some other sensitive data and didn't

85
00:02:40,860 --> 00:02:42,780
know what to do it's not the point of

86
00:02:42,780 --> 00:02:44,400
your operation but you log it as a

87
00:02:44,400 --> 00:02:46,260
finding and you just ignore it

88
00:02:46,260 --> 00:02:48,180
you might also have been asked to start

89
00:02:48,180 --> 00:02:50,040
recording these things as findings you

90
00:02:50,040 --> 00:02:51,300
know if you come across this sense of

91
00:02:51,300 --> 00:02:53,459
data hey please record it let us know

92
00:02:53,459 --> 00:02:55,140
you might have also been specifically

93
00:02:55,140 --> 00:02:58,080
asked to create a privacy focused

94
00:02:58,080 --> 00:02:59,940
version which you normally do and maybe

95
00:02:59,940 --> 00:03:01,200
weren't sure exactly how that was

96
00:03:01,200 --> 00:03:02,640
supposed to look

97
00:03:02,640 --> 00:03:04,260
and then maybe you've just had a

98
00:03:04,260 --> 00:03:05,819
standard security finding that you

99
00:03:05,819 --> 00:03:07,200
really weren't able to get a lot of

100
00:03:07,200 --> 00:03:08,940
traction on because someone told you it

101
00:03:08,940 --> 00:03:10,260
didn't have the right security impact

102
00:03:10,260 --> 00:03:12,300
right didn't have enough of that impact

103
00:03:12,300 --> 00:03:13,860
uh myself and a colleague found

104
00:03:13,860 --> 00:03:15,540
ourselves in this situation back in 2016

105
00:03:15,540 --> 00:03:17,580
at black hat in Europe where we were

106
00:03:17,580 --> 00:03:18,480
presenting some results on

107
00:03:18,480 --> 00:03:20,239
vulnerabilities we found in iot devices

108
00:03:20,239 --> 00:03:22,620
one of those vulnerabilities was a code

109
00:03:22,620 --> 00:03:25,260
injection onto a phone uh the phone app

110
00:03:25,260 --> 00:03:27,599
associated with the iot device allowed

111
00:03:27,599 --> 00:03:29,159
us to do some things but people didn't

112
00:03:29,159 --> 00:03:30,480
think was a big deal because the code

113
00:03:30,480 --> 00:03:31,980
injection vulnerability was pretty

114
00:03:31,980 --> 00:03:33,659
vanilla right it wasn't particularly

115
00:03:33,659 --> 00:03:35,640
impressive and it was sort of hard to

116
00:03:35,640 --> 00:03:36,720
execute because you had to be on the

117
00:03:36,720 --> 00:03:38,459
same network as the device

118
00:03:38,459 --> 00:03:40,739
but our point was this code injection

119
00:03:40,739 --> 00:03:43,200
vulnerability allowed us to pull off all

120
00:03:43,200 --> 00:03:44,940
the photos and other files off the

121
00:03:44,940 --> 00:03:46,680
device and turn that phone into a GPS

122
00:03:46,680 --> 00:03:48,480
tracker that would become back your

123
00:03:48,480 --> 00:03:49,920
location no matter what network you were

124
00:03:49,920 --> 00:03:52,019
on and the time we tried to land this

125
00:03:52,019 --> 00:03:53,819
impact by saying hey isn't it weird that

126
00:03:53,819 --> 00:03:55,080
these things can happen to you just

127
00:03:55,080 --> 00:03:56,519
because you wanted an Internet connected

128
00:03:56,519 --> 00:03:57,900
crock pot

129
00:03:57,900 --> 00:03:59,700
nowadays I think about that same thing

130
00:03:59,700 --> 00:04:00,840
and I say well yeah the security

131
00:04:00,840 --> 00:04:01,980
vulnerability might have been pretty

132
00:04:01,980 --> 00:04:04,260
vanilla but the Privacy impact of that

133
00:04:04,260 --> 00:04:06,060
vulnerability was super high your

134
00:04:06,060 --> 00:04:07,560
location your photos that kind of sends

135
00:04:07,560 --> 00:04:08,640
it information somebody getting their

136
00:04:08,640 --> 00:04:10,799
hands on that's really a privacy impact

137
00:04:10,799 --> 00:04:12,720
so maybe you've had that same sort of uh

138
00:04:12,720 --> 00:04:14,400
issue

139
00:04:14,400 --> 00:04:16,680
now let's talk about it conceptually

140
00:04:16,680 --> 00:04:18,540
the whole conversation starts off with

141
00:04:18,540 --> 00:04:20,940
the notion of risk on the slide what you

142
00:04:20,940 --> 00:04:22,800
see is this Venn diagram of the

143
00:04:22,800 --> 00:04:24,660
overlapping risks of security and

144
00:04:24,660 --> 00:04:26,040
privacy and you don't have to take my

145
00:04:26,040 --> 00:04:27,360
word on this that these are overlapping

146
00:04:27,360 --> 00:04:29,220
because this Venn diagram comes from the

147
00:04:29,220 --> 00:04:31,020
nist Privacy framework

148
00:04:31,020 --> 00:04:32,520
and really what we're talking about here

149
00:04:32,520 --> 00:04:34,919
is perceived risk that is an

150
00:04:34,919 --> 00:04:38,220
individual's subjective judgment on the

151
00:04:38,220 --> 00:04:40,860
likelihood of a negative event occurring

152
00:04:40,860 --> 00:04:42,720
those security and privacy programs we

153
00:04:42,720 --> 00:04:44,340
all know about part of what they do is

154
00:04:44,340 --> 00:04:46,620
help mitigate this risk and the reason

155
00:04:46,620 --> 00:04:48,780
the way they do that is by combining

156
00:04:48,780 --> 00:04:51,240
people processes and Technology what we

157
00:04:51,240 --> 00:04:53,100
would call a blue team right to help

158
00:04:53,100 --> 00:04:55,500
prevent these risks from being realized

159
00:04:55,500 --> 00:04:57,360
and as a red team operator what you're

160
00:04:57,360 --> 00:04:59,220
going to do is this adversarial testing

161
00:04:59,220 --> 00:05:01,080
to figure out how well those mitigations

162
00:05:01,080 --> 00:05:03,060
hold up how well they're actually

163
00:05:03,060 --> 00:05:04,680
mitigating the risk

164
00:05:04,680 --> 00:05:06,180
and what you're doing here is you're

165
00:05:06,180 --> 00:05:08,759
coming up with actual risk now the

166
00:05:08,759 --> 00:05:10,080
difference between perceived and actual

167
00:05:10,080 --> 00:05:11,880
right one is someone's judgment the

168
00:05:11,880 --> 00:05:13,620
other is a quantification of that risk

169
00:05:13,620 --> 00:05:15,960
if you're able to bypass the mitigation

170
00:05:15,960 --> 00:05:18,000
it's no longer just someone's thought

171
00:05:18,000 --> 00:05:19,560
that this could be an issue you've

172
00:05:19,560 --> 00:05:21,300
actually proved it you've done it right

173
00:05:21,300 --> 00:05:24,300
so the idea is is you're finding actual

174
00:05:24,300 --> 00:05:26,280
risk you might also actually find new

175
00:05:26,280 --> 00:05:27,780
risks right so think about a couple

176
00:05:27,780 --> 00:05:30,000
years ago before ransomware was a big

177
00:05:30,000 --> 00:05:31,199
deal had you identify that in an

178
00:05:31,199 --> 00:05:32,639
operation somebody could rant some data

179
00:05:32,639 --> 00:05:34,080
hey that'd be a new risk that maybe

180
00:05:34,080 --> 00:05:36,479
people should try and mitigate

181
00:05:36,479 --> 00:05:38,340
now if we pull this Venn diagram apart a

182
00:05:38,340 --> 00:05:39,180
little bit we can start to understand

183
00:05:39,180 --> 00:05:41,460
the differences between the two teams so

184
00:05:41,460 --> 00:05:43,440
let's start on the cyber security side

185
00:05:43,440 --> 00:05:45,240
one of the risks you might be interested

186
00:05:45,240 --> 00:05:46,740
in mitigating is attack surface

187
00:05:46,740 --> 00:05:48,240
enumeration

188
00:05:48,240 --> 00:05:49,680
one of the ways you would do that is by

189
00:05:49,680 --> 00:05:52,020
installing a firewall that firewall when

190
00:05:52,020 --> 00:05:53,639
it alerts there's a process to respond

191
00:05:53,639 --> 00:05:55,620
to those alerts people Implement that

192
00:05:55,620 --> 00:05:57,180
process and also operate and maintain

193
00:05:57,180 --> 00:05:59,340
the firewall so that combination of

194
00:05:59,340 --> 00:06:01,139
people processes and technology is the

195
00:06:01,139 --> 00:06:02,520
mitigation

196
00:06:02,520 --> 00:06:04,500
standard red team activity during a

197
00:06:04,500 --> 00:06:06,120
Recon phase might be to scan that Target

198
00:06:06,120 --> 00:06:08,100
network if you don't get much back from

199
00:06:08,100 --> 00:06:09,419
those scans hey the firewall is working

200
00:06:09,419 --> 00:06:10,979
great otherwise maybe you need to make

201
00:06:10,979 --> 00:06:12,300
some tweaks

202
00:06:12,300 --> 00:06:15,000
in either case what you're doing is

203
00:06:15,000 --> 00:06:17,580
identifying the actual risk to the

204
00:06:17,580 --> 00:06:19,320
systems and networks associated with

205
00:06:19,320 --> 00:06:21,360
that Target

206
00:06:21,360 --> 00:06:22,620
now let's look at what we're doing on

207
00:06:22,620 --> 00:06:23,940
the Privacy side

208
00:06:23,940 --> 00:06:25,740
one of the risks we care a lot about is

209
00:06:25,740 --> 00:06:28,020
large-scale access to data

210
00:06:28,020 --> 00:06:29,639
the way we mitigate that or one of the

211
00:06:29,639 --> 00:06:31,080
ways we mitigate that is through rate

212
00:06:31,080 --> 00:06:32,819
limits right limits say you can only

213
00:06:32,819 --> 00:06:34,979
access so much data in a particular

214
00:06:34,979 --> 00:06:36,720
period of time

215
00:06:36,720 --> 00:06:38,940
as a red team operator on a privacy red

216
00:06:38,940 --> 00:06:41,520
team anytime you find access to

217
00:06:41,520 --> 00:06:43,139
sensitive data or important data things

218
00:06:43,139 --> 00:06:44,160
you didn't think you should get access

219
00:06:44,160 --> 00:06:45,960
to the first thing you're going to do is

220
00:06:45,960 --> 00:06:47,220
see how much more of it you can get

221
00:06:47,220 --> 00:06:48,539
right you're going to scale up that

222
00:06:48,539 --> 00:06:50,639
access you're going to scrape if those

223
00:06:50,639 --> 00:06:52,259
rate limits are working well then hey

224
00:06:52,259 --> 00:06:53,400
you probably aren't able to do much

225
00:06:53,400 --> 00:06:54,900
there otherwise you'll probably need to

226
00:06:54,900 --> 00:06:57,240
make some tweaks to the rate limits in

227
00:06:57,240 --> 00:06:59,100
either case what you're doing is

228
00:06:59,100 --> 00:07:02,039
identifying the actual risk to the

229
00:07:02,039 --> 00:07:04,319
user's data and their privacy very

230
00:07:04,319 --> 00:07:05,580
directly

231
00:07:05,580 --> 00:07:06,960
so that's the basis for this

232
00:07:06,960 --> 00:07:09,300
conversation on the differences

233
00:07:09,300 --> 00:07:11,220
now let's dive into some of the more

234
00:07:11,220 --> 00:07:13,919
specific differences you'll see

235
00:07:13,919 --> 00:07:16,740
so because of the evolving legal and

236
00:07:16,740 --> 00:07:18,360
Regulatory landscape in the last few

237
00:07:18,360 --> 00:07:20,639
years if you're a red team operator you

238
00:07:20,639 --> 00:07:22,139
might have decided that there's a whole

239
00:07:22,139 --> 00:07:24,000
bunch of risks just for your team and

240
00:07:24,000 --> 00:07:26,099
accessing user user data on an operation

241
00:07:26,099 --> 00:07:27,479
so maybe you've actually said hey we're

242
00:07:27,479 --> 00:07:29,639
going to avoid doing that entirely

243
00:07:29,639 --> 00:07:31,380
well based on what I just showed you in

244
00:07:31,380 --> 00:07:32,699
the Privacy region we can't do that

245
00:07:32,699 --> 00:07:34,620
right that's the whole point is to find

246
00:07:34,620 --> 00:07:37,080
the access to data that shouldn't be

247
00:07:37,080 --> 00:07:39,300
there right we can't avoid those

248
00:07:39,300 --> 00:07:41,280
different implications this is not only

249
00:07:41,280 --> 00:07:43,199
a key differentiator but there's sort of

250
00:07:43,199 --> 00:07:45,180
a public service announcement here make

251
00:07:45,180 --> 00:07:46,860
sure you partner with your legal teams

252
00:07:46,860 --> 00:07:48,180
to understand the risks of the

253
00:07:48,180 --> 00:07:50,160
operations you're doing and how they

254
00:07:50,160 --> 00:07:51,960
relate to the the different laws and

255
00:07:51,960 --> 00:07:55,340
regulations that you may encounter

256
00:07:56,520 --> 00:07:57,780
the next difference I want to talk about

257
00:07:57,780 --> 00:07:59,580
is adversaries so in the security

258
00:07:59,580 --> 00:08:01,740
communities you all know we care a lot

259
00:08:01,740 --> 00:08:03,120
about those advanced persistent threats

260
00:08:03,120 --> 00:08:05,460
like nation state actors and maybe some

261
00:08:05,460 --> 00:08:07,380
cyber criminal groups and of course in

262
00:08:07,380 --> 00:08:09,300
privacy we care about those as well but

263
00:08:09,300 --> 00:08:10,500
we also care about other types of

264
00:08:10,500 --> 00:08:11,880
adversaries and I like to draw the

265
00:08:11,880 --> 00:08:13,440
distinction by thinking about it along

266
00:08:13,440 --> 00:08:14,940
three different axes

267
00:08:14,940 --> 00:08:16,979
one is time scales yeah there's

268
00:08:16,979 --> 00:08:18,599
resources and the final one is technical

269
00:08:18,599 --> 00:08:20,039
sophistication

270
00:08:20,039 --> 00:08:22,080
if you think about an apt they're pretty

271
00:08:22,080 --> 00:08:24,000
much defined by having infinite time

272
00:08:24,000 --> 00:08:26,699
scales infinite resources and a high

273
00:08:26,699 --> 00:08:29,160
degree of technical sophistication

274
00:08:29,160 --> 00:08:31,020
if we look at a privacy adversary we

275
00:08:31,020 --> 00:08:32,458
care a lot about like an abusive

276
00:08:32,458 --> 00:08:34,500
commercial service a company who's

277
00:08:34,500 --> 00:08:36,360
basically contracted to extract data

278
00:08:36,360 --> 00:08:38,099
from our platforms and sell it to

279
00:08:38,099 --> 00:08:39,360
somebody else

280
00:08:39,360 --> 00:08:41,399
well their time scales are probably

281
00:08:41,399 --> 00:08:42,539
going to be limited by whatever that

282
00:08:42,539 --> 00:08:45,000
contract period is their resources are

283
00:08:45,000 --> 00:08:45,899
going to be limited by whatever

284
00:08:45,899 --> 00:08:46,980
someone's paying them to do that

285
00:08:46,980 --> 00:08:47,880
activity

286
00:08:47,880 --> 00:08:49,560
and their technical sophistication we

287
00:08:49,560 --> 00:08:51,000
expect to be a heck of a lot lower than

288
00:08:51,000 --> 00:08:52,740
an apt

289
00:08:52,740 --> 00:08:54,899
another interesting example are an

290
00:08:54,899 --> 00:08:56,820
opportunistic bad actor trying to scrape

291
00:08:56,820 --> 00:08:58,320
data from the platform and dump it on

292
00:08:58,320 --> 00:09:00,120
the dark web

293
00:09:00,120 --> 00:09:01,380
so that kind of an actually you think is

294
00:09:01,380 --> 00:09:02,640
sort of a lone actor and they're

295
00:09:02,640 --> 00:09:04,500
opportunistic which means their time

296
00:09:04,500 --> 00:09:06,420
scales and resources are by and large

297
00:09:06,420 --> 00:09:08,399
bounded by their attention span

298
00:09:08,399 --> 00:09:10,260
but their technical sophistication is

299
00:09:10,260 --> 00:09:12,120
going to be anywhere between an abusive

300
00:09:12,120 --> 00:09:15,440
commercial service and ABT

301
00:09:16,380 --> 00:09:17,820
now at this point you might be thinking

302
00:09:17,820 --> 00:09:18,839
yourself well look I do red team

303
00:09:18,839 --> 00:09:20,459
operations all the time my standard op

304
00:09:20,459 --> 00:09:22,380
looks like this I fish for some

305
00:09:22,380 --> 00:09:24,360
credentials I log into a box I move

306
00:09:24,360 --> 00:09:26,040
laterally through that network with nday

307
00:09:26,040 --> 00:09:28,320
exploits I drop malware for persistence

308
00:09:28,320 --> 00:09:30,360
I maybe grab some creds with Mimi cats

309
00:09:30,360 --> 00:09:31,920
log into a database and actual data so

310
00:09:31,920 --> 00:09:33,360
look at me I'm doing privacy red team

311
00:09:33,360 --> 00:09:35,760
right because I got access to data

312
00:09:35,760 --> 00:09:37,320
but if we think about how you did that

313
00:09:37,320 --> 00:09:39,839
it was very indirect you compromised an

314
00:09:39,839 --> 00:09:41,640
entire network of systems to get access

315
00:09:41,640 --> 00:09:43,140
to that data

316
00:09:43,140 --> 00:09:44,940
the Privacy red team side of the world

317
00:09:44,940 --> 00:09:46,560
is more interested in that direct access

318
00:09:46,560 --> 00:09:49,740
maybe through user interfaces or apis

319
00:09:49,740 --> 00:09:51,420
so if you take nothing else away from

320
00:09:51,420 --> 00:09:53,040
the difference between a security and a

321
00:09:53,040 --> 00:09:54,300
privacy red team I want you to think of

322
00:09:54,300 --> 00:09:56,100
it like this

323
00:09:56,100 --> 00:09:58,440
security red teams are targeting the

324
00:09:58,440 --> 00:10:00,360
company think of the companies the

325
00:10:00,360 --> 00:10:02,339
container of information you're

326
00:10:02,339 --> 00:10:04,860
targeting that the Privacy red team is

327
00:10:04,860 --> 00:10:06,660
targeting the user data that that

328
00:10:06,660 --> 00:10:09,180
company holds what's in that container

329
00:10:09,180 --> 00:10:11,459
that's the tldr that's the thing to

330
00:10:11,459 --> 00:10:13,579
remember

331
00:10:13,920 --> 00:10:15,420
and before we get done with these

332
00:10:15,420 --> 00:10:16,320
differences I want to talk a little bit

333
00:10:16,320 --> 00:10:17,640
about blue teams as you saw a couple

334
00:10:17,640 --> 00:10:19,560
slides ago we have separate set of

335
00:10:19,560 --> 00:10:21,779
privacy risks at meta and we've hired a

336
00:10:21,779 --> 00:10:23,279
separate set of people and created new

337
00:10:23,279 --> 00:10:24,540
processes and Technologies to help

338
00:10:24,540 --> 00:10:26,820
mitigate that risk so one could say we

339
00:10:26,820 --> 00:10:28,680
have a separate blue team and in fact

340
00:10:28,680 --> 00:10:30,420
you could say that this privacy red team

341
00:10:30,420 --> 00:10:32,160
makes a lot of sense because we have a

342
00:10:32,160 --> 00:10:33,420
separate blue team we need a separate

343
00:10:33,420 --> 00:10:34,980
red team to test it

344
00:10:34,980 --> 00:10:36,360
but there's another important factor

345
00:10:36,360 --> 00:10:38,339
when we talk about Bluetooth and that is

346
00:10:38,339 --> 00:10:40,800
that adversaries steal data for reasons

347
00:10:40,800 --> 00:10:43,260
right so if they're an Espionage or

348
00:10:43,260 --> 00:10:45,240
e-crime act or something like that well

349
00:10:45,240 --> 00:10:47,160
the types of activities that you perform

350
00:10:47,160 --> 00:10:48,899
as a privacy red team might look a lot

351
00:10:48,899 --> 00:10:50,640
like what those actors are doing which

352
00:10:50,640 --> 00:10:52,800
means that if you have an Integrity blue

353
00:10:52,800 --> 00:10:54,660
team you might trip over some of those

354
00:10:54,660 --> 00:10:56,880
detections set off those alarms

355
00:10:56,880 --> 00:10:59,100
likewise the things you might attack

356
00:10:59,100 --> 00:11:00,839
like let's say an authentication system

357
00:11:00,839 --> 00:11:03,120
might have detections that you trip in

358
00:11:03,120 --> 00:11:05,399
Your Standard Security blue team

359
00:11:05,399 --> 00:11:07,079
so the point being it's really important

360
00:11:07,079 --> 00:11:09,000
to figure out who you need to partner

361
00:11:09,000 --> 00:11:11,339
with ahead of time what blue teams you

362
00:11:11,339 --> 00:11:13,260
might actually be triggering before you

363
00:11:13,260 --> 00:11:15,920
do an operation

364
00:11:17,220 --> 00:11:18,300
all right now let's talk about what

365
00:11:18,300 --> 00:11:19,620
we've done at meta to build a privacy

366
00:11:19,620 --> 00:11:20,880
red team

367
00:11:20,880 --> 00:11:22,019
if you take everything we've talked

368
00:11:22,019 --> 00:11:23,399
about so far and boil it down you get

369
00:11:23,399 --> 00:11:25,019
this mission statement what we're doing

370
00:11:25,019 --> 00:11:27,120
is proactively testing people processes

371
00:11:27,120 --> 00:11:29,160
and Technologies from an adversarial

372
00:11:29,160 --> 00:11:31,500
perspective to identify the actual risk

373
00:11:31,500 --> 00:11:33,959
to our users data and their privacy two

374
00:11:33,959 --> 00:11:35,459
keywords are of course a proactive and

375
00:11:35,459 --> 00:11:37,920
adversarial proactive meaning we want to

376
00:11:37,920 --> 00:11:39,959
do this stuff before real adversaries do

377
00:11:39,959 --> 00:11:40,980
it so that we can defend ourselves

378
00:11:40,980 --> 00:11:42,899
better against them and of course

379
00:11:42,899 --> 00:11:44,519
adversarial testing is kind of the

380
00:11:44,519 --> 00:11:47,100
unique part about red teaming right

381
00:11:47,100 --> 00:11:48,779
now the four functions we have in the

382
00:11:48,779 --> 00:11:50,220
middle you can read left to right and

383
00:11:50,220 --> 00:11:51,480
it's really the core of how we do what

384
00:11:51,480 --> 00:11:52,920
we do

385
00:11:52,920 --> 00:11:54,480
starting about starting about talking

386
00:11:54,480 --> 00:11:56,579
about adversarial testing well the first

387
00:11:56,579 --> 00:11:57,779
thing you need to know there's is you

388
00:11:57,779 --> 00:11:59,220
need to understand the adversary as he

389
00:11:59,220 --> 00:12:01,680
talked about before this space of

390
00:12:01,680 --> 00:12:04,019
privacy adversaries is less well-defined

391
00:12:04,019 --> 00:12:06,060
and less well known maybe the security

392
00:12:06,060 --> 00:12:08,220
industry so what we're trying to do here

393
00:12:08,220 --> 00:12:09,660
is really figure this out by modeling

394
00:12:09,660 --> 00:12:11,820
those adversaries we take one of those

395
00:12:11,820 --> 00:12:13,620
profiles I would say our profiles and

396
00:12:13,620 --> 00:12:15,300
apply them these technical assessments

397
00:12:15,300 --> 00:12:17,820
that we do which generate finding some

398
00:12:17,820 --> 00:12:19,019
of those findings are individual

399
00:12:19,019 --> 00:12:21,420
weaknesses and products and services and

400
00:12:21,420 --> 00:12:22,440
we think it's really important to

401
00:12:22,440 --> 00:12:24,360
memorialize those types of weaknesses

402
00:12:24,360 --> 00:12:26,640
right catalog them so that we can share

403
00:12:26,640 --> 00:12:28,140
them with engineering teams right

404
00:12:28,140 --> 00:12:29,940
educate and inform those folks who can

405
00:12:29,940 --> 00:12:31,620
prevent those things from happening in

406
00:12:31,620 --> 00:12:33,300
the future

407
00:12:33,300 --> 00:12:35,100
now the key products and services listed

408
00:12:35,100 --> 00:12:36,839
on the slide is how we Implement each of

409
00:12:36,839 --> 00:12:38,160
those functions I'm going to go through

410
00:12:38,160 --> 00:12:40,079
them in more detail on subsequent slides

411
00:12:40,079 --> 00:12:41,519
but here I just want to do a quick

412
00:12:41,519 --> 00:12:43,740
mapping of products and services to

413
00:12:43,740 --> 00:12:46,500
functions so starting in the left top

414
00:12:46,500 --> 00:12:49,079
the Privacy attack framework is our

415
00:12:49,079 --> 00:12:50,279
attempt to better understand the

416
00:12:50,279 --> 00:12:52,920
adversary that's our adversary modeling

417
00:12:52,920 --> 00:12:55,680
privacy weaknesses taxonomy is our

418
00:12:55,680 --> 00:12:57,360
instantiation of privacy weaknesses

419
00:12:57,360 --> 00:12:59,700
cataloging that middle row are the

420
00:12:59,700 --> 00:13:01,200
different types of technical assessments

421
00:13:01,200 --> 00:13:03,060
that we do and on the right are the

422
00:13:03,060 --> 00:13:04,920
different ways that we educate and

423
00:13:04,920 --> 00:13:07,139
inform the rest of the company

424
00:13:07,139 --> 00:13:08,880
and before we dive into those in a

425
00:13:08,880 --> 00:13:09,899
little bit more detail I want to take a

426
00:13:09,899 --> 00:13:10,980
second to talk about the team

427
00:13:10,980 --> 00:13:12,540
composition how do we how do we build

428
00:13:12,540 --> 00:13:14,519
this team who did we hire

429
00:13:14,519 --> 00:13:16,200
a lot of people are not terribly

430
00:13:16,200 --> 00:13:17,700
interested in privacy because they think

431
00:13:17,700 --> 00:13:19,320
about it as a sort of risk assessment

432
00:13:19,320 --> 00:13:22,139
thing a non-technical discipline first

433
00:13:22,139 --> 00:13:23,399
and foremost I want to say risk

434
00:13:23,399 --> 00:13:25,320
assessments are really really important

435
00:13:25,320 --> 00:13:26,820
to a privacy program it's kind of vital

436
00:13:26,820 --> 00:13:28,800
that you do those but it is not what we

437
00:13:28,800 --> 00:13:31,980
do we do technical assessments and in

438
00:13:31,980 --> 00:13:34,260
fact privacy engineering operators are

439
00:13:34,260 --> 00:13:36,720
actual privacy Engineers right privacy

440
00:13:36,720 --> 00:13:38,700
routine operator privacy engineers and

441
00:13:38,700 --> 00:13:40,440
so the types of engineers we're looking

442
00:13:40,440 --> 00:13:42,420
for have three main characteristics

443
00:13:42,420 --> 00:13:44,639
one obviously adversarial mindset they

444
00:13:44,639 --> 00:13:45,480
have to be able to think like an

445
00:13:45,480 --> 00:13:47,399
adversary to emulate an adversary

446
00:13:47,399 --> 00:13:49,680
to an offensive security skill set so

447
00:13:49,680 --> 00:13:50,820
this breaks down a couple different

448
00:13:50,820 --> 00:13:53,160
components one is because we're

449
00:13:53,160 --> 00:13:54,839
attacking the same kinds of systems so

450
00:13:54,839 --> 00:13:56,760
web and mobile systems you have to have

451
00:13:56,760 --> 00:13:58,200
some understanding of those different

452
00:13:58,200 --> 00:14:00,000
tools and how to use those tools to

453
00:14:00,000 --> 00:14:01,560
implement different tactics techniques

454
00:14:01,560 --> 00:14:03,180
and procedures

455
00:14:03,180 --> 00:14:04,800
but the other side of the other

456
00:14:04,800 --> 00:14:06,839
perspective on this is imagine you're

457
00:14:06,839 --> 00:14:08,579
somebody who has a really in-depth

458
00:14:08,579 --> 00:14:10,019
knowledge of Linux or Windows some

459
00:14:10,019 --> 00:14:11,579
operating system and you've gotten

460
00:14:11,579 --> 00:14:12,600
really good at manipulating that

461
00:14:12,600 --> 00:14:14,399
operating system you've kind of have

462
00:14:14,399 --> 00:14:16,920
knowledge and built a skill set there

463
00:14:16,920 --> 00:14:18,839
well we don't really want your knowledge

464
00:14:18,839 --> 00:14:20,399
of Windows and Linux because of course

465
00:14:20,399 --> 00:14:22,380
we're not attacking those things but we

466
00:14:22,380 --> 00:14:24,060
do want your skill set and how you know

467
00:14:24,060 --> 00:14:25,440
how to manipulate those things we just

468
00:14:25,440 --> 00:14:27,720
want to apply that skill set to our

469
00:14:27,720 --> 00:14:30,779
platforms Facebook Instagram messenger

470
00:14:30,779 --> 00:14:32,700
Etc and we can teach you and give you

471
00:14:32,700 --> 00:14:34,139
the knowledge to make you successful

472
00:14:34,139 --> 00:14:36,480
manipulating those things

473
00:14:36,480 --> 00:14:38,220
and then lastly privacy instincts

474
00:14:38,220 --> 00:14:40,260
privacy is kind of too new especially

475
00:14:40,260 --> 00:14:42,060
for this kind of an audience to to say

476
00:14:42,060 --> 00:14:43,620
hey we need you to have five years of

477
00:14:43,620 --> 00:14:44,940
experience so really we're looking for

478
00:14:44,940 --> 00:14:46,199
people who just have good instincts

479
00:14:46,199 --> 00:14:47,880
about it care a lot about it

480
00:14:47,880 --> 00:14:49,560
and as you can imagine that means we're

481
00:14:49,560 --> 00:14:51,540
recruiting from these four these four

482
00:14:51,540 --> 00:14:53,220
disciplines you see on the screen

483
00:14:53,220 --> 00:14:54,600
but we're doing this very purposefully

484
00:14:54,600 --> 00:14:57,120
because we want to attack any problem

485
00:14:57,120 --> 00:14:59,940
from two sides sort of an internal white

486
00:14:59,940 --> 00:15:01,440
box side and sort of an external Black

487
00:15:01,440 --> 00:15:02,579
Box side

488
00:15:02,579 --> 00:15:03,959
so you think about as your vulnerability

489
00:15:03,959 --> 00:15:05,519
researchers and your apps like Engineers

490
00:15:05,519 --> 00:15:07,079
really good at looking at code and

491
00:15:07,079 --> 00:15:08,279
you're looking at code whether it's

492
00:15:08,279 --> 00:15:09,959
source code or reverse engineered code

493
00:15:09,959 --> 00:15:12,000
they attack the problem from that angle

494
00:15:12,000 --> 00:15:14,760
and then red team and Pen testers do

495
00:15:14,760 --> 00:15:16,560
more of that external probing of both

496
00:15:16,560 --> 00:15:18,660
processes and systems so we think if we

497
00:15:18,660 --> 00:15:19,920
blend these two together we get a nice

498
00:15:19,920 --> 00:15:22,380
great team approach to everything

499
00:15:22,380 --> 00:15:24,060
and lastly I want to note that there are

500
00:15:24,060 --> 00:15:25,380
some other important Partnerships here

501
00:15:25,380 --> 00:15:27,180
so legal risk and policy because we're

502
00:15:27,180 --> 00:15:28,380
talking about privacy are super

503
00:15:28,380 --> 00:15:30,240
important Partners to have

504
00:15:30,240 --> 00:15:32,579
but at meta we're set up very well to

505
00:15:32,579 --> 00:15:34,980
facilitate those Partnerships but we

506
00:15:34,980 --> 00:15:37,320
don't have them as members of the team

507
00:15:37,320 --> 00:15:38,880
and I'm saying this because I don't want

508
00:15:38,880 --> 00:15:40,380
you to think that if you and your

509
00:15:40,380 --> 00:15:42,120
organization stand up one of these teams

510
00:15:42,120 --> 00:15:43,980
and put a lawyer on that team that

511
00:15:43,980 --> 00:15:45,959
you're doing it wrong you're not you're

512
00:15:45,959 --> 00:15:48,000
just set up differently that legal

513
00:15:48,000 --> 00:15:49,620
partnership is required and if you have

514
00:15:49,620 --> 00:15:51,180
it and that's how you you do it that's

515
00:15:51,180 --> 00:15:52,500
totally fine it's just not how we've

516
00:15:52,500 --> 00:15:53,519
done it because the company Works

517
00:15:53,519 --> 00:15:56,760
different but definitely do it

518
00:15:56,760 --> 00:15:58,139
all right now let's jump back into some

519
00:15:58,139 --> 00:15:59,519
of those products and services so

520
00:15:59,519 --> 00:16:02,820
privacy weaknesses privacy weaknesses

521
00:16:02,820 --> 00:16:04,199
are the things we're going to look for

522
00:16:04,199 --> 00:16:06,060
right those are the things we need to

523
00:16:06,060 --> 00:16:07,680
have a good understanding of they're the

524
00:16:07,680 --> 00:16:09,899
false flaws errors and code that we

525
00:16:09,899 --> 00:16:10,980
might find

526
00:16:10,980 --> 00:16:12,120
and you might be saying well why aren't

527
00:16:12,120 --> 00:16:13,079
you using the term security

528
00:16:13,079 --> 00:16:14,579
vulnerabilities those are sort of the

529
00:16:14,579 --> 00:16:17,100
same thing and the answer is maybe we

530
00:16:17,100 --> 00:16:18,000
don't know

531
00:16:18,000 --> 00:16:19,740
so we specifically call them something

532
00:16:19,740 --> 00:16:21,480
else so we can explore this space and

533
00:16:21,480 --> 00:16:24,000
answer this question of are security

534
00:16:24,000 --> 00:16:25,620
vulnerabilities and privacy weaknesses

535
00:16:25,620 --> 00:16:27,480
completely distinct partially

536
00:16:27,480 --> 00:16:30,240
overlapping entirely overlapping or is

537
00:16:30,240 --> 00:16:32,220
one a subset of the other we just don't

538
00:16:32,220 --> 00:16:34,139
know yet but we're looking into it

539
00:16:34,139 --> 00:16:36,480
of course this is an important thing to

540
00:16:36,480 --> 00:16:37,980
do not only because it's what we're

541
00:16:37,980 --> 00:16:39,480
looking for but it's the language you're

542
00:16:39,480 --> 00:16:41,040
going to use to talk to our different

543
00:16:41,040 --> 00:16:42,779
product and Engineering teams when we

544
00:16:42,779 --> 00:16:44,579
find a particular type of issue we want

545
00:16:44,579 --> 00:16:46,560
to say to them hey this is what it is

546
00:16:46,560 --> 00:16:48,839
this is the impact of it this is what it

547
00:16:48,839 --> 00:16:50,160
looks like in code this is how you

548
00:16:50,160 --> 00:16:52,620
prevent it or remediate it in the future

549
00:16:52,620 --> 00:16:54,480
and we can also end up using these

550
00:16:54,480 --> 00:16:56,639
things to Define metrics like hey we

551
00:16:56,639 --> 00:16:58,560
keep finding this issue this type of

552
00:16:58,560 --> 00:17:00,000
weakness in a particular product or

553
00:17:00,000 --> 00:17:01,980
service or code base maybe we should

554
00:17:01,980 --> 00:17:03,480
expend some more resources on fixing

555
00:17:03,480 --> 00:17:06,799
that and eradicating it

556
00:17:07,740 --> 00:17:10,799
similarly we've started to look into a

557
00:17:10,799 --> 00:17:13,260
privacy attack framework so the idea

558
00:17:13,260 --> 00:17:15,240
here again we're a red team so we want

559
00:17:15,240 --> 00:17:16,799
to emulate adversary activity we have to

560
00:17:16,799 --> 00:17:18,240
know what that activity is what are the

561
00:17:18,240 --> 00:17:19,619
tactics techniques and procedures that

562
00:17:19,619 --> 00:17:20,760
they're using

563
00:17:20,760 --> 00:17:22,559
this is of course vitally important to

564
00:17:22,559 --> 00:17:24,599
us to do our job but it's also important

565
00:17:24,599 --> 00:17:26,040
for the blue teams to understand this so

566
00:17:26,040 --> 00:17:26,880
they can build this detection

567
00:17:26,880 --> 00:17:28,679
intermediate and detection prevention

568
00:17:28,679 --> 00:17:31,080
systems the problem is as I mentioned

569
00:17:31,080 --> 00:17:32,460
before it's a little bit less well

570
00:17:32,460 --> 00:17:34,080
understood of a space so we had to

571
00:17:34,080 --> 00:17:35,039
attack this problem a little bit

572
00:17:35,039 --> 00:17:37,200
differently than miter has miter took

573
00:17:37,200 --> 00:17:38,880
all these different reports and they

574
00:17:38,880 --> 00:17:40,440
distilled from them the different ttps

575
00:17:40,440 --> 00:17:41,760
that they could then link to those

576
00:17:41,760 --> 00:17:43,740
actors we kind of did it the other way

577
00:17:43,740 --> 00:17:45,179
we did it in a Bottoms Up approach

578
00:17:45,179 --> 00:17:47,460
meaning we said hey this is the kind of

579
00:17:47,460 --> 00:17:49,320
actor we want to emulate in this

580
00:17:49,320 --> 00:17:51,480
particular operation and then once we do

581
00:17:51,480 --> 00:17:53,460
that operation we figure out the ttps we

582
00:17:53,460 --> 00:17:55,020
use to be successful and then say okay

583
00:17:55,020 --> 00:17:56,460
well this must be what that kind of

584
00:17:56,460 --> 00:17:57,780
actor would do

585
00:17:57,780 --> 00:17:59,460
obviously as this space moves forward

586
00:17:59,460 --> 00:18:01,620
and matures we hope to have attacked

587
00:18:01,620 --> 00:18:03,480
this the same way that miter did

588
00:18:03,480 --> 00:18:05,340
and I will note that both the Privacy

589
00:18:05,340 --> 00:18:06,900
weaknesses taxonomy the Privacy attack

590
00:18:06,900 --> 00:18:08,820
framework are things in the future we

591
00:18:08,820 --> 00:18:10,200
hope to share with you maybe in this

592
00:18:10,200 --> 00:18:13,700
form or others more broadly

593
00:18:14,340 --> 00:18:15,600
all right now let's talk about the kinds

594
00:18:15,600 --> 00:18:17,039
of technical assessments we perform and

595
00:18:17,039 --> 00:18:18,360
again we took a page from the security

596
00:18:18,360 --> 00:18:19,860
Playbook here

597
00:18:19,860 --> 00:18:21,059
first thing we do is what you think of

598
00:18:21,059 --> 00:18:22,799
as a normal red team operation which is

599
00:18:22,799 --> 00:18:25,500
adversary emulation so these things are

600
00:18:25,500 --> 00:18:27,720
objective focused very long-term in

601
00:18:27,720 --> 00:18:29,700
duration campaign style thing run over

602
00:18:29,700 --> 00:18:32,039
many months and because they're

603
00:18:32,039 --> 00:18:33,419
objective focused right we want to give

604
00:18:33,419 --> 00:18:35,100
ourselves the most space to be

605
00:18:35,100 --> 00:18:37,559
successful so we kind of put very few

606
00:18:37,559 --> 00:18:39,299
limits on the scope of this use

607
00:18:39,299 --> 00:18:40,980
different platforms combinations of

608
00:18:40,980 --> 00:18:42,539
features in those platforms whatever we

609
00:18:42,539 --> 00:18:44,820
need to do to be successful and the goal

610
00:18:44,820 --> 00:18:46,740
is to measure and understand our

611
00:18:46,740 --> 00:18:48,600
resilience to a particular type of

612
00:18:48,600 --> 00:18:50,460
adversary

613
00:18:50,460 --> 00:18:52,140
next we have something like purple team

614
00:18:52,140 --> 00:18:53,940
operations so again this is very much

615
00:18:53,940 --> 00:18:55,679
scoped to a particular defensive

616
00:18:55,679 --> 00:18:57,179
technology and us helping a blue team

617
00:18:57,179 --> 00:18:58,500
improve it

618
00:18:58,500 --> 00:19:00,120
specific examples could be a privacy

619
00:19:00,120 --> 00:19:01,620
control that we've added to one of our

620
00:19:01,620 --> 00:19:03,360
products or could be some sort of a

621
00:19:03,360 --> 00:19:04,740
privacy safeguard

622
00:19:04,740 --> 00:19:06,120
and the questions they might ask are

623
00:19:06,120 --> 00:19:07,679
sort of like hey we think we've covered

624
00:19:07,679 --> 00:19:09,059
this entire space of what someone could

625
00:19:09,059 --> 00:19:11,820
do here uh have we or hey how do you get

626
00:19:11,820 --> 00:19:13,080
can you see if you can find a way to

627
00:19:13,080 --> 00:19:14,220
bypass this because we don't want that

628
00:19:14,220 --> 00:19:16,380
to happen

629
00:19:16,380 --> 00:19:18,480
lastly we have our version of what you'd

630
00:19:18,480 --> 00:19:20,280
call a penetration test which we call a

631
00:19:20,280 --> 00:19:22,260
product compromise test just like a

632
00:19:22,260 --> 00:19:24,120
penetration test we're focusing on one

633
00:19:24,120 --> 00:19:26,760
specific thing product service feature

634
00:19:26,760 --> 00:19:29,100
and we're doing trying to do one of two

635
00:19:29,100 --> 00:19:29,880
things

636
00:19:29,880 --> 00:19:32,039
either uh do something like finding all

637
00:19:32,039 --> 00:19:33,299
the vulnerabilities which in this case

638
00:19:33,299 --> 00:19:34,559
would be finding all the weaknesses

639
00:19:34,559 --> 00:19:36,299
which again is why we need this

640
00:19:36,299 --> 00:19:37,860
weaknesses taxonomy to understand what

641
00:19:37,860 --> 00:19:39,240
we're looking for

642
00:19:39,240 --> 00:19:41,280
and then the other uh activity we

643
00:19:41,280 --> 00:19:42,840
perform the other goal here could be to

644
00:19:42,840 --> 00:19:45,299
do something like gaining root on a box

645
00:19:45,299 --> 00:19:47,640
in our case gaining root would be more

646
00:19:47,640 --> 00:19:50,160
akin to finding all the different types

647
00:19:50,160 --> 00:19:51,840
of data and then pulling as much data

648
00:19:51,840 --> 00:19:54,660
out as we can so classic example might

649
00:19:54,660 --> 00:19:56,760
be an API right there's some API that

650
00:19:56,760 --> 00:19:58,860
you think allows access to certain types

651
00:19:58,860 --> 00:20:01,559
of data and in certain amounts if we can

652
00:20:01,559 --> 00:20:03,419
squeeze that API and get all that data

653
00:20:03,419 --> 00:20:04,679
all those data types and all the data

654
00:20:04,679 --> 00:20:06,600
Associated out of it we've kind of done

655
00:20:06,600 --> 00:20:10,399
root right we're trying to hit root

656
00:20:10,679 --> 00:20:12,840
so with that in mind let's talk about

657
00:20:12,840 --> 00:20:14,820
some ideas for operations that you might

658
00:20:14,820 --> 00:20:16,679
want to perform

659
00:20:16,679 --> 00:20:18,419
now the first one is an adversarial

660
00:20:18,419 --> 00:20:19,799
emulation operation and it's really

661
00:20:19,799 --> 00:20:22,080
applicable to any company that has any

662
00:20:22,080 --> 00:20:23,820
sort of an online presence

663
00:20:23,820 --> 00:20:25,200
so if you have something where someone

664
00:20:25,200 --> 00:20:26,760
can create an account there are

665
00:20:26,760 --> 00:20:28,020
definitely actors in the world that want

666
00:20:28,020 --> 00:20:30,419
to do one of two things either figure

667
00:20:30,419 --> 00:20:32,280
out the contact information associated

668
00:20:32,280 --> 00:20:33,660
with that account so they might have a

669
00:20:33,660 --> 00:20:35,039
list of contact for information email

670
00:20:35,039 --> 00:20:36,960
addresses phone numbers and figure out

671
00:20:36,960 --> 00:20:38,820
what accounts are associated with or

672
00:20:38,820 --> 00:20:40,320
they might want to do the opposite and

673
00:20:40,320 --> 00:20:42,000
take a list of accounts where they know

674
00:20:42,000 --> 00:20:43,559
the people associate with them and

675
00:20:43,559 --> 00:20:44,640
figure out what the contact information

676
00:20:44,640 --> 00:20:46,320
is

677
00:20:46,320 --> 00:20:48,120
in any case the methodology is likely

678
00:20:48,120 --> 00:20:49,140
going to be the same they're going to

679
00:20:49,140 --> 00:20:50,460
look for the pieces of functionality

680
00:20:50,460 --> 00:20:52,080
that they can either input contact

681
00:20:52,080 --> 00:20:53,940
information or that output contact

682
00:20:53,940 --> 00:20:55,500
information and try and string them

683
00:20:55,500 --> 00:20:57,000
together in sort of a chained exploit

684
00:20:57,000 --> 00:21:00,179
fashion to get to that goal

685
00:21:00,179 --> 00:21:01,740
and and when you think about this kind

686
00:21:01,740 --> 00:21:04,140
of functionality you know the the blue

687
00:21:04,140 --> 00:21:05,760
team that you might imagine an Envision

688
00:21:05,760 --> 00:21:07,740
of the Privacy blue teams that might

689
00:21:07,740 --> 00:21:09,539
play here is the security of losings

690
00:21:09,539 --> 00:21:10,620
because they obviously probably have

691
00:21:10,620 --> 00:21:12,480
some detections regarding malicious

692
00:21:12,480 --> 00:21:14,100
behavior with those different pieces of

693
00:21:14,100 --> 00:21:15,299
functionality

694
00:21:15,299 --> 00:21:17,220
overall though we think because those

695
00:21:17,220 --> 00:21:19,200
functionality they're just available via

696
00:21:19,200 --> 00:21:21,780
you know a web page a web browser or a

697
00:21:21,780 --> 00:21:23,340
mobile phone they're pretty accessible

698
00:21:23,340 --> 00:21:25,020
to low sophisticated adversaries who

699
00:21:25,020 --> 00:21:28,400
don't have a lot of time or resources

700
00:21:28,860 --> 00:21:30,780
another interesting one an example of a

701
00:21:30,780 --> 00:21:32,460
purple team operation is sort of a

702
00:21:32,460 --> 00:21:34,679
sensitive data leak detection

703
00:21:34,679 --> 00:21:36,179
so you can imagine you have a team

704
00:21:36,179 --> 00:21:38,640
internally who cares about determining

705
00:21:38,640 --> 00:21:41,159
if and when sensitive data is leaving

706
00:21:41,159 --> 00:21:43,559
internal infrastructure but not at like

707
00:21:43,559 --> 00:21:45,120
a network security level this is not an

708
00:21:45,120 --> 00:21:46,559
idea of collecting a bunch of packet

709
00:21:46,559 --> 00:21:48,059
data pcap data and then kind of

710
00:21:48,059 --> 00:21:49,260
reconstructing the streams and

711
00:21:49,260 --> 00:21:51,000
determining the sensitive data we're

712
00:21:51,000 --> 00:21:52,559
thinking of it as more of an application

713
00:21:52,559 --> 00:21:53,940
layer thing

714
00:21:53,940 --> 00:21:55,500
and so when you think about it from that

715
00:21:55,500 --> 00:21:57,360
perspective there's an interesting I'll

716
00:21:57,360 --> 00:22:00,000
put in quotes adversary here and that's

717
00:22:00,000 --> 00:22:01,799
what we call the absent-minded developer

718
00:22:01,799 --> 00:22:03,840
this is somebody who's maybe creating a

719
00:22:03,840 --> 00:22:05,400
new micro service you know in your

720
00:22:05,400 --> 00:22:06,780
internal environment and they realize

721
00:22:06,780 --> 00:22:08,460
that they can get some data that they

722
00:22:08,460 --> 00:22:11,280
need to process from an external

723
00:22:11,280 --> 00:22:13,500
resource some restful API on the web

724
00:22:13,500 --> 00:22:15,299
somewhere and they make a request to

725
00:22:15,299 --> 00:22:17,039
that restful API but they don't

726
00:22:17,039 --> 00:22:18,780
recognize that hidden net request is

727
00:22:18,780 --> 00:22:19,740
some data that shouldn't have really

728
00:22:19,740 --> 00:22:21,659
left the environment

729
00:22:21,659 --> 00:22:23,820
so this internal team of folks is trying

730
00:22:23,820 --> 00:22:25,620
to detect both that there are these new

731
00:22:25,620 --> 00:22:27,059
data streams going out from new services

732
00:22:27,059 --> 00:22:29,159
and whether or not those data streams

733
00:22:29,159 --> 00:22:31,500
contain sensitive information

734
00:22:31,500 --> 00:22:33,539
so as a privacy red team operator you

735
00:22:33,539 --> 00:22:35,340
can do sort of a hide and seek operation

736
00:22:35,340 --> 00:22:37,260
here right take a two-week Sprint model

737
00:22:37,260 --> 00:22:39,720
first week the team comes up with all

738
00:22:39,720 --> 00:22:41,039
these different data streams some of

739
00:22:41,039 --> 00:22:41,940
them contain interesting information

740
00:22:41,940 --> 00:22:44,520
some of them do not and then in week two

741
00:22:44,520 --> 00:22:46,260
they say okay go find them see if your

742
00:22:46,260 --> 00:22:47,940
detection technology found them if not

743
00:22:47,940 --> 00:22:49,919
maybe hunt for them at the end of those

744
00:22:49,919 --> 00:22:51,240
two weeks everybody comes back together

745
00:22:51,240 --> 00:22:53,100
shares Lessons Learned and maybe does a

746
00:22:53,100 --> 00:22:55,200
repeat another Sprint

747
00:22:55,200 --> 00:22:57,299
of course this is also relevant if

748
00:22:57,299 --> 00:22:58,740
you're trying to detect insiders you

749
00:22:58,740 --> 00:23:01,679
know exfiltrating data

750
00:23:01,679 --> 00:23:03,059
and the last operation I want to share

751
00:23:03,059 --> 00:23:05,039
with you is something data type focused

752
00:23:05,039 --> 00:23:05,820
right this is another thing that's

753
00:23:05,820 --> 00:23:07,679
pretty much broadly applicable any

754
00:23:07,679 --> 00:23:09,600
organization has certain types of data

755
00:23:09,600 --> 00:23:11,280
they store that they know are more

756
00:23:11,280 --> 00:23:13,260
sensitive than others so one thing you

757
00:23:13,260 --> 00:23:14,460
can really easily do is just say okay

758
00:23:14,460 --> 00:23:15,900
let's pick one of those and see if we

759
00:23:15,900 --> 00:23:17,760
can get access to it and it's

760
00:23:17,760 --> 00:23:19,559
interesting here to pick both two

761
00:23:19,559 --> 00:23:21,299
different adversary profiles one that's

762
00:23:21,299 --> 00:23:22,860
low skilled meaning they just use

763
00:23:22,860 --> 00:23:25,380
off-the-shelf stuff don't really know a

764
00:23:25,380 --> 00:23:26,340
whole lot about what they're doing not

765
00:23:26,340 --> 00:23:28,260
terribly skilled and then a high

766
00:23:28,260 --> 00:23:29,700
capability adversary so someone who has

767
00:23:29,700 --> 00:23:31,679
like really skilled teams who can create

768
00:23:31,679 --> 00:23:32,940
custom chilling really know what they're

769
00:23:32,940 --> 00:23:34,679
doing because you get a notion of how

770
00:23:34,679 --> 00:23:37,080
resilient you are to each

771
00:23:37,080 --> 00:23:38,940
and the goal here of course is you want

772
00:23:38,940 --> 00:23:40,380
to be able to identify not only the

773
00:23:40,380 --> 00:23:42,120
interesting types of data people might

774
00:23:42,120 --> 00:23:43,919
want but help improve those detection

775
00:23:43,919 --> 00:23:45,720
Technologies so the standard methodology

776
00:23:45,720 --> 00:23:47,520
for doing this is saying okay pretend to

777
00:23:47,520 --> 00:23:49,080
be those lower high school adversaries

778
00:23:49,080 --> 00:23:50,520
look at what data might be available

779
00:23:50,520 --> 00:23:52,140
what are the ones they're interested in

780
00:23:52,140 --> 00:23:54,299
then enumerate a whole bunch of ttps

781
00:23:54,299 --> 00:23:56,400
they might use to get that data execute

782
00:23:56,400 --> 00:23:58,500
them to see how successful they are this

783
00:23:58,500 --> 00:23:59,940
has the added benefit that even ones

784
00:23:59,940 --> 00:24:01,799
that aren't successful are still

785
00:24:01,799 --> 00:24:03,840
attempts that your blue teams can look

786
00:24:03,840 --> 00:24:05,340
at and go aha I can tell if someone's

787
00:24:05,340 --> 00:24:07,620
even trying to do this

788
00:24:07,620 --> 00:24:09,780
because these are data type focused

789
00:24:09,780 --> 00:24:11,640
right an actor wants the data for a

790
00:24:11,640 --> 00:24:14,100
particular reason you might end up doing

791
00:24:14,100 --> 00:24:16,559
things that look like what the Integrity

792
00:24:16,559 --> 00:24:17,940
team would track like you create some

793
00:24:17,940 --> 00:24:19,860
on-platform assets that they know

794
00:24:19,860 --> 00:24:21,299
certain types of actors create so you

795
00:24:21,299 --> 00:24:22,679
might end up tripping those detections

796
00:24:22,679 --> 00:24:24,860
there

797
00:24:25,620 --> 00:24:26,760
all right now let's talk a little bit

798
00:24:26,760 --> 00:24:27,780
about findings and the differences

799
00:24:27,780 --> 00:24:30,419
between security and privacy uh findings

800
00:24:30,419 --> 00:24:32,880
so private excuse me security findings

801
00:24:32,880 --> 00:24:35,100
are by and large very objective right if

802
00:24:35,100 --> 00:24:36,360
you tell somebody I found X

803
00:24:36,360 --> 00:24:38,039
vulnerability like cross-site scripting

804
00:24:38,039 --> 00:24:39,780
they mean to say okay I got it I

805
00:24:39,780 --> 00:24:40,919
understand why that's bad I understand

806
00:24:40,919 --> 00:24:42,659
the impact of it and I actually probably

807
00:24:42,659 --> 00:24:44,039
know how to fix it I know exactly what

808
00:24:44,039 --> 00:24:45,960
you did or didn't do and I can go fix

809
00:24:45,960 --> 00:24:48,020
that

810
00:24:48,020 --> 00:24:50,640
privacy findings can be much more

811
00:24:50,640 --> 00:24:52,679
subjective because the very notion of a

812
00:24:52,679 --> 00:24:54,120
finding can be influenced by a number of

813
00:24:54,120 --> 00:24:56,159
different factors first and foremost

814
00:24:56,159 --> 00:24:58,799
your organization probably operates in

815
00:24:58,799 --> 00:25:00,480
some portion of the world and there are

816
00:25:00,480 --> 00:25:02,039
certain legal and Regulatory things

817
00:25:02,039 --> 00:25:03,179
going on in that portion of the world

818
00:25:03,179 --> 00:25:05,520
that could influence what a finding is

819
00:25:05,520 --> 00:25:07,140
second your company may have made

820
00:25:07,140 --> 00:25:09,120
statements about how they protect users

821
00:25:09,120 --> 00:25:11,280
data in their privacy and if you find

822
00:25:11,280 --> 00:25:12,780
that statement to not quite be true with

823
00:25:12,780 --> 00:25:14,159
your finding well that could that could

824
00:25:14,159 --> 00:25:16,020
then be a finding

825
00:25:16,020 --> 00:25:18,299
and lastly even if the the prior two are

826
00:25:18,299 --> 00:25:20,880
true meaning your finding uh is in line

827
00:25:20,880 --> 00:25:22,740
with us with the company statements and

828
00:25:22,740 --> 00:25:24,480
it's not buying violating a law or

829
00:25:24,480 --> 00:25:27,480
regulation you as a user of that same

830
00:25:27,480 --> 00:25:29,340
platform may say to yourself you know

831
00:25:29,340 --> 00:25:31,860
what for me as a user I still don't

832
00:25:31,860 --> 00:25:33,240
think this meets the expectation of

833
00:25:33,240 --> 00:25:35,039
privacy and you might want to call that

834
00:25:35,039 --> 00:25:36,539
a finding

835
00:25:36,539 --> 00:25:38,220
now in the future we're hoping to really

836
00:25:38,220 --> 00:25:40,440
move from the subject to the objective I

837
00:25:40,440 --> 00:25:41,640
think we've got to do two things to do

838
00:25:41,640 --> 00:25:43,320
that one is understand these privacy

839
00:25:43,320 --> 00:25:45,600
weaknesses better and two is understand

840
00:25:45,600 --> 00:25:48,000
how to do privacy by Design

841
00:25:48,000 --> 00:25:51,299
and again I think we'll get there

842
00:25:51,299 --> 00:25:53,279
all right to wrap this up I want to

843
00:25:53,279 --> 00:25:54,179
leave you with a couple of final

844
00:25:54,179 --> 00:25:55,919
thoughts and the first one I know you're

845
00:25:55,919 --> 00:25:57,000
going to be really excited about because

846
00:25:57,000 --> 00:25:58,559
I know everywhere in this room loves a

847
00:25:58,559 --> 00:26:00,419
topic of metrics

848
00:26:00,419 --> 00:26:02,880
and I hate to disappoint you but if you

849
00:26:02,880 --> 00:26:04,799
do if you're a red team operator now I

850
00:26:04,799 --> 00:26:06,480
know this can be very disappointing but

851
00:26:06,480 --> 00:26:09,419
most of your metrics don't apply here

852
00:26:09,419 --> 00:26:11,220
time to compromise the system doesn't

853
00:26:11,220 --> 00:26:12,539
really make sense because hey we're not

854
00:26:12,539 --> 00:26:14,580
compromising systems time to detection

855
00:26:14,580 --> 00:26:16,080
might not even make sense because as we

856
00:26:16,080 --> 00:26:17,520
just said we might not even know what

857
00:26:17,520 --> 00:26:18,960
we're trying to detect so we might not

858
00:26:18,960 --> 00:26:21,120
have anything to detect them

859
00:26:21,120 --> 00:26:23,159
so what do we do well the answer is I

860
00:26:23,159 --> 00:26:23,940
don't know yet I don't know what the

861
00:26:23,940 --> 00:26:25,860
perfect set of metrics are but I want to

862
00:26:25,860 --> 00:26:27,000
give you some framing thoughts on this

863
00:26:27,000 --> 00:26:29,760
first framing thought is the goal of

864
00:26:29,760 --> 00:26:31,440
these metrics should be to drive that

865
00:26:31,440 --> 00:26:32,460
fundamental change in your

866
00:26:32,460 --> 00:26:34,500
organization's privacy posture make them

867
00:26:34,500 --> 00:26:36,299
better at privacy

868
00:26:36,299 --> 00:26:37,980
and I think you can do that by looking

869
00:26:37,980 --> 00:26:41,880
at three big buckets to measure one is

870
00:26:41,880 --> 00:26:43,380
how your organization is doing it

871
00:26:43,380 --> 00:26:45,240
understanding that space that privacy

872
00:26:45,240 --> 00:26:47,520
space especially the adversarial space

873
00:26:47,520 --> 00:26:49,620
the findings you have about New ttps and

874
00:26:49,620 --> 00:26:50,700
new weaknesses are probably going to

875
00:26:50,700 --> 00:26:52,620
help them understand that

876
00:26:52,620 --> 00:26:53,880
the next one is understanding how the

877
00:26:53,880 --> 00:26:56,640
company themselves are doing right so do

878
00:26:56,640 --> 00:26:58,200
they have defenses how well do those

879
00:26:58,200 --> 00:27:00,360
defenses work how well are they doing it

880
00:27:00,360 --> 00:27:02,100
identifying the gaps in those defenses

881
00:27:02,100 --> 00:27:03,659
and filling them

882
00:27:03,659 --> 00:27:04,980
and lastly of course you want to measure

883
00:27:04,980 --> 00:27:06,179
how your own team is doing right how is

884
00:27:06,179 --> 00:27:08,340
your privacy red team doing at red team

885
00:27:08,340 --> 00:27:10,380
and for that I like to use the Privacy

886
00:27:10,380 --> 00:27:12,600
problem pyramid on the right

887
00:27:12,600 --> 00:27:14,460
so as we go up in this pyramid you get

888
00:27:14,460 --> 00:27:16,260
more impact and the lower we are the

889
00:27:16,260 --> 00:27:17,400
more things you'll find so if you think

890
00:27:17,400 --> 00:27:18,360
about the kinds of findings you might

891
00:27:18,360 --> 00:27:20,400
have in an operation that lowest layer

892
00:27:20,400 --> 00:27:21,900
of the pyramid is going to be your bugs

893
00:27:21,900 --> 00:27:24,179
your vulnerabilities those flaws and

894
00:27:24,179 --> 00:27:26,580
weaknesses and code that might cause

895
00:27:26,580 --> 00:27:28,740
privacy issues those are pretty obvious

896
00:27:28,740 --> 00:27:29,940
right you can show this to anybody and

897
00:27:29,940 --> 00:27:31,919
they say yep we got to fix these got it

898
00:27:31,919 --> 00:27:33,659
we'll do that

899
00:27:33,659 --> 00:27:35,400
next level up hopefully you have less of

900
00:27:35,400 --> 00:27:37,020
these this next level are definitely not

901
00:27:37,020 --> 00:27:40,080
bugs and weaknesses right but they are

902
00:27:40,080 --> 00:27:41,760
things that you would bring to a product

903
00:27:41,760 --> 00:27:44,640
team an engineering team and say hey I I

904
00:27:44,640 --> 00:27:46,140
think this is an issue I think we should

905
00:27:46,140 --> 00:27:48,299
do something about this and they go oh

906
00:27:48,299 --> 00:27:50,100
yeah we should definitely fix that but

907
00:27:50,100 --> 00:27:51,480
it's going to be fairly complicated so

908
00:27:51,480 --> 00:27:53,580
we're going to throw that in our roadmap

909
00:27:53,580 --> 00:27:54,900
right and if that's why I call them

910
00:27:54,900 --> 00:27:56,940
roadmap changes

911
00:27:56,940 --> 00:27:59,340
now the last category of things are

912
00:27:59,340 --> 00:28:01,200
neither of the first two and hopefully

913
00:28:01,200 --> 00:28:02,760
are definitely the least number of

914
00:28:02,760 --> 00:28:04,080
things you'll find I think that of them

915
00:28:04,080 --> 00:28:06,059
design issues because they're things

916
00:28:06,059 --> 00:28:07,320
you're probably going to go to that same

917
00:28:07,320 --> 00:28:09,600
engineering team with and say look

918
00:28:09,600 --> 00:28:10,799
um I think this is something you need to

919
00:28:10,799 --> 00:28:13,320
change and they're going to go nope

920
00:28:13,320 --> 00:28:14,640
everything we say about how we're

921
00:28:14,640 --> 00:28:17,340
protecting users privacy is done here it

922
00:28:17,340 --> 00:28:19,500
doesn't violate any law regulation

923
00:28:19,500 --> 00:28:21,419
now you're going to come back and say

924
00:28:21,419 --> 00:28:23,820
well but yeah it violates my expectation

925
00:28:23,820 --> 00:28:25,080
of privacy and I'm a user of this

926
00:28:25,080 --> 00:28:26,880
platform and if you keep pushing this

927
00:28:26,880 --> 00:28:28,440
and you're really successful in getting

928
00:28:28,440 --> 00:28:30,539
them to make that change basically what

929
00:28:30,539 --> 00:28:33,240
you've done is both learn and taught a

930
00:28:33,240 --> 00:28:34,440
better design because fundamentally

931
00:28:34,440 --> 00:28:35,279
you're probably going to be talking

932
00:28:35,279 --> 00:28:37,620
about a design issue right and it's not

933
00:28:37,620 --> 00:28:39,120
necessarily bad here right that it just

934
00:28:39,120 --> 00:28:40,440
might have been an older product that

935
00:28:40,440 --> 00:28:41,940
they didn't think about user privacy

936
00:28:41,940 --> 00:28:43,620
when they were building it but if you

937
00:28:43,620 --> 00:28:45,240
get to the point where actually helping

938
00:28:45,240 --> 00:28:47,700
people learn how to design things better

939
00:28:47,700 --> 00:28:49,080
they're probably not going to make that

940
00:28:49,080 --> 00:28:50,100
mistake in the future they're going to

941
00:28:50,100 --> 00:28:52,080
bake in those learnings the next time

942
00:28:52,080 --> 00:28:54,740
they build something

943
00:28:56,580 --> 00:28:58,740
right so so now let's talk about some

944
00:28:58,740 --> 00:28:59,820
lessons learned to wrap this whole

945
00:28:59,820 --> 00:29:01,679
conversation up and I want to start with

946
00:29:01,679 --> 00:29:03,480
a bit of a story so I've talked to folks

947
00:29:03,480 --> 00:29:05,340
both internally and externally to the

948
00:29:05,340 --> 00:29:06,720
company about this concept and

949
00:29:06,720 --> 00:29:08,520
interestingly I've got the same question

950
00:29:08,520 --> 00:29:10,799
multiple times so it's worth telling the

951
00:29:10,799 --> 00:29:12,360
story here and it goes something like

952
00:29:12,360 --> 00:29:14,279
this hey Scott this is a great concept

953
00:29:14,279 --> 00:29:15,900
love what you're doing here seems like

954
00:29:15,900 --> 00:29:17,760
it's super valuable but here's my

955
00:29:17,760 --> 00:29:18,779
question

956
00:29:18,779 --> 00:29:20,760
if you have all these database tables

957
00:29:20,760 --> 00:29:22,440
like how do you ensure they all have

958
00:29:22,440 --> 00:29:24,360
retention limits on them and those are

959
00:29:24,360 --> 00:29:26,399
the right retention limits and I say I

960
00:29:26,399 --> 00:29:28,559
got this no problem very simply

961
00:29:28,559 --> 00:29:30,539
I don't do that

962
00:29:30,539 --> 00:29:32,640
it's not my job what you're telling me

963
00:29:32,640 --> 00:29:34,080
is you have a requirement to have

964
00:29:34,080 --> 00:29:35,760
retention limits on database tables and

965
00:29:35,760 --> 00:29:36,899
you want to know who's validating that

966
00:29:36,899 --> 00:29:39,419
requirement that's a compliance function

967
00:29:39,419 --> 00:29:41,220
and by the way compliance is hugely

968
00:29:41,220 --> 00:29:42,840
important you absolutely need to have

969
00:29:42,840 --> 00:29:44,820
that but that's not what we do

970
00:29:44,820 --> 00:29:47,279
we go above and beyond compliance we

971
00:29:47,279 --> 00:29:48,659
provide a level of confidence that

972
00:29:48,659 --> 00:29:49,740
you're doing the right thing you're

973
00:29:49,740 --> 00:29:51,539
doing more than just meeting

974
00:29:51,539 --> 00:29:53,100
requirements you're going beyond that

975
00:29:53,100 --> 00:29:55,080
that's Assurance that's what red teams

976
00:29:55,080 --> 00:29:57,059
do

977
00:29:57,059 --> 00:29:58,679
uh the next thing I think is important

978
00:29:58,679 --> 00:30:00,679
to reiterate here is

979
00:30:00,679 --> 00:30:03,720
accessing collecting storing using data

980
00:30:03,720 --> 00:30:06,240
for this purpose of red teaming might be

981
00:30:06,240 --> 00:30:07,860
different than the way your company ever

982
00:30:07,860 --> 00:30:10,020
envisioned doing that and that might

983
00:30:10,020 --> 00:30:11,580
have some depending on the area of the

984
00:30:11,580 --> 00:30:12,960
world you're operating in that might

985
00:30:12,960 --> 00:30:14,760
have some regulatory legal risks

986
00:30:14,760 --> 00:30:16,320
associated with it so you definitely

987
00:30:16,320 --> 00:30:18,000
need to partner with your legal teams to

988
00:30:18,000 --> 00:30:20,100
figure out how you mitigate those risks

989
00:30:20,100 --> 00:30:23,279
because they can be Show Stoppers

990
00:30:23,279 --> 00:30:25,260
and the last uh thought I want to leave

991
00:30:25,260 --> 00:30:27,179
you with here has something to do with

992
00:30:27,179 --> 00:30:28,620
sort of where I think we have been and

993
00:30:28,620 --> 00:30:31,500
where we're going as a privacy industry

994
00:30:31,500 --> 00:30:34,500
so the uh on the right here this little

995
00:30:34,500 --> 00:30:36,240
diagram kind of shows my own thought on

996
00:30:36,240 --> 00:30:37,559
on kind of the differences between

997
00:30:37,559 --> 00:30:39,240
security and privacy historically so I

998
00:30:39,240 --> 00:30:41,100
think they're on this spectrum of very

999
00:30:41,100 --> 00:30:44,159
technology focused to very risk focused

1000
00:30:44,159 --> 00:30:45,480
and if you think about where security

1001
00:30:45,480 --> 00:30:47,880
was maybe 20 25 years ago

1002
00:30:47,880 --> 00:30:49,500
um they were way back on this you know

1003
00:30:49,500 --> 00:30:51,299
Tech focused area so there were people

1004
00:30:51,299 --> 00:30:53,220
figuring out new ways to break things

1005
00:30:53,220 --> 00:30:56,220
and other people figuring out uh ways to

1006
00:30:56,220 --> 00:30:57,360
defend against that it was very

1007
00:30:57,360 --> 00:30:58,980
technology focused

1008
00:30:58,980 --> 00:31:01,799
as the industry grew up corporations got

1009
00:31:01,799 --> 00:31:03,720
involved created Security Programs they

1010
00:31:03,720 --> 00:31:05,340
introduced the notion of risk right to

1011
00:31:05,340 --> 00:31:06,659
figure out what technologies they need

1012
00:31:06,659 --> 00:31:08,279
to have and nowadays we have this nice

1013
00:31:08,279 --> 00:31:11,520
balance between Tech and risk

1014
00:31:11,520 --> 00:31:14,220
I think privacy started in the other

1015
00:31:14,220 --> 00:31:15,720
side right they start on the risk side

1016
00:31:15,720 --> 00:31:16,860
it's probably a reason a lot of us

1017
00:31:16,860 --> 00:31:18,659
didn't get into that

1018
00:31:18,659 --> 00:31:20,039
um talking about things like Hey where's

1019
00:31:20,039 --> 00:31:22,380
your sensitive data who can access it

1020
00:31:22,380 --> 00:31:23,220
Etc

1021
00:31:23,220 --> 00:31:24,299
but if you think about those questions

1022
00:31:24,299 --> 00:31:25,860
nowadays like where's your sensitive

1023
00:31:25,860 --> 00:31:28,679
data it's on my phones and my laptop

1024
00:31:28,679 --> 00:31:30,360
it's in multiple Cloud environments

1025
00:31:30,360 --> 00:31:31,980
right it's all in all these different

1026
00:31:31,980 --> 00:31:33,539
Technologies

1027
00:31:33,539 --> 00:31:37,039
so that notion of Technology you know

1028
00:31:37,039 --> 00:31:39,779
infusing more risk into into privacy and

1029
00:31:39,779 --> 00:31:41,159
kind of pulling privacy towards that

1030
00:31:41,159 --> 00:31:42,720
Tech Direction I think is where we're

1031
00:31:42,720 --> 00:31:44,520
going and I think we're kind of at the

1032
00:31:44,520 --> 00:31:45,960
beginning stages of that like we were

1033
00:31:45,960 --> 00:31:48,539
you know maybe 20 years ago in uh in

1034
00:31:48,539 --> 00:31:50,880
security hopefully though in the future

1035
00:31:50,880 --> 00:31:53,100
right we'll get this nice balance and

1036
00:31:53,100 --> 00:31:54,840
people will be sitting in a room like

1037
00:31:54,840 --> 00:31:56,100
this and going I can't believe we ever

1038
00:31:56,100 --> 00:31:58,620
debated whether offensive privacy was a

1039
00:31:58,620 --> 00:31:59,760
thing we should have in a privacy

1040
00:31:59,760 --> 00:32:01,919
program I think starting this

1041
00:32:01,919 --> 00:32:03,539
conversation now is going to really help

1042
00:32:03,539 --> 00:32:06,020
us get there

1043
00:32:06,299 --> 00:32:08,340
so all that being said um I want to

1044
00:32:08,340 --> 00:32:09,600
Circle back what I said at the beginning

1045
00:32:09,600 --> 00:32:11,940
you may disagree in part or in whole

1046
00:32:11,940 --> 00:32:13,620
with a lot of things I've said today or

1047
00:32:13,620 --> 00:32:15,539
you might agree either way I don't care

1048
00:32:15,539 --> 00:32:16,799
I think it's good that's what a

1049
00:32:16,799 --> 00:32:19,080
conversation is it's a back and forth so

1050
00:32:19,080 --> 00:32:21,299
let's keep talking

1051
00:32:21,299 --> 00:32:22,799
thank you for your time and I'll take

1052
00:32:22,799 --> 00:32:24,850
any questions you may have

1053
00:32:24,850 --> 00:32:25,340
[Applause]

1054
00:32:25,340 --> 00:32:31,349
[Music]

1055
00:32:35,190 --> 00:32:38,299
[Music]

