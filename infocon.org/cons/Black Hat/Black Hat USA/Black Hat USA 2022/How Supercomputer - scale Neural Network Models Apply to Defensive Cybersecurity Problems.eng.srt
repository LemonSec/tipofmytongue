1
00:00:01,730 --> 00:00:03,720
[Music]

2
00:00:03,720 --> 00:00:06,720
foreign

3
00:00:08,960 --> 00:00:12,940
to the stage young Huli and Joshua sacks

4
00:00:12,940 --> 00:00:16,698
[Applause]

5
00:00:18,359 --> 00:00:19,800
okay

6
00:00:19,800 --> 00:00:21,060
um

7
00:00:21,060 --> 00:00:22,619
so

8
00:00:22,619 --> 00:00:25,680
let me fix this really quickly

9
00:00:25,680 --> 00:00:27,000
so we're gonna be talking about a lot of

10
00:00:27,000 --> 00:00:30,240
technical ideas today but uh perhaps the

11
00:00:30,240 --> 00:00:31,439
greatest feat of engineering has

12
00:00:31,439 --> 00:00:33,540
happened in this talk is the team that

13
00:00:33,540 --> 00:00:35,520
just got our slides up on the up on the

14
00:00:35,520 --> 00:00:37,440
screen so apologies for the delay and uh

15
00:00:37,440 --> 00:00:38,579
happy to be here hopefully that

16
00:00:38,579 --> 00:00:39,480
hopefully we won't have any more

17
00:00:39,480 --> 00:00:41,280
technical difficulties

18
00:00:41,280 --> 00:00:43,140
um okay so our our talk today is

19
00:00:43,140 --> 00:00:46,320
entitled gpt3 and me how super super

20
00:00:46,320 --> 00:00:47,820
computer scale neural network models

21
00:00:47,820 --> 00:00:48,960
apply to defensive cyber security

22
00:00:48,960 --> 00:00:51,840
problems I'm Josh sacks I'm Chief

23
00:00:51,840 --> 00:00:53,940
scientist at Sophos I'm here with Yahoo

24
00:00:53,940 --> 00:00:56,280
Lee a principal research scientist at

25
00:00:56,280 --> 00:00:58,620
sofos

26
00:00:58,620 --> 00:01:00,239
um just so I get a sense of the audience

27
00:01:00,239 --> 00:01:01,140
here

28
00:01:01,140 --> 00:01:03,180
um how many of you have heard of gpt3 or

29
00:01:03,180 --> 00:01:05,280
know what it know what it is okay so I

30
00:01:05,280 --> 00:01:06,780
think almost almost everybody raised

31
00:01:06,780 --> 00:01:08,640
their hands but oh I'm gonna I'm gonna

32
00:01:08,640 --> 00:01:09,659
assume

33
00:01:09,659 --> 00:01:11,880
um not too much knowledge of the machine

34
00:01:11,880 --> 00:01:14,340
learning domain and gpt3 um that quickly

35
00:01:14,340 --> 00:01:16,020
get quickly we'll get into

36
00:01:16,020 --> 00:01:18,180
um sort of the nuts and bolts of the

37
00:01:18,180 --> 00:01:19,560
work that we did here and why we think

38
00:01:19,560 --> 00:01:21,900
it's significant

39
00:01:21,900 --> 00:01:22,680
um

40
00:01:22,680 --> 00:01:25,619
okay so this is us I'm gonna go Fairly

41
00:01:25,619 --> 00:01:26,880
rapidly here since we lost a few minutes

42
00:01:26,880 --> 00:01:29,040
at the beginning of this talk

43
00:01:29,040 --> 00:01:30,119
um I want to I want to just present the

44
00:01:30,119 --> 00:01:32,759
Theses of this talk up front

45
00:01:32,759 --> 00:01:34,140
um and then we'll get into sort of

46
00:01:34,140 --> 00:01:38,280
arguing for them um so one

47
00:01:38,280 --> 00:01:39,600
um there's there's something new going

48
00:01:39,600 --> 00:01:41,400
on in machine learning in the last four

49
00:01:41,400 --> 00:01:42,720
or five years

50
00:01:42,720 --> 00:01:44,340
um and it really involves two components

51
00:01:44,340 --> 00:01:46,619
uh first uh we're seeing the emergence

52
00:01:46,619 --> 00:01:49,079
of these very large scale models and

53
00:01:49,079 --> 00:01:50,579
these models have fundamentally new

54
00:01:50,579 --> 00:01:52,740
capabilities and they've been much

55
00:01:52,740 --> 00:01:54,479
discussed in the in the domain of like

56
00:01:54,479 --> 00:01:56,280
natural language processing image

57
00:01:56,280 --> 00:01:57,540
Generation

58
00:01:57,540 --> 00:01:59,280
Um we think that these new capabilities

59
00:01:59,280 --> 00:02:00,540
are really important for cyber security

60
00:02:00,540 --> 00:02:01,860
as well

61
00:02:01,860 --> 00:02:02,700
um

62
00:02:02,700 --> 00:02:05,399
uh another new trend in machine learning

63
00:02:05,399 --> 00:02:06,899
is this idea of self-supervised learning

64
00:02:06,899 --> 00:02:08,580
which allows machine learning models

65
00:02:08,580 --> 00:02:09,899
especially large machine learning models

66
00:02:09,899 --> 00:02:12,780
to take advantage of unlabeled web scale

67
00:02:12,780 --> 00:02:14,280
data I'll be talking about why I think

68
00:02:14,280 --> 00:02:17,340
that's important as well as well

69
00:02:17,340 --> 00:02:18,540
um

70
00:02:18,540 --> 00:02:20,340
third and this is really the punchline

71
00:02:20,340 --> 00:02:21,420
of our talk

72
00:02:21,420 --> 00:02:24,540
um machine learning has changed and we

73
00:02:24,540 --> 00:02:26,220
want to provoke interests and folks

74
00:02:26,220 --> 00:02:27,739
coming together and

75
00:02:27,739 --> 00:02:30,180
looking at the way in which these

76
00:02:30,180 --> 00:02:31,800
changes namely Large Scale Models

77
00:02:31,800 --> 00:02:33,360
trained in the self-supervised fashion

78
00:02:33,360 --> 00:02:35,700
can impact cyber security in a positive

79
00:02:35,700 --> 00:02:37,020
way particularly defensive cyber

80
00:02:37,020 --> 00:02:39,540
security this talks really early work in

81
00:02:39,540 --> 00:02:40,580
this space

82
00:02:40,580 --> 00:02:42,540
we think we've developed some proof of

83
00:02:42,540 --> 00:02:43,620
Concepts which are really interesting

84
00:02:43,620 --> 00:02:45,840
with respect to improving cyber security

85
00:02:45,840 --> 00:02:47,819
defense but what we're really hoping for

86
00:02:47,819 --> 00:02:49,879
is other researchers in the community

87
00:02:49,879 --> 00:02:52,140
to do their own research in this area

88
00:02:52,140 --> 00:02:54,239
and we're also hoping to get feedback

89
00:02:54,239 --> 00:02:56,700
from practitioners around how how the

90
00:02:56,700 --> 00:02:57,720
large models we're going to be talking

91
00:02:57,720 --> 00:03:00,120
about in the presentation today could be

92
00:03:00,120 --> 00:03:02,940
efficacious relative to defensive cyber

93
00:03:02,940 --> 00:03:04,920
security problems

94
00:03:04,920 --> 00:03:06,840
okay and also in the spirit of

95
00:03:06,840 --> 00:03:09,360
presenting results up front uh we're

96
00:03:09,360 --> 00:03:11,220
going to present two proof of concept

97
00:03:11,220 --> 00:03:13,200
experiments that we did this is almost

98
00:03:13,200 --> 00:03:16,920
all young who's work uh first we're

99
00:03:16,920 --> 00:03:19,019
going to show that we can use gpt3 this

100
00:03:19,019 --> 00:03:21,780
large super super computer scale uh

101
00:03:21,780 --> 00:03:24,420
neural network model uh to solve the

102
00:03:24,420 --> 00:03:25,680
following problem

103
00:03:25,680 --> 00:03:27,720
um so in this example

104
00:03:27,720 --> 00:03:30,720
um we have a command line which is

105
00:03:30,720 --> 00:03:34,080
suspicious and hard to parse uh has sort

106
00:03:34,080 --> 00:03:35,459
of high cognitive load to make sense of

107
00:03:35,459 --> 00:03:37,800
even if you're used to scripting and um

108
00:03:37,800 --> 00:03:40,560
in in on the Windows command shell

109
00:03:40,560 --> 00:03:43,140
um and then on the right we have gpt3's

110
00:03:43,140 --> 00:03:44,819
translation using a method that Yahoo

111
00:03:44,819 --> 00:03:48,060
and I developed of that sort of Arcane

112
00:03:48,060 --> 00:03:52,560
set of syntax into a natural a a human a

113
00:03:52,560 --> 00:03:54,180
lucid human readable natural language

114
00:03:54,180 --> 00:03:56,580
string so you know you can just sort of

115
00:03:56,580 --> 00:03:58,560
run the run the mental experiment

116
00:03:58,560 --> 00:04:00,060
yourself like try to make sense of

117
00:04:00,060 --> 00:04:01,140
what's going on in this command line

118
00:04:01,140 --> 00:04:02,400
this is the kind of command line that

119
00:04:02,400 --> 00:04:03,780
analysts that sofos and many other

120
00:04:03,780 --> 00:04:05,519
places spend a lot of their day looking

121
00:04:05,519 --> 00:04:07,980
through to detect evidence of compromise

122
00:04:07,980 --> 00:04:10,799
um clearly it's a significant cognitive

123
00:04:10,799 --> 00:04:12,060
load to sort of make sense of what's

124
00:04:12,060 --> 00:04:14,099
going on here and then the description

125
00:04:14,099 --> 00:04:17,160
um is much easier to to grok the

126
00:04:17,160 --> 00:04:18,600
description is the command will create a

127
00:04:18,600 --> 00:04:20,880
file called execute.bat in the temp

128
00:04:20,880 --> 00:04:23,520
folder it will then run the command

129
00:04:23,520 --> 00:04:25,860
um user's admin OneDrive administrators

130
00:04:25,860 --> 00:04:27,720
Inc and output the results to the

131
00:04:27,720 --> 00:04:29,699
underscore output file in the local

132
00:04:29,699 --> 00:04:31,380
machine the batch file will then execute

133
00:04:31,380 --> 00:04:33,660
itself and delete itself afterwards so

134
00:04:33,660 --> 00:04:36,300
this is one example of what we're going

135
00:04:36,300 --> 00:04:39,840
to show around what gpt3 can do and how

136
00:04:39,840 --> 00:04:42,600
it can help in a stock context

137
00:04:42,600 --> 00:04:44,520
the second result we're going to show in

138
00:04:44,520 --> 00:04:45,600
young who's you know who's going to go

139
00:04:45,600 --> 00:04:47,900
into depth around this experiment

140
00:04:47,900 --> 00:04:53,240
is that large models like jpt3

141
00:04:53,240 --> 00:04:56,940
can learn to detect attacks and

142
00:04:56,940 --> 00:04:59,759
malicious observables and spam with a

143
00:04:59,759 --> 00:05:03,419
tiny volume of training data so Yahoo is

144
00:05:03,419 --> 00:05:04,500
going to talk more about this later but

145
00:05:04,500 --> 00:05:06,720
what this result

146
00:05:06,720 --> 00:05:10,080
um means here is that when we train

147
00:05:10,080 --> 00:05:11,940
um an email detection model to

148
00:05:11,940 --> 00:05:13,380
distinguish between bad email and good

149
00:05:13,380 --> 00:05:15,900
email we can we can

150
00:05:15,900 --> 00:05:17,940
um and using older machine learning

151
00:05:17,940 --> 00:05:21,479
models like non non-gpt like not gpt3

152
00:05:21,479 --> 00:05:23,639
and much smaller scale models um we

153
00:05:23,639 --> 00:05:25,259
basically can't train a model with that

154
00:05:25,259 --> 00:05:26,460
scale of training data I think that's a

155
00:05:26,460 --> 00:05:27,720
ridiculously small training set but with

156
00:05:27,720 --> 00:05:29,340
gpt3 we can achieve like a Deployable

157
00:05:29,340 --> 00:05:31,500
accuracy and that's significant because

158
00:05:31,500 --> 00:05:33,660
there are many contexts and Security in

159
00:05:33,660 --> 00:05:35,340
which we just have a few examples of a

160
00:05:35,340 --> 00:05:36,479
bad thing that we're looking for and

161
00:05:36,479 --> 00:05:37,860
we'd like to be able to show an AI

162
00:05:37,860 --> 00:05:40,199
system those examples so we could find

163
00:05:40,199 --> 00:05:43,080
similar bad examples and what we found

164
00:05:43,080 --> 00:05:44,460
is the gpt3 is really good at this

165
00:05:44,460 --> 00:05:46,620
problem

166
00:05:46,620 --> 00:05:47,820
okay

167
00:05:47,820 --> 00:05:49,680
um so those are like the main arguments

168
00:05:49,680 --> 00:05:50,940
and Main results that we're going to

169
00:05:50,940 --> 00:05:52,440
present today the rest of the talk is

170
00:05:52,440 --> 00:05:54,600
going to be a deep dive instruments that

171
00:05:54,600 --> 00:05:56,039
uh that we've done in sofos around

172
00:05:56,039 --> 00:05:57,660
applying those large models to cyber

173
00:05:57,660 --> 00:06:00,380
security problems

174
00:06:00,840 --> 00:06:03,539
okay so first some just like General

175
00:06:03,539 --> 00:06:05,759
backgrounds around the trends that I'm

176
00:06:05,759 --> 00:06:08,520
referring to in machine learning

177
00:06:08,520 --> 00:06:09,720
deep learning models are just getting

178
00:06:09,720 --> 00:06:11,759
bigger um here's here's a really useful

179
00:06:11,759 --> 00:06:13,979
platform from towards data science.com

180
00:06:13,979 --> 00:06:18,539
uh showing the the the the growth in the

181
00:06:18,539 --> 00:06:20,880
size of models proposed in academic

182
00:06:20,880 --> 00:06:23,100
machine learning papers since really the

183
00:06:23,100 --> 00:06:24,060
birth of machine learning in the

184
00:06:24,060 --> 00:06:26,220
post-war period in like the 1950s

185
00:06:26,220 --> 00:06:28,979
um so on the on the vertical axis here

186
00:06:28,979 --> 00:06:30,840
you have parameter account which is a

187
00:06:30,840 --> 00:06:32,280
measure of the size of the machine

188
00:06:32,280 --> 00:06:34,620
learning model and on the horizontal

189
00:06:34,620 --> 00:06:36,419
axis you have publication dates of

190
00:06:36,419 --> 00:06:38,280
machine learning research papers and

191
00:06:38,280 --> 00:06:40,259
this is a log scale so you're looking at

192
00:06:40,259 --> 00:06:41,819
orders of magnitude here but so if you

193
00:06:41,819 --> 00:06:44,280
go back to the 1950s you know you had

194
00:06:44,280 --> 00:06:45,840
um like neural network early neural

195
00:06:45,840 --> 00:06:48,539
network models with like thousands of

196
00:06:48,539 --> 00:06:50,400
um of parameters a parameter here is

197
00:06:50,400 --> 00:06:51,900
like an interconnection between two

198
00:06:51,900 --> 00:06:53,460
artificial neurons

199
00:06:53,460 --> 00:06:55,860
um uh going forward you have this like

200
00:06:55,860 --> 00:06:57,240
log linear relationship between

201
00:06:57,240 --> 00:07:00,960
parameter counts and and time so so to

202
00:07:00,960 --> 00:07:03,000
all of a sudden just exploding in size

203
00:07:03,000 --> 00:07:05,759
um so what happens what happened is that

204
00:07:05,759 --> 00:07:06,900
researchers

205
00:07:06,900 --> 00:07:10,500
um have become aware where over the last

206
00:07:10,500 --> 00:07:13,620
five years or so that merely scaling up

207
00:07:13,620 --> 00:07:15,180
a neural network without changing

208
00:07:15,180 --> 00:07:18,300
anything else about it say increasing

209
00:07:18,300 --> 00:07:19,740
the width of your neural network layers

210
00:07:19,740 --> 00:07:22,020
or increasing depth but not adding any

211
00:07:22,020 --> 00:07:23,340
new cleverness just merely increasing

212
00:07:23,340 --> 00:07:24,259
the scale

213
00:07:24,259 --> 00:07:26,460
yields better results for some reason

214
00:07:26,460 --> 00:07:28,319
and I'm going to Deep dive into that and

215
00:07:28,319 --> 00:07:29,759
just

216
00:07:29,759 --> 00:07:31,080
show you guys a bunch of evidence to

217
00:07:31,080 --> 00:07:32,400
convince you that that's really true but

218
00:07:32,400 --> 00:07:33,479
that's sort of what's happening there

219
00:07:33,479 --> 00:07:34,680
neural network models are just getting

220
00:07:34,680 --> 00:07:36,960
bigger

221
00:07:36,960 --> 00:07:38,599
um and another thing is happening too

222
00:07:38,599 --> 00:07:40,680
which is that neural network models are

223
00:07:40,680 --> 00:07:44,039
getting trained in a new way so kind of

224
00:07:44,039 --> 00:07:45,360
classically in the Deep learning space

225
00:07:45,360 --> 00:07:47,280
the way we train neural network models

226
00:07:47,280 --> 00:07:50,099
was if we wanted a neural network model

227
00:07:50,099 --> 00:07:51,479
to distinguish between malware and

228
00:07:51,479 --> 00:07:52,740
benign wear we gave it a bunch of

229
00:07:52,740 --> 00:07:55,020
labeled examples of malware and benign

230
00:07:55,020 --> 00:07:56,160
wear

231
00:07:56,160 --> 00:07:57,900
um the problem with that is that there's

232
00:07:57,900 --> 00:07:59,699
lots of software

233
00:07:59,699 --> 00:08:01,199
um that's in the gray area we're not

234
00:08:01,199 --> 00:08:02,880
sure if it's malware of a nightwear like

235
00:08:02,880 --> 00:08:05,400
in our databases at sofas we have on the

236
00:08:05,400 --> 00:08:06,660
order of billions of files in our

237
00:08:06,660 --> 00:08:08,880
database and many of those files we're

238
00:08:08,880 --> 00:08:10,500
not sure if they're good or bad and the

239
00:08:10,500 --> 00:08:11,819
question is how do we train on that data

240
00:08:11,819 --> 00:08:14,340
and more broadly there's just a ton of

241
00:08:14,340 --> 00:08:16,080
data out there right I mean this is a

242
00:08:16,080 --> 00:08:17,940
plot showing the growth in sort of

243
00:08:17,940 --> 00:08:22,080
machine data over the last uh 10 years

244
00:08:22,080 --> 00:08:24,060
and protecting into the future and

245
00:08:24,060 --> 00:08:25,500
there's just more and more data

246
00:08:25,500 --> 00:08:26,520
available

247
00:08:26,520 --> 00:08:28,020
um I mean you can go you know if you ran

248
00:08:28,020 --> 00:08:29,580
a web crawler today versus 20 years ago

249
00:08:29,580 --> 00:08:32,219
right you get much more data also also

250
00:08:32,219 --> 00:08:34,919
all sorts of digital instruments or

251
00:08:34,919 --> 00:08:36,120
generating data

252
00:08:36,120 --> 00:08:37,679
Factory user cars and this kind of thing

253
00:08:37,679 --> 00:08:38,940
and how do we train on that data when we

254
00:08:38,940 --> 00:08:40,760
don't have annotations attached to it

255
00:08:40,760 --> 00:08:43,080
and what the research Community has

256
00:08:43,080 --> 00:08:44,760
found is that there's a methods is

257
00:08:44,760 --> 00:08:46,320
there's a category of algorithms called

258
00:08:46,320 --> 00:08:48,959
self-supervised algorithms that allow us

259
00:08:48,959 --> 00:08:50,399
to train on data that's not annotated

260
00:08:50,399 --> 00:08:52,440
and improve our machine learning models

261
00:08:52,440 --> 00:08:54,420
and the basic workflow here is that we

262
00:08:54,420 --> 00:08:56,220
use these self-supervised training

263
00:08:56,220 --> 00:08:57,360
algorithms they'll Define what they are

264
00:08:57,360 --> 00:08:58,620
in a minute but um we usually

265
00:08:58,620 --> 00:09:00,660
self-supervised training algorithms to

266
00:09:00,660 --> 00:09:02,519
train neural network models on

267
00:09:02,519 --> 00:09:05,700
unannotated unlabeled data and then we

268
00:09:05,700 --> 00:09:07,140
use our label data to fine-tune those

269
00:09:07,140 --> 00:09:08,700
neural networks to solve a specific

270
00:09:08,700 --> 00:09:10,620
problem like detecting malware or

271
00:09:10,620 --> 00:09:12,720
detecting cats versus dogs or pick your

272
00:09:12,720 --> 00:09:15,000
classic machine learning problem

273
00:09:15,000 --> 00:09:17,519
now how does cell supervising learn like

274
00:09:17,519 --> 00:09:19,500
how does self-supervised learning work

275
00:09:19,500 --> 00:09:20,700
um I'm going to give a few examples to

276
00:09:20,700 --> 00:09:22,440
give you guys um some intuition about

277
00:09:22,440 --> 00:09:23,580
that

278
00:09:23,580 --> 00:09:25,800
um so imagine you have like a huge data

279
00:09:25,800 --> 00:09:27,660
set of images that you scrapes from the

280
00:09:27,660 --> 00:09:28,920
web uh you don't know what's in the

281
00:09:28,920 --> 00:09:29,760
images you don't know what they're

282
00:09:29,760 --> 00:09:31,620
pictures of but you'd like your neural

283
00:09:31,620 --> 00:09:33,000
network model to get better thanks to

284
00:09:33,000 --> 00:09:34,260
those images

285
00:09:34,260 --> 00:09:35,580
um what you do if you're using

286
00:09:35,580 --> 00:09:37,200
self-supervised learning is you you

287
00:09:37,200 --> 00:09:40,140
create uh

288
00:09:40,140 --> 00:09:42,180
a series of puzzles for your neural

289
00:09:42,180 --> 00:09:43,800
network to solve that are just derived

290
00:09:43,800 --> 00:09:45,959
from the data so for example a common

291
00:09:45,959 --> 00:09:47,060
technique

292
00:09:47,060 --> 00:09:49,920
goes something like this take an image

293
00:09:49,920 --> 00:09:53,399
remove a patch of pixels from it and and

294
00:09:53,399 --> 00:09:55,200
then ask your neural network to predict

295
00:09:55,200 --> 00:09:57,959
what pixels go in that patch and do that

296
00:09:57,959 --> 00:09:59,820
for lots of different images this is my

297
00:09:59,820 --> 00:10:01,260
two-year-old since I've been removing

298
00:10:01,260 --> 00:10:03,540
this patch here and then asking it to

299
00:10:03,540 --> 00:10:06,060
predict the pixels there

300
00:10:06,060 --> 00:10:08,279
um here's some horses near where I live

301
00:10:08,279 --> 00:10:10,320
in Kansas uh you know remove this patch

302
00:10:10,320 --> 00:10:11,279
here and then we're asking the internet

303
00:10:11,279 --> 00:10:12,899
to predict this past year and you can do

304
00:10:12,899 --> 00:10:15,720
this billions upon billion that is a

305
00:10:15,720 --> 00:10:18,060
neural network is forced to learn about

306
00:10:18,060 --> 00:10:19,800
the visual worlds right because in order

307
00:10:19,800 --> 00:10:21,480
to predict the pixels that go in here it

308
00:10:21,480 --> 00:10:23,100
needs to learn what a horse looks like

309
00:10:23,100 --> 00:10:24,839
and needs to learn that

310
00:10:24,839 --> 00:10:25,680
um

311
00:10:25,680 --> 00:10:28,260
there's a horse here and that you know a

312
00:10:28,260 --> 00:10:29,580
horse's back

313
00:10:29,580 --> 00:10:31,740
um is you know uh has a very particular

314
00:10:31,740 --> 00:10:33,540
shape and that those pixels should be

315
00:10:33,540 --> 00:10:35,820
filled in in an intuitive way right it

316
00:10:35,820 --> 00:10:37,140
needs to learn about Landscapes and

317
00:10:37,140 --> 00:10:38,399
about background and foreground and

318
00:10:38,399 --> 00:10:40,620
about depth in order to solve that pixel

319
00:10:40,620 --> 00:10:42,120
prediction problem you have to learn an

320
00:10:42,120 --> 00:10:45,600
enormous amount of semantics uh about uh

321
00:10:45,600 --> 00:10:48,060
about the visual worlds

322
00:10:48,060 --> 00:10:51,120
in the following way um we

323
00:10:51,120 --> 00:10:53,339
um openai the organization that's built

324
00:10:53,339 --> 00:10:54,480
gpt3

325
00:10:54,480 --> 00:10:58,440
um gives gives this model gives the gpt3

326
00:10:58,440 --> 00:11:00,180
model like web scale

327
00:11:00,180 --> 00:11:03,120
um a web scale volume of text uh and

328
00:11:03,120 --> 00:11:05,339
gpt3 is just trained to predict the next

329
00:11:05,339 --> 00:11:08,040
few characters of a document

330
00:11:08,040 --> 00:11:09,300
um so you might give it a sentence how

331
00:11:09,300 --> 00:11:11,040
to self-supervised learning and that's

332
00:11:11,040 --> 00:11:13,620
asking to predict the next um

333
00:11:13,620 --> 00:11:15,240
the next few characters the next word

334
00:11:15,240 --> 00:11:17,279
and that's the prediction Target now

335
00:11:17,279 --> 00:11:18,899
again you don't need labeled data to do

336
00:11:18,899 --> 00:11:20,940
this you can just scrape lots of data

337
00:11:20,940 --> 00:11:22,920
right hopefully get it from a source

338
00:11:22,920 --> 00:11:24,120
that you trust that has good information

339
00:11:24,120 --> 00:11:27,060
and and then just train gpt3 to protect

340
00:11:27,060 --> 00:11:28,380
the next few characters and you can see

341
00:11:28,380 --> 00:11:30,060
this is similar to the image problem in

342
00:11:30,060 --> 00:11:31,440
that in order to protect predict the

343
00:11:31,440 --> 00:11:34,620
next few characters uh a model needs to

344
00:11:34,620 --> 00:11:36,540
have really deep intelligence about the

345
00:11:36,540 --> 00:11:39,300
language domain right if I say 55 plus

346
00:11:39,300 --> 00:11:42,120
32 the neural network needs to be able

347
00:11:42,120 --> 00:11:44,640
to add right in order to to predict the

348
00:11:44,640 --> 00:11:46,140
next few characters I mean what we find

349
00:11:46,140 --> 00:11:48,120
is actually is that gbt3 does learn to

350
00:11:48,120 --> 00:11:50,399
do Urban arithmetic just just based on

351
00:11:50,399 --> 00:11:51,779
this training task of predicting the

352
00:11:51,779 --> 00:11:54,320
next few characters

353
00:11:54,720 --> 00:11:56,880
um now here's a final example of a

354
00:11:56,880 --> 00:11:58,680
self-supervised learning task so there's

355
00:11:58,680 --> 00:12:00,660
lots of images on the web that have alt

356
00:12:00,660 --> 00:12:03,959
text attached to them in HTML so here's

357
00:12:03,959 --> 00:12:05,640
an example where you know imagining some

358
00:12:05,640 --> 00:12:07,620
alt text like horses grazing if you call

359
00:12:07,620 --> 00:12:09,360
it Kansas Fields the trees and the

360
00:12:09,360 --> 00:12:11,279
foreground above them a fence separates

361
00:12:11,279 --> 00:12:12,959
the viewer from the horses and the grass

362
00:12:12,959 --> 00:12:14,940
and trees stretch into the distance the

363
00:12:14,940 --> 00:12:16,920
prediction Target here would be just the

364
00:12:16,920 --> 00:12:19,140
pixels in the whole image

365
00:12:19,140 --> 00:12:21,120
so hopefully hopefully the intuition is

366
00:12:21,120 --> 00:12:22,500
is clear around why self-supervised

367
00:12:22,500 --> 00:12:24,600
learning is a good idea uh it allows us

368
00:12:24,600 --> 00:12:25,800
to take advantage of these web scale

369
00:12:25,800 --> 00:12:26,820
data sets even when they don't have

370
00:12:26,820 --> 00:12:28,500
labels attached to them and and the

371
00:12:28,500 --> 00:12:30,660
result of training large neural network

372
00:12:30,660 --> 00:12:32,940
models in this way is that they learn

373
00:12:32,940 --> 00:12:37,019
um a model of language or of images or a

374
00:12:37,019 --> 00:12:39,240
video or audio whatever the domain is in

375
00:12:39,240 --> 00:12:40,860
which you're training them

376
00:12:40,860 --> 00:12:43,380
now here's a real example from a neural

377
00:12:43,380 --> 00:12:47,040
network from a research team at Google

378
00:12:47,040 --> 00:12:48,300
um

379
00:12:48,300 --> 00:12:50,220
and understanding quick time checks to

380
00:12:50,220 --> 00:12:51,600
make sure we have

381
00:12:51,600 --> 00:12:53,279
um enough time here

382
00:12:53,279 --> 00:12:56,279
um and this team uh trained a model on

383
00:12:56,279 --> 00:12:57,899
like web scale data to solve the problem

384
00:12:57,899 --> 00:13:00,000
they just defined uh predict the pixels

385
00:13:00,000 --> 00:13:03,420
in the image based on a caption

386
00:13:03,420 --> 00:13:05,820
um so here they actually made up a

387
00:13:05,820 --> 00:13:08,160
caption uh that didn't exist in their

388
00:13:08,160 --> 00:13:10,019
training sets and they tested to see

389
00:13:10,019 --> 00:13:12,240
whether or not the model could generate

390
00:13:12,240 --> 00:13:14,339
an image um based on the caption so so

391
00:13:14,339 --> 00:13:16,079
the sentence is a portrait photo of a

392
00:13:16,079 --> 00:13:17,880
kangaroo wearing an orange hoodie and

393
00:13:17,880 --> 00:13:19,740
blue sunglasses standing on on the grass

394
00:13:19,740 --> 00:13:20,820
in front of the Sydney Opera House

395
00:13:20,820 --> 00:13:22,920
holding a sign on its chest that says

396
00:13:22,920 --> 00:13:25,740
welcome friends so this is like this is

397
00:13:25,740 --> 00:13:27,480
such a wild caption that is highly

398
00:13:27,480 --> 00:13:28,740
unlikely this image actually exists in

399
00:13:28,740 --> 00:13:30,000
the wild and in fact you know this is

400
00:13:30,000 --> 00:13:31,380
the creation of some researchers at

401
00:13:31,380 --> 00:13:32,519
Google

402
00:13:32,519 --> 00:13:34,260
um now when they ask their models to

403
00:13:34,260 --> 00:13:35,820
generate the resulting image this is

404
00:13:35,820 --> 00:13:37,019
what they got

405
00:13:37,019 --> 00:13:39,360
um with a very large model that had 350

406
00:13:39,360 --> 00:13:42,899
million parameters so 350 million

407
00:13:42,899 --> 00:13:44,519
um uh like floating Point values that

408
00:13:44,519 --> 00:13:46,260
Define the interconnections between the

409
00:13:46,260 --> 00:13:48,000
artificial neurons and neural networks

410
00:13:48,000 --> 00:13:49,500
and this is like already an impressive

411
00:13:49,500 --> 00:13:51,120
result right and there's this animal

412
00:13:51,120 --> 00:13:53,220
that's vaguely kangaroo-ish there's

413
00:13:53,220 --> 00:13:54,660
something that sort of vaguely sit in

414
00:13:54,660 --> 00:13:56,940
the opera house like there's this is a

415
00:13:56,940 --> 00:13:59,339
sort of fabric that approximates a

416
00:13:59,339 --> 00:14:00,959
hoodie um you know you're not really

417
00:14:00,959 --> 00:14:02,160
getting the characters but you do get a

418
00:14:02,160 --> 00:14:04,440
sign with some gestures and letters here

419
00:14:04,440 --> 00:14:05,940
um so it's already quite incredible that

420
00:14:05,940 --> 00:14:08,220
an AI model can generate this image

421
00:14:08,220 --> 00:14:09,660
um but I want to demonstrate what

422
00:14:09,660 --> 00:14:10,860
happens when you scale these neural

423
00:14:10,860 --> 00:14:12,600
network models up without changing

424
00:14:12,600 --> 00:14:14,940
anything else when you just make them

425
00:14:14,940 --> 00:14:16,620
bigger with no new clever Matthew ideas

426
00:14:16,620 --> 00:14:19,139
uh what happens when you scale the model

427
00:14:19,139 --> 00:14:20,519
up to three billion parameters is you

428
00:14:20,519 --> 00:14:22,139
get a kangaroo now and you get something

429
00:14:22,139 --> 00:14:24,300
that's much closer to a hoodie and you

430
00:14:24,300 --> 00:14:26,040
even get the neural network learning a

431
00:14:26,040 --> 00:14:27,720
little bit about how to write letters in

432
00:14:27,720 --> 00:14:29,040
the visual domain

433
00:14:29,040 --> 00:14:30,120
um so it's not quite getting welcome

434
00:14:30,120 --> 00:14:31,740
friends and it's adding some weird sign

435
00:14:31,740 --> 00:14:33,779
down here but it's getting closer

436
00:14:33,779 --> 00:14:35,279
um then we get when you get up to 20

437
00:14:35,279 --> 00:14:37,320
billion parameters uh the model is able

438
00:14:37,320 --> 00:14:38,760
to actually understand the relationship

439
00:14:38,760 --> 00:14:41,279
between text and and imagery

440
00:14:41,279 --> 00:14:43,019
um so it's learned to write in this case

441
00:14:43,019 --> 00:14:44,100
right

442
00:14:44,100 --> 00:14:45,839
um even though the the researchers

443
00:14:45,839 --> 00:14:47,880
didn't explicitly train it to learn to

444
00:14:47,880 --> 00:14:50,279
inscribe um natural language text into

445
00:14:50,279 --> 00:14:51,720
the image so I know what a hoodie looks

446
00:14:51,720 --> 00:14:53,220
like it's got the blue sunglasses that's

447
00:14:53,220 --> 00:14:54,480
in the opera house

448
00:14:54,480 --> 00:14:56,040
um Yahoo who's from Australia can tell

449
00:14:56,040 --> 00:14:58,680
me if this is exactly correct but um at

450
00:14:58,680 --> 00:15:00,779
least it's closed and it's recognizable

451
00:15:00,779 --> 00:15:01,980
um so there's this magic thing that

452
00:15:01,980 --> 00:15:04,139
happens when you combine self-supervised

453
00:15:04,139 --> 00:15:06,180
training with very very large scale

454
00:15:06,180 --> 00:15:07,380
models to be clear a 20 billion

455
00:15:07,380 --> 00:15:09,180
parameter model would need to run in

456
00:15:09,180 --> 00:15:10,800
like a room scale supercomputer with

457
00:15:10,800 --> 00:15:12,480
like a ton of gpus and take a ton of

458
00:15:12,480 --> 00:15:13,380
energy

459
00:15:13,380 --> 00:15:15,300
um so you know it's not easy to create

460
00:15:15,300 --> 00:15:17,880
such models um but it's pretty magical

461
00:15:17,880 --> 00:15:19,320
what happens when you get into this sort

462
00:15:19,320 --> 00:15:21,420
of large model self-supervised uh

463
00:15:21,420 --> 00:15:23,399
learning regime

464
00:15:23,399 --> 00:15:24,720
um there's lots of examples of this that

465
00:15:24,720 --> 00:15:26,220
you can find if you look up the Google

466
00:15:26,220 --> 00:15:29,100
party paper which is where these images

467
00:15:29,100 --> 00:15:30,779
are from you can see lots of examples

468
00:15:30,779 --> 00:15:32,579
from their work uh but here's an example

469
00:15:32,579 --> 00:15:35,459
of uh the results from the models of

470
00:15:35,459 --> 00:15:37,139
these different scales uh when it when

471
00:15:37,139 --> 00:15:38,820
prompted a map of the United States made

472
00:15:38,820 --> 00:15:40,740
out of sushi it is on a table next to a

473
00:15:40,740 --> 00:15:42,120
glass of red wine

474
00:15:42,120 --> 00:15:43,800
um you can see you know doesn't get it

475
00:15:43,800 --> 00:15:45,600
with a small model with a large model it

476
00:15:45,600 --> 00:15:47,959
really does

477
00:15:48,000 --> 00:15:50,880
um and again uh just just look up Google

478
00:15:50,880 --> 00:15:52,440
and party if you want more example

479
00:15:52,440 --> 00:15:55,320
examples of this of this model

480
00:15:55,320 --> 00:15:57,180
um now let's get down to gpt3 which is

481
00:15:57,180 --> 00:15:58,680
the model that we're using

482
00:15:58,680 --> 00:15:59,279
um

483
00:15:59,279 --> 00:16:00,600
uh to do the research that we're going

484
00:16:00,600 --> 00:16:03,180
to present today uh so gpt3 was trained

485
00:16:03,180 --> 00:16:04,800
on text to protect the next few

486
00:16:04,800 --> 00:16:07,019
characters in a document but what it's

487
00:16:07,019 --> 00:16:09,120
learned to do is

488
00:16:09,120 --> 00:16:12,240
um for example uh create valid python

489
00:16:12,240 --> 00:16:15,899
code so so here I prompted um gpt3 uh

490
00:16:15,899 --> 00:16:18,300
with the prompts uh compute mean the

491
00:16:18,300 --> 00:16:19,800
standard deviation and then I give it a

492
00:16:19,800 --> 00:16:21,959
doc string compute meanest standard

493
00:16:21,959 --> 00:16:23,279
deviation of the input data and pure

494
00:16:23,279 --> 00:16:25,019
Python and render the results in flashy

495
00:16:25,019 --> 00:16:27,180
HTML on a page titled don't trust

496
00:16:27,180 --> 00:16:28,740
summary statistics

497
00:16:28,740 --> 00:16:29,880
um then if you just ask it to

498
00:16:29,880 --> 00:16:31,800
autocomplete it actually generates valid

499
00:16:31,800 --> 00:16:32,940
code that does both those things and

500
00:16:32,940 --> 00:16:34,800
composes those Concepts together

501
00:16:34,800 --> 00:16:36,180
um so this is you can see how this is

502
00:16:36,180 --> 00:16:39,300
analogous to the to the image example uh

503
00:16:39,300 --> 00:16:41,160
so so here we ask them to do two things

504
00:16:41,160 --> 00:16:42,779
compute some summary statistics from

505
00:16:42,779 --> 00:16:45,180
sort of stats 101 and then render that

506
00:16:45,180 --> 00:16:47,820
stuff in HTML and it sort of knows about

507
00:16:47,820 --> 00:16:49,199
summary statistics and knows about HTML

508
00:16:49,199 --> 00:16:50,940
and also knows how to sort of knit those

509
00:16:50,940 --> 00:16:52,560
Concepts together into a valid python

510
00:16:52,560 --> 00:16:55,680
function that actually actually works

511
00:16:55,680 --> 00:16:57,480
um it's a bit to be clear like our our

512
00:16:57,480 --> 00:17:00,120
role here is we are using open ai's

513
00:17:00,120 --> 00:17:02,339
models through their API

514
00:17:02,339 --> 00:17:04,140
um that we that they gave us access to

515
00:17:04,140 --> 00:17:05,520
as researchers

516
00:17:05,520 --> 00:17:07,740
um and we're building on top of gpt3 and

517
00:17:07,740 --> 00:17:09,299
you'll see how we've we've done that for

518
00:17:09,299 --> 00:17:11,099
security use cases um in youngview's

519
00:17:11,099 --> 00:17:14,178
portion of the of the talk

520
00:17:14,760 --> 00:17:16,619
um now so this magic thing that happens

521
00:17:16,619 --> 00:17:19,679
when we scale neural networks up um and

522
00:17:19,679 --> 00:17:20,880
train them in the self-supervised

523
00:17:20,880 --> 00:17:22,679
fashion is that there's like this really

524
00:17:22,679 --> 00:17:25,919
clean relationship between model scale

525
00:17:25,919 --> 00:17:28,980
and reduction and model error so what

526
00:17:28,980 --> 00:17:30,660
you're seeing here I mean I can go into

527
00:17:30,660 --> 00:17:32,280
the details but basically the punch line

528
00:17:32,280 --> 00:17:33,480
is

529
00:17:33,480 --> 00:17:36,179
um a team at openai published this

530
00:17:36,179 --> 00:17:37,799
classic paper where they showed that as

531
00:17:37,799 --> 00:17:39,780
they scale up the size of a model in

532
00:17:39,780 --> 00:17:41,460
terms of like orders of magnitude of

533
00:17:41,460 --> 00:17:42,720
interconnections between between

534
00:17:42,720 --> 00:17:45,419
artificial neurons there's this smooth

535
00:17:45,419 --> 00:17:47,700
decline in the error rate of those

536
00:17:47,700 --> 00:17:49,679
models which is really remarkable it's

537
00:17:49,679 --> 00:17:51,059
like I would say it's a key result in

538
00:17:51,059 --> 00:17:52,200
machine learning that's come out of the

539
00:17:52,200 --> 00:17:52,919
last

540
00:17:52,919 --> 00:17:54,840
um like five years of machine learning

541
00:17:54,840 --> 00:17:56,760
research

542
00:17:56,760 --> 00:17:58,380
now

543
00:17:58,380 --> 00:18:00,480
why does this matter for security

544
00:18:00,480 --> 00:18:01,140
um

545
00:18:01,140 --> 00:18:03,120
the size of today's security data

546
00:18:03,120 --> 00:18:05,820
science models um Falls in this kind of

547
00:18:05,820 --> 00:18:07,080
size range

548
00:18:07,080 --> 00:18:07,679
um

549
00:18:07,679 --> 00:18:11,640
so Ed so our day job at sofos is is to

550
00:18:11,640 --> 00:18:13,620
operate about 40 machine learning

551
00:18:13,620 --> 00:18:15,660
product Integrations within sofos's like

552
00:18:15,660 --> 00:18:17,340
firewall products uh endpoint security

553
00:18:17,340 --> 00:18:18,780
product mobile security email security

554
00:18:18,780 --> 00:18:20,640
we do a lot of machine learning at sofos

555
00:18:20,640 --> 00:18:22,200
and we're using machine learning in

556
00:18:22,200 --> 00:18:23,520
almost all of our

557
00:18:23,520 --> 00:18:25,260
um detection pipelines within our

558
00:18:25,260 --> 00:18:26,760
company's products

559
00:18:26,760 --> 00:18:28,380
um but the models that we've deployed

560
00:18:28,380 --> 00:18:30,660
all fall on this kind of size band

561
00:18:30,660 --> 00:18:32,840
um uh in the distribution of model sizes

562
00:18:32,840 --> 00:18:35,520
we haven't yet and I know my colleagues

563
00:18:35,520 --> 00:18:36,900
at other companies as far as I know

564
00:18:36,900 --> 00:18:39,419
anyways haven't yet explored what

565
00:18:39,419 --> 00:18:41,820
happens when we scale security models so

566
00:18:41,820 --> 00:18:44,400
not not natural language not um not

567
00:18:44,400 --> 00:18:46,140
computer vision but but models that like

568
00:18:46,140 --> 00:18:47,880
detect bad stuff that help stock

569
00:18:47,880 --> 00:18:49,860
analysts when we we have an experiment

570
00:18:49,860 --> 00:18:52,380
with it yet with scaling security models

571
00:18:52,380 --> 00:18:53,880
up to this kind of size range that we're

572
00:18:53,880 --> 00:18:54,660
seeing

573
00:18:54,660 --> 00:18:55,980
um in the broader machine Learning

574
00:18:55,980 --> 00:18:57,840
Community now the presentation we're

575
00:18:57,840 --> 00:18:59,700
making today is the result of our early

576
00:18:59,700 --> 00:19:03,360
experiments and uh and applying these

577
00:19:03,360 --> 00:19:04,740
very large models of security problems

578
00:19:04,740 --> 00:19:06,539
we think it's really important that

579
00:19:06,539 --> 00:19:08,640
researchers in our community and like

580
00:19:08,640 --> 00:19:10,320
the security data science world go in

581
00:19:10,320 --> 00:19:11,760
this direction and you know so again

582
00:19:11,760 --> 00:19:13,440
like we're hoping that other folks

583
00:19:13,440 --> 00:19:14,700
follow up and do even more impressive

584
00:19:14,700 --> 00:19:17,940
stuff with um large-scale models

585
00:19:17,940 --> 00:19:20,039
uh so I so before I'm about to hand it

586
00:19:20,039 --> 00:19:21,780
off to Yahoo but before I before I do

587
00:19:21,780 --> 00:19:22,740
that I just want to give a little bit

588
00:19:22,740 --> 00:19:24,660
more intuition as to why these large

589
00:19:24,660 --> 00:19:26,880
models May matter for security so one of

590
00:19:26,880 --> 00:19:28,860
the models that we use at sofos is a

591
00:19:28,860 --> 00:19:30,840
model that looks at a domain and decides

592
00:19:30,840 --> 00:19:32,640
what content category it falls in like

593
00:19:32,640 --> 00:19:35,340
we have like K-12 School customers that

594
00:19:35,340 --> 00:19:36,720
you know don't want kids looking at

595
00:19:36,720 --> 00:19:37,919
certain categories of content and this

596
00:19:37,919 --> 00:19:39,059
kind of thing and so this is one of the

597
00:19:39,059 --> 00:19:41,460
things that we do on our team

598
00:19:41,460 --> 00:19:43,500
um we train our domain content

599
00:19:43,500 --> 00:19:45,539
classification model

600
00:19:45,539 --> 00:19:48,600
um like tens of millions of examples

601
00:19:48,600 --> 00:19:50,760
um and we need to it's a small model and

602
00:19:50,760 --> 00:19:52,740
it needs to be trained on a lot of data

603
00:19:52,740 --> 00:19:54,600
um we did we did a quick experiment with

604
00:19:54,600 --> 00:19:57,419
gpt3 to see how well it could categorize

605
00:19:57,419 --> 00:19:59,580
domains into content categories using

606
00:19:59,580 --> 00:20:02,580
just five Training examples and it did a

607
00:20:02,580 --> 00:20:04,200
really good job I mean sort of

608
00:20:04,200 --> 00:20:05,880
definitely blew me away when I saw this

609
00:20:05,880 --> 00:20:07,860
result um so here I just I just showed

610
00:20:07,860 --> 00:20:10,620
gpt3 a prompt I I show it berkeley.edu

611
00:20:10,620 --> 00:20:12,960
maps to education Amazon maps of

612
00:20:12,960 --> 00:20:13,860
shopping

613
00:20:13,860 --> 00:20:15,960
um Etc and then I showed a new domain

614
00:20:15,960 --> 00:20:16,799
that it hasn't seen before

615
00:20:16,799 --> 00:20:18,780
shootingrange.com and it just knows to

616
00:20:18,780 --> 00:20:21,419
autocomplete that as weapons

617
00:20:21,419 --> 00:20:24,600
um in a malware detection context

618
00:20:24,600 --> 00:20:27,960
um if we're trying to detect uh say uh

619
00:20:27,960 --> 00:20:30,720
like phishing domains um you know we can

620
00:20:30,720 --> 00:20:32,100
give it like four examples of like

621
00:20:32,100 --> 00:20:34,440
definitely a fishing domain here I mean

622
00:20:34,440 --> 00:20:35,640
I just made this up that you know it

623
00:20:35,640 --> 00:20:37,500
looks like a phishing domain PayPal

624
00:20:37,500 --> 00:20:39,020
customer support dot blah blah

625
00:20:39,020 --> 00:20:42,059
blah.ac.uk some good domains another bad

626
00:20:42,059 --> 00:20:44,460
one and then and then it it Nails it

627
00:20:44,460 --> 00:20:46,380
when I give it a new phishing domain um

628
00:20:46,380 --> 00:20:48,600
so again an example of like

629
00:20:48,600 --> 00:20:50,760
the phenomenon where gpd3 because it's

630
00:20:50,760 --> 00:20:53,460
been trained on um like the entire web

631
00:20:53,460 --> 00:20:56,640
of data it's learned some syntax and

632
00:20:56,640 --> 00:20:57,960
semantics around language and it's able

633
00:20:57,960 --> 00:20:59,580
to see that oh

634
00:20:59,580 --> 00:21:01,919
um what's going on here is categorizing

635
00:21:01,919 --> 00:21:03,600
sites into good and bad and it's it's

636
00:21:03,600 --> 00:21:04,860
sort of queuing off of all of the

637
00:21:04,860 --> 00:21:05,640
knowledge that learned in that

638
00:21:05,640 --> 00:21:07,620
self-supervised training context

639
00:21:07,620 --> 00:21:09,419
um and very quickly learning to do what

640
00:21:09,419 --> 00:21:10,740
we're asking you to do in this context

641
00:21:10,740 --> 00:21:13,620
and this is significant because like you

642
00:21:13,620 --> 00:21:15,000
know in the future as people start to

643
00:21:15,000 --> 00:21:16,679
use these large models in like a sock

644
00:21:16,679 --> 00:21:17,940
context if you're seeing a certain type

645
00:21:17,940 --> 00:21:19,919
of thing and you want to go find that

646
00:21:19,919 --> 00:21:21,919
thing in all your data you can imagine

647
00:21:21,919 --> 00:21:24,840
writing a little prompt like this

648
00:21:24,840 --> 00:21:27,480
um and then pointing gpt3 add a bunch of

649
00:21:27,480 --> 00:21:29,159
data and having it find examples that

650
00:21:29,159 --> 00:21:30,299
you're looking for in a much more

651
00:21:30,299 --> 00:21:31,919
intelligent way than today's machine

652
00:21:31,919 --> 00:21:35,760
learning models that are a smaller scale

653
00:21:35,760 --> 00:21:36,659
um we're gonna be talking about two

654
00:21:36,659 --> 00:21:38,700
different ways of using gpt3 today one

655
00:21:38,700 --> 00:21:40,380
is prompting which I just showed where

656
00:21:40,380 --> 00:21:41,640
we just showed a prompt asking to

657
00:21:41,640 --> 00:21:42,840
autocomplete and get an answer out of

658
00:21:42,840 --> 00:21:45,120
g53 the other involves um back

659
00:21:45,120 --> 00:21:46,980
propagation and stochastic gradient

660
00:21:46,980 --> 00:21:48,600
descent for data scientists in the room

661
00:21:48,600 --> 00:21:49,919
this is just the standard way that you

662
00:21:49,919 --> 00:21:51,780
optimize neural networks

663
00:21:51,780 --> 00:21:54,480
um and uh that's called fine tuning and

664
00:21:54,480 --> 00:21:56,940
what we do in fine tuning is we we

665
00:21:56,940 --> 00:22:00,179
adjust the the the interconnection

666
00:22:00,179 --> 00:22:02,340
values between the neurons just a little

667
00:22:02,340 --> 00:22:04,320
bit more Beyond uh what they were when

668
00:22:04,320 --> 00:22:05,940
we finished self-supervised training my

669
00:22:05,940 --> 00:22:07,860
model like gpt3 in order to solve a

670
00:22:07,860 --> 00:22:10,620
problem like spam detection or malicious

671
00:22:10,620 --> 00:22:13,280
URL detection

672
00:22:13,740 --> 00:22:15,419
um okay so this is the last slide in my

673
00:22:15,419 --> 00:22:18,299
my section here um hopefully I've wet

674
00:22:18,299 --> 00:22:19,559
your appetite into thinking about how

675
00:22:19,559 --> 00:22:22,140
these large models May apply in security

676
00:22:22,140 --> 00:22:23,640
um I think you can probably think about

677
00:22:23,640 --> 00:22:25,320
some offensive applications of these

678
00:22:25,320 --> 00:22:27,299
these these models we're mostly we're

679
00:22:27,299 --> 00:22:28,620
thinking in this talk about defensive

680
00:22:28,620 --> 00:22:30,659
applications we've we've tried a bunch

681
00:22:30,659 --> 00:22:31,799
of things

682
00:22:31,799 --> 00:22:33,539
um young who's done a bunch of work in

683
00:22:33,539 --> 00:22:34,860
building a natural language user

684
00:22:34,860 --> 00:22:37,020
interface where we the user types in

685
00:22:37,020 --> 00:22:39,900
um like show me all uh network

686
00:22:39,900 --> 00:22:41,580
connections that are open

687
00:22:41,580 --> 00:22:44,820
um from Windows machines outgoing to to

688
00:22:44,820 --> 00:22:46,919
China and that gets translated into a

689
00:22:46,919 --> 00:22:48,240
database query

690
00:22:48,240 --> 00:22:50,039
um uh we think this is useful for

691
00:22:50,039 --> 00:22:51,360
detection

692
00:22:51,360 --> 00:22:53,039
um what you'll see the results that we

693
00:22:53,039 --> 00:22:54,419
have around using this reverse

694
00:22:54,419 --> 00:22:55,620
engineering but we think there's lots of

695
00:22:55,620 --> 00:22:58,620
other applications as as well

696
00:22:58,620 --> 00:23:00,299
um okay and with that I will pass it off

697
00:23:00,299 --> 00:23:01,380
to Yahoo

698
00:23:01,380 --> 00:23:03,500
um

699
00:23:05,039 --> 00:23:06,380
thank you

700
00:23:06,380 --> 00:23:09,360
Joshua was very impressive to me who

701
00:23:09,360 --> 00:23:11,940
just came from Australia

702
00:23:11,940 --> 00:23:15,299
yeah it is great to see those Australia

703
00:23:15,299 --> 00:23:18,059
animal oriented building here again

704
00:23:18,059 --> 00:23:20,880
in the second part of our talk I will be

705
00:23:20,880 --> 00:23:22,740
talking about how we can create two

706
00:23:22,740 --> 00:23:25,740
cyber security applications using a

707
00:23:25,740 --> 00:23:28,260
large-scale language model we will be

708
00:23:28,260 --> 00:23:29,340
using

709
00:23:29,340 --> 00:23:33,539
uh open AI tpt3 as our large language

710
00:23:33,539 --> 00:23:34,799
model

711
00:23:34,799 --> 00:23:37,200
so to model it is so large you can

712
00:23:37,200 --> 00:23:40,559
directly use it unless you have a super

713
00:23:40,559 --> 00:23:41,700
computer

714
00:23:41,700 --> 00:23:43,980
fortunately we can access the model now

715
00:23:43,980 --> 00:23:46,799
through the open AI API

716
00:23:46,799 --> 00:23:49,380
so our first application is a spam

717
00:23:49,380 --> 00:23:51,980
detector

718
00:23:53,039 --> 00:23:56,400
when you start a new ml product probably

719
00:23:56,400 --> 00:24:00,900
you will be starting with few examples

720
00:24:00,900 --> 00:24:05,820
and also we just collect a few new spam

721
00:24:05,820 --> 00:24:09,179
messages but we are going to detect

722
00:24:09,179 --> 00:24:13,100
those similar ones when we train a small

723
00:24:13,100 --> 00:24:16,440
traditional models you will be required

724
00:24:16,440 --> 00:24:18,780
to collect a large set of training data

725
00:24:18,780 --> 00:24:22,140
to train a new classification problem it

726
00:24:22,140 --> 00:24:24,059
is something like when you train a small

727
00:24:24,059 --> 00:24:26,820
puppy probably you need to show him many

728
00:24:26,820 --> 00:24:30,120
examples however a

729
00:24:30,120 --> 00:24:33,000
smart talk with a lot of experience we

730
00:24:33,000 --> 00:24:35,700
quickly learn with few examples and our

731
00:24:35,700 --> 00:24:39,780
smart gp3 can do the same job

732
00:24:39,780 --> 00:24:43,740
so this is our performance of spam

733
00:24:43,740 --> 00:24:47,100
detection gpt3 with only one hem and one

734
00:24:47,100 --> 00:24:49,740
span achieved in press result of

735
00:24:49,740 --> 00:24:54,240
detection of rate of 90 with 8 samples

736
00:24:54,240 --> 00:24:58,200
even better we got 95 acreage on the

737
00:24:58,200 --> 00:25:00,419
other hand traditional random forest

738
00:25:00,419 --> 00:25:03,900
model only got about 55 which is

739
00:25:03,900 --> 00:25:06,539
slightly better than random guessing

740
00:25:06,539 --> 00:25:08,820
we will talk about how we can achieve

741
00:25:08,820 --> 00:25:11,280
this impressive result

742
00:25:11,280 --> 00:25:14,640
and these are our various data and the

743
00:25:14,640 --> 00:25:16,679
model settings

744
00:25:16,679 --> 00:25:19,860
so teaching tpt3 to solve a prediction

745
00:25:19,860 --> 00:25:23,340
problem can be as simple as designing a

746
00:25:23,340 --> 00:25:26,640
prompt so tp3 can auto complete the

747
00:25:26,640 --> 00:25:29,460
demanding part for example converting

748
00:25:29,460 --> 00:25:32,820
movie titles into Emoji icons is quite

749
00:25:32,820 --> 00:25:35,159
simple so we just provide three examples

750
00:25:35,159 --> 00:25:37,980
here back to the future with relevant

751
00:25:37,980 --> 00:25:39,960
icons and the betterment and

752
00:25:39,960 --> 00:25:42,059
Transformers and then we ask about our

753
00:25:42,059 --> 00:25:44,360
questions Star Wars and then we get

754
00:25:44,360 --> 00:25:48,179
impressed result the level icon this is

755
00:25:48,179 --> 00:25:49,919
how we can

756
00:25:49,919 --> 00:25:53,340
provide the data to the model to auto

757
00:25:53,340 --> 00:25:56,039
complete the remaining part so now

758
00:25:56,039 --> 00:25:58,799
design let's design our prompt for our

759
00:25:58,799 --> 00:25:59,760
problem

760
00:25:59,760 --> 00:26:02,720
so we start with a simple instruction

761
00:26:02,720 --> 00:26:06,419
which is classified message as spam or

762
00:26:06,419 --> 00:26:08,520
hand and then we provide some examples

763
00:26:08,520 --> 00:26:10,919
so we select one span and another one

764
00:26:10,919 --> 00:26:14,100
from hem and then we add our question

765
00:26:14,100 --> 00:26:17,700
sample free top ringtone so with this

766
00:26:17,700 --> 00:26:20,940
input GPS can generate the span as

767
00:26:20,940 --> 00:26:24,120
output so gp3 is a pre-trained language

768
00:26:24,120 --> 00:26:26,940
model it has been pre-trained to predict

769
00:26:26,940 --> 00:26:30,120
the next World so GPS you can generate

770
00:26:30,120 --> 00:26:34,740
the most likely the same as output

771
00:26:34,740 --> 00:26:36,720
so let me show you some other examples

772
00:26:36,720 --> 00:26:39,360
so from the previous examples so now we

773
00:26:39,360 --> 00:26:42,779
can test use them first for example uh

774
00:26:42,779 --> 00:26:44,700
or that your mobile number has been

775
00:26:44,700 --> 00:26:47,700
awarded this one is definitely spam and

776
00:26:47,700 --> 00:26:50,100
it's correctly identify the scan and

777
00:26:50,100 --> 00:26:53,640
another one I'm yes I'm in office it's a

778
00:26:53,640 --> 00:26:57,299
detected same hem correctly so actually

779
00:26:57,299 --> 00:27:00,120
this is a screenshot from the open AI

780
00:27:00,120 --> 00:27:03,120
playground website where we can test our

781
00:27:03,120 --> 00:27:05,460
input and output with some settings here

782
00:27:05,460 --> 00:27:09,240
one important setting is the model with

783
00:27:09,240 --> 00:27:13,380
set as a text this is the last gptc

784
00:27:13,380 --> 00:27:16,440
model for text generation version so our

785
00:27:16,440 --> 00:27:19,200
application the first application so gp3

786
00:27:19,200 --> 00:27:21,059
with Fusion learning is a powerful tool

787
00:27:21,059 --> 00:27:25,679
to generate a classification problem

788
00:27:25,679 --> 00:27:28,440
so the second application is generating

789
00:27:28,440 --> 00:27:32,279
human DW explanation of malicious

790
00:27:32,279 --> 00:27:35,000
Commander lines

791
00:27:36,240 --> 00:27:38,600
the soc analyst

792
00:27:38,600 --> 00:27:41,820
analyzed thousands of malicious command

793
00:27:41,820 --> 00:27:45,720
every day and it is really hard and time

794
00:27:45,720 --> 00:27:48,000
consuming itself and as you can see this

795
00:27:48,000 --> 00:27:50,580
is one of the malicious command so it is

796
00:27:50,580 --> 00:27:53,700
really long and it's hard to pass

797
00:27:53,700 --> 00:27:56,279
so our question is can large language

798
00:27:56,279 --> 00:27:58,860
models can make this job easier by

799
00:27:58,860 --> 00:28:01,500
describing this command in simple

800
00:28:01,500 --> 00:28:02,820
language

801
00:28:02,820 --> 00:28:05,760
so yes it is possible so from the

802
00:28:05,760 --> 00:28:07,919
command we can generate human readable

803
00:28:07,919 --> 00:28:09,600
description this is actually the

804
00:28:09,600 --> 00:28:11,220
description we generate from the model

805
00:28:11,220 --> 00:28:14,520
so the description set the command will

806
00:28:14,520 --> 00:28:17,960
create a file called

807
00:28:17,960 --> 00:28:21,419
exp.v85 and it will execute and delete

808
00:28:21,419 --> 00:28:24,059
afterward so it is a one of the

809
00:28:24,059 --> 00:28:27,059
malicious behaviors uh so what we can

810
00:28:27,059 --> 00:28:29,580
actually recognize from the description

811
00:28:29,580 --> 00:28:32,159
so let me show you how we can achieve

812
00:28:32,159 --> 00:28:33,779
this one

813
00:28:33,779 --> 00:28:37,080
actually g53 reports two type of

814
00:28:37,080 --> 00:28:39,900
different models from open AI the first

815
00:28:39,900 --> 00:28:43,620
one is a text generating version so we

816
00:28:43,620 --> 00:28:47,100
just use the text generated version for

817
00:28:47,100 --> 00:28:49,919
our spam data and the second version is

818
00:28:49,919 --> 00:28:51,900
a whole generation version called the

819
00:28:51,900 --> 00:28:54,600
Codex so the Codex models has been

820
00:28:54,600 --> 00:28:56,700
pre-trained with uh

821
00:28:56,700 --> 00:28:59,700
many open source projects from the

822
00:28:59,700 --> 00:29:02,640
GitHub so it can write code in many

823
00:29:02,640 --> 00:29:05,179
different languages including JavaScript

824
00:29:05,179 --> 00:29:08,580
Python and JavaScript as well so this is

825
00:29:08,580 --> 00:29:12,720
our choice for our Second Use case

826
00:29:12,720 --> 00:29:17,279
so let's design our prompt so we have

827
00:29:17,279 --> 00:29:19,380
two sections the first one we provide

828
00:29:19,380 --> 00:29:22,080
the command and the second section is

829
00:29:22,080 --> 00:29:25,320
full description so this will guide the

830
00:29:25,320 --> 00:29:28,140
gpt3 to Auto completely to The Domain in

831
00:29:28,140 --> 00:29:31,559
part so let's say we get the result

832
00:29:31,559 --> 00:29:35,039
so now we have a uh the description from

833
00:29:35,039 --> 00:29:38,700
the command so the command will copy the

834
00:29:38,700 --> 00:29:41,520
binary into the temp folder so it

835
00:29:41,520 --> 00:29:43,380
generates a valid description from the

836
00:29:43,380 --> 00:29:46,440
command however the command is a

837
00:29:46,440 --> 00:29:48,179
malicious because it copies the value

838
00:29:48,179 --> 00:29:50,640
from the system folder to a temp report

839
00:29:50,640 --> 00:29:53,760
as a DOT exe so it is a malicious

840
00:29:53,760 --> 00:29:56,520
activity however our description did not

841
00:29:56,520 --> 00:30:00,179
point out the malicious part so we need

842
00:30:00,179 --> 00:30:03,120
to improve the quality

843
00:30:03,120 --> 00:30:06,000
and our approach is we needed to provide

844
00:30:06,000 --> 00:30:07,940
some additional context information

845
00:30:07,940 --> 00:30:10,260
usually the space command can be

846
00:30:10,260 --> 00:30:12,899
detected by signature based rules so we

847
00:30:12,899 --> 00:30:16,140
can use Yara rules or Sigma rules so

848
00:30:16,140 --> 00:30:18,080
this case the previous command actually

849
00:30:18,080 --> 00:30:21,679
detected by one of Sigma rules and the

850
00:30:21,679 --> 00:30:25,260
signals was a Windows service copy

851
00:30:25,260 --> 00:30:28,620
system 32 so we can use some additional

852
00:30:28,620 --> 00:30:32,640
information from the signatures so this

853
00:30:32,640 --> 00:30:35,880
is our second version of prompt so we

854
00:30:35,880 --> 00:30:37,559
use the same command but we add

855
00:30:37,559 --> 00:30:41,100
additional tag section because one

856
00:30:41,100 --> 00:30:42,600
comment can be detected by multiple

857
00:30:42,600 --> 00:30:45,120
signatures so we we can add all the

858
00:30:45,120 --> 00:30:50,520
signatures in a text section so now we

859
00:30:50,520 --> 00:30:52,500
can open the description as you can see

860
00:30:52,500 --> 00:30:55,140
now the description says the command

861
00:30:55,140 --> 00:30:58,080
will copy the binary to a tempo for this

862
00:30:58,080 --> 00:31:00,899
adult so where the attackers can use the

863
00:31:00,899 --> 00:31:03,840
binary to perform malicious activity so

864
00:31:03,840 --> 00:31:06,179
now it described the command correctly

865
00:31:06,179 --> 00:31:08,760
and also mentioned about the malicious

866
00:31:08,760 --> 00:31:12,120
behavior as well so now we have the

867
00:31:12,120 --> 00:31:14,820
better description however we wanted to

868
00:31:14,820 --> 00:31:17,520
improve further from here so what we can

869
00:31:17,520 --> 00:31:20,520
do is actually uh if we look at the

870
00:31:20,520 --> 00:31:23,220
the settings we set the model as the

871
00:31:23,220 --> 00:31:25,440
code is this is the one of the Codex

872
00:31:25,440 --> 00:31:27,600
model and then also we can change the

873
00:31:27,600 --> 00:31:31,260
temperature from 7.7 to 0.8 well we can

874
00:31:31,260 --> 00:31:34,679
also change the top probability so with

875
00:31:34,679 --> 00:31:36,960
this settings from the same input we can

876
00:31:36,960 --> 00:31:39,360
generate the multiple descriptions and

877
00:31:39,360 --> 00:31:42,360
then we can select the best one so our

878
00:31:42,360 --> 00:31:44,279
operator selected the best description

879
00:31:44,279 --> 00:31:47,340
is back translation

880
00:31:47,340 --> 00:31:50,159
so in natural language translation tasks

881
00:31:50,159 --> 00:31:53,460
for example translation from English to

882
00:31:53,460 --> 00:31:56,779
French it is not easy to evaluate the

883
00:31:56,779 --> 00:32:00,000
output on friends but if we translate

884
00:32:00,000 --> 00:32:02,340
the French to English now it's clear we

885
00:32:02,340 --> 00:32:05,460
can compare the original English to

886
00:32:05,460 --> 00:32:09,179
Black translate Frozen so we can apply

887
00:32:09,179 --> 00:32:12,120
the same mechanism for our second case

888
00:32:12,120 --> 00:32:15,419
so the command is one language and

889
00:32:15,419 --> 00:32:17,640
description is another thing is this so

890
00:32:17,640 --> 00:32:20,220
we can actually generate the command

891
00:32:20,220 --> 00:32:22,799
from the description so now we have the

892
00:32:22,799 --> 00:32:24,720
command and the back translated command

893
00:32:24,720 --> 00:32:27,960
so so we can easily compare the

894
00:32:27,960 --> 00:32:30,120
similarity between the original one and

895
00:32:30,120 --> 00:32:31,980
back translated version

896
00:32:31,980 --> 00:32:34,440
so let's have a look at the um yeah

897
00:32:34,440 --> 00:32:37,140
these are our the overall steps so in

898
00:32:37,140 --> 00:32:38,940
step one we will generate multiple

899
00:32:38,940 --> 00:32:42,539
descriptions from the command and tags

900
00:32:42,539 --> 00:32:45,720
in a second step we can generate the

901
00:32:45,720 --> 00:32:48,000
command from the previous generated ones

902
00:32:48,000 --> 00:32:50,820
in the last step we can rank the

903
00:32:50,820 --> 00:32:53,039
descriptions by similarly squads between

904
00:32:53,039 --> 00:32:55,320
the original command and the back

905
00:32:55,320 --> 00:32:58,020
translated ones

906
00:32:58,020 --> 00:33:01,380
so this is our new prompt for the second

907
00:33:01,380 --> 00:33:04,320
step back translating the translation

908
00:33:04,320 --> 00:33:07,500
step so we provided the same the tag and

909
00:33:07,500 --> 00:33:10,620
the description and then we ask model to

910
00:33:10,620 --> 00:33:12,899
complete the domain in command so this

911
00:33:12,899 --> 00:33:14,760
way we can degenerate the previous

912
00:33:14,760 --> 00:33:17,580
command so if the command is describing

913
00:33:17,580 --> 00:33:20,519
the original command correctly we will

914
00:33:20,519 --> 00:33:23,700
be able to deconstruct the command

915
00:33:23,700 --> 00:33:26,220
so let me show you two examples of

916
00:33:26,220 --> 00:33:28,500
descriptions we generated these two

917
00:33:28,500 --> 00:33:30,840
description from the previous command so

918
00:33:30,840 --> 00:33:32,700
the first one actually I did not

919
00:33:32,700 --> 00:33:35,100
correctly mentioned the final name but

920
00:33:35,100 --> 00:33:37,740
it just mentioned temp so it failed to

921
00:33:37,740 --> 00:33:39,480
really construct the previous command

922
00:33:39,480 --> 00:33:43,260
however the second description correctly

923
00:33:43,260 --> 00:33:46,200
uh construct the previous one because it

924
00:33:46,200 --> 00:33:50,220
has the correct file name so I'll pick

925
00:33:50,220 --> 00:33:52,320
translation method can be used to

926
00:33:52,320 --> 00:33:56,240
improve the description further

927
00:33:56,240 --> 00:34:00,179
so this is another example so the

928
00:34:00,179 --> 00:34:02,940
command is um maybe if you are not

929
00:34:02,940 --> 00:34:05,159
familiar with this one's uh not easy to

930
00:34:05,159 --> 00:34:07,559
understand however our description said

931
00:34:07,559 --> 00:34:10,918
the command will sort the files on the

932
00:34:10,918 --> 00:34:12,659
test Club folder and the server force

933
00:34:12,659 --> 00:34:15,418
and then we'll find out the file

934
00:34:15,418 --> 00:34:17,940
containing the password actually it is

935
00:34:17,940 --> 00:34:22,580
finding your password from the desktop

936
00:34:23,760 --> 00:34:27,320
so our source code is available in our

937
00:34:27,320 --> 00:34:30,540
GitHub repositories and it includes our

938
00:34:30,540 --> 00:34:34,440
two applications the spam detect and the

939
00:34:34,440 --> 00:34:37,260
command analysis analyze

940
00:34:37,260 --> 00:34:40,440
so in summary gpt3 with future learning

941
00:34:40,440 --> 00:34:42,719
is so flexible and Powerful you can

942
00:34:42,719 --> 00:34:45,780
easily create powerful applications

943
00:34:45,780 --> 00:34:51,659
the title of Auto is a gptc and b so it

944
00:34:51,659 --> 00:34:53,820
was our successful story and it's not

945
00:34:53,820 --> 00:34:56,960
it's a time for you to create your

946
00:34:56,960 --> 00:35:00,780
application that will be your tpt3 and

947
00:35:00,780 --> 00:35:02,520
you

948
00:35:02,520 --> 00:35:04,500
thanks for listening it's a time for

949
00:35:04,500 --> 00:35:06,480
training

950
00:35:06,480 --> 00:35:08,260
thank you

951
00:35:08,260 --> 00:35:10,260
[Music]

952
00:35:10,260 --> 00:35:13,260
foreign

953
00:35:15,220 --> 00:35:18,319
[Music]

