1
00:00:01,180 --> 00:00:14,730
[Music]

2
00:00:16,079 --> 00:00:17,039
hello

3
00:00:17,039 --> 00:00:19,680
hi welcome to this virtual blackhead

4
00:00:19,680 --> 00:00:20,640
briefing

5
00:00:20,640 --> 00:00:22,880
so today we'll be talking about new new

6
00:00:22,880 --> 00:00:24,000
methods for

7
00:00:24,000 --> 00:00:27,599
hypervisor detection just a few words

8
00:00:27,599 --> 00:00:28,400
about me

9
00:00:28,400 --> 00:00:31,519
i work in academia i'm a postdoc in

10
00:00:31,519 --> 00:00:34,800
sapiens university in italy i work in

11
00:00:34,800 --> 00:00:36,800
software and system security

12
00:00:36,800 --> 00:00:40,079
and uh i'm returning to blakket this

13
00:00:40,079 --> 00:00:40,879
year

14
00:00:40,879 --> 00:00:43,920
last year i was presenting a system blue

15
00:00:43,920 --> 00:00:46,160
pill for handling invested malware

16
00:00:46,160 --> 00:00:48,719
but this year i'm working for the other

17
00:00:48,719 --> 00:00:49,760
site

18
00:00:49,760 --> 00:00:53,680
we will be presenting new red pills

19
00:00:53,680 --> 00:00:56,840
in particular we will be dealing

20
00:00:56,840 --> 00:01:00,320
with sandboxes that are able to hide

21
00:01:00,320 --> 00:01:02,719
discrepancies of virtualization

22
00:01:02,719 --> 00:01:06,159
by thinking the the results of time

23
00:01:06,159 --> 00:01:08,400
measurements made by a program

24
00:01:08,400 --> 00:01:11,680
so we will be building our own covert

25
00:01:11,680 --> 00:01:14,320
time source and we will be retrofitting

26
00:01:14,320 --> 00:01:15,600
existing detections

27
00:01:15,600 --> 00:01:18,479
based on time for hypervisors and we

28
00:01:18,479 --> 00:01:19,600
will see if

29
00:01:19,600 --> 00:01:22,720
now these retrofitted primitives

30
00:01:22,720 --> 00:01:25,600
can can detects and bosses and then the

31
00:01:25,600 --> 00:01:26,400
other

32
00:01:26,400 --> 00:01:28,000
the the other attack that i'm going to

33
00:01:28,000 --> 00:01:30,560
present is a premium probe attack

34
00:01:30,560 --> 00:01:33,920
on the last level of cache to detect

35
00:01:33,920 --> 00:01:35,840
again the presence of a virtual machine

36
00:01:35,840 --> 00:01:37,759
monitor

37
00:01:37,759 --> 00:01:41,600
let's get started i want to talk briefly

38
00:01:41,600 --> 00:01:43,680
about the importance of hypervisors and

39
00:01:43,680 --> 00:01:44,560
why cannot be

40
00:01:44,560 --> 00:01:47,840
avoided in malware analysis today well

41
00:01:47,840 --> 00:01:49,759
hypervisors are important for

42
00:01:49,759 --> 00:01:52,640
scalability of the analysis because you

43
00:01:52,640 --> 00:01:54,880
can run many virtual machines

44
00:01:54,880 --> 00:01:57,600
and do your analysis on servers but also

45
00:01:57,600 --> 00:01:59,840
from a transparency point of view

46
00:01:59,840 --> 00:02:04,000
so in recent years

47
00:02:04,000 --> 00:02:07,119
many many researchers and companies they

48
00:02:07,119 --> 00:02:09,679
they've proposed the signs where the

49
00:02:09,679 --> 00:02:11,760
agent functionality of a sandbox is

50
00:02:11,760 --> 00:02:14,080
implemented at a hypervisor level using

51
00:02:14,080 --> 00:02:16,000
virtual machine introspection

52
00:02:16,000 --> 00:02:18,080
so to reduce the number of artifacts

53
00:02:18,080 --> 00:02:20,640
that you have in the execution and then

54
00:02:20,640 --> 00:02:23,680
that an adversary can look for so

55
00:02:23,680 --> 00:02:26,720
hypervisors are are really important

56
00:02:26,720 --> 00:02:30,400
and uh the problem uh with hypervisors

57
00:02:30,400 --> 00:02:31,760
is that they introduce some

58
00:02:31,760 --> 00:02:32,959
discrepancies

59
00:02:32,959 --> 00:02:34,959
to understand these discrepancies let's

60
00:02:34,959 --> 00:02:36,640
let's talk a little bit of

61
00:02:36,640 --> 00:02:40,000
how virtualization works under the hood

62
00:02:40,000 --> 00:02:44,000
so the cpu offers assistance

63
00:02:44,000 --> 00:02:47,360
to hypervisors for virtualization

64
00:02:47,360 --> 00:02:51,760
there is the dmx operation of the cpu

65
00:02:51,760 --> 00:02:55,280
so there is a vmx root mode it's the

66
00:02:55,280 --> 00:02:56,080
high privilege

67
00:02:56,080 --> 00:02:59,200
mode that is where your virtual machine

68
00:02:59,200 --> 00:02:59,920
monitor

69
00:02:59,920 --> 00:03:03,360
resides and operates so this vmm

70
00:03:03,360 --> 00:03:06,239
is your host is giving your resources

71
00:03:06,239 --> 00:03:06,879
assigning

72
00:03:06,879 --> 00:03:10,640
virtual processors to guests etc

73
00:03:10,640 --> 00:03:13,360
and then you have a new root mode where

74
00:03:13,360 --> 00:03:15,599
your guest is running this is your

75
00:03:15,599 --> 00:03:18,159
virtual machine and there is a virtual

76
00:03:18,159 --> 00:03:20,400
machine control structure that regulates

77
00:03:20,400 --> 00:03:22,000
this the transitions

78
00:03:22,000 --> 00:03:24,640
between root and root mode so this is

79
00:03:24,640 --> 00:03:26,319
important because there are some

80
00:03:26,319 --> 00:03:27,120
operations

81
00:03:27,120 --> 00:03:31,440
in the guest that operations or events

82
00:03:31,440 --> 00:03:34,640
that require vmx street mods so what

83
00:03:34,640 --> 00:03:37,680
happens is that there is a vm exit event

84
00:03:37,680 --> 00:03:41,120
the vmm takes over and once the monitor

85
00:03:41,120 --> 00:03:42,640
has finished there will be

86
00:03:42,640 --> 00:03:47,280
a vm entry event back into the guest

87
00:03:47,280 --> 00:03:50,159
virtualization in hardware assisted

88
00:03:50,159 --> 00:03:52,000
virtualization has been

89
00:03:52,000 --> 00:03:56,080
uh conceived for high performance and

90
00:03:56,080 --> 00:03:57,760
compatibility

91
00:03:57,760 --> 00:04:00,560
there is a seminal work from gerfinkel

92
00:04:00,560 --> 00:04:02,400
from 13 years ago

93
00:04:02,400 --> 00:04:04,720
where he was claiming that in the

94
00:04:04,720 --> 00:04:07,519
presence of a dedicated adversary

95
00:04:07,519 --> 00:04:10,640
it's it's almost impossible to build a

96
00:04:10,640 --> 00:04:12,480
fully transparent virtual machine

97
00:04:12,480 --> 00:04:13,360
monitor

98
00:04:13,360 --> 00:04:16,320
so there are some discrepancies and even

99
00:04:16,320 --> 00:04:18,000
though many enhancements

100
00:04:18,000 --> 00:04:22,079
have been made by cpu producers

101
00:04:22,079 --> 00:04:25,360
think of extended page tables or other

102
00:04:25,360 --> 00:04:26,560
mechanisms

103
00:04:26,560 --> 00:04:30,000
there are still some problems

104
00:04:30,000 --> 00:04:31,840
in terms of transparency and for

105
00:04:31,840 --> 00:04:34,000
instance the transitions to the virtual

106
00:04:34,000 --> 00:04:35,680
machine monitor are

107
00:04:35,680 --> 00:04:38,960
inevitable let's let's start with an

108
00:04:38,960 --> 00:04:41,280
example the situate the instruction

109
00:04:41,280 --> 00:04:44,560
so your cpu id reveals you properties

110
00:04:44,560 --> 00:04:48,479
of the processor and this will cause a

111
00:04:48,479 --> 00:04:50,080
vm exit

112
00:04:50,080 --> 00:04:53,919
so the moment that you you execute cprd

113
00:04:53,919 --> 00:04:54,960
in the guest

114
00:04:54,960 --> 00:04:58,160
the vmain takes over and also has the

115
00:04:58,160 --> 00:05:00,000
possibility of

116
00:05:00,000 --> 00:05:01,680
changing the properties that you're

117
00:05:01,680 --> 00:05:03,039
exposing or

118
00:05:03,039 --> 00:05:06,080
for the cpu to the guest so you might be

119
00:05:06,080 --> 00:05:06,800
changing

120
00:05:06,800 --> 00:05:12,080
brand string or other aspects but

121
00:05:12,400 --> 00:05:15,520
there is also a so-called hypervisor bit

122
00:05:15,520 --> 00:05:17,120
that is one when you're running in a

123
00:05:17,120 --> 00:05:19,280
hypervisor that in a sandbox you should

124
00:05:19,280 --> 00:05:19,840
be

125
00:05:19,840 --> 00:05:22,800
turning into zero but the point here is

126
00:05:22,800 --> 00:05:25,759
not about the data returned by cpuid

127
00:05:25,759 --> 00:05:28,160
the point is about how long it takes for

128
00:05:28,160 --> 00:05:29,919
cpu id to run

129
00:05:29,919 --> 00:05:34,400
so if we time the execution of cpu id

130
00:05:34,400 --> 00:05:36,000
for instance on the laptop that i'm

131
00:05:36,000 --> 00:05:38,400
using for recording this presentation

132
00:05:38,400 --> 00:05:41,199
we will see that if i do this i run the

133
00:05:41,199 --> 00:05:41,840
sequence

134
00:05:41,840 --> 00:05:45,360
on the native host on the operating

135
00:05:45,360 --> 00:05:46,320
system

136
00:05:46,320 --> 00:05:49,680
i will be measuring around 300

137
00:05:49,680 --> 00:05:53,840
cycles while if i do it under virtualbox

138
00:05:53,840 --> 00:05:56,160
i will be getting 10 times more because

139
00:05:56,160 --> 00:05:57,919
here i'm including the latency of

140
00:05:57,919 --> 00:06:01,360
performing a vm entry and bmx it

141
00:06:01,360 --> 00:06:04,960
so what can i do as a sandbox architect

142
00:06:04,960 --> 00:06:08,160
well yeah i mean i should be tracking

143
00:06:08,160 --> 00:06:11,440
uh those instructions like cpu id or

144
00:06:11,440 --> 00:06:15,440
other patterns that might be abused

145
00:06:15,440 --> 00:06:18,080
because vm exit but that covers me only

146
00:06:18,080 --> 00:06:20,160
for the detection part for

147
00:06:20,160 --> 00:06:22,000
countering those attempts i need to

148
00:06:22,000 --> 00:06:24,800
control the time sources i need to

149
00:06:24,800 --> 00:06:27,919
alter the perception of time

150
00:06:27,919 --> 00:06:30,800
inside the guest and it's not enough to

151
00:06:30,800 --> 00:06:31,120
just

152
00:06:31,120 --> 00:06:33,199
hook the apis and change the results

153
00:06:33,199 --> 00:06:34,639
what you need to do

154
00:06:34,639 --> 00:06:36,960
is you need to intercept the execution

155
00:06:36,960 --> 00:06:39,520
or the rdtsc instruction

156
00:06:39,520 --> 00:06:41,360
you have to configure the virtual

157
00:06:41,360 --> 00:06:43,680
machine monitor to

158
00:06:43,680 --> 00:06:46,960
have a vm exit also for rdtsc and you

159
00:06:46,960 --> 00:06:47,520
can

160
00:06:47,520 --> 00:06:49,440
keep track of the time that you spend in

161
00:06:49,440 --> 00:06:50,960
the bmm and you can re

162
00:06:50,960 --> 00:06:54,240
like subtract this time from

163
00:06:54,240 --> 00:06:57,599
the values that rdtsc is returning

164
00:06:57,599 --> 00:07:00,880
during the execution

165
00:07:01,120 --> 00:07:04,800
this problem uh like

166
00:07:04,800 --> 00:07:08,720
is not new in other areas either so

167
00:07:08,720 --> 00:07:12,240
for instance in the microarchitectural

168
00:07:12,240 --> 00:07:14,880
attacks literature there was this

169
00:07:14,880 --> 00:07:17,199
seminal work to spine the sandbox where

170
00:07:17,199 --> 00:07:18,240
they were able to

171
00:07:18,240 --> 00:07:22,880
to perform an llc attack from a browser

172
00:07:22,880 --> 00:07:26,000
using javascript and the performance now

173
00:07:26,000 --> 00:07:29,680
primitive of javascript so to

174
00:07:29,680 --> 00:07:32,240
to shut the door to those attacks bender

175
00:07:32,240 --> 00:07:32,960
said okay

176
00:07:32,960 --> 00:07:36,400
let's just make uh this clock much worse

177
00:07:36,400 --> 00:07:38,720
we reduce the resolution

178
00:07:38,720 --> 00:07:41,599
but researchers they came up with uh

179
00:07:41,599 --> 00:07:44,240
with two counter measures one was

180
00:07:44,240 --> 00:07:46,879
recovering resolution even from a

181
00:07:46,879 --> 00:07:48,240
crippled clock

182
00:07:48,240 --> 00:07:50,800
and the other uh which which i will be

183
00:07:50,800 --> 00:07:51,440
using

184
00:07:51,440 --> 00:07:54,479
in in this work is to build your own

185
00:07:54,479 --> 00:07:56,080
time source

186
00:07:56,080 --> 00:07:59,360
what do i mean by that timestamp counter

187
00:07:59,360 --> 00:08:01,759
is essentially a variable that you can

188
00:08:01,759 --> 00:08:04,319
only read with dedicated instructions

189
00:08:04,319 --> 00:08:06,639
but you may say okay i want to build my

190
00:08:06,639 --> 00:08:08,000
own variable

191
00:08:08,000 --> 00:08:12,319
i i can dedicate a cpu core just to

192
00:08:12,319 --> 00:08:13,520
increment

193
00:08:13,520 --> 00:08:16,800
this variable and i will read it from

194
00:08:16,800 --> 00:08:20,000
from my main my main thread and whenever

195
00:08:20,000 --> 00:08:20,720
i need to

196
00:08:20,720 --> 00:08:23,199
to time the execution of cpuid i will be

197
00:08:23,199 --> 00:08:27,280
reading this variable twice

198
00:08:27,280 --> 00:08:31,280
i mean this variable how often

199
00:08:31,280 --> 00:08:33,679
gets incremented it is fast enough the

200
00:08:33,679 --> 00:08:35,440
resolution is good

201
00:08:35,440 --> 00:08:38,320
and are those measurements reliable so

202
00:08:38,320 --> 00:08:40,479
let's do some tests

203
00:08:40,479 --> 00:08:44,080
uh this is some code for

204
00:08:44,080 --> 00:08:47,680
computing the approximate resolution of

205
00:08:47,680 --> 00:08:49,200
our time sources

206
00:08:49,200 --> 00:08:51,360
we will be comparing the timestamp

207
00:08:51,360 --> 00:08:52,399
counter

208
00:08:52,399 --> 00:08:56,800
and uh with rdtsc and our counter clock

209
00:08:56,800 --> 00:08:59,120
so with the timestamp counter the nice

210
00:08:59,120 --> 00:09:02,399
thing is that in recent intel cpus

211
00:09:02,399 --> 00:09:04,959
uh the clock ticks at the nominal

212
00:09:04,959 --> 00:09:05,839
frequency

213
00:09:05,839 --> 00:09:07,519
so it doesn't depend on the current

214
00:09:07,519 --> 00:09:09,680
frequency of the cpu

215
00:09:09,680 --> 00:09:12,080
let's make some measurements and with

216
00:09:12,080 --> 00:09:14,959
this with this code we obtain for rdtsc

217
00:09:14,959 --> 00:09:17,040
some values that are very very close to

218
00:09:17,040 --> 00:09:18,560
the nominal frequency

219
00:09:18,560 --> 00:09:21,680
for the cpu but for the counter thread

220
00:09:21,680 --> 00:09:22,320
we got

221
00:09:22,320 --> 00:09:25,920
a much lower resolution it's not too bad

222
00:09:25,920 --> 00:09:29,440
it's like five six times worse

223
00:09:29,440 --> 00:09:31,200
but it might not be enough for some

224
00:09:31,200 --> 00:09:32,959
attacks it's good for cpu id

225
00:09:32,959 --> 00:09:36,399
may not for others so

226
00:09:36,399 --> 00:09:39,200
can we do better can we increment that

227
00:09:39,200 --> 00:09:41,600
variable faster

228
00:09:41,600 --> 00:09:45,200
and uh there is some researchers in

229
00:09:45,200 --> 00:09:47,440
harass university take him up with a

230
00:09:47,440 --> 00:09:48,880
clever idea

231
00:09:48,880 --> 00:09:52,560
they say the problem of that increment

232
00:09:52,560 --> 00:09:56,320
is that to to update the counter you

233
00:09:56,320 --> 00:09:58,800
first have to read the current value

234
00:09:58,800 --> 00:10:01,519
and then you can update it and you're

235
00:10:01,519 --> 00:10:02,399
reading and

236
00:10:02,399 --> 00:10:05,760
writing from memory so this means two

237
00:10:05,760 --> 00:10:08,560
accesses to the l1 cache you can save

238
00:10:08,560 --> 00:10:09,200
one of those

239
00:10:09,200 --> 00:10:12,000
accesses by keeping the counter in a

240
00:10:12,000 --> 00:10:14,800
register so you increment a register

241
00:10:14,800 --> 00:10:17,279
and then you copy to register contents

242
00:10:17,279 --> 00:10:18,880
to memory

243
00:10:18,880 --> 00:10:21,040
this works very very well because

244
00:10:21,040 --> 00:10:22,320
increment is

245
00:10:22,320 --> 00:10:24,959
like super low latency and the move is

246
00:10:24,959 --> 00:10:26,240
not that bad

247
00:10:26,240 --> 00:10:28,880
and actually you'll be surprised but you

248
00:10:28,880 --> 00:10:30,480
can get

249
00:10:30,480 --> 00:10:33,200
an enhanced counter thread that can take

250
00:10:33,200 --> 00:10:34,160
faster

251
00:10:34,160 --> 00:10:36,399
than the original timestamp counter

252
00:10:36,399 --> 00:10:38,720
thanks to instruction level parallelism

253
00:10:38,720 --> 00:10:40,160
and other

254
00:10:40,160 --> 00:10:41,720
magic that happens at the

255
00:10:41,720 --> 00:10:43,760
microarchitectural level

256
00:10:43,760 --> 00:10:47,120
so the resolution problem seems

257
00:10:47,120 --> 00:10:49,600
kind of solved let's see about

258
00:10:49,600 --> 00:10:50,720
reliability

259
00:10:50,720 --> 00:10:54,160
so we need we need a cpu core for

260
00:10:54,160 --> 00:10:57,839
uh running this counter thread we cannot

261
00:10:57,839 --> 00:10:59,920
run the counter thread alongside our

262
00:10:59,920 --> 00:11:00,959
detection

263
00:11:00,959 --> 00:11:03,839
on the same thread on the same core so

264
00:11:03,839 --> 00:11:04,959
what can we do

265
00:11:04,959 --> 00:11:08,000
uh yeah i mean if we don't we don't want

266
00:11:08,000 --> 00:11:09,120
to trust

267
00:11:09,120 --> 00:11:11,360
what the operating system says i have

268
00:11:11,360 --> 00:11:12,480
eight cores four

269
00:11:12,480 --> 00:11:14,959
cores or three cores this number can be

270
00:11:14,959 --> 00:11:16,320
faked

271
00:11:16,320 --> 00:11:17,760
we need to be sure that we're not

272
00:11:17,760 --> 00:11:20,160
dealing with a single core machine

273
00:11:20,160 --> 00:11:22,320
so there is a detection method proposed

274
00:11:22,320 --> 00:11:23,600
in this paper

275
00:11:23,600 --> 00:11:27,120
uh which is to to check from one thread

276
00:11:27,120 --> 00:11:29,120
if another thread is running and the

277
00:11:29,120 --> 00:11:30,560
other way around

278
00:11:30,560 --> 00:11:33,360
so you we can use antiquary system

279
00:11:33,360 --> 00:11:34,160
information

280
00:11:34,160 --> 00:11:36,640
access some internal structures or

281
00:11:36,640 --> 00:11:37,360
windows

282
00:11:37,360 --> 00:11:41,440
and check the trade state from there

283
00:11:41,440 --> 00:11:44,399
this works but you know a sandbox

284
00:11:44,399 --> 00:11:46,640
architect that knows this trick can

285
00:11:46,640 --> 00:11:49,279
fake those results so let's do it

286
00:11:49,279 --> 00:11:51,360
without apis

287
00:11:51,360 --> 00:11:54,079
so what we do is we still raise two

288
00:11:54,079 --> 00:11:55,120
threads

289
00:11:55,120 --> 00:11:58,240
and the idea is that every thread

290
00:11:58,240 --> 00:12:02,079
has its own counter

291
00:12:02,079 --> 00:12:05,440
and we see from from the other thread

292
00:12:05,440 --> 00:12:08,320
if this thread is incrementing this

293
00:12:08,320 --> 00:12:11,200
counter so we make an observation

294
00:12:11,200 --> 00:12:14,320
and then we make another and we check if

295
00:12:14,320 --> 00:12:17,360
in the meantime the the thread has

296
00:12:17,360 --> 00:12:19,680
increased the counter so this this

297
00:12:19,680 --> 00:12:20,959
mechanism is

298
00:12:20,959 --> 00:12:23,680
yeah this is more complicated to to

299
00:12:23,680 --> 00:12:24,880
intercept

300
00:12:24,880 --> 00:12:28,480
and fake for for a sandbox

301
00:12:28,480 --> 00:12:30,800
we we have detection methods to to

302
00:12:30,800 --> 00:12:31,519
determine

303
00:12:31,519 --> 00:12:33,680
whether we have enough course to run our

304
00:12:33,680 --> 00:12:35,360
counter threads

305
00:12:35,360 --> 00:12:38,000
there's still a problem though that is

306
00:12:38,000 --> 00:12:39,760
the workload of the machine

307
00:12:39,760 --> 00:12:42,560
i mean even if you have two cores there

308
00:12:42,560 --> 00:12:45,040
are still a possibility that

309
00:12:45,040 --> 00:12:47,920
you might be the schedule so your clock

310
00:12:47,920 --> 00:12:49,680
stops sticking

311
00:12:49,680 --> 00:12:51,839
and you get the stale value and you

312
00:12:51,839 --> 00:12:54,320
cannot make measurements

313
00:12:54,320 --> 00:12:56,560
you can say okay i'm just set a very

314
00:12:56,560 --> 00:12:58,639
high priority for the thread but this

315
00:12:58,639 --> 00:13:01,839
this doesn't solve the problem

316
00:13:01,839 --> 00:13:03,839
i mean can improve the situation but

317
00:13:03,839 --> 00:13:05,120
it's not a solution

318
00:13:05,120 --> 00:13:07,760
it's also conspicuous what you can do is

319
00:13:07,760 --> 00:13:08,480
you can

320
00:13:08,480 --> 00:13:11,519
poke the counter you can check for a

321
00:13:11,519 --> 00:13:12,560
heartbeat

322
00:13:12,560 --> 00:13:15,760
you can read the counter read it again

323
00:13:15,760 --> 00:13:18,959
and see if the value has changed if

324
00:13:18,959 --> 00:13:21,680
if it has changed the trade is beating

325
00:13:21,680 --> 00:13:22,959
so it's ticking

326
00:13:22,959 --> 00:13:25,120
and you can you can take that last

327
00:13:25,120 --> 00:13:26,880
measurement and that will be your

328
00:13:26,880 --> 00:13:29,839
starting time otherwise you keep waiting

329
00:13:29,839 --> 00:13:31,760
and then it's important in general with

330
00:13:31,760 --> 00:13:34,560
counter threads but also with the rdtlc

331
00:13:34,560 --> 00:13:36,959
that you serialize your measurements

332
00:13:36,959 --> 00:13:37,600
using

333
00:13:37,600 --> 00:13:40,800
fences so

334
00:13:40,800 --> 00:13:43,600
now we have time primitive we want to

335
00:13:43,600 --> 00:13:45,680
put it into action

336
00:13:45,680 --> 00:13:49,199
so we started uh

337
00:13:49,199 --> 00:13:51,839
popular time-based detection for

338
00:13:51,839 --> 00:13:53,360
hypervisors

339
00:13:53,360 --> 00:13:57,040
and we implemented them both with rdtsc

340
00:13:57,040 --> 00:13:58,160
and then we plugged

341
00:13:58,160 --> 00:14:01,279
the counterthread version in our counter

342
00:14:01,279 --> 00:14:02,959
threat primitives and then we compare

343
00:14:02,959 --> 00:14:04,240
the results

344
00:14:04,240 --> 00:14:06,000
so i'm i will be presenting four

345
00:14:06,000 --> 00:14:08,320
detections one i already kind of

346
00:14:08,320 --> 00:14:10,000
presented it to ready the

347
00:14:10,000 --> 00:14:13,279
latency of cpu at the instruction

348
00:14:13,279 --> 00:14:15,199
i mean if you fail this test it's not a

349
00:14:15,199 --> 00:14:17,440
good sign you know sandbox

350
00:14:17,440 --> 00:14:20,079
but the idea is that in this test you

351
00:14:20,079 --> 00:14:22,240
normally

352
00:14:22,240 --> 00:14:24,880
you can make different observations take

353
00:14:24,880 --> 00:14:27,360
the average value and compare it against

354
00:14:27,360 --> 00:14:28,240
some

355
00:14:28,240 --> 00:14:32,320
bare metal threshold say 100 000

356
00:14:32,320 --> 00:14:36,079
as tsc difference um then there is

357
00:14:36,079 --> 00:14:36,800
another

358
00:14:36,800 --> 00:14:40,560
test which is a different flavor

359
00:14:40,560 --> 00:14:44,079
and appeared in the loki malware the

360
00:14:44,079 --> 00:14:45,760
first time

361
00:14:45,760 --> 00:14:48,320
so the lucky authors had this clever

362
00:14:48,320 --> 00:14:48,880
idea

363
00:14:48,880 --> 00:14:51,279
of comparing the execution time of get

364
00:14:51,279 --> 00:14:52,160
process hip

365
00:14:52,160 --> 00:14:54,720
and close handle normally get press's

366
00:14:54,720 --> 00:14:57,440
hip is like super fast it's just

367
00:14:57,440 --> 00:15:00,160
three instructions and close handle

368
00:15:00,160 --> 00:15:01,279
takes longer

369
00:15:01,279 --> 00:15:04,079
however if you execute this code without

370
00:15:04,079 --> 00:15:05,760
uh

371
00:15:05,760 --> 00:15:07,839
hardware assistance for your virtual

372
00:15:07,839 --> 00:15:09,600
machine

373
00:15:09,600 --> 00:15:12,480
you will get a high high execution time

374
00:15:12,480 --> 00:15:14,320
forget process here because you're

375
00:15:14,320 --> 00:15:15,360
accessing

376
00:15:15,360 --> 00:15:17,600
through the segment register you're

377
00:15:17,600 --> 00:15:19,519
accessing the process entry block the

378
00:15:19,519 --> 00:15:21,279
trade entry block

379
00:15:21,279 --> 00:15:26,000
for uh for this operation um but also i

380
00:15:26,000 --> 00:15:28,000
mean you will not be detecting

381
00:15:28,000 --> 00:15:30,800
uh virtualbox with this method but you

382
00:15:30,800 --> 00:15:33,199
might be detecting a custom hypervisor

383
00:15:33,199 --> 00:15:35,519
that is intercepting

384
00:15:35,519 --> 00:15:38,560
uh accesses to the process entry block

385
00:15:38,560 --> 00:15:40,079
and the thread entry block

386
00:15:40,079 --> 00:15:42,560
so this this detection will actually

387
00:15:42,560 --> 00:15:43,839
give us surprising

388
00:15:43,839 --> 00:15:47,120
surprising results but first uh there

389
00:15:47,120 --> 00:15:49,440
are two more detections to present

390
00:15:49,440 --> 00:15:52,959
that they were described in a game the

391
00:15:52,959 --> 00:15:55,759
paper that i referenced before so we

392
00:15:55,759 --> 00:15:57,680
reproduced the research

393
00:15:57,680 --> 00:16:00,720
and the first detection is to instead of

394
00:16:00,720 --> 00:16:03,120
checking the absolute execution time for

395
00:16:03,120 --> 00:16:04,639
cpuid

396
00:16:04,639 --> 00:16:07,680
we we make a comparison we

397
00:16:07,680 --> 00:16:11,440
we run a cpu id in a loop and then we

398
00:16:11,440 --> 00:16:11,759
run

399
00:16:11,759 --> 00:16:14,000
another instruction in a loop we make

400
00:16:14,000 --> 00:16:15,360
different measurements

401
00:16:15,360 --> 00:16:18,399
and we compare the execution time ratio

402
00:16:18,399 --> 00:16:20,560
because i mean the absolute times can

403
00:16:20,560 --> 00:16:22,480
change between different architectures

404
00:16:22,480 --> 00:16:23,759
and can be forged

405
00:16:23,759 --> 00:16:28,079
but the ratio is is more reliable and

406
00:16:28,079 --> 00:16:31,120
you can compare cpu id to some low

407
00:16:31,120 --> 00:16:32,399
latency structure

408
00:16:32,399 --> 00:16:35,519
we use knob just like the others

409
00:16:35,519 --> 00:16:38,720
and the the other detection is clever

410
00:16:38,720 --> 00:16:41,600
actually this time we are not looking

411
00:16:41,600 --> 00:16:44,160
for a latency

412
00:16:44,160 --> 00:16:46,720
because of the vm mm monitor the vm

413
00:16:46,720 --> 00:16:49,440
monitor has to execute this time

414
00:16:49,440 --> 00:16:52,240
we look for a latency that is induced by

415
00:16:52,240 --> 00:16:54,240
some threshing some pollution

416
00:16:54,240 --> 00:16:57,600
on the microarchitectural state from the

417
00:16:57,600 --> 00:16:58,320
vmm

418
00:16:58,320 --> 00:17:01,519
execution so in this attack

419
00:17:01,519 --> 00:17:04,880
we uh we search for tlb andres the

420
00:17:04,880 --> 00:17:06,799
transitional leukocyte buffer entries

421
00:17:06,799 --> 00:17:09,439
that are addicted by the vmm

422
00:17:09,439 --> 00:17:13,039
so we fill the tlb then we execute cpu

423
00:17:13,039 --> 00:17:13,520
id

424
00:17:13,520 --> 00:17:16,640
or cause a vm exit in other ways

425
00:17:16,640 --> 00:17:21,359
and then we we analyze the latencies in

426
00:17:21,359 --> 00:17:25,359
accessing some attacker control pages

427
00:17:25,359 --> 00:17:27,839
and yeah the advantage is that you

428
00:17:27,839 --> 00:17:29,840
cannot fool this by just subtracting

429
00:17:29,840 --> 00:17:30,400
time

430
00:17:30,400 --> 00:17:33,840
because we are not measuring cpu id here

431
00:17:33,840 --> 00:17:36,640
we are measuring the effects the only

432
00:17:36,640 --> 00:17:38,400
downside of this strategy is that

433
00:17:38,400 --> 00:17:42,080
filling the tlb there there is no

434
00:17:42,080 --> 00:17:44,720
a unique strategy but there is the

435
00:17:44,720 --> 00:17:46,480
linear filling algorithm that works

436
00:17:46,480 --> 00:17:47,840
quite well

437
00:17:47,840 --> 00:17:51,280
uh which which is that you you

438
00:17:51,280 --> 00:17:54,000
you guess first the tlb sites then you

439
00:17:54,000 --> 00:17:56,799
allocate that many pages to

440
00:17:56,799 --> 00:18:00,320
to fill it you load them you take care

441
00:18:00,320 --> 00:18:00,640
of

442
00:18:00,640 --> 00:18:03,919
caches to cancel their effects with

443
00:18:03,919 --> 00:18:05,360
flashing and you

444
00:18:05,360 --> 00:18:08,720
measure the maximum access time

445
00:18:08,720 --> 00:18:12,160
that you observe for all the pages so

446
00:18:12,160 --> 00:18:16,880
you make some comparison with cpu id

447
00:18:16,880 --> 00:18:20,160
and then you you get the same the the

448
00:18:20,160 --> 00:18:21,200
baseline

449
00:18:21,200 --> 00:18:25,360
with for instance you run knob in a loop

450
00:18:25,360 --> 00:18:28,559
and let's see the results right so yeah

451
00:18:28,559 --> 00:18:29,600
i mean we we

452
00:18:29,600 --> 00:18:32,000
obtained results on several machines

453
00:18:32,000 --> 00:18:33,280
that we controlled

454
00:18:33,280 --> 00:18:35,120
but the interesting part is when we

455
00:18:35,120 --> 00:18:37,039
submitted this to

456
00:18:37,039 --> 00:18:39,600
malware analysis services to send boxes

457
00:18:39,600 --> 00:18:40,720
so

458
00:18:40,720 --> 00:18:44,320
we resorted to public services and some

459
00:18:44,320 --> 00:18:48,320
subscriptions that we had and also a

460
00:18:48,320 --> 00:18:50,000
nice thing is that many people

461
00:18:50,000 --> 00:18:52,240
downloaded it from the feeds when we

462
00:18:52,240 --> 00:18:53,919
were submitting those from public

463
00:18:53,919 --> 00:18:55,039
services

464
00:18:55,039 --> 00:18:59,440
we obtained um yeah

465
00:18:59,440 --> 00:19:02,799
around 76

466
00:19:02,799 --> 00:19:06,320
results on like 76

467
00:19:06,320 --> 00:19:10,080
machines completed most of our tests

468
00:19:10,080 --> 00:19:12,799
let's see in detail first of all let's

469
00:19:12,799 --> 00:19:13,919
see how did it go

470
00:19:13,919 --> 00:19:17,039
with the counter thread resolution so we

471
00:19:17,039 --> 00:19:18,080
observed that

472
00:19:18,080 --> 00:19:20,640
uh for nearly half of the machine we had

473
00:19:20,640 --> 00:19:22,559
a timestamp counter

474
00:19:22,559 --> 00:19:25,919
uh that was slower

475
00:19:25,919 --> 00:19:29,200
than the counter thread which was good

476
00:19:29,200 --> 00:19:32,720
and but in the other half

477
00:19:32,720 --> 00:19:35,840
we we didn't get a faster uh

478
00:19:35,840 --> 00:19:38,240
clock but we still a pretty pretty good

479
00:19:38,240 --> 00:19:38,960
clock

480
00:19:38,960 --> 00:19:41,919
so we're sticking within 40 percent of

481
00:19:41,919 --> 00:19:43,039
the

482
00:19:43,039 --> 00:19:45,840
of the frequency this means that there

483
00:19:45,840 --> 00:19:46,960
is some work to do

484
00:19:46,960 --> 00:19:50,000
in finding other primitives for

485
00:19:50,000 --> 00:19:52,080
for incrementing the variable faster

486
00:19:52,080 --> 00:19:55,760
when when using other microarchitectures

487
00:19:55,760 --> 00:19:57,440
but the interesting part is that we

488
00:19:57,440 --> 00:19:59,360
observed in some cases that

489
00:19:59,360 --> 00:20:01,600
tsc frequency that we measured with our

490
00:20:01,600 --> 00:20:03,039
method was

491
00:20:03,039 --> 00:20:05,039
significantly different than when you

492
00:20:05,039 --> 00:20:06,320
you would expect for

493
00:20:06,320 --> 00:20:09,200
the cpu model that was exposed by the

494
00:20:09,200 --> 00:20:10,080
sandbox so

495
00:20:10,080 --> 00:20:12,159
meaning that probably that that model

496
00:20:12,159 --> 00:20:14,799
was fake

497
00:20:15,360 --> 00:20:18,799
for cpu id uh well we

498
00:20:18,799 --> 00:20:22,480
we observed that only 23 machines

499
00:20:22,480 --> 00:20:26,000
fail past past this test sorry

500
00:20:26,000 --> 00:20:29,600
23. so we obtained this number by double

501
00:20:29,600 --> 00:20:30,159
checking

502
00:20:30,159 --> 00:20:32,480
the latencies also with the results that

503
00:20:32,480 --> 00:20:33,760
we obtain

504
00:20:33,760 --> 00:20:35,840
with detection trees since the average

505
00:20:35,840 --> 00:20:37,520
is not really a good method

506
00:20:37,520 --> 00:20:40,640
but so it's done in the wild and what

507
00:20:40,640 --> 00:20:42,799
about these 23 machines

508
00:20:42,799 --> 00:20:45,120
i mean the other machines that one that

509
00:20:45,120 --> 00:20:46,880
failed the test you observe that also

510
00:20:46,880 --> 00:20:48,640
with the counter thread

511
00:20:48,640 --> 00:20:52,080
we obtain high values but for those that

512
00:20:52,080 --> 00:20:53,760
passed the test

513
00:20:53,760 --> 00:20:57,200
we saw that 14 were single core

514
00:20:57,200 --> 00:21:00,320
and so they are trivially detected

515
00:21:00,320 --> 00:21:03,760
for six we were observing fake times 10

516
00:21:03,760 --> 00:21:05,520
counter values

517
00:21:05,520 --> 00:21:09,039
because the counter threats were high

518
00:21:09,039 --> 00:21:11,520
the counter trade measurements were high

519
00:21:11,520 --> 00:21:13,360
and we're revealing the actual latency

520
00:21:13,360 --> 00:21:14,960
of cpuid

521
00:21:14,960 --> 00:21:17,919
we found one case where it was running

522
00:21:17,919 --> 00:21:18,799
in qmu

523
00:21:18,799 --> 00:21:21,280
where the counter thread was was going

524
00:21:21,280 --> 00:21:23,039
super slow

525
00:21:23,039 --> 00:21:27,200
and uh we we found also that in one case

526
00:21:27,200 --> 00:21:29,360
uh yeah it was too close to call and in

527
00:21:29,360 --> 00:21:30,480
another case

528
00:21:30,480 --> 00:21:32,720
the sandbox timed out too fast before we

529
00:21:32,720 --> 00:21:34,480
could get also the counter-thread

530
00:21:34,480 --> 00:21:35,760
measurements

531
00:21:35,760 --> 00:21:38,159
so this test is not really reassuring

532
00:21:38,159 --> 00:21:40,400
for

533
00:21:40,799 --> 00:21:43,520
i mean for defenders perspective because

534
00:21:43,520 --> 00:21:44,640
only 23

535
00:21:44,640 --> 00:21:47,440
passed this test

536
00:21:47,760 --> 00:21:51,360
and uh we also saw that the lucky task

537
00:21:51,360 --> 00:21:53,919
is surprising results

538
00:21:53,919 --> 00:21:58,159
again 23 machines not the same 23 but

539
00:21:58,159 --> 00:22:01,280
23 were running in an emulator or they

540
00:22:01,280 --> 00:22:02,159
were trapping

541
00:22:02,159 --> 00:22:05,280
on those memory accesses and

542
00:22:05,280 --> 00:22:09,360
13 of them tested to be single core

543
00:22:09,360 --> 00:22:12,159
according to our tests so this gave us

544
00:22:12,159 --> 00:22:14,559
surprising results because this uh

545
00:22:14,559 --> 00:22:19,039
i mean we were we were expecting fewer

546
00:22:19,039 --> 00:22:21,120
but let's talk about detection three

547
00:22:21,120 --> 00:22:23,520
which revealed two more machines

548
00:22:23,520 --> 00:22:26,720
10 detection one by looking at those

549
00:22:26,720 --> 00:22:28,240
results

550
00:22:28,240 --> 00:22:30,480
actually we saw that two were failing

551
00:22:30,480 --> 00:22:32,720
the loki test

552
00:22:32,720 --> 00:22:36,240
seven had fake timestamp counter values

553
00:22:36,240 --> 00:22:39,280
so we were able to detect them with the

554
00:22:39,280 --> 00:22:41,679
counter thread but for 12 of them there

555
00:22:41,679 --> 00:22:44,000
was just too much noise

556
00:22:44,000 --> 00:22:46,660
so for the knob cycle so

557
00:22:46,660 --> 00:22:47,919
[Music]

558
00:22:47,919 --> 00:22:51,200
we wish we will try in the future to run

559
00:22:51,200 --> 00:22:53,200
this experiment again using another

560
00:22:53,200 --> 00:22:55,440
instruction

561
00:22:55,440 --> 00:22:58,320
and we observe something uh very

562
00:22:58,320 --> 00:23:00,640
interesting for the fourth detection

563
00:23:00,640 --> 00:23:02,880
which is the most effective when it when

564
00:23:02,880 --> 00:23:04,559
it runs

565
00:23:04,559 --> 00:23:06,640
was completed by fewer machines because

566
00:23:06,640 --> 00:23:09,039
it takes long to execute

567
00:23:09,039 --> 00:23:11,600
and while for several machines the

568
00:23:11,600 --> 00:23:13,280
latencies were

569
00:23:13,280 --> 00:23:16,400
unstable so probably the tlb feeling

570
00:23:16,400 --> 00:23:18,240
didn't succeed

571
00:23:18,240 --> 00:23:22,720
we observed that out of 29 machines

572
00:23:22,720 --> 00:23:26,000
24 were detected and there were no

573
00:23:26,000 --> 00:23:28,240
discrepancies for the counter threats

574
00:23:28,240 --> 00:23:29,200
because

575
00:23:29,200 --> 00:23:31,440
i mean there was no point for sandboxes

576
00:23:31,440 --> 00:23:33,840
in faking

577
00:23:33,840 --> 00:23:37,039
the timestamp counter in those case

578
00:23:37,039 --> 00:23:39,039
in those cases unless they knew when

579
00:23:39,039 --> 00:23:40,559
they detected this

580
00:23:40,559 --> 00:23:43,360
this attack so at the end of the day we

581
00:23:43,360 --> 00:23:45,360
obtained that we were able to

582
00:23:45,360 --> 00:23:48,400
detect many sandboxes either as a single

583
00:23:48,400 --> 00:23:51,200
core machine or we could tell that they

584
00:23:51,200 --> 00:23:54,559
their uh time stem counters were being

585
00:23:54,559 --> 00:23:55,279
forged

586
00:23:55,279 --> 00:23:57,520
so counter threads helped helped a lot

587
00:23:57,520 --> 00:23:59,679
in this regard

588
00:23:59,679 --> 00:24:01,919
but it's time to to present the second

589
00:24:01,919 --> 00:24:03,760
contribution of this talk

590
00:24:03,760 --> 00:24:06,960
it's a new detection and it's based on

591
00:24:06,960 --> 00:24:10,159
an llc primary probe attack

592
00:24:10,159 --> 00:24:13,600
so the idea is to look for effects just

593
00:24:13,600 --> 00:24:15,840
like the tlb eviction

594
00:24:15,840 --> 00:24:18,640
but on caches which can be quite

595
00:24:18,640 --> 00:24:20,480
reliable to measure especially on the

596
00:24:20,480 --> 00:24:21,840
llc

597
00:24:21,840 --> 00:24:24,880
and we will be looking for a last level

598
00:24:24,880 --> 00:24:26,880
cache lines that we are evicted by the

599
00:24:26,880 --> 00:24:29,919
execution of a virtual machine monitor

600
00:24:29,919 --> 00:24:33,039
and the llc yeah i mean they're widely

601
00:24:33,039 --> 00:24:35,279
used in my architectural research for

602
00:24:35,279 --> 00:24:36,720
attacks

603
00:24:36,720 --> 00:24:39,760
um for high resolution attacks and we

604
00:24:39,760 --> 00:24:42,400
will mount a prime and probe attack

605
00:24:42,400 --> 00:24:44,880
but first of all let me tell you just a

606
00:24:44,880 --> 00:24:46,559
little bit of how

607
00:24:46,559 --> 00:24:49,679
llc addressing works so

608
00:24:49,679 --> 00:24:52,000
the idea is that they are addressed by

609
00:24:52,000 --> 00:24:53,120
physical addresses

610
00:24:53,120 --> 00:24:56,559
so if you have some data to virtual

611
00:24:56,559 --> 00:24:59,600
this virtual address x in a program you

612
00:24:59,600 --> 00:25:00,799
need first to

613
00:25:00,799 --> 00:25:04,640
transform it into a physical address

614
00:25:04,640 --> 00:25:07,840
right you have the mmu for that and

615
00:25:07,840 --> 00:25:10,799
from the bits of this physical address

616
00:25:10,799 --> 00:25:11,600
you will be

617
00:25:11,600 --> 00:25:14,799
able to determine in which cash set and

618
00:25:14,799 --> 00:25:17,679
which slice of the cash you should be

619
00:25:17,679 --> 00:25:19,760
putting this cash line when you are

620
00:25:19,760 --> 00:25:21,360
reading or writing it

621
00:25:21,360 --> 00:25:24,320
and uh the number of sets minutes

622
00:25:24,320 --> 00:25:25,919
depends on the

623
00:25:25,919 --> 00:25:27,840
size of the cash but also on the

624
00:25:27,840 --> 00:25:28,960
associativity

625
00:25:28,960 --> 00:25:30,960
of the cache the number of ways which is

626
00:25:30,960 --> 00:25:32,240
also the

627
00:25:32,240 --> 00:25:36,559
the size of the the sides of the

628
00:25:36,559 --> 00:25:40,480
set so we will be mounting a primary

629
00:25:40,480 --> 00:25:41,440
probe attack

630
00:25:41,440 --> 00:25:44,559
the idea is that we will fill a

631
00:25:44,559 --> 00:25:47,919
cache set entry sorry we will

632
00:25:47,919 --> 00:25:51,200
fill each cache set entry and with

633
00:25:51,200 --> 00:25:52,960
attacker control data

634
00:25:52,960 --> 00:25:55,840
then we will cause a transition to the

635
00:25:55,840 --> 00:25:56,960
vmm

636
00:25:56,960 --> 00:25:59,039
and we will try to see if this

637
00:25:59,039 --> 00:26:00,159
transaction

638
00:26:00,159 --> 00:26:02,480
evicted polluted one or more lines that

639
00:26:02,480 --> 00:26:04,559
we were controlling

640
00:26:04,559 --> 00:26:07,279
and those lines they will see a higher

641
00:26:07,279 --> 00:26:09,279
latency when we try to access them

642
00:26:09,279 --> 00:26:12,559
because they will cause an llc miss

643
00:26:12,559 --> 00:26:15,919
but how do you find eviction sets uh

644
00:26:15,919 --> 00:26:19,200
for llc eviction sets if you don't know

645
00:26:19,200 --> 00:26:19,600
them

646
00:26:19,600 --> 00:26:22,880
they are some sets that

647
00:26:22,880 --> 00:26:25,120
contain virtual addresses that they map

648
00:26:25,120 --> 00:26:27,039
to the same cache set

649
00:26:27,039 --> 00:26:30,000
so the optimal size is given by the

650
00:26:30,000 --> 00:26:32,080
associativity of the cache so

651
00:26:32,080 --> 00:26:35,840
for a 16 way associative you need 16

652
00:26:35,840 --> 00:26:38,880
addresses to to feel that set

653
00:26:38,880 --> 00:26:42,559
and you need also to build for this

654
00:26:42,559 --> 00:26:43,440
attack

655
00:26:43,440 --> 00:26:46,960
a minimal eviction set an optimal one

656
00:26:46,960 --> 00:26:50,000
for all the available

657
00:26:50,840 --> 00:26:53,600
callers

658
00:26:53,600 --> 00:26:57,120
so the color is determined by some bits

659
00:26:57,120 --> 00:27:00,159
of the physical address that normally

660
00:27:00,159 --> 00:27:02,799
you don't control unless you're native

661
00:27:02,799 --> 00:27:04,720
hardware with huge pages

662
00:27:04,720 --> 00:27:08,320
but uh those bits are part of the set

663
00:27:08,320 --> 00:27:09,279
index

664
00:27:09,279 --> 00:27:11,279
that will tell you in which cash set

665
00:27:11,279 --> 00:27:12,960
you're ending up

666
00:27:12,960 --> 00:27:15,440
for this cash line and the slice is

667
00:27:15,440 --> 00:27:16,880
determined also by

668
00:27:16,880 --> 00:27:20,960
the cash stack but the point is that in

669
00:27:20,960 --> 00:27:23,440
inside the vm you have a further level

670
00:27:23,440 --> 00:27:24,720
of indirection

671
00:27:24,720 --> 00:27:27,279
so even if you know the correspondence

672
00:27:27,279 --> 00:27:28,480
between the virtual

673
00:27:28,480 --> 00:27:31,200
addresses and the physical addresses

674
00:27:31,200 --> 00:27:33,679
that are available to the guests

675
00:27:33,679 --> 00:27:37,039
to the operating system in the guest

676
00:27:37,039 --> 00:27:39,840
there is this extra level of indirection

677
00:27:39,840 --> 00:27:41,520
because guest physical addresses they

678
00:27:41,520 --> 00:27:43,520
need to be translated to host physical

679
00:27:43,520 --> 00:27:44,240
addresses

680
00:27:44,240 --> 00:27:47,360
and those hpas are the

681
00:27:47,360 --> 00:27:49,600
addresses that you use for indexing your

682
00:27:49,600 --> 00:27:52,159
cache and in a sandbox you can make new

683
00:27:52,159 --> 00:27:52,960
assumptions

684
00:27:52,960 --> 00:27:55,200
on the on the mapping between virtual

685
00:27:55,200 --> 00:27:57,600
addresses and host physical addresses

686
00:27:57,600 --> 00:27:59,520
so you need techniques that can build

687
00:27:59,520 --> 00:28:02,080
eviction sets without making assumptions

688
00:28:02,080 --> 00:28:04,640
on the mapping between virtual addresses

689
00:28:04,640 --> 00:28:06,399
and cache sets

690
00:28:06,399 --> 00:28:09,919
so there is this uh paper

691
00:28:09,919 --> 00:28:13,039
from oakland last year they presented a

692
00:28:13,039 --> 00:28:14,960
method and released the code which we

693
00:28:14,960 --> 00:28:15,679
use

694
00:28:15,679 --> 00:28:19,039
to build uh eviction sets

695
00:28:19,039 --> 00:28:21,600
in a time that is linear in the size of

696
00:28:21,600 --> 00:28:22,799
the cache

697
00:28:22,799 --> 00:28:26,000
and we starting from a large buffer they

698
00:28:26,000 --> 00:28:28,399
prune it with some clever

699
00:28:28,399 --> 00:28:30,880
group thresholding heuristics and it

700
00:28:30,880 --> 00:28:32,559
works pretty well

701
00:28:32,559 --> 00:28:35,360
so we build eviction sites for all cache

702
00:28:35,360 --> 00:28:35,919
callers

703
00:28:35,919 --> 00:28:38,960
using this method then we we do

704
00:28:38,960 --> 00:28:41,120
the priming part of the attack so we

705
00:28:41,120 --> 00:28:42,240
preload

706
00:28:42,240 --> 00:28:45,120
the entries from the eviction set in the

707
00:28:45,120 --> 00:28:46,159
cache set

708
00:28:46,159 --> 00:28:49,200
and then we prime so we we measure the

709
00:28:49,200 --> 00:28:51,679
access time we will see that it is

710
00:28:51,679 --> 00:28:54,880
constant for every for every entry

711
00:28:54,880 --> 00:28:56,480
then we trigger a transition in the

712
00:28:56,480 --> 00:28:58,240
virtual machine monitor

713
00:28:58,240 --> 00:29:01,200
and we we measure again the access time

714
00:29:01,200 --> 00:29:03,279
for every line in the set and the moment

715
00:29:03,279 --> 00:29:04,240
that

716
00:29:04,240 --> 00:29:08,240
the maximum access time becomes high

717
00:29:08,240 --> 00:29:10,840
and yet we can tell that there was a

718
00:29:10,840 --> 00:29:13,840
miss and this miss was likely caused by

719
00:29:13,840 --> 00:29:16,320
the vmm execution

720
00:29:16,320 --> 00:29:19,520
so we we implemented this uh

721
00:29:19,520 --> 00:29:22,720
actually the code is agnostic you works

722
00:29:22,720 --> 00:29:23,039
on

723
00:29:23,039 --> 00:29:26,240
linux windows mac os you only need a

724
00:29:26,240 --> 00:29:28,880
library functions to allocate memory and

725
00:29:28,880 --> 00:29:31,039
it works with counter threads too

726
00:29:31,039 --> 00:29:34,080
so it's good even if you're you have a

727
00:29:34,080 --> 00:29:35,760
reliable

728
00:29:35,760 --> 00:29:37,919
timestamp counter measurements in a

729
00:29:37,919 --> 00:29:40,080
sandbox you can try counter threads

730
00:29:40,080 --> 00:29:42,240
we tested this code on a whole lot of

731
00:29:42,240 --> 00:29:43,760
intel cpus

732
00:29:43,760 --> 00:29:47,679
uh from old to pretty recent one

733
00:29:47,679 --> 00:29:50,640
it's like whiskey lake architecture and

734
00:29:50,640 --> 00:29:53,360
we tried several versions of virtualbox

735
00:29:53,360 --> 00:29:54,559
vmware

736
00:29:54,559 --> 00:29:57,679
on different host operating systems and

737
00:29:57,679 --> 00:30:00,000
we tried kvm and xan

738
00:30:00,000 --> 00:30:02,240
i will be presenting some some of the

739
00:30:02,240 --> 00:30:03,679
results

740
00:30:03,679 --> 00:30:06,640
so on this machine we were able to try

741
00:30:06,640 --> 00:30:08,559
most different combinations

742
00:30:08,559 --> 00:30:12,399
and we saw that this is the whisky lake

743
00:30:12,399 --> 00:30:13,279
one

744
00:30:13,279 --> 00:30:16,320
so we saw that for instance a virtual

745
00:30:16,320 --> 00:30:17,440
box

746
00:30:17,440 --> 00:30:20,480
on windows during a cpu id

747
00:30:20,480 --> 00:30:23,840
was with polluting about 20 out of the

748
00:30:23,840 --> 00:30:28,000
120 way at 128 eviction sets that would

749
00:30:28,000 --> 00:30:28,399
be

750
00:30:28,399 --> 00:30:32,000
we built on linux was just a bit less

751
00:30:32,000 --> 00:30:36,000
on similar numbers we saw on vmware

752
00:30:36,000 --> 00:30:37,760
even though we were not able to build

753
00:30:37,760 --> 00:30:40,080
all the

754
00:30:40,080 --> 00:30:42,720
code the desired cache sets probably for

755
00:30:42,720 --> 00:30:44,320
some partitioning we are still

756
00:30:44,320 --> 00:30:45,840
investigating

757
00:30:45,840 --> 00:30:49,279
uh same for kvm

758
00:30:49,279 --> 00:30:52,480
and uh this was done the test

759
00:30:52,480 --> 00:30:55,039
took two to three minutes while on on

760
00:30:55,039 --> 00:30:55,840
the

761
00:30:55,840 --> 00:30:58,320
on the native host it took around one

762
00:30:58,320 --> 00:31:00,559
minute

763
00:31:00,559 --> 00:31:03,440
also we we kept looking into virtualbox

764
00:31:03,440 --> 00:31:03,840
and we

765
00:31:03,840 --> 00:31:07,840
observed that even on different machines

766
00:31:07,840 --> 00:31:11,200
there was a a significant increase in

767
00:31:11,200 --> 00:31:12,480
the number of sets

768
00:31:12,480 --> 00:31:15,519
of sets that are polluted when moving

769
00:31:15,519 --> 00:31:16,080
from

770
00:31:16,080 --> 00:31:19,240
version 5

771
00:31:19,240 --> 00:31:22,720
5.2 to virtualbox 6

772
00:31:22,720 --> 00:31:25,840
and we we observed in general that also

773
00:31:25,840 --> 00:31:26,720
another

774
00:31:26,720 --> 00:31:29,840
cpu and hypervisor combinations

775
00:31:29,840 --> 00:31:32,960
while on a native execution you don't

776
00:31:32,960 --> 00:31:33,919
see

777
00:31:33,919 --> 00:31:37,200
evictions or you might get some one or

778
00:31:37,200 --> 00:31:37,760
two

779
00:31:37,760 --> 00:31:41,279
but evicted because some uh the system

780
00:31:41,279 --> 00:31:45,120
workload was high here we consistently

781
00:31:45,120 --> 00:31:48,240
got several sets that were being evicted

782
00:31:48,240 --> 00:31:49,840
then the interesting part

783
00:31:49,840 --> 00:31:52,159
is that if you're running on a custom

784
00:31:52,159 --> 00:31:53,840
virtual machine monitor

785
00:31:53,840 --> 00:31:56,399
that performs for instance analysis at

786
00:31:56,399 --> 00:31:57,600
the hypervisor

787
00:31:57,600 --> 00:32:00,080
level you might be polluting even more

788
00:32:00,080 --> 00:32:01,360
cache sets

789
00:32:01,360 --> 00:32:04,880
um the limitations of this technique is

790
00:32:04,880 --> 00:32:05,679
that

791
00:32:05,679 --> 00:32:08,080
for big caches the execution time might

792
00:32:08,080 --> 00:32:08,960
be long

793
00:32:08,960 --> 00:32:11,840
longer than the timeout of your sandbox

794
00:32:11,840 --> 00:32:12,880
or

795
00:32:12,880 --> 00:32:14,880
even worse the eviction set construction

796
00:32:14,880 --> 00:32:16,559
may fail for instance if you're dealing

797
00:32:16,559 --> 00:32:18,399
with non-inclusive caches like

798
00:32:18,399 --> 00:32:21,679
on some ceo machines so right now i'm

799
00:32:21,679 --> 00:32:22,640
working

800
00:32:22,640 --> 00:32:24,799
on extending those results with the

801
00:32:24,799 --> 00:32:26,399
techniques that are described in these

802
00:32:26,399 --> 00:32:27,519
two papers

803
00:32:27,519 --> 00:32:30,399
one is dealing with non-inclusive caches

804
00:32:30,399 --> 00:32:32,240
for building eviction sets

805
00:32:32,240 --> 00:32:35,200
and the other uh improves the method

806
00:32:35,200 --> 00:32:36,080
that i've been

807
00:32:36,080 --> 00:32:38,880
discussing before to build minimal

808
00:32:38,880 --> 00:32:40,559
eviction sets

809
00:32:40,559 --> 00:32:44,320
much quicker so there is there is uh

810
00:32:44,320 --> 00:32:47,360
still some potential to explore

811
00:32:47,360 --> 00:32:50,720
but to to conclude my talk uh well

812
00:32:50,720 --> 00:32:53,919
uh i think that this intersection

813
00:32:53,919 --> 00:32:56,880
uh between microarchitectural research

814
00:32:56,880 --> 00:32:59,200
and malware analysis mobile revision

815
00:32:59,200 --> 00:33:01,840
could be a promising research area

816
00:33:01,840 --> 00:33:04,880
i think that from the point of view of

817
00:33:04,880 --> 00:33:06,799
sandbox architects

818
00:33:06,799 --> 00:33:10,080
they should explore some a code analysis

819
00:33:10,080 --> 00:33:13,279
to detect at least the possibility that

820
00:33:13,279 --> 00:33:14,480
you're dealing with

821
00:33:14,480 --> 00:33:17,840
um counter threads or

822
00:33:17,840 --> 00:33:20,480
uh microarchitectural attacks like prime

823
00:33:20,480 --> 00:33:21,760
and probe patterns

824
00:33:21,760 --> 00:33:24,000
this is yeah this is easier say than

825
00:33:24,000 --> 00:33:24,960
done but

826
00:33:24,960 --> 00:33:26,559
at least for counter threads for

827
00:33:26,559 --> 00:33:29,039
instance you can you can think of them

828
00:33:29,039 --> 00:33:31,519
as a race condition on a variable

829
00:33:31,519 --> 00:33:33,360
between different threads in terms of

830
00:33:33,360 --> 00:33:34,720
code analysis

831
00:33:34,720 --> 00:33:37,360
and another thing to do that is pretty

832
00:33:37,360 --> 00:33:38,000
uh

833
00:33:38,000 --> 00:33:40,559
low effort for them is to keep track of

834
00:33:40,559 --> 00:33:42,159
performance counters

835
00:33:42,159 --> 00:33:44,880
for the detection side for instance with

836
00:33:44,880 --> 00:33:46,880
performance counters you will be able to

837
00:33:46,880 --> 00:33:48,399
detect that the

838
00:33:48,399 --> 00:33:52,799
llc premium probatakis uh is going on

839
00:33:52,799 --> 00:33:55,360
while for a defensive part for new

840
00:33:55,360 --> 00:33:56,880
aversion i think there is

841
00:33:56,880 --> 00:34:00,159
a lot of room to explore

842
00:34:00,159 --> 00:34:03,200
uh you might be using uh these

843
00:34:03,200 --> 00:34:04,720
techniques

844
00:34:04,720 --> 00:34:08,000
for uh looking this time for specific

845
00:34:08,000 --> 00:34:10,560
virtual machine monitor features

846
00:34:10,560 --> 00:34:14,000
and there are also several other

847
00:34:14,000 --> 00:34:16,159
micro architectural attack vectors that

848
00:34:16,159 --> 00:34:17,918
are worth exploring and

849
00:34:17,918 --> 00:34:20,560
can be exposing the virtual machine

850
00:34:20,560 --> 00:34:22,800
monitor in other ways so

851
00:34:22,800 --> 00:34:27,119
um i hope that you enjoy this talk

852
00:34:27,119 --> 00:34:29,760
but before i finish i would like to to

853
00:34:29,760 --> 00:34:30,719
thank

854
00:34:30,719 --> 00:34:32,800
three guys christian pietro and federico

855
00:34:32,800 --> 00:34:34,000
that helped me at different

856
00:34:34,000 --> 00:34:37,679
stages of this research and

857
00:34:37,679 --> 00:34:40,320
i want to thank you very much for the

858
00:34:40,320 --> 00:34:40,960
attention

859
00:34:40,960 --> 00:34:44,399
and yeah feel free to hit me up

860
00:34:44,399 --> 00:34:46,839
with with your questions thank you very

861
00:34:46,839 --> 00:34:49,839
much

