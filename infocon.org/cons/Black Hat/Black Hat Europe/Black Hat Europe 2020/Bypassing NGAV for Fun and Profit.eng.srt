1
00:00:01,180 --> 00:00:14,730
[Music]

2
00:00:16,160 --> 00:00:17,920
hello and thank you for joining our

3
00:00:17,920 --> 00:00:19,920
our session by passing next generation

4
00:00:19,920 --> 00:00:23,439
anti-viruses for fun and profit

5
00:00:23,439 --> 00:00:26,000
i'm ishai the head of deep learning at

6
00:00:26,000 --> 00:00:28,160
deep instinct and with me would present

7
00:00:28,160 --> 00:00:28,420
a

8
00:00:28,420 --> 00:00:30,160
[Music]

9
00:00:30,160 --> 00:00:32,640
data scientist and security researcher

10
00:00:32,640 --> 00:00:33,760
in the

11
00:00:33,760 --> 00:00:37,120
deep instinct the deep learning group

12
00:00:37,120 --> 00:00:39,200
our outline is as follows we are going

13
00:00:39,200 --> 00:00:41,840
to implement an end-to-end adversarial

14
00:00:41,840 --> 00:00:44,480
attack that generates runnable pes that

15
00:00:44,480 --> 00:00:45,039
evades

16
00:00:45,039 --> 00:00:47,360
next-generation anti-viruses which using

17
00:00:47,360 --> 00:00:48,879
the static pe

18
00:00:48,879 --> 00:00:52,000
features uh in order to maintain the

19
00:00:52,000 --> 00:00:53,920
malicious functionality we'll split

20
00:00:53,920 --> 00:00:56,399
split our vessel example into two phases

21
00:00:56,399 --> 00:00:58,480
the first we would assess the

22
00:00:58,480 --> 00:01:02,320
impact of different features for the

23
00:01:02,320 --> 00:01:03,840
that would be used by the malware

24
00:01:03,840 --> 00:01:05,840
classifier and then we'll do a feature

25
00:01:05,840 --> 00:01:07,200
specific modification

26
00:01:07,200 --> 00:01:09,520
only on features that can be modified

27
00:01:09,520 --> 00:01:10,720
without having the

28
00:01:10,720 --> 00:01:14,080
malicious business functionality finally

29
00:01:14,080 --> 00:01:16,320
we will show and demonstrate that a

30
00:01:16,320 --> 00:01:17,920
modified a

31
00:01:17,920 --> 00:01:21,200
pe can evade not just the target a

32
00:01:21,200 --> 00:01:23,360
mirror classifier but also other malware

33
00:01:23,360 --> 00:01:24,400
classifiers

34
00:01:24,400 --> 00:01:26,159
using the property of transferability

35
00:01:26,159 --> 00:01:28,080
which we will discuss

36
00:01:28,080 --> 00:01:31,119
further in in the following slides

37
00:01:31,119 --> 00:01:33,840
uh our agenda would be as follows first

38
00:01:33,840 --> 00:01:35,520
we will discuss about the

39
00:01:35,520 --> 00:01:38,640
the differences and similarities between

40
00:01:38,640 --> 00:01:40,640
bypassing next-generation anti-virus and

41
00:01:40,640 --> 00:01:43,200
a traditional machine

42
00:01:43,200 --> 00:01:46,240
and traditional anti-malware software

43
00:01:46,240 --> 00:01:47,680
then we'll discuss a bit about

44
00:01:47,680 --> 00:01:49,200
adversarial learning and what does it

45
00:01:49,200 --> 00:01:51,119
mean in the context of static malware

46
00:01:51,119 --> 00:01:52,000
classifiers

47
00:01:52,000 --> 00:01:53,680
we will talk about the unique challenges

48
00:01:53,680 --> 00:01:55,040
of adversarial learning in the cyber

49
00:01:55,040 --> 00:01:56,240
security domain

50
00:01:56,240 --> 00:02:01,119
we will present our own adversarial uh

51
00:02:01,119 --> 00:02:03,759
attack based on explainability we will

52
00:02:03,759 --> 00:02:05,600
talk about the two main challenges the

53
00:02:05,600 --> 00:02:08,239
lack of knowledge of the attacker of the

54
00:02:08,239 --> 00:02:11,440
architecture and features and the needs

55
00:02:11,440 --> 00:02:12,879
to keep the malicious functionality

56
00:02:12,879 --> 00:02:13,920
intact

57
00:02:13,920 --> 00:02:17,280
and finally we we will hand over to shai

58
00:02:17,280 --> 00:02:21,440
to see a concrete example of bypassing a

59
00:02:21,440 --> 00:02:23,440
real-life commercial next generation

60
00:02:23,440 --> 00:02:24,800
antivirus

61
00:02:24,800 --> 00:02:28,319
so let's start by by talking about the

62
00:02:28,319 --> 00:02:29,920
similarities and differences between

63
00:02:29,920 --> 00:02:32,160
bypassing natural generation antibiotics

64
00:02:32,160 --> 00:02:34,400
and bypassing a traditional anti-malware

65
00:02:34,400 --> 00:02:35,760
product

66
00:02:35,760 --> 00:02:39,200
first of all we are using different

67
00:02:39,200 --> 00:02:43,680
techniques and tools in traditional

68
00:02:43,680 --> 00:02:46,720
in a antivirus bypass

69
00:02:46,720 --> 00:02:50,400
we are using a disassembly debugging

70
00:02:50,400 --> 00:02:53,440
and packing and in next generation

71
00:02:53,440 --> 00:02:56,640
anti-virus bypass using a techniques

72
00:02:56,640 --> 00:02:58,400
say data science techniques such as

73
00:02:58,400 --> 00:03:01,120
explanability building a surrogate model

74
00:03:01,120 --> 00:03:04,239
and generating perturbation

75
00:03:04,239 --> 00:03:07,360
the end result is is the same

76
00:03:07,360 --> 00:03:11,120
by passing the defender software whether

77
00:03:11,120 --> 00:03:13,760
it's next-generation anti-anti-virus

78
00:03:13,760 --> 00:03:17,120
or a regular anti-malware software which

79
00:03:17,120 --> 00:03:17,760
has

80
00:03:17,760 --> 00:03:21,840
minimal effort on to the attacker's side

81
00:03:21,840 --> 00:03:24,480
and the methodology of the tools are

82
00:03:24,480 --> 00:03:25,920
basically the same

83
00:03:25,920 --> 00:03:27,840
whether you're using disassembling or

84
00:03:27,840 --> 00:03:29,760
explainability algorithm you want

85
00:03:29,760 --> 00:03:32,319
to see a basic non-interactive

86
00:03:32,319 --> 00:03:33,280
understanding

87
00:03:33,280 --> 00:03:36,239
of what happened of the business logic

88
00:03:36,239 --> 00:03:37,760
of the defender software

89
00:03:37,760 --> 00:03:39,760
whether you're using debugging or

90
00:03:39,760 --> 00:03:41,200
serogate model meaning

91
00:03:41,200 --> 00:03:43,680
building a model to simulate the malware

92
00:03:43,680 --> 00:03:44,560
classifier

93
00:03:44,560 --> 00:03:48,080
you are trying to to perform a

94
00:03:48,080 --> 00:03:51,519
interactive in interactive analysis

95
00:03:51,519 --> 00:03:54,560
or interactive experiments of the

96
00:03:54,560 --> 00:03:55,840
software and trying to understand what

97
00:03:55,840 --> 00:03:57,760
would work in order to bypass it

98
00:03:57,760 --> 00:04:01,200
and the packing or generating

99
00:04:01,200 --> 00:04:02,239
perturbation

100
00:04:02,239 --> 00:04:04,319
are two techniques each in its own

101
00:04:04,319 --> 00:04:05,760
domain that allows you

102
00:04:05,760 --> 00:04:09,360
to bypass a marble classifier without

103
00:04:09,360 --> 00:04:14,080
uh harming the malicious business logic

104
00:04:14,080 --> 00:04:16,238
so what is adversarial learning in the

105
00:04:16,238 --> 00:04:17,279
context of

106
00:04:17,279 --> 00:04:21,199
a of malware classifiers

107
00:04:21,199 --> 00:04:23,040
so first of all adversarial learning or

108
00:04:23,040 --> 00:04:25,280
adversary can take place in one of two

109
00:04:25,280 --> 00:04:25,840
phases

110
00:04:25,840 --> 00:04:27,680
it can take place either in the learning

111
00:04:27,680 --> 00:04:29,280
phase in which

112
00:04:29,280 --> 00:04:32,320
there is training data being inserted

113
00:04:32,320 --> 00:04:34,160
into machine learning algorithm

114
00:04:34,160 --> 00:04:36,720
and from this a model is being produced

115
00:04:36,720 --> 00:04:38,000
so if you

116
00:04:38,000 --> 00:04:41,040
inject a malicious or

117
00:04:41,040 --> 00:04:44,080
sometimes called poisoned poison data

118
00:04:44,080 --> 00:04:45,360
and therefore the attack is sometimes

119
00:04:45,360 --> 00:04:46,880
called poisoning attack

120
00:04:46,880 --> 00:04:48,639
into the machine learning algorithm it

121
00:04:48,639 --> 00:04:50,240
will train on it and will

122
00:04:50,240 --> 00:04:53,120
create a poisoned model which would

123
00:04:53,120 --> 00:04:55,120
underperform the on samples that are

124
00:04:55,120 --> 00:04:56,560
similar to the

125
00:04:56,560 --> 00:05:00,000
injected samples however this

126
00:05:00,000 --> 00:05:02,400
form of attack the poisoning attack

127
00:05:02,400 --> 00:05:05,759
requires a lot of efforts from the

128
00:05:05,759 --> 00:05:08,880
from the attacker and while it for

129
00:05:08,880 --> 00:05:09,600
instance

130
00:05:09,600 --> 00:05:11,360
access to the data pipeline of the

131
00:05:11,360 --> 00:05:12,880
training of the model

132
00:05:12,880 --> 00:05:18,160
and while it is possible in eg

133
00:05:18,160 --> 00:05:20,720
supply chain attacks it's a highly

134
00:05:20,720 --> 00:05:22,400
unlikely and therefore will focus

135
00:05:22,400 --> 00:05:24,639
on the other phase and the prediction

136
00:05:24,639 --> 00:05:25,759
phase attack

137
00:05:25,759 --> 00:05:27,680
in which they sometimes called invasion

138
00:05:27,680 --> 00:05:29,440
attacks in which case that

139
00:05:29,440 --> 00:05:31,520
the attacker doesn't change or modify

140
00:05:31,520 --> 00:05:32,720
the model in any way

141
00:05:32,720 --> 00:05:35,520
but he modified the malware that is

142
00:05:35,520 --> 00:05:36,639
being presented

143
00:05:36,639 --> 00:05:39,120
to the malware classifier by removing

144
00:05:39,120 --> 00:05:42,000
modifying or adding

145
00:05:42,000 --> 00:05:44,320
features and this is sometimes called

146
00:05:44,320 --> 00:05:45,280
perturbation

147
00:05:45,280 --> 00:05:47,680
in order to affect the way the model

148
00:05:47,680 --> 00:05:51,520
classified this specific circuit

149
00:05:51,520 --> 00:05:54,880
the basic idea behind this is

150
00:05:54,880 --> 00:05:57,919
that the malware is a

151
00:05:57,919 --> 00:06:00,479
the model classifier is being trained on

152
00:06:00,479 --> 00:06:02,319
a certain distribution and therefore it

153
00:06:02,319 --> 00:06:04,319
has a different decision boundary

154
00:06:04,319 --> 00:06:06,880
then the optimal decision boundary and

155
00:06:06,880 --> 00:06:07,520
the

156
00:06:07,520 --> 00:06:10,000
perturbation try to leverage uh to

157
00:06:10,000 --> 00:06:11,039
leverage this

158
00:06:11,039 --> 00:06:13,840
now in the context of static malware

159
00:06:13,840 --> 00:06:14,720
classifiers

160
00:06:14,720 --> 00:06:18,560
static analysis uh malware classifiers

161
00:06:18,560 --> 00:06:21,280
the the basic premise is as follows you

162
00:06:21,280 --> 00:06:22,400
cannot

163
00:06:22,400 --> 00:06:26,000
train a malware classifier

164
00:06:26,000 --> 00:06:29,120
that will take all the files into

165
00:06:29,120 --> 00:06:33,120
a and turn it all into features in most

166
00:06:33,120 --> 00:06:36,720
in most cases the the

167
00:06:36,720 --> 00:06:39,759
computers or the machine have only

168
00:06:39,759 --> 00:06:41,520
limited amount of gpu

169
00:06:41,520 --> 00:06:44,400
of ram of cpu and therefore you are

170
00:06:44,400 --> 00:06:46,479
picking only handful of

171
00:06:46,479 --> 00:06:48,960
selected feature the most indicative

172
00:06:48,960 --> 00:06:49,759
feature

173
00:06:49,759 --> 00:06:53,680
now because of this those features are

174
00:06:53,680 --> 00:06:56,240
quote unquote circumstantial evidence

175
00:06:56,240 --> 00:06:57,360
you cannot

176
00:06:57,360 --> 00:07:00,080
handle everything and for instance while

177
00:07:00,080 --> 00:07:01,120
you can take

178
00:07:01,120 --> 00:07:03,680
very impactful feature features such as

179
00:07:03,680 --> 00:07:05,120
import address table

180
00:07:05,120 --> 00:07:08,240
you would not be able to use a

181
00:07:08,240 --> 00:07:10,560
to build the entire call flow graph in

182
00:07:10,560 --> 00:07:12,080
order to see the interdependencies

183
00:07:12,080 --> 00:07:13,440
between different functions because

184
00:07:13,440 --> 00:07:15,759
it takes too much memory and therefore

185
00:07:15,759 --> 00:07:16,880
because of those

186
00:07:16,880 --> 00:07:19,360
circumstantial photovoltaic substantial

187
00:07:19,360 --> 00:07:20,080
features

188
00:07:20,080 --> 00:07:23,120
you can bypass bypass them in

189
00:07:23,120 --> 00:07:25,599
and modify them in a way that would not

190
00:07:25,599 --> 00:07:26,800
harm the malicious

191
00:07:26,800 --> 00:07:30,720
functionality of the world

192
00:07:30,720 --> 00:07:32,639
let's talk a bit about the challenges of

193
00:07:32,639 --> 00:07:33,840
adversarial learning in the cyber

194
00:07:33,840 --> 00:07:35,039
security domain

195
00:07:35,039 --> 00:07:37,039
besides the regular chances we have two

196
00:07:37,039 --> 00:07:38,400
main challenges

197
00:07:38,400 --> 00:07:40,560
one is the attacker lack of knowledge of

198
00:07:40,560 --> 00:07:42,800
the classifier

199
00:07:42,800 --> 00:07:44,400
and this is because unlike in the

200
00:07:44,400 --> 00:07:45,840
computer vision domain when the

201
00:07:45,840 --> 00:07:48,240
architecture our public domain

202
00:07:48,240 --> 00:07:51,280
in the cyber security domain every uh

203
00:07:51,280 --> 00:07:53,520
next generation antivirus uses slightly

204
00:07:53,520 --> 00:07:55,199
different features they are

205
00:07:55,199 --> 00:07:58,240
much more a feature

206
00:07:58,240 --> 00:08:01,280
to be used not just the pixel colors

207
00:08:01,280 --> 00:08:04,400
also import address table

208
00:08:04,400 --> 00:08:07,520
entries uh dynamic api calls

209
00:08:07,520 --> 00:08:10,840
p structural metadata

210
00:08:10,840 --> 00:08:14,800
etc the second the the second difference

211
00:08:14,800 --> 00:08:16,879
is the original emulation functionality

212
00:08:16,879 --> 00:08:18,319
must remain intact and

213
00:08:18,319 --> 00:08:21,759
unlike in a picture when you can modify

214
00:08:21,759 --> 00:08:25,280
a every pixel without a affecting it's

215
00:08:25,280 --> 00:08:26,319
still a valid

216
00:08:26,319 --> 00:08:29,520
a valid image you cannot arbitrarily

217
00:08:29,520 --> 00:08:32,000
change a byte inside the pe

218
00:08:32,000 --> 00:08:35,120
while maintaining its its functionality

219
00:08:35,120 --> 00:08:36,000
it might cause

220
00:08:36,000 --> 00:08:40,080
excess violation or illegal instruction

221
00:08:40,080 --> 00:08:44,000
exceptions let's talk a bit about

222
00:08:44,000 --> 00:08:48,320
our own uh end-to-end adversarial attack

223
00:08:48,320 --> 00:08:50,320
first of all the threat model we are

224
00:08:50,320 --> 00:08:51,680
using as mentioned

225
00:08:51,680 --> 00:08:54,720
static analysis on our classifier the

226
00:08:54,720 --> 00:08:57,040
adversary has no knowledge about the

227
00:08:57,040 --> 00:09:00,320
attacker the the defender classifier

228
00:09:00,320 --> 00:09:02,640
type architecture and training set

229
00:09:02,640 --> 00:09:05,440
the adversary does know the prediction

230
00:09:05,440 --> 00:09:07,279
score given by their tactical model

231
00:09:07,279 --> 00:09:09,040
meaning it's a grey box attack

232
00:09:09,040 --> 00:09:10,880
it doesn't know just the label but also

233
00:09:10,880 --> 00:09:12,720
the the confidence score

234
00:09:12,720 --> 00:09:14,560
the adversary has limited knowledge

235
00:09:14,560 --> 00:09:16,240
about the the input feature

236
00:09:16,240 --> 00:09:19,839
he must have a non-empty a subset of

237
00:09:19,839 --> 00:09:20,560
feature

238
00:09:20,560 --> 00:09:22,320
that he would be able to modify and

239
00:09:22,320 --> 00:09:24,080
would affect the

240
00:09:24,080 --> 00:09:26,880
marble classifier and how he does gain

241
00:09:26,880 --> 00:09:28,720
this insight will show

242
00:09:28,720 --> 00:09:31,200
shortly the adversary has access to a

243
00:09:31,200 --> 00:09:33,120
data set of benign and malicious samples

244
00:09:33,120 --> 00:09:34,560
and this is in order to

245
00:09:34,560 --> 00:09:37,360
to find the proper value to which to

246
00:09:37,360 --> 00:09:38,240
change

247
00:09:38,240 --> 00:09:41,360
the modified features and the adversary

248
00:09:41,360 --> 00:09:43,360
has no access to the source code of the

249
00:09:43,360 --> 00:09:44,080
sample

250
00:09:44,080 --> 00:09:46,480
he wish to modify and this is in order

251
00:09:46,480 --> 00:09:48,959
to to make it easy the attack easier to

252
00:09:48,959 --> 00:09:51,760
use by a larger audience

253
00:09:51,760 --> 00:09:54,080
let's talk about the the different

254
00:09:54,080 --> 00:09:55,920
challenges we specified before first of

255
00:09:55,920 --> 00:09:57,440
all the lack of knowledge of the

256
00:09:57,440 --> 00:09:58,640
attacked

257
00:09:58,640 --> 00:10:01,680
model we can

258
00:10:01,680 --> 00:10:03,600
mitigate this attack by using

259
00:10:03,600 --> 00:10:05,600
explainability algorithm expandability

260
00:10:05,600 --> 00:10:07,360
algorithms is algorithm that

261
00:10:07,360 --> 00:10:10,720
gets as input a

262
00:10:10,720 --> 00:10:13,279
a classifier either black box or white

263
00:10:13,279 --> 00:10:15,120
box and does produce

264
00:10:15,120 --> 00:10:17,920
the list of most impactful feature for a

265
00:10:17,920 --> 00:10:18,880
specific

266
00:10:18,880 --> 00:10:21,040
sample in our case the malware example

267
00:10:21,040 --> 00:10:22,720
that we want to

268
00:10:22,720 --> 00:10:25,440
uh we want to to evade the the marble

269
00:10:25,440 --> 00:10:26,320
classifier

270
00:10:26,320 --> 00:10:28,880
in this in this example we see it in the

271
00:10:28,880 --> 00:10:30,240
computer vision domain

272
00:10:30,240 --> 00:10:32,560
when you see as a picture of a snake

273
00:10:32,560 --> 00:10:34,160
being classified as gartner snake

274
00:10:34,160 --> 00:10:36,560
and we see three different explanability

275
00:10:36,560 --> 00:10:37,200
algorithm

276
00:10:37,200 --> 00:10:39,760
and all of them are showing a uh

277
00:10:39,760 --> 00:10:41,920
highlighting the most impactful feature

278
00:10:41,920 --> 00:10:44,399
for this classification and you see that

279
00:10:44,399 --> 00:10:46,160
it's always the snake head

280
00:10:46,160 --> 00:10:49,360
which does make sense

281
00:10:50,079 --> 00:10:54,160
additionally we can use the concept of a

282
00:10:54,160 --> 00:10:56,640
result example transferability meaning

283
00:10:56,640 --> 00:10:57,680
if we create

284
00:10:57,680 --> 00:11:00,800
a modified malware aka adversal

285
00:11:00,800 --> 00:11:02,560
example that evades a specific

286
00:11:02,560 --> 00:11:04,399
classifier classifier area

287
00:11:04,399 --> 00:11:06,720
it's more probable that it would also

288
00:11:06,720 --> 00:11:08,800
fool other type of classifiers

289
00:11:08,800 --> 00:11:12,240
how we can leverage this ability we can

290
00:11:12,240 --> 00:11:15,040
try to attack a classifier which we are

291
00:11:15,040 --> 00:11:16,320
more familiar with

292
00:11:16,320 --> 00:11:19,360
feature architecture etc

293
00:11:19,360 --> 00:11:21,519
uh in our case we take the ember

294
00:11:21,519 --> 00:11:23,440
classifier which use

295
00:11:23,440 --> 00:11:26,480
a static a p e feature

296
00:11:26,480 --> 00:11:30,000
such as be header metadata and other

297
00:11:30,000 --> 00:11:33,279
a feature that are used by a

298
00:11:33,279 --> 00:11:35,279
many commercial next generation

299
00:11:35,279 --> 00:11:36,320
antiviruses

300
00:11:36,320 --> 00:11:38,959
we can attack this specific classifier

301
00:11:38,959 --> 00:11:39,680
and then

302
00:11:39,680 --> 00:11:42,160
we can leverage the same successful

303
00:11:42,160 --> 00:11:44,160
attack and use the same modified

304
00:11:44,160 --> 00:11:47,360
malware against our target

305
00:11:47,360 --> 00:11:50,480
classifier and in this case we can

306
00:11:50,480 --> 00:11:53,760
have a very fast bootstrap of

307
00:11:53,760 --> 00:11:57,760
how to to find the feature we want

308
00:11:57,760 --> 00:12:00,639
to update uh so i will present another

309
00:12:00,639 --> 00:12:01,440
technique

310
00:12:01,440 --> 00:12:03,279
we use the sliding window water that

311
00:12:03,279 --> 00:12:04,880
would also help us

312
00:12:04,880 --> 00:12:08,720
uh to understand the target classifier

313
00:12:08,720 --> 00:12:10,880
in a black box map

314
00:12:10,880 --> 00:12:13,120
the second challenge is keeping the

315
00:12:13,120 --> 00:12:14,560
malicious functionality in that

316
00:12:14,560 --> 00:12:16,959
intact and in order to do this we split

317
00:12:16,959 --> 00:12:18,720
the adversarial example generation

318
00:12:18,720 --> 00:12:21,680
into three phases which are being

319
00:12:21,680 --> 00:12:23,440
repeatedly

320
00:12:23,440 --> 00:12:26,000
used first we perform a data set

321
00:12:26,000 --> 00:12:28,000
analysis in order to understand the

322
00:12:28,000 --> 00:12:28,880
values

323
00:12:28,880 --> 00:12:32,160
of a different feature we want to modify

324
00:12:32,160 --> 00:12:32,959
for instance

325
00:12:32,959 --> 00:12:35,519
import address table entries a section

326
00:12:35,519 --> 00:12:37,200
name etc

327
00:12:37,200 --> 00:12:41,440
second we are finding the impact

328
00:12:41,440 --> 00:12:45,120
of specific feature using either

329
00:12:45,120 --> 00:12:47,760
a either explainability algorithm or the

330
00:12:47,760 --> 00:12:48,880
sliding window

331
00:12:48,880 --> 00:12:52,079
as i will demonstrate shortly

332
00:12:52,079 --> 00:12:53,920
then we use a feature specific

333
00:12:53,920 --> 00:12:55,200
modification

334
00:12:55,200 --> 00:12:58,320
certain features can only be

335
00:12:58,320 --> 00:13:00,959
added for instance import address table

336
00:13:00,959 --> 00:13:01,920
other features

337
00:13:01,920 --> 00:13:05,040
can be modified uh using a trampoline

338
00:13:05,040 --> 00:13:08,560
into the entry points etc

339
00:13:08,560 --> 00:13:11,760
and we repeat those two phases

340
00:13:11,760 --> 00:13:15,040
iteratively those uh four

341
00:13:15,040 --> 00:13:17,360
phases of dataset analysis existing

342
00:13:17,360 --> 00:13:18,839
feature

343
00:13:18,839 --> 00:13:21,839
expandability selecting and modifying a

344
00:13:21,839 --> 00:13:24,079
feature and modify the subset would

345
00:13:24,079 --> 00:13:25,680
eventually bring us to

346
00:13:25,680 --> 00:13:28,959
an attack that uh evades and by

347
00:13:28,959 --> 00:13:32,160
a bypass the target classifier and then

348
00:13:32,160 --> 00:13:34,320
we will use the transferability

349
00:13:34,320 --> 00:13:37,760
a property to bypass even more

350
00:13:37,760 --> 00:13:40,000
next-generation anti-virus classifier

351
00:13:40,000 --> 00:13:42,800
now to show a concrete use case of how

352
00:13:42,800 --> 00:13:43,839
we bypassed

353
00:13:43,839 --> 00:13:46,320
a commercial next-generation anti-virus

354
00:13:46,320 --> 00:13:46,959
i'm

355
00:13:46,959 --> 00:13:50,160
handing over to shai thank you very much

356
00:13:50,160 --> 00:13:52,880
thank you shai hi my name is shai i'll

357
00:13:52,880 --> 00:13:54,959
be presenting the second part of our

358
00:13:54,959 --> 00:13:57,600
presentation of bypassing a commercial

359
00:13:57,600 --> 00:13:59,199
ngiv

360
00:13:59,199 --> 00:14:02,000
so we will start about discussing a

361
00:14:02,000 --> 00:14:03,760
little bit about the data set

362
00:14:03,760 --> 00:14:07,040
analysis which is a step that we

363
00:14:07,040 --> 00:14:08,399
conducted in

364
00:14:08,399 --> 00:14:11,680
independently and here we want

365
00:14:11,680 --> 00:14:14,399
to uh find some information that will

366
00:14:14,399 --> 00:14:16,639
help us

367
00:14:16,639 --> 00:14:18,959
change the classifier's verdict and we

368
00:14:18,959 --> 00:14:21,600
do that with the tools of data science

369
00:14:21,600 --> 00:14:24,399
and we assume that all classifiers and

370
00:14:24,399 --> 00:14:25,199
all vendors

371
00:14:25,199 --> 00:14:28,480
they use similar data sets

372
00:14:28,480 --> 00:14:32,160
we want to have a data set that we can

373
00:14:32,160 --> 00:14:34,560
investigate with a similar distribution

374
00:14:34,560 --> 00:14:35,199
to what

375
00:14:35,199 --> 00:14:38,800
the commercial antivirus next generation

376
00:14:38,800 --> 00:14:40,639
antivirus uses

377
00:14:40,639 --> 00:14:43,120
so it will reliably represent the

378
00:14:43,120 --> 00:14:45,680
distribution of the features also

379
00:14:45,680 --> 00:14:48,800
and for this presentation

380
00:14:48,800 --> 00:14:52,000
we analyzed mostly

381
00:14:52,000 --> 00:14:55,040
one feature which is the imports

382
00:14:55,040 --> 00:14:58,399
that are used in the benign dataset and

383
00:14:58,399 --> 00:15:00,160
the malicious dataset

384
00:15:00,160 --> 00:15:03,360
and we used the other set that uh

385
00:15:03,360 --> 00:15:07,040
came from ember which is an academic

386
00:15:07,040 --> 00:15:10,839
dataset with uh roughly one million

387
00:15:10,839 --> 00:15:12,079
samples

388
00:15:12,079 --> 00:15:15,120
and we analyzed the import table of the

389
00:15:15,120 --> 00:15:18,000
benign and malicious and we applied

390
00:15:18,000 --> 00:15:20,399
simple statistics

391
00:15:20,399 --> 00:15:23,600
to extract the how many

392
00:15:23,600 --> 00:15:26,639
imports and which imports are appear in

393
00:15:26,639 --> 00:15:27,519
a benign

394
00:15:27,519 --> 00:15:30,560
population and malicious population the

395
00:15:30,560 --> 00:15:31,839
imports themselves

396
00:15:31,839 --> 00:15:34,560
are not malicious of course they are

397
00:15:34,560 --> 00:15:35,440
simply

398
00:15:35,440 --> 00:15:38,000
api calls and they depend on the context

399
00:15:38,000 --> 00:15:39,279
of usage

400
00:15:39,279 --> 00:15:43,120
and we ended up with the list

401
00:15:43,120 --> 00:15:46,720
that uh can tell us which imports are

402
00:15:46,720 --> 00:15:49,680
mostly found in the binary population of

403
00:15:49,680 --> 00:15:51,440
the benign population and the malicious

404
00:15:51,440 --> 00:15:52,880
population

405
00:15:52,880 --> 00:15:56,720
respectively so this table uh lists the

406
00:15:56,720 --> 00:16:00,639
top three most prevalent b9 imports and

407
00:16:00,639 --> 00:16:02,959
top three most prevalent malicious

408
00:16:02,959 --> 00:16:04,240
imports

409
00:16:04,240 --> 00:16:05,759
which you can see that they have a

410
00:16:05,759 --> 00:16:07,680
negative score and the positive score

411
00:16:07,680 --> 00:16:08,800
for the

412
00:16:08,800 --> 00:16:12,079
more benign ones so we will use that

413
00:16:12,079 --> 00:16:12,639
later

414
00:16:12,639 --> 00:16:16,720
in one of in our attack as we will show

415
00:16:16,720 --> 00:16:19,440
and the next question is how are we

416
00:16:19,440 --> 00:16:20,880
going to

417
00:16:20,880 --> 00:16:23,920
find which features are important for

418
00:16:23,920 --> 00:16:24,240
our

419
00:16:24,240 --> 00:16:26,800
classifier so we don't have access to

420
00:16:26,800 --> 00:16:28,480
the classifier we can only

421
00:16:28,480 --> 00:16:31,600
uh query for uh the score

422
00:16:31,600 --> 00:16:36,480
uh we do assume that it's a um

423
00:16:36,480 --> 00:16:40,240
pe classifier uh and uh it has

424
00:16:40,240 --> 00:16:43,279
some inherent uh features that uh

425
00:16:43,279 --> 00:16:46,160
are due to the fact that it parses pe

426
00:16:46,160 --> 00:16:48,160
files so

427
00:16:48,160 --> 00:16:51,680
we assume that uh it will use the header

428
00:16:51,680 --> 00:16:54,240
various sections uh the overlay of the

429
00:16:54,240 --> 00:16:56,480
file the imports

430
00:16:56,480 --> 00:17:00,560
etc and in order to understand

431
00:17:00,560 --> 00:17:04,079
which features are more important and we

432
00:17:04,079 --> 00:17:08,079
should perturb we use a surrogate model

433
00:17:08,079 --> 00:17:10,400
and this is the model that uh released

434
00:17:10,400 --> 00:17:11,839
by ember

435
00:17:11,839 --> 00:17:15,280
and we also use uh the shop package

436
00:17:15,280 --> 00:17:18,640
that will allow us to question

437
00:17:18,640 --> 00:17:21,359
the surrogate model and ask for the

438
00:17:21,359 --> 00:17:22,559
specific sample

439
00:17:22,559 --> 00:17:25,839
which features are most influential

440
00:17:25,839 --> 00:17:29,679
for that classifier just note that

441
00:17:29,679 --> 00:17:32,320
we're not asking the target classifier

442
00:17:32,320 --> 00:17:34,880
we're asking the surrogate classifier

443
00:17:34,880 --> 00:17:38,080
about the future importance and

444
00:17:38,080 --> 00:17:41,440
here we present a list of the top 15

445
00:17:41,440 --> 00:17:45,520
features with the highest shop score

446
00:17:45,520 --> 00:17:49,440
and let's try to make it uh

447
00:17:49,440 --> 00:17:52,799
simpler and we will highlight with green

448
00:17:52,799 --> 00:17:54,880
features that are under a complete

449
00:17:54,880 --> 00:17:56,080
control

450
00:17:56,080 --> 00:17:59,120
for example section names

451
00:17:59,120 --> 00:18:02,880
for example the header cuff timestamp um

452
00:18:02,880 --> 00:18:04,559
with the orange highlight we highlight

453
00:18:04,559 --> 00:18:06,320
features that are

454
00:18:06,320 --> 00:18:09,360
we have some control over for example

455
00:18:09,360 --> 00:18:13,840
we cannot easily remove or

456
00:18:13,840 --> 00:18:17,039
change import names uh import libraries

457
00:18:17,039 --> 00:18:18,640
but we can add

458
00:18:18,640 --> 00:18:22,640
uh quite easily uh for the

459
00:18:22,640 --> 00:18:25,360
purple highlight we show features that

460
00:18:25,360 --> 00:18:25,919
are

461
00:18:25,919 --> 00:18:28,240
uh we have indirect control over for

462
00:18:28,240 --> 00:18:29,840
example if we change

463
00:18:29,840 --> 00:18:31,520
a character this specific character

464
00:18:31,520 --> 00:18:33,840
distribution we're also affecting other

465
00:18:33,840 --> 00:18:36,960
characters distribution and for the red

466
00:18:36,960 --> 00:18:38,640
highlight those are features that

467
00:18:38,640 --> 00:18:39,679
virtually

468
00:18:39,679 --> 00:18:42,160
impossible to change or extremely

469
00:18:42,160 --> 00:18:44,640
difficult to change

470
00:18:44,640 --> 00:18:47,360
so this is our highlights it's not

471
00:18:47,360 --> 00:18:48,160
mutually

472
00:18:48,160 --> 00:18:51,280
exclusive and features can

473
00:18:51,280 --> 00:18:55,280
be can also change

474
00:18:55,280 --> 00:18:58,640
our groups but for the general uh

475
00:18:58,640 --> 00:19:00,960
purpose of the demonstration this is uh

476
00:19:00,960 --> 00:19:02,960
how we split the features

477
00:19:02,960 --> 00:19:06,080
and we have some good candidates to

478
00:19:06,080 --> 00:19:06,880
start uh

479
00:19:06,880 --> 00:19:11,280
perturbing and changing and we will see

480
00:19:11,280 --> 00:19:14,559
our next method of the sliding attack

481
00:19:14,559 --> 00:19:15,600
window

482
00:19:15,600 --> 00:19:18,720
so in this method we're

483
00:19:18,720 --> 00:19:22,160
trying to detect

484
00:19:22,160 --> 00:19:24,799
which parts of the pe are the most

485
00:19:24,799 --> 00:19:26,640
influential

486
00:19:26,640 --> 00:19:30,000
and this time we're querying the target

487
00:19:30,000 --> 00:19:33,120
classifier and not the surrogate one

488
00:19:33,120 --> 00:19:37,520
and we simply slide a window

489
00:19:37,520 --> 00:19:40,640
we can either zero out the entire window

490
00:19:40,640 --> 00:19:44,080
or scramble strings if we find in the

491
00:19:44,080 --> 00:19:44,799
window

492
00:19:44,799 --> 00:19:48,320
and we pass that new modified pe to the

493
00:19:48,320 --> 00:19:49,919
classifier

494
00:19:49,919 --> 00:19:53,440
and ask him what is the prediction now

495
00:19:53,440 --> 00:19:56,000
what is the score so for this kind of

496
00:19:56,000 --> 00:19:57,760
attack we don't need a pe to be

497
00:19:57,760 --> 00:19:58,559
functional in

498
00:19:58,559 --> 00:20:01,120
any sort of way we're just interested to

499
00:20:01,120 --> 00:20:03,120
see which areas of the pe have the

500
00:20:03,120 --> 00:20:03,840
highest

501
00:20:03,840 --> 00:20:07,360
impact on the score so

502
00:20:07,360 --> 00:20:10,870
why does it make sense as i

503
00:20:10,870 --> 00:20:12,480
[Music]

504
00:20:12,480 --> 00:20:14,400
explained in the first part of the

505
00:20:14,400 --> 00:20:15,840
presentation

506
00:20:15,840 --> 00:20:18,880
a lot of classifiers use circumstantial

507
00:20:18,880 --> 00:20:20,640
evidence that they collect from the pe

508
00:20:20,640 --> 00:20:21,280
header

509
00:20:21,280 --> 00:20:24,080
and it is very difficult to understand

510
00:20:24,080 --> 00:20:24,880
for example

511
00:20:24,880 --> 00:20:27,440
if a string is actually going to be

512
00:20:27,440 --> 00:20:30,000
resolved to an import

513
00:20:30,000 --> 00:20:33,200
later dynamically or it has some other

514
00:20:33,200 --> 00:20:34,000
meaning so

515
00:20:34,000 --> 00:20:36,400
all of this information is collected and

516
00:20:36,400 --> 00:20:37,039
uh

517
00:20:37,039 --> 00:20:38,960
calculated by the classifier to the

518
00:20:38,960 --> 00:20:40,559
final score

519
00:20:40,559 --> 00:20:43,039
so by hiding this uh information we can

520
00:20:43,039 --> 00:20:44,080
understand

521
00:20:44,080 --> 00:20:46,320
what the classifier sees as the most

522
00:20:46,320 --> 00:20:48,559
important part or most influential

523
00:20:48,559 --> 00:20:51,679
part of the file

524
00:20:51,679 --> 00:20:54,559
this attack is not easily applied on the

525
00:20:54,559 --> 00:20:56,080
pe header

526
00:20:56,080 --> 00:20:58,320
simply because if the classifier expects

527
00:20:58,320 --> 00:21:00,480
to parse a p header then it will fail to

528
00:21:00,480 --> 00:21:03,039
do so and

529
00:21:03,039 --> 00:21:05,039
the findings of this attack are not

530
00:21:05,039 --> 00:21:07,360
always very useful for example

531
00:21:07,360 --> 00:21:11,280
if we discover that the code section

532
00:21:11,280 --> 00:21:14,559
has a very high impact on the score it's

533
00:21:14,559 --> 00:21:15,520
not very

534
00:21:15,520 --> 00:21:19,120
easy and simple to change it

535
00:21:19,120 --> 00:21:21,679
so here we will show the illustration of

536
00:21:21,679 --> 00:21:23,039
our

537
00:21:23,039 --> 00:21:25,440
sliding window attack or sliding window

538
00:21:25,440 --> 00:21:26,400
probing

539
00:21:26,400 --> 00:21:29,600
so we start with the malicious file

540
00:21:29,600 --> 00:21:32,159
and the malicious is of course composed

541
00:21:32,159 --> 00:21:33,840
of the p header sections

542
00:21:33,840 --> 00:21:37,520
and an overlay and we pass that to the

543
00:21:37,520 --> 00:21:38,640
classifier and we get

544
00:21:38,640 --> 00:21:41,679
our prediction our score and

545
00:21:41,679 --> 00:21:45,039
for this example it's minus one and

546
00:21:45,039 --> 00:21:47,840
the blue rectangle uh illustrates the

547
00:21:47,840 --> 00:21:49,840
actual sliding window that we

548
00:21:49,840 --> 00:21:52,880
move along the way and each time

549
00:21:52,880 --> 00:21:56,240
we uh either zero out or

550
00:21:56,240 --> 00:21:58,960
scramble uh the strings for this

551
00:21:58,960 --> 00:22:01,600
specific example we used a 32 kilobyte

552
00:22:01,600 --> 00:22:05,039
sliding window and we only scrambled

553
00:22:05,039 --> 00:22:06,720
the strings that we found in the window

554
00:22:06,720 --> 00:22:08,480
leaving all other data

555
00:22:08,480 --> 00:22:13,039
as is and finally what we want to do is

556
00:22:13,039 --> 00:22:16,080
examine why uh the differences in the

557
00:22:16,080 --> 00:22:16,720
score

558
00:22:16,720 --> 00:22:20,000
occurred so let's start

559
00:22:20,000 --> 00:22:23,440
playing and we will show now the output

560
00:22:23,440 --> 00:22:25,200
of the sliding window attack on the

561
00:22:25,200 --> 00:22:26,720
sample

562
00:22:26,720 --> 00:22:30,000
so as you can see uh

563
00:22:30,000 --> 00:22:33,280
all the scores are uh still

564
00:22:33,280 --> 00:22:37,120
very malicious but we have one score

565
00:22:37,120 --> 00:22:37,760
that is

566
00:22:37,760 --> 00:22:41,120
a little bit uh bigger

567
00:22:41,120 --> 00:22:44,400
but not by much but we think that

568
00:22:44,400 --> 00:22:46,960
uh at this point it's very important to

569
00:22:46,960 --> 00:22:48,159
look at the precision

570
00:22:48,159 --> 00:22:50,720
that the classifier has on the score and

571
00:22:50,720 --> 00:22:53,520
we change from 10 to the -11 precision

572
00:22:53,520 --> 00:22:54,880
to 10 to the minus

573
00:22:54,880 --> 00:22:58,080
3 precision and even though it doesn't

574
00:22:58,080 --> 00:22:58,960
look like much

575
00:22:58,960 --> 00:23:02,080
but due to the non-linearity of the

576
00:23:02,080 --> 00:23:03,280
classifier

577
00:23:03,280 --> 00:23:06,400
this is very important and

578
00:23:06,400 --> 00:23:09,919
now we'll try to understand what is the

579
00:23:09,919 --> 00:23:12,720
specific address and as we can see uh it

580
00:23:12,720 --> 00:23:14,640
corresponds to the import table

581
00:23:14,640 --> 00:23:18,000
of the file and um

582
00:23:18,000 --> 00:23:20,960
this also what this was what we saw with

583
00:23:20,960 --> 00:23:21,360
the

584
00:23:21,360 --> 00:23:24,480
shop package uh shop showed us that

585
00:23:24,480 --> 00:23:26,960
import library and the import function

586
00:23:26,960 --> 00:23:28,320
are very high

587
00:23:28,320 --> 00:23:31,280
uh in the importance so both techniques

588
00:23:31,280 --> 00:23:32,000
agree here

589
00:23:32,000 --> 00:23:35,039
and we can move on to the actual uh

590
00:23:35,039 --> 00:23:37,840
attack

591
00:23:38,960 --> 00:23:42,400
for the actual attack we will attack

592
00:23:42,400 --> 00:23:45,360
several features of the p file here we

593
00:23:45,360 --> 00:23:47,200
will explain a little bit about

594
00:23:47,200 --> 00:23:50,400
how we attack them so

595
00:23:50,400 --> 00:23:53,520
the first one is the checksum and the

596
00:23:53,520 --> 00:23:54,880
checksum

597
00:23:54,880 --> 00:23:56,559
has no impact on the functionality of

598
00:23:56,559 --> 00:23:57,919
the pe

599
00:23:57,919 --> 00:24:00,799
and usually correcting the checksum to

600
00:24:00,799 --> 00:24:01,760
the correct value

601
00:24:01,760 --> 00:24:04,799
only improves the score and

602
00:24:04,799 --> 00:24:08,000
it's only relevant for a driver or a

603
00:24:08,000 --> 00:24:09,279
critical dll which is

604
00:24:09,279 --> 00:24:12,720
out of the scope for us timestamp has no

605
00:24:12,720 --> 00:24:14,320
impact on the functionality

606
00:24:14,320 --> 00:24:18,640
and although it's a d word or 4 bytes

607
00:24:18,640 --> 00:24:19,679
value

608
00:24:19,679 --> 00:24:21,370
with a possible of 4 billion

609
00:24:21,370 --> 00:24:22,799
[Music]

610
00:24:22,799 --> 00:24:26,960
possibilities we here chose to

611
00:24:26,960 --> 00:24:30,080
just pick up specific values

612
00:24:30,080 --> 00:24:32,080
where the timestamp reflect no longer

613
00:24:32,080 --> 00:24:33,679
than 15 15

614
00:24:33,679 --> 00:24:37,039
years in the past and for each year

615
00:24:37,039 --> 00:24:40,960
we uh divided it into 12 parts so we try

616
00:24:40,960 --> 00:24:41,679
to match

617
00:24:41,679 --> 00:24:44,320
each month of the week of the year and

618
00:24:44,320 --> 00:24:47,039
this results only in 180 values that we

619
00:24:47,039 --> 00:24:47,919
can

620
00:24:47,919 --> 00:24:51,360
simply check and uh conclude that

621
00:24:51,360 --> 00:24:54,400
attack very quickly

622
00:24:54,400 --> 00:24:58,480
for new sections we can add new sections

623
00:24:58,480 --> 00:25:00,400
with specific characteristics as we

624
00:25:00,400 --> 00:25:01,760
choose either to be

625
00:25:01,760 --> 00:25:05,279
a code section or data section

626
00:25:05,279 --> 00:25:08,320
and we can also generate buffers with

627
00:25:08,320 --> 00:25:11,360
the desired entropies that we wish be it

628
00:25:11,360 --> 00:25:14,400
high entropy or low entropy

629
00:25:14,400 --> 00:25:17,440
this attack usually did not

630
00:25:17,440 --> 00:25:20,559
very much improve the score in our favor

631
00:25:20,559 --> 00:25:23,840
and we actually did not

632
00:25:23,840 --> 00:25:27,039
use it as a standalone attack entry

633
00:25:27,039 --> 00:25:28,720
point trampoline

634
00:25:28,720 --> 00:25:31,919
um in this attack we can either

635
00:25:31,919 --> 00:25:34,799
uh insert a trampoline in the original

636
00:25:34,799 --> 00:25:35,440
code section

637
00:25:35,440 --> 00:25:38,559
if we have enough slack space or

638
00:25:38,559 --> 00:25:41,520
uh insert a new section that jumps to

639
00:25:41,520 --> 00:25:42,240
the original

640
00:25:42,240 --> 00:25:45,520
entry point of the file and this is what

641
00:25:45,520 --> 00:25:46,960
we used

642
00:25:46,960 --> 00:25:50,240
and for the rest of the code section

643
00:25:50,240 --> 00:25:54,080
uh we simply pasted a

644
00:25:54,080 --> 00:25:56,000
different code section from a very

645
00:25:56,000 --> 00:25:59,360
benign file from the os vendor

646
00:25:59,360 --> 00:26:03,279
and we used our prologue

647
00:26:03,279 --> 00:26:07,039
and conditioned it with an always false

648
00:26:07,039 --> 00:26:07,679
condition

649
00:26:07,679 --> 00:26:10,720
to the very benign code section

650
00:26:10,720 --> 00:26:13,760
and jump to the original code section of

651
00:26:13,760 --> 00:26:14,480
the file

652
00:26:14,480 --> 00:26:16,400
so essentially the functionality remains

653
00:26:16,400 --> 00:26:18,080
the same

654
00:26:18,080 --> 00:26:21,679
and as you will probably notice

655
00:26:21,679 --> 00:26:24,960
all the addresses all the virtual

656
00:26:24,960 --> 00:26:25,600
addresses

657
00:26:25,600 --> 00:26:28,320
and rbas will be incorrect in that sense

658
00:26:28,320 --> 00:26:28,640
but

659
00:26:28,640 --> 00:26:31,200
it doesn't matter because it's very

660
00:26:31,200 --> 00:26:32,720
difficult for classifier

661
00:26:32,720 --> 00:26:36,960
to actually understand this information

662
00:26:36,960 --> 00:26:40,159
from the code section and it is usually

663
00:26:40,159 --> 00:26:41,679
not done

664
00:26:41,679 --> 00:26:45,760
as you can see you will see uh shortly

665
00:26:45,760 --> 00:26:49,279
for the new imports uh we had four

666
00:26:49,279 --> 00:26:51,200
methods of introducing new imports and

667
00:26:51,200 --> 00:26:52,880
the inputs are of course taken

668
00:26:52,880 --> 00:26:56,320
from the list that we generated before

669
00:26:56,320 --> 00:26:59,360
in the dataset analysis and the first

670
00:26:59,360 --> 00:27:00,080
method

671
00:27:00,080 --> 00:27:02,880
is the very well trivial one is just

672
00:27:02,880 --> 00:27:04,400
introducing

673
00:27:04,400 --> 00:27:07,840
a new imports to the file but this

674
00:27:07,840 --> 00:27:10,960
usually causes the files to uh break in

675
00:27:10,960 --> 00:27:11,440
a sense

676
00:27:11,440 --> 00:27:13,679
and not load because of missing

677
00:27:13,679 --> 00:27:15,200
dependencies

678
00:27:15,200 --> 00:27:18,799
uh also splitting new imports

679
00:27:18,799 --> 00:27:20,640
that for for libraries that already

680
00:27:20,640 --> 00:27:22,720
imported by the pe file

681
00:27:22,720 --> 00:27:26,399
and dumping the rest as uh strings

682
00:27:26,399 --> 00:27:28,320
could also cause the file to not load

683
00:27:28,320 --> 00:27:30,799
because of different versions

684
00:27:30,799 --> 00:27:34,080
of libraries keep in mind that in the

685
00:27:34,080 --> 00:27:36,720
data set analysis we work on a

686
00:27:36,720 --> 00:27:39,039
large uh data set to extract the imports

687
00:27:39,039 --> 00:27:41,039
and we don't want to

688
00:27:41,039 --> 00:27:43,919
uh go into details of versions of dlls

689
00:27:43,919 --> 00:27:45,600
and which

690
00:27:45,600 --> 00:27:49,840
function names exist in which dlls

691
00:27:50,880 --> 00:27:54,000
and the last two methods are simply dump

692
00:27:54,000 --> 00:27:55,120
the strings

693
00:27:55,120 --> 00:27:58,960
into the overlay or dump it in a new

694
00:27:58,960 --> 00:28:00,840
section that will be of course data

695
00:28:00,840 --> 00:28:02,240
section

696
00:28:02,240 --> 00:28:05,360
uh renaming sections um

697
00:28:05,360 --> 00:28:08,399
same method as uh

698
00:28:08,399 --> 00:28:10,480
the imports analysis can be applied here

699
00:28:10,480 --> 00:28:11,760
to understand which

700
00:28:11,760 --> 00:28:13,760
section names are mostly found in the

701
00:28:13,760 --> 00:28:15,919
benign files versus the malicious

702
00:28:15,919 --> 00:28:17,600
population

703
00:28:17,600 --> 00:28:20,799
and simply choose the most prevalent

704
00:28:20,799 --> 00:28:23,360
benign names we didn't use that for the

705
00:28:23,360 --> 00:28:24,480
attack

706
00:28:24,480 --> 00:28:28,399
simply because the pe file already had

707
00:28:28,399 --> 00:28:30,000
the most benign section names that we

708
00:28:30,000 --> 00:28:33,279
can want and additional features that uh

709
00:28:33,279 --> 00:28:35,520
for this time we found them uh not

710
00:28:35,520 --> 00:28:36,720
contributing too much

711
00:28:36,720 --> 00:28:39,840
uh such as the linker version mean major

712
00:28:39,840 --> 00:28:40,880
os version

713
00:28:40,880 --> 00:28:44,080
and several more that we

714
00:28:44,080 --> 00:28:47,279
found by looking at the tiny pe project

715
00:28:47,279 --> 00:28:50,399
and we got very nice ideas from

716
00:28:50,399 --> 00:28:54,880
from that so our next slide will

717
00:28:54,880 --> 00:28:57,919
show the results of the attack and we

718
00:28:57,919 --> 00:28:58,559
will

719
00:28:58,559 --> 00:29:01,840
talk about several steps so we start

720
00:29:01,840 --> 00:29:02,159
from

721
00:29:02,159 --> 00:29:04,640
almost a perfect minus one score from

722
00:29:04,640 --> 00:29:05,600
our target

723
00:29:05,600 --> 00:29:09,760
classifier and the first step that we do

724
00:29:09,760 --> 00:29:13,919
is insert 10k imports into the overlay

725
00:29:13,919 --> 00:29:17,200
and correcting the checksum and as we

726
00:29:17,200 --> 00:29:18,399
discussed before

727
00:29:18,399 --> 00:29:22,240
uh this changes the precision

728
00:29:22,240 --> 00:29:24,640
most significantly but the score is

729
00:29:24,640 --> 00:29:27,120
still very very uh malicious

730
00:29:27,120 --> 00:29:32,399
it's a minus 0.99 and

731
00:29:32,720 --> 00:29:35,360
what we hope to achieve by this is to

732
00:29:35,360 --> 00:29:37,360
make a big impact on the precision

733
00:29:37,360 --> 00:29:39,600
and we found that inserting imports one

734
00:29:39,600 --> 00:29:41,120
by one

735
00:29:41,120 --> 00:29:44,399
bit import names or as strings

736
00:29:44,399 --> 00:29:46,960
does not have a big impact on the score

737
00:29:46,960 --> 00:29:47,760
so we

738
00:29:47,760 --> 00:29:50,240
work here with a large batch of 10k

739
00:29:50,240 --> 00:29:51,440
imports and we achieve

740
00:29:51,440 --> 00:29:53,520
a significant change in terms of

741
00:29:53,520 --> 00:29:55,840
precision

742
00:29:56,480 --> 00:29:58,399
for each step we also corrected the

743
00:29:58,399 --> 00:30:00,000
timestamp and the checksum so we will

744
00:30:00,000 --> 00:30:01,600
not discuss this

745
00:30:01,600 --> 00:30:04,080
every time and the next important step

746
00:30:04,080 --> 00:30:06,880
is the trampoline

747
00:30:06,880 --> 00:30:08,799
and here we inserted a new code section

748
00:30:08,799 --> 00:30:10,240
as we described before with

749
00:30:10,240 --> 00:30:13,039
uh a prologue to a very benign code

750
00:30:13,039 --> 00:30:14,640
section that we extracted

751
00:30:14,640 --> 00:30:18,240
and uh in addition we added the same

752
00:30:18,240 --> 00:30:21,440
10k imports from the first step into

753
00:30:21,440 --> 00:30:25,520
the overlay and we can see that

754
00:30:25,520 --> 00:30:28,799
for the trampoline we achieved 0.1

755
00:30:28,799 --> 00:30:31,200
almost change in the score and in

756
00:30:31,200 --> 00:30:32,159
addition the

757
00:30:32,159 --> 00:30:34,399
10k into the 10k imports into the

758
00:30:34,399 --> 00:30:35,360
overlay

759
00:30:35,360 --> 00:30:38,880
achieved a total of 0.519

760
00:30:38,880 --> 00:30:42,399
which is very impressive

761
00:30:42,480 --> 00:30:45,039
and again the functionality of the pe

762
00:30:45,039 --> 00:30:46,880
remains the same there is actually

763
00:30:46,880 --> 00:30:48,480
nothing that we did to change the

764
00:30:48,480 --> 00:30:50,880
functionality of the pe

765
00:30:50,880 --> 00:30:52,799
but we're still in the malicious

766
00:30:52,799 --> 00:30:55,919
threshold so it's not enough

767
00:30:55,919 --> 00:30:59,279
and the next step will take 20k imports

768
00:30:59,279 --> 00:31:02,000
and iterate over them with the 1k

769
00:31:02,000 --> 00:31:02,640
batches

770
00:31:02,640 --> 00:31:05,279
choosing batches that improve the score

771
00:31:05,279 --> 00:31:06,480
only

772
00:31:06,480 --> 00:31:09,840
and as you can see we

773
00:31:09,840 --> 00:31:13,720
had a big jump here of

774
00:31:13,720 --> 00:31:16,880
1.28 in the score and now

775
00:31:16,880 --> 00:31:20,000
the classifier says it's a 0.8

776
00:31:20,000 --> 00:31:22,640
and it's actually very sure that this is

777
00:31:22,640 --> 00:31:24,880
a benign file

778
00:31:24,880 --> 00:31:27,840
and in a sense this concludes the attack

779
00:31:27,840 --> 00:31:29,600
so we had um

780
00:31:29,600 --> 00:31:32,559
six uh additional steps of imports that

781
00:31:32,559 --> 00:31:34,960
we added which are illustrated in the

782
00:31:34,960 --> 00:31:37,760
graph where the orange line is

783
00:31:37,760 --> 00:31:39,039
representing the

784
00:31:39,039 --> 00:31:41,919
classifier score and the blue line that

785
00:31:41,919 --> 00:31:43,919
we want to uh

786
00:31:43,919 --> 00:31:47,120
to keep each batch that we add

787
00:31:47,120 --> 00:31:49,679
we wanted to improve the previous score

788
00:31:49,679 --> 00:31:50,480
which is not

789
00:31:50,480 --> 00:31:53,679
necessarily the optimal uh approach

790
00:31:53,679 --> 00:31:55,919
because we can have combinations that we

791
00:31:55,919 --> 00:31:57,200
haven't checked which

792
00:31:57,200 --> 00:32:00,240
uh achieve higher changes in the score

793
00:32:00,240 --> 00:32:03,120
but we tried to keep it simple and it

794
00:32:03,120 --> 00:32:03,600
worked

795
00:32:03,600 --> 00:32:07,679
so there was no reason to

796
00:32:07,679 --> 00:32:09,600
check a lot of combinations and the blue

797
00:32:09,600 --> 00:32:10,799
line describes

798
00:32:10,799 --> 00:32:13,440
how each batch affected the score so you

799
00:32:13,440 --> 00:32:14,080
can see that

800
00:32:14,080 --> 00:32:16,640
are some batches that reduce the score

801
00:32:16,640 --> 00:32:18,240
and some batches that uh

802
00:32:18,240 --> 00:32:21,440
improve the score and the last uh

803
00:32:21,440 --> 00:32:24,000
last batch uh improved the score by a

804
00:32:24,000 --> 00:32:25,360
0.8

805
00:32:25,360 --> 00:32:28,159
in total and it put us in the benign

806
00:32:28,159 --> 00:32:29,279
threshold

807
00:32:29,279 --> 00:32:31,200
so this concludes the attack and now we

808
00:32:31,200 --> 00:32:33,679
can uh try to see

809
00:32:33,679 --> 00:32:36,799
uh what other antiviruses

810
00:32:36,799 --> 00:32:38,960
in our ngav think about the files so we

811
00:32:38,960 --> 00:32:43,600
started with a 57 out of 68 detections

812
00:32:43,600 --> 00:32:46,399
uh and our ngav is currently detecting

813
00:32:46,399 --> 00:32:48,399
the original sample of course with a

814
00:32:48,399 --> 00:32:52,000
score of nearly nearly perfect minus one

815
00:32:52,000 --> 00:32:55,039
and after our modification we concluded

816
00:32:55,039 --> 00:32:57,279
with 30 out of 71

817
00:32:57,279 --> 00:33:00,159
and our ngav is no longer no longer

818
00:33:00,159 --> 00:33:01,360
detecting the sample

819
00:33:01,360 --> 00:33:04,240
alongside with two additional next

820
00:33:04,240 --> 00:33:05,200
generation

821
00:33:05,200 --> 00:33:08,320
antiviruses and this

822
00:33:08,320 --> 00:33:11,200
uh also shows the transferability of

823
00:33:11,200 --> 00:33:13,519
explainability that uh ishai mentioned

824
00:33:13,519 --> 00:33:16,399
in the first part of the presentation

825
00:33:16,399 --> 00:33:17,919
this concludes my part of the

826
00:33:17,919 --> 00:33:18,799
presentation

827
00:33:18,799 --> 00:33:21,840
and ishai will give

828
00:33:21,840 --> 00:33:25,360
the summary thank you very much

829
00:33:25,360 --> 00:33:28,559
thank you shai and now uh let's say sum

830
00:33:28,559 --> 00:33:29,279
things up

831
00:33:29,279 --> 00:33:30,679
first of all next generation

832
00:33:30,679 --> 00:33:32,960
anti-antivirus is not a silver bullet

833
00:33:32,960 --> 00:33:34,559
and especially when it uses

834
00:33:34,559 --> 00:33:37,039
a engineered feature which attacker can

835
00:33:37,039 --> 00:33:38,960
understand and can modify

836
00:33:38,960 --> 00:33:40,880
in a way that will not harm the

837
00:33:40,880 --> 00:33:42,640
malicious

838
00:33:42,640 --> 00:33:45,039
functionality of the malware second of

839
00:33:45,039 --> 00:33:46,399
all explainability

840
00:33:46,399 --> 00:33:49,279
is a dual edged sword while it does help

841
00:33:49,279 --> 00:33:51,360
internally for debugging etc

842
00:33:51,360 --> 00:33:54,159
it also can serve the attacker in order

843
00:33:54,159 --> 00:33:56,960
to understand which feature

844
00:33:56,960 --> 00:33:59,760
is more impactful and more defined focus

845
00:33:59,760 --> 00:34:00,720
on them also

846
00:34:00,720 --> 00:34:03,679
also and finally we had some practical

847
00:34:03,679 --> 00:34:04,960
insights first

848
00:34:04,960 --> 00:34:08,079
the fact that the order in which you

849
00:34:08,079 --> 00:34:10,719
made the perturbation does may makes a

850
00:34:10,719 --> 00:34:11,679
difference

851
00:34:11,679 --> 00:34:15,040
uh and if you choose perturbation a

852
00:34:15,040 --> 00:34:18,719
after b or b after a you sometimes get

853
00:34:18,719 --> 00:34:21,119
different results which is interesting

854
00:34:21,119 --> 00:34:22,239
the second thing

855
00:34:22,239 --> 00:34:25,199
is that while small perturbations seem

856
00:34:25,199 --> 00:34:27,280
to have a very insignificant effect like

857
00:34:27,280 --> 00:34:28,239
you saw in

858
00:34:28,239 --> 00:34:31,599
shai's example eventually because of the

859
00:34:31,599 --> 00:34:34,320
non-linear nature of those classifier

860
00:34:34,320 --> 00:34:34,879
you would

861
00:34:34,879 --> 00:34:38,800
get a a sudden drop in the

862
00:34:38,800 --> 00:34:40,879
in the classifier and therefore you will

863
00:34:40,879 --> 00:34:41,839
get

864
00:34:41,839 --> 00:34:44,800
a a big impact and therefore keep on

865
00:34:44,800 --> 00:34:45,440
trying

866
00:34:45,440 --> 00:34:48,480
and eventually you will succeed

867
00:34:48,480 --> 00:34:51,040
this concludes our our session and we

868
00:34:51,040 --> 00:34:52,560
are now open for a question

869
00:34:52,560 --> 00:34:55,599
thank you very much

