1
00:00:01,130 --> 00:00:14,690
[Music]

2
00:00:19,439 --> 00:00:21,039
good morning good afternoon and good

3
00:00:21,039 --> 00:00:22,080
evening

4
00:00:22,080 --> 00:00:23,680
no matter what timezone you're joining

5
00:00:23,680 --> 00:00:25,599
us from it is my great pleasure

6
00:00:25,599 --> 00:00:28,240
to talk to you today about our briefing

7
00:00:28,240 --> 00:00:28,640
on

8
00:00:28,640 --> 00:00:30,560
effective vulnerability discovery with

9
00:00:30,560 --> 00:00:32,079
machine learning

10
00:00:32,079 --> 00:00:34,640
i'm a sankhya and this is joint work

11
00:00:34,640 --> 00:00:36,239
with my colleague mingy

12
00:00:36,239 --> 00:00:39,680
from veracore in this talk

13
00:00:39,680 --> 00:00:41,440
we will talk about vulnerability

14
00:00:41,440 --> 00:00:43,600
discovery we will see

15
00:00:43,600 --> 00:00:45,120
how finding vulnerabilities in your

16
00:00:45,120 --> 00:00:47,200
application goes beyond the code that

17
00:00:47,200 --> 00:00:49,039
you have written yourself

18
00:00:49,039 --> 00:00:50,800
if you look at any modern software

19
00:00:50,800 --> 00:00:52,960
application it is composed of

20
00:00:52,960 --> 00:00:54,640
a number of third-party components and

21
00:00:54,640 --> 00:00:56,000
libraries

22
00:00:56,000 --> 00:00:57,840
the increase in the number of libraries

23
00:00:57,840 --> 00:00:59,840
means that your application today has a

24
00:00:59,840 --> 00:01:00,239
much

25
00:01:00,239 --> 00:01:03,120
wider surface of attack in this

26
00:01:03,120 --> 00:01:04,799
presentation we will discuss

27
00:01:04,799 --> 00:01:07,439
about ways in which we can curate and

28
00:01:07,439 --> 00:01:08,720
track these vulnerabilities

29
00:01:08,720 --> 00:01:12,240
at scale this is a brief

30
00:01:12,240 --> 00:01:14,720
bio about us i am a sankhya i'm the

31
00:01:14,720 --> 00:01:16,000
director of engineering

32
00:01:16,000 --> 00:01:19,200
at sca which is the software composition

33
00:01:19,200 --> 00:01:19,920
analysis

34
00:01:19,920 --> 00:01:22,960
product group at varaco i'm joined in my

35
00:01:22,960 --> 00:01:23,600
talk

36
00:01:23,600 --> 00:01:25,920
with ming who is a senior research

37
00:01:25,920 --> 00:01:27,360
engineer also working

38
00:01:27,360 --> 00:01:32,479
at the sca product group at veracore

39
00:01:32,479 --> 00:01:34,720
our agenda for today has three points

40
00:01:34,720 --> 00:01:36,560
first we will talk about the problem of

41
00:01:36,560 --> 00:01:38,640
vulnerability curation in the context of

42
00:01:38,640 --> 00:01:40,960
software composition analysis

43
00:01:40,960 --> 00:01:42,720
then we'll discuss about our machine

44
00:01:42,720 --> 00:01:44,240
learning approach which is used to

45
00:01:44,240 --> 00:01:46,320
identify these vulnerabilities

46
00:01:46,320 --> 00:01:47,920
and at the end we'll talk about what it

47
00:01:47,920 --> 00:01:50,000
means to be effective at doing

48
00:01:50,000 --> 00:01:54,640
vulnerability discovery at scale

49
00:01:54,640 --> 00:01:56,880
so what are some of the difficulties in

50
00:01:56,880 --> 00:01:57,920
tracking down these

51
00:01:57,920 --> 00:02:01,119
uh vulnerabilities um if you look at

52
00:02:01,119 --> 00:02:05,439
the number of libraries and components

53
00:02:05,439 --> 00:02:07,280
that are used have they have exploded in

54
00:02:07,280 --> 00:02:08,800
the past few years

55
00:02:08,800 --> 00:02:11,599
today uh developers have a choice of you

56
00:02:11,599 --> 00:02:12,560
know downloading

57
00:02:12,560 --> 00:02:14,720
millions of libraries uh from

58
00:02:14,720 --> 00:02:16,640
third-party repositories

59
00:02:16,640 --> 00:02:18,800
uh it becomes very difficult to keep

60
00:02:18,800 --> 00:02:19,680
track of

61
00:02:19,680 --> 00:02:21,200
vulnerabilities that exist in these

62
00:02:21,200 --> 00:02:23,520
third-party libraries so we need a way

63
00:02:23,520 --> 00:02:24,800
in order to curate

64
00:02:24,800 --> 00:02:26,480
and collect the vulnerabilities that are

65
00:02:26,480 --> 00:02:28,080
found and rely on some sort of a

66
00:02:28,080 --> 00:02:29,520
vulnerability database

67
00:02:29,520 --> 00:02:31,680
when we analyze these libraries and

68
00:02:31,680 --> 00:02:34,080
applications

69
00:02:34,080 --> 00:02:35,760
how do we curate these vulnerabilities

70
00:02:35,760 --> 00:02:38,319
right so we process data

71
00:02:38,319 --> 00:02:40,720
from a variety of internet sources

72
00:02:40,720 --> 00:02:41,519
including

73
00:02:41,519 --> 00:02:43,440
the nvd or the national vulnerability

74
00:02:43,440 --> 00:02:45,920
database

75
00:02:46,720 --> 00:02:49,519
we track the upstream software artifact

76
00:02:49,519 --> 00:02:50,640
repositories of

77
00:02:50,640 --> 00:02:53,599
all um open source libraries so these

78
00:02:53,599 --> 00:02:54,640
include things like

79
00:02:54,640 --> 00:02:56,720
their bug reporting systems like jira

80
00:02:56,720 --> 00:02:58,480
bugzilla github issues

81
00:02:58,480 --> 00:03:00,879
or their source control repositories um

82
00:03:00,879 --> 00:03:01,680
like get

83
00:03:01,680 --> 00:03:05,280
bitbucket etc we do that because we

84
00:03:05,280 --> 00:03:06,000
realize

85
00:03:06,000 --> 00:03:07,680
that even if there is a vulnerability

86
00:03:07,680 --> 00:03:11,040
that eventually gets assigned a cve

87
00:03:11,040 --> 00:03:12,720
there is a high likelihood that there

88
00:03:12,720 --> 00:03:14,159
are clues or hints about that

89
00:03:14,159 --> 00:03:15,200
vulnerability

90
00:03:15,200 --> 00:03:17,599
which are available in the upstream

91
00:03:17,599 --> 00:03:20,000
software artifacts of these repositories

92
00:03:20,000 --> 00:03:21,680
where you could actually track them much

93
00:03:21,680 --> 00:03:23,280
much earlier before they eventually

94
00:03:23,280 --> 00:03:23,840
reach

95
00:03:23,840 --> 00:03:26,159
the nvd and in case of open source

96
00:03:26,159 --> 00:03:27,519
libraries many of the

97
00:03:27,519 --> 00:03:29,840
vulnerabilities and security issues

98
00:03:29,840 --> 00:03:31,440
still do not get assigned with a

99
00:03:31,440 --> 00:03:35,280
cbe now

100
00:03:35,280 --> 00:03:37,440
when we started this process we were

101
00:03:37,440 --> 00:03:38,640
doing things manually

102
00:03:38,640 --> 00:03:40,799
and we realized that it is extremely

103
00:03:40,799 --> 00:03:41,840
difficult

104
00:03:41,840 --> 00:03:44,480
and the reason for that is we have to

105
00:03:44,480 --> 00:03:46,159
support millions of

106
00:03:46,159 --> 00:03:49,760
libraries we actively track thousands of

107
00:03:49,760 --> 00:03:52,080
git repositories and in order to

108
00:03:52,080 --> 00:03:53,439
manually do this means that somebody

109
00:03:53,439 --> 00:03:55,280
needs to sit in and take a look at

110
00:03:55,280 --> 00:03:57,040
every single commit message or a bug

111
00:03:57,040 --> 00:03:58,480
report that is filed

112
00:03:58,480 --> 00:04:00,239
and then make a judgment whether to see

113
00:04:00,239 --> 00:04:01,760
whether it's related to a vulnerability

114
00:04:01,760 --> 00:04:02,239
or not

115
00:04:02,239 --> 00:04:03,760
right and once you know that it's

116
00:04:03,760 --> 00:04:05,040
related to one ability you still have to

117
00:04:05,040 --> 00:04:06,959
do further investigation to figure out

118
00:04:06,959 --> 00:04:08,640
what versions are affected what is the

119
00:04:08,640 --> 00:04:10,319
fix and how do you

120
00:04:10,319 --> 00:04:12,640
address that vulnerability so we need a

121
00:04:12,640 --> 00:04:14,560
solution that can scale

122
00:04:14,560 --> 00:04:15,680
with the increase in the number of

123
00:04:15,680 --> 00:04:19,600
libraries and third party components

124
00:04:19,600 --> 00:04:21,918
um so it's quite natural to think about

125
00:04:21,918 --> 00:04:23,600
using machine learning in this context

126
00:04:23,600 --> 00:04:24,960
because if you look at it from a

127
00:04:24,960 --> 00:04:26,400
perspective of machine learning this is

128
00:04:26,400 --> 00:04:27,120
like a

129
00:04:27,120 --> 00:04:29,040
classification problem so you have some

130
00:04:29,040 --> 00:04:30,560
particular data source whether it is a

131
00:04:30,560 --> 00:04:33,360
bug report or a commit or

132
00:04:33,360 --> 00:04:36,240
mail advisory and you want to figure out

133
00:04:36,240 --> 00:04:37,120
whether this is

134
00:04:37,120 --> 00:04:38,800
related to a vulnerability or not so you

135
00:04:38,800 --> 00:04:40,639
have like a binary classification

136
00:04:40,639 --> 00:04:41,199
problem

137
00:04:41,199 --> 00:04:42,800
right so when you look at it from a

138
00:04:42,800 --> 00:04:44,240
machine learning perspective you'll

139
00:04:44,240 --> 00:04:46,479
realize that

140
00:04:46,479 --> 00:04:48,000
the data set that you're dealing with is

141
00:04:48,000 --> 00:04:49,759
highly imbalanced so

142
00:04:49,759 --> 00:04:52,000
the chance that a given commit out of

143
00:04:52,000 --> 00:04:53,600
all possible commits is related to

144
00:04:53,600 --> 00:04:55,360
vulnerability is actually very very low

145
00:04:55,360 --> 00:04:57,360
right so when we looked at our own data

146
00:04:57,360 --> 00:04:59,360
we realized that

147
00:04:59,360 --> 00:05:01,440
depending on the data source uh even

148
00:05:01,440 --> 00:05:02,960
after doing some pre-processing or

149
00:05:02,960 --> 00:05:05,120
removing you know some obvious things

150
00:05:05,120 --> 00:05:08,479
or filtering obvious candidates we ended

151
00:05:08,479 --> 00:05:10,080
up having a data set which is highly

152
00:05:10,080 --> 00:05:10,960
imbalanced

153
00:05:10,960 --> 00:05:13,600
so in some cases it could only less than

154
00:05:13,600 --> 00:05:14,800
six percent of the

155
00:05:14,800 --> 00:05:16,479
uh data set was related to a

156
00:05:16,479 --> 00:05:18,160
vulnerability right

157
00:05:18,160 --> 00:05:19,919
and as we continue to expand on the

158
00:05:19,919 --> 00:05:21,680
different sources or we continue to add

159
00:05:21,680 --> 00:05:22,400
more uh

160
00:05:22,400 --> 00:05:25,759
libraries to our system the size of the

161
00:05:25,759 --> 00:05:27,600
label data set keeps increasing

162
00:05:27,600 --> 00:05:30,639
but the unlabeled data set is always

163
00:05:30,639 --> 00:05:31,199
there

164
00:05:31,199 --> 00:05:33,199
so imagine you start using the system

165
00:05:33,199 --> 00:05:34,479
and then you start predicting

166
00:05:34,479 --> 00:05:37,120
what items are related to vulnerability

167
00:05:37,120 --> 00:05:38,800
eventually you will have a

168
00:05:38,800 --> 00:05:40,240
system where you're always doing

169
00:05:40,240 --> 00:05:42,240
positive class predictions and over a

170
00:05:42,240 --> 00:05:43,199
period of time

171
00:05:43,199 --> 00:05:44,880
your label data set will only consist of

172
00:05:44,880 --> 00:05:46,639
positively predicted data because you're

173
00:05:46,639 --> 00:05:48,639
not really verifying or validating

174
00:05:48,639 --> 00:05:50,320
the things that are predicted to be not

175
00:05:50,320 --> 00:05:51,840
a vulnerability right so that's the

176
00:05:51,840 --> 00:05:53,440
whole point so you want to scale

177
00:05:53,440 --> 00:05:55,759
so you end up having a data set which is

178
00:05:55,759 --> 00:05:57,120
uh labeled

179
00:05:57,120 --> 00:05:59,360
it's highly imbalanced and the labels

180
00:05:59,360 --> 00:06:01,120
are mostly related to the positive

181
00:06:01,120 --> 00:06:02,720
predicted data set right

182
00:06:02,720 --> 00:06:04,960
so due to these two problems we really

183
00:06:04,960 --> 00:06:06,960
needed a solution that can balance

184
00:06:06,960 --> 00:06:09,199
and scale the system despite having

185
00:06:09,199 --> 00:06:12,240
these two issues

186
00:06:12,639 --> 00:06:14,720
at this point i would hand over to my

187
00:06:14,720 --> 00:06:16,639
colleague ming who would go over

188
00:06:16,639 --> 00:06:18,960
about and talk more about our approach

189
00:06:18,960 --> 00:06:20,240
towards vulnerability

190
00:06:20,240 --> 00:06:22,000
curation which is based on machine

191
00:06:22,000 --> 00:06:24,720
learning over to you ming

192
00:06:24,720 --> 00:06:28,160
thanks asankia as noted previously

193
00:06:28,160 --> 00:06:30,319
we wish to develop a process to hunt for

194
00:06:30,319 --> 00:06:32,240
vulnerabilities at scale

195
00:06:32,240 --> 00:06:34,240
so we iterated on our machine learning

196
00:06:34,240 --> 00:06:36,160
approach that is able to keep up with

197
00:06:36,160 --> 00:06:38,960
our requirements and skill

198
00:06:38,960 --> 00:06:40,880
the following section is a condensed

199
00:06:40,880 --> 00:06:42,720
summary of the machine learning approach

200
00:06:42,720 --> 00:06:44,639
we presented at the mining software

201
00:06:44,639 --> 00:06:45,680
repositories

202
00:06:45,680 --> 00:06:48,800
2020. in this new approach

203
00:06:48,800 --> 00:06:51,520
we incorporated more data sources and

204
00:06:51,520 --> 00:06:54,560
supported more programming languages

205
00:06:54,560 --> 00:06:56,800
on top of that after having the system

206
00:06:56,800 --> 00:06:59,039
run over a period of time

207
00:06:59,039 --> 00:07:02,400
our data has become highly imbalanced

208
00:07:02,400 --> 00:07:04,880
the highest imbalance from our most

209
00:07:04,880 --> 00:07:06,800
affected source went from about six

210
00:07:06,800 --> 00:07:07,440
percent

211
00:07:07,440 --> 00:07:10,960
to about three percent what this means

212
00:07:10,960 --> 00:07:11,520
is that

213
00:07:11,520 --> 00:07:13,440
if we looked at 100 items we would not

214
00:07:13,440 --> 00:07:16,240
utilize the other 97 of them

215
00:07:16,240 --> 00:07:18,240
this became an issue as it can cause the

216
00:07:18,240 --> 00:07:20,000
machine learning model to be overly

217
00:07:20,000 --> 00:07:20,800
biased

218
00:07:20,800 --> 00:07:22,319
depending on the machine learning

219
00:07:22,319 --> 00:07:25,759
parameters we desired

220
00:07:26,160 --> 00:07:28,720
to solve the issue of data imbalance we

221
00:07:28,720 --> 00:07:30,000
introduced self-training

222
00:07:30,000 --> 00:07:32,800
into our machine learning approach the

223
00:07:32,800 --> 00:07:34,240
self-training approach allows the

224
00:07:34,240 --> 00:07:35,520
machine learning

225
00:07:35,520 --> 00:07:37,840
to utilize the unlabeled data for

226
00:07:37,840 --> 00:07:39,599
training

227
00:07:39,599 --> 00:07:41,919
this is particularly useful for data

228
00:07:41,919 --> 00:07:43,440
sources that display

229
00:07:43,440 --> 00:07:45,680
a huge imbalance of labeled data

230
00:07:45,680 --> 00:07:46,800
proportion

231
00:07:46,800 --> 00:07:50,560
such as for commits as asankyo mentioned

232
00:07:50,560 --> 00:07:51,120
earlier

233
00:07:51,120 --> 00:07:53,599
in a machine learning system we will

234
00:07:53,599 --> 00:07:54,319
want to be

235
00:07:54,319 --> 00:07:57,599
only one to be able to only focus on the

236
00:07:57,599 --> 00:07:59,440
data that matters

237
00:07:59,440 --> 00:08:02,479
and so the majority of the data we

238
00:08:02,479 --> 00:08:03,039
process

239
00:08:03,039 --> 00:08:05,520
comes from the data that were predicted

240
00:08:05,520 --> 00:08:08,799
to be vulnerable

241
00:08:09,039 --> 00:08:11,599
however as a machine learning model is

242
00:08:11,599 --> 00:08:12,160
usually

243
00:08:12,160 --> 00:08:15,039
imperfect there will be type 2 errors

244
00:08:15,039 --> 00:08:16,560
where they provide

245
00:08:16,560 --> 00:08:19,759
false negative predictions together with

246
00:08:19,759 --> 00:08:21,599
the false negative predictions

247
00:08:21,599 --> 00:08:24,080
we also have a portion of data which

248
00:08:24,080 --> 00:08:25,840
have never passed through the initial

249
00:08:25,840 --> 00:08:28,080
filter

250
00:08:28,080 --> 00:08:29,759
these two types of data makes up the

251
00:08:29,759 --> 00:08:31,199
unlabeled data which

252
00:08:31,199 --> 00:08:33,039
will be utilized for the self-training

253
00:08:33,039 --> 00:08:35,519
approach

254
00:08:36,799 --> 00:08:38,958
through our evaluation we find that the

255
00:08:38,958 --> 00:08:42,640
new model is generally performed

256
00:08:42,640 --> 00:08:45,680
no worse than the old model and in most

257
00:08:45,680 --> 00:08:46,480
cases

258
00:08:46,480 --> 00:08:48,959
we did see an improvement of performance

259
00:08:48,959 --> 00:08:51,680
from the new models with self training

260
00:08:51,680 --> 00:08:53,839
from this study we also made a couple of

261
00:08:53,839 --> 00:08:56,000
observations

262
00:08:56,000 --> 00:08:58,240
self training generally increases the

263
00:08:58,240 --> 00:08:59,279
data set

264
00:08:59,279 --> 00:09:02,000
which the model is trained on and the

265
00:09:02,000 --> 00:09:02,720
increase

266
00:09:02,720 --> 00:09:06,240
of performance diminishes as

267
00:09:06,240 --> 00:09:10,080
if we test it on models which originally

268
00:09:10,080 --> 00:09:13,120
have a high recovery

269
00:09:13,120 --> 00:09:15,680
overall we have deemed the study to be a

270
00:09:15,680 --> 00:09:16,880
successful one and

271
00:09:16,880 --> 00:09:19,279
throughout the rest of the talk when we

272
00:09:19,279 --> 00:09:21,920
talk about discovering vulnerabilities

273
00:09:21,920 --> 00:09:22,160
it

274
00:09:22,160 --> 00:09:24,720
is generally from processing data that

275
00:09:24,720 --> 00:09:26,320
we have put through

276
00:09:26,320 --> 00:09:29,920
our machine learning model

277
00:09:30,160 --> 00:09:32,399
so up until this point you have heard

278
00:09:32,399 --> 00:09:33,839
about vulnerability

279
00:09:33,839 --> 00:09:36,720
creation and how machine learning has

280
00:09:36,720 --> 00:09:38,160
been utilized

281
00:09:38,160 --> 00:09:39,600
to help us discover and curate

282
00:09:39,600 --> 00:09:41,680
vulnerabilities

283
00:09:41,680 --> 00:09:44,080
however it's time to take a step back

284
00:09:44,080 --> 00:09:45,279
and wonder why

285
00:09:45,279 --> 00:09:48,880
all these are necessary why are we

286
00:09:48,880 --> 00:09:51,600
even doing this and to think about what

287
00:09:51,600 --> 00:09:53,440
we are trying to achieve

288
00:09:53,440 --> 00:09:55,760
to understand about the complexity of

289
00:09:55,760 --> 00:09:58,000
this issue

290
00:09:58,000 --> 00:10:00,640
moments ago you have heard about how we

291
00:10:00,640 --> 00:10:02,320
have implemented a machine learning

292
00:10:02,320 --> 00:10:06,000
solution that enabled us to process data

293
00:10:06,000 --> 00:10:07,120
at scale

294
00:10:07,120 --> 00:10:08,320
with the main goal of finding

295
00:10:08,320 --> 00:10:10,160
vulnerability related data

296
00:10:10,160 --> 00:10:14,480
from the entire stack of general data

297
00:10:14,480 --> 00:10:16,720
it is shown to be efficient at finding

298
00:10:16,720 --> 00:10:18,560
vulnerability related data

299
00:10:18,560 --> 00:10:20,880
however it it does not automatically

300
00:10:20,880 --> 00:10:22,560
translate to data

301
00:10:22,560 --> 00:10:25,680
we are interested in so what exactly are

302
00:10:25,680 --> 00:10:26,880
we looking for

303
00:10:26,880 --> 00:10:30,480
and why at this point you may even be

304
00:10:30,480 --> 00:10:32,079
asking me hey ming

305
00:10:32,079 --> 00:10:34,160
isn't there a ton of databases and

306
00:10:34,160 --> 00:10:36,959
central authorities we could use to help

307
00:10:36,959 --> 00:10:40,079
identify these vulnerabilities

308
00:10:40,079 --> 00:10:42,720
well before i get to that first allow me

309
00:10:42,720 --> 00:10:44,880
to provide some context and motivation

310
00:10:44,880 --> 00:10:46,320
behind why we are so

311
00:10:46,320 --> 00:10:47,760
interested in discovering

312
00:10:47,760 --> 00:10:50,480
vulnerabilities firsthand

313
00:10:50,480 --> 00:10:51,760
to help understand some of the

314
00:10:51,760 --> 00:10:54,399
motivation we will learn about the

315
00:10:54,399 --> 00:10:55,920
nature

316
00:10:55,920 --> 00:10:59,519
of modern software composition

317
00:10:59,519 --> 00:11:01,120
before moving on to the topic of

318
00:11:01,120 --> 00:11:02,560
dependencies

319
00:11:02,560 --> 00:11:04,160
and finally to highlight some

320
00:11:04,160 --> 00:11:05,680
inefficiencies

321
00:11:05,680 --> 00:11:09,440
in particular the central authorities

322
00:11:09,440 --> 00:11:11,440
as we will see in the next few slides

323
00:11:11,440 --> 00:11:13,519
the problem of securing today's

324
00:11:13,519 --> 00:11:15,839
software is not as simple as we would

325
00:11:15,839 --> 00:11:18,240
like it

326
00:11:18,560 --> 00:11:20,800
let's relook at how we typically think

327
00:11:20,800 --> 00:11:22,640
of securing our code

328
00:11:22,640 --> 00:11:26,000
first we start off with ensuring that

329
00:11:26,000 --> 00:11:28,240
developers adhere to safe coding

330
00:11:28,240 --> 00:11:29,839
practices

331
00:11:29,839 --> 00:11:31,920
then we run static analysis to further

332
00:11:31,920 --> 00:11:33,440
ensure our first party code

333
00:11:33,440 --> 00:11:35,600
will be relatively free from well-known

334
00:11:35,600 --> 00:11:36,800
vulnerabilities

335
00:11:36,800 --> 00:11:39,680
such as sql injection or directory

336
00:11:39,680 --> 00:11:41,360
traversal

337
00:11:41,360 --> 00:11:44,240
we might even run dynamic analysis to

338
00:11:44,240 --> 00:11:45,040
check

339
00:11:45,040 --> 00:11:46,800
if we might have missed out from

340
00:11:46,800 --> 00:11:48,959
detecting some subtle blocks

341
00:11:48,959 --> 00:11:51,040
or to reach code that static analysis

342
00:11:51,040 --> 00:11:54,240
would not be able to fully understand

343
00:11:54,240 --> 00:11:56,560
to double down on finding exploitable

344
00:11:56,560 --> 00:11:58,639
vulnerabilities at runtime

345
00:11:58,639 --> 00:12:02,000
we can also conduct penetration tests

346
00:12:02,000 --> 00:12:03,600
and if we have done everything up to

347
00:12:03,600 --> 00:12:06,079
this point our code is

348
00:12:06,079 --> 00:12:08,839
relatively secure what else could go

349
00:12:08,839 --> 00:12:10,480
wrong well an

350
00:12:10,480 --> 00:12:12,720
often overlooked point is the trend of

351
00:12:12,720 --> 00:12:14,880
external dependencies

352
00:12:14,880 --> 00:12:17,360
when you use external dependencies you

353
00:12:17,360 --> 00:12:18,720
are subject to both

354
00:12:18,720 --> 00:12:21,760
the good and the bad part of it the

355
00:12:21,760 --> 00:12:25,040
threat ranges from regular code flaws to

356
00:12:25,040 --> 00:12:27,360
malicious threats that tries to hide

357
00:12:27,360 --> 00:12:29,200
itself through pre-installed

358
00:12:29,200 --> 00:12:31,839
post-in-source scripts or even through

359
00:12:31,839 --> 00:12:33,519
social engineering attempts

360
00:12:33,519 --> 00:12:38,000
such as like typo sporting

361
00:12:38,000 --> 00:12:40,160
the threat of external dependencies is

362
00:12:40,160 --> 00:12:42,800
not just about what kind of threats are

363
00:12:42,800 --> 00:12:43,760
out there

364
00:12:43,760 --> 00:12:46,880
it is also about how it is increasing

365
00:12:46,880 --> 00:12:48,079
our attack surface

366
00:12:48,079 --> 00:12:51,360
without us knowing about it just in the

367
00:12:51,360 --> 00:12:52,399
picture

368
00:12:52,399 --> 00:12:54,800
on the right of this page describes a

369
00:12:54,800 --> 00:12:57,040
regular expression denial of service

370
00:12:57,040 --> 00:12:57,760
issue

371
00:12:57,760 --> 00:13:01,279
found in url rejects

372
00:13:01,279 --> 00:13:03,040
if you take a closer look on the fifth

373
00:13:03,040 --> 00:13:07,120
row where it says path the url rejects

374
00:13:07,120 --> 00:13:07,760
package

375
00:13:07,760 --> 00:13:10,639
is actually not directly being used by

376
00:13:10,639 --> 00:13:12,160
this application

377
00:13:12,160 --> 00:13:15,040
but it is found in the sixth layer of

378
00:13:15,040 --> 00:13:17,279
dependency

379
00:13:17,279 --> 00:13:19,600
hopefully by highlighting this example

380
00:13:19,600 --> 00:13:21,600
you would have a better picture on

381
00:13:21,600 --> 00:13:24,240
how the issues can go unattended and how

382
00:13:24,240 --> 00:13:25,279
it can actually go

383
00:13:25,279 --> 00:13:27,760
dangerous

384
00:13:28,560 --> 00:13:30,480
now that we have discussed about the

385
00:13:30,480 --> 00:13:32,800
potential of a dependency causing harm

386
00:13:32,800 --> 00:13:34,000
let's look at the nature

387
00:13:34,000 --> 00:13:37,120
of modern software composition

388
00:13:37,120 --> 00:13:38,959
most software built today are almost

389
00:13:38,959 --> 00:13:41,040
always built with a ton of third-party

390
00:13:41,040 --> 00:13:42,800
dependencies

391
00:13:42,800 --> 00:13:44,560
very few of us would write our own

392
00:13:44,560 --> 00:13:47,839
framework or even a http request client

393
00:13:47,839 --> 00:13:49,519
from scratch

394
00:13:49,519 --> 00:13:51,519
just to implement a feature that may

395
00:13:51,519 --> 00:13:52,959
take a few hours or

396
00:13:52,959 --> 00:13:55,920
a few days to write

397
00:13:56,079 --> 00:13:58,880
to give a quick overview of modern

398
00:13:58,880 --> 00:14:01,040
software composition

399
00:14:01,040 --> 00:14:03,440
i used some key information from vera

400
00:14:03,440 --> 00:14:05,199
code's latest volume

401
00:14:05,199 --> 00:14:09,680
of the state of software security report

402
00:14:09,839 --> 00:14:11,519
depending on the programming language

403
00:14:11,519 --> 00:14:14,639
used and the type of application

404
00:14:14,639 --> 00:14:16,800
a real world application would typically

405
00:14:16,800 --> 00:14:18,399
include tens

406
00:14:18,399 --> 00:14:21,279
to a hundreds or even over a thousand

407
00:14:21,279 --> 00:14:23,680
third-party libraries

408
00:14:23,680 --> 00:14:26,079
when you have such a large amount of

409
00:14:26,079 --> 00:14:28,079
third-party libraries being used

410
00:14:28,079 --> 00:14:30,079
most of the code in the application

411
00:14:30,079 --> 00:14:31,279
would most probably

412
00:14:31,279 --> 00:14:34,880
not consist consist of your own code

413
00:14:34,880 --> 00:14:37,680
but would instead mostly consist of code

414
00:14:37,680 --> 00:14:40,320
that others have written

415
00:14:40,320 --> 00:14:43,440
these code may not be audited by anyone

416
00:14:43,440 --> 00:14:46,079
and it would also be too expensive to

417
00:14:46,079 --> 00:14:48,240
run static scans on the

418
00:14:48,240 --> 00:14:51,120
applications if your application is

419
00:14:51,120 --> 00:14:52,880
pulling in hundreds to a thousand

420
00:14:52,880 --> 00:14:57,120
over third party libraries

421
00:14:57,360 --> 00:14:59,920
the top 10 used libraries in javascript

422
00:14:59,920 --> 00:15:00,720
is included

423
00:15:00,720 --> 00:15:04,800
in over 80 of javascript applications

424
00:15:04,800 --> 00:15:07,600
well one way to look at this is if any

425
00:15:07,600 --> 00:15:09,199
of these top 10 libraries

426
00:15:09,199 --> 00:15:12,880
was vulnerable it could cause

427
00:15:12,880 --> 00:15:14,959
most of the javascript applications to

428
00:15:14,959 --> 00:15:16,320
be vulnerable

429
00:15:16,320 --> 00:15:18,880
in fact we found that at least two of

430
00:15:18,880 --> 00:15:21,120
these libraries in the top 10 list

431
00:15:21,120 --> 00:15:23,199
have had known vulnerabilities at some

432
00:15:23,199 --> 00:15:25,519
point

433
00:15:25,839 --> 00:15:28,320
in a study of all applications scanned

434
00:15:28,320 --> 00:15:29,519
over a year

435
00:15:29,519 --> 00:15:34,000
of over 70 of applications tested

436
00:15:34,000 --> 00:15:37,120
has at least one external library flaw

437
00:15:37,120 --> 00:15:40,480
and of which over 40 of these external

438
00:15:40,480 --> 00:15:42,160
library libraries were not

439
00:15:42,160 --> 00:15:46,320
directly requested by the developer

440
00:15:46,320 --> 00:15:49,040
again all this just shows how widespread

441
00:15:49,040 --> 00:15:50,320
the issue could get

442
00:15:50,320 --> 00:15:52,480
when developers use third-party

443
00:15:52,480 --> 00:15:55,839
libraries in the application

444
00:15:56,560 --> 00:16:00,399
how about relying on central authorities

445
00:16:00,399 --> 00:16:02,000
when it comes to the topic of central

446
00:16:02,000 --> 00:16:04,320
authorities well we agree that central

447
00:16:04,320 --> 00:16:05,759
authorities provides

448
00:16:05,759 --> 00:16:09,519
validated vulnerability information

449
00:16:09,519 --> 00:16:11,839
the issue arises when they are overly

450
00:16:11,839 --> 00:16:12,800
relied on

451
00:16:12,800 --> 00:16:14,720
to provide the source of truth of

452
00:16:14,720 --> 00:16:17,440
vulnerabilities

453
00:16:17,680 --> 00:16:20,639
so the issue of central authorities

454
00:16:20,639 --> 00:16:22,160
include the time taken for

455
00:16:22,160 --> 00:16:24,720
vulnerabilities to be published

456
00:16:24,720 --> 00:16:27,120
the inaccuracy of the data where

457
00:16:27,120 --> 00:16:28,720
information could suggest that

458
00:16:28,720 --> 00:16:30,880
all versions before a certain version is

459
00:16:30,880 --> 00:16:32,399
affected

460
00:16:32,399 --> 00:16:34,800
but it's usually not true as the

461
00:16:34,800 --> 00:16:36,480
vulnerability may

462
00:16:36,480 --> 00:16:40,399
be introduced only at a certain version

463
00:16:40,399 --> 00:16:42,800
imposition of the data where information

464
00:16:42,800 --> 00:16:43,680
could suggest

465
00:16:43,680 --> 00:16:47,680
imprecise software component

466
00:16:47,680 --> 00:16:50,639
an example would be like if spring boot

467
00:16:50,639 --> 00:16:51,600
was

468
00:16:51,600 --> 00:16:54,399
vulnerable or stated to be vulnerable it

469
00:16:54,399 --> 00:16:54,959
is

470
00:16:54,959 --> 00:16:57,920
usually only a specific component within

471
00:16:57,920 --> 00:17:00,479
spring boot

472
00:17:01,120 --> 00:17:03,600
the inaccuracy and imprecision of this

473
00:17:03,600 --> 00:17:05,439
data generally causes

474
00:17:05,439 --> 00:17:09,280
it not to be directly actionable

475
00:17:09,280 --> 00:17:11,280
furthermore there are flaws which are

476
00:17:11,280 --> 00:17:12,319
not found on

477
00:17:12,319 --> 00:17:15,199
central authorities the percentage of

478
00:17:15,199 --> 00:17:17,679
such flaws varies be

479
00:17:17,679 --> 00:17:20,079
programming language and the overall

480
00:17:20,079 --> 00:17:20,799
average

481
00:17:20,799 --> 00:17:24,799
was found to be at 15 percent

482
00:17:25,280 --> 00:17:27,359
with respect to understanding what your

483
00:17:27,359 --> 00:17:28,480
application is

484
00:17:28,480 --> 00:17:31,679
one vulnerable to one of the gaps would

485
00:17:31,679 --> 00:17:36,960
be to only rely on central authorities

486
00:17:38,000 --> 00:17:40,000
when we look at how software is built

487
00:17:40,000 --> 00:17:41,679
into this landscape

488
00:17:41,679 --> 00:17:43,919
to develop the intuition of discovering

489
00:17:43,919 --> 00:17:45,039
vulnerabilities in

490
00:17:45,039 --> 00:17:48,000
party libraries we will need to also

491
00:17:48,000 --> 00:17:49,760
understand the challenges with finding

492
00:17:49,760 --> 00:17:52,400
such vulnerabilities

493
00:17:52,400 --> 00:17:55,919
two main challenges arises resources are

494
00:17:55,919 --> 00:17:57,760
limited

495
00:17:57,760 --> 00:18:00,400
and new libraries or library updates are

496
00:18:00,400 --> 00:18:01,039
usually

497
00:18:01,039 --> 00:18:04,080
many and frequent

498
00:18:04,080 --> 00:18:05,919
therefore we find that as a starting

499
00:18:05,919 --> 00:18:07,840
place we wouldn't recommend to

500
00:18:07,840 --> 00:18:09,760
directly look for vulnerabilities in

501
00:18:09,760 --> 00:18:12,080
third party libraries

502
00:18:12,080 --> 00:18:13,840
after all we don't really know what we

503
00:18:13,840 --> 00:18:15,360
can expect to find and

504
00:18:15,360 --> 00:18:18,400
would not know where to look from

505
00:18:18,400 --> 00:18:20,400
for the remainder of this talk i will

506
00:18:20,400 --> 00:18:22,080
not go into the details of

507
00:18:22,080 --> 00:18:25,120
collecting the precise information

508
00:18:25,120 --> 00:18:28,000
of vulnerabilities instead we shall

509
00:18:28,000 --> 00:18:30,160
focus on the vulnerabilities themselves

510
00:18:30,160 --> 00:18:34,320
and how we can discover vulnerabilities

511
00:18:35,520 --> 00:18:37,200
so instead of the traditional way of

512
00:18:37,200 --> 00:18:39,440
securing code such as using static

513
00:18:39,440 --> 00:18:42,880
scans we could use we could look for

514
00:18:42,880 --> 00:18:44,559
sources where the developers and

515
00:18:44,559 --> 00:18:45,520
contributors

516
00:18:45,520 --> 00:18:48,640
will interact data sources

517
00:18:48,640 --> 00:18:52,799
such as github jira and mailing list

518
00:18:52,799 --> 00:18:55,919
are very rich in information to know the

519
00:18:55,919 --> 00:18:57,120
good and the bad about

520
00:18:57,120 --> 00:19:00,160
a particular library

521
00:19:00,160 --> 00:19:02,160
and to test our intuition we have

522
00:19:02,160 --> 00:19:04,160
formulated a process to help us gather

523
00:19:04,160 --> 00:19:05,679
these data

524
00:19:05,679 --> 00:19:08,559
however doing so also results in an

525
00:19:08,559 --> 00:19:09,600
infeasible large

526
00:19:09,600 --> 00:19:12,080
dataset in a hundred thousands range per

527
00:19:12,080 --> 00:19:13,520
week

528
00:19:13,520 --> 00:19:15,360
for this reason we implemented the

529
00:19:15,360 --> 00:19:16,559
machine learning approach

530
00:19:16,559 --> 00:19:18,799
that reduces this amount to thousands

531
00:19:18,799 --> 00:19:20,799
per week

532
00:19:20,799 --> 00:19:22,840
to talk about the results of this

533
00:19:22,840 --> 00:19:25,280
implementation i will be sharing some

534
00:19:25,280 --> 00:19:29,440
data examples in the next few slides

535
00:19:30,400 --> 00:19:33,039
first we have a case of denial service

536
00:19:33,039 --> 00:19:35,840
found in the axios package

537
00:19:35,840 --> 00:19:38,799
the issue here is where axial streams

538
00:19:38,799 --> 00:19:40,559
will not be destroyed

539
00:19:40,559 --> 00:19:43,280
if it exceeds the value of max content

540
00:19:43,280 --> 00:19:44,640
length

541
00:19:44,640 --> 00:19:46,240
and having lots of them would lead to

542
00:19:46,240 --> 00:19:47,679
high cpu usage

543
00:19:47,679 --> 00:19:50,720
thus causing the denial of service

544
00:19:50,720 --> 00:19:53,760
normally this wouldn't be such a huge

545
00:19:53,760 --> 00:19:55,520
issue

546
00:19:55,520 --> 00:19:58,080
however axios is downloaded over 13

547
00:19:58,080 --> 00:19:58,559
million

548
00:19:58,559 --> 00:20:01,200
times a week and is depended on by at

549
00:20:01,200 --> 00:20:03,840
least 44 000 others

550
00:20:03,840 --> 00:20:06,320
this example highlights the potential

551
00:20:06,320 --> 00:20:08,000
for issues to be

552
00:20:08,000 --> 00:20:10,960
highly widespread

553
00:20:11,600 --> 00:20:14,480
next we have an issue of denial service

554
00:20:14,480 --> 00:20:16,880
through regular expressions

555
00:20:16,880 --> 00:20:20,159
found in the trim package this example

556
00:20:20,159 --> 00:20:22,240
also highlights on the potential for

557
00:20:22,240 --> 00:20:25,360
issues to be highly widespread the

558
00:20:25,360 --> 00:20:27,840
package is downloaded over 3.4 million

559
00:20:27,840 --> 00:20:29,200
times weekly

560
00:20:29,200 --> 00:20:32,840
and is used in over 371 thousand

561
00:20:32,840 --> 00:20:34,240
repositories

562
00:20:34,240 --> 00:20:36,240
if it look closer in the picture we can

563
00:20:36,240 --> 00:20:38,480
see that the issue was still being left

564
00:20:38,480 --> 00:20:38,960
open

565
00:20:38,960 --> 00:20:41,520
and was at least 7 days old when the

566
00:20:41,520 --> 00:20:43,919
screenshot was taken

567
00:20:43,919 --> 00:20:46,880
for such a widely used library the time

568
00:20:46,880 --> 00:20:49,280
to react to such issue may result in a

569
00:20:49,280 --> 00:20:52,480
more severe penalty

570
00:20:52,640 --> 00:20:54,320
cross-site scripting has been

571
00:20:54,320 --> 00:20:56,480
consistently one of opp's

572
00:20:56,480 --> 00:20:59,440
top 10 vulnerabilities here we see a

573
00:20:59,440 --> 00:21:01,120
particular case of

574
00:21:01,120 --> 00:21:05,120
x found in xxl job used by over 2000

575
00:21:05,120 --> 00:21:07,039
repositories

576
00:21:07,039 --> 00:21:09,360
this issue isn't going to reach as many

577
00:21:09,360 --> 00:21:10,480
end users

578
00:21:10,480 --> 00:21:13,600
as the previous two examples but it

579
00:21:13,600 --> 00:21:17,679
should not be left alone as well

580
00:21:17,679 --> 00:21:20,080
the omni-off package is vulnerable to

581
00:21:20,080 --> 00:21:22,400
crossset requests for the ray

582
00:21:22,400 --> 00:21:25,520
and it is rated as a high severity issue

583
00:21:25,520 --> 00:21:27,679
by nvd

584
00:21:27,679 --> 00:21:29,840
omnioff is a library that provides

585
00:21:29,840 --> 00:21:32,159
flexible multi-provider

586
00:21:32,159 --> 00:21:35,120
authentication for web applications and

587
00:21:35,120 --> 00:21:37,600
it is typically used in ruby on rails

588
00:21:37,600 --> 00:21:40,880
applications while the issue is only

589
00:21:40,880 --> 00:21:41,679
present in

590
00:21:41,679 --> 00:21:44,640
specific conditions it is written as a

591
00:21:44,640 --> 00:21:46,400
high severity issue

592
00:21:46,400 --> 00:21:48,720
as it can allow an account to

593
00:21:48,720 --> 00:21:49,679
authenticate as

594
00:21:49,679 --> 00:21:52,880
another account a ruby on real

595
00:21:52,880 --> 00:21:53,600
application

596
00:21:53,600 --> 00:21:56,159
could likely use the omni-off library

597
00:21:56,159 --> 00:21:57,280
for authentication

598
00:21:57,280 --> 00:22:00,400
in the unsafe manner and have this form

599
00:22:00,400 --> 00:22:03,520
baked right into the application in this

600
00:22:03,520 --> 00:22:05,520
specific example we can see that

601
00:22:05,520 --> 00:22:08,559
a warning has been added to the readme

602
00:22:08,559 --> 00:22:10,840
and it was not addressed directly in the

603
00:22:10,840 --> 00:22:12,559
library

604
00:22:12,559 --> 00:22:14,720
a possible reason might be due to the

605
00:22:14,720 --> 00:22:18,799
flexibility attribute of the library

606
00:22:19,520 --> 00:22:21,600
here's an attempt at security by

607
00:22:21,600 --> 00:22:23,919
obscurity in zen cli

608
00:22:23,919 --> 00:22:28,320
through a one word description patch

609
00:22:28,320 --> 00:22:30,640
the issue was caused by a weak regular

610
00:22:30,640 --> 00:22:32,480
expression that could not properly

611
00:22:32,480 --> 00:22:35,280
sanitize file paths

612
00:22:35,280 --> 00:22:36,960
these are some of the data points where

613
00:22:36,960 --> 00:22:38,960
we think that the machine learning

614
00:22:38,960 --> 00:22:39,440
approach

615
00:22:39,440 --> 00:22:41,600
shows its efficiency at discovering

616
00:22:41,600 --> 00:22:43,360
vulnerabilities at scale

617
00:22:43,360 --> 00:22:45,280
without the need to run any form of

618
00:22:45,280 --> 00:22:46,720
static or dynamic

619
00:22:46,720 --> 00:22:49,360
analysis

620
00:22:50,559 --> 00:22:53,440
an issue of arbitrary code execution was

621
00:22:53,440 --> 00:22:54,159
found where

622
00:22:54,159 --> 00:22:57,760
eval was used for json passing

623
00:22:57,760 --> 00:23:00,640
in this example it would be fairly easy

624
00:23:00,640 --> 00:23:02,640
to write a code password to find such

625
00:23:02,640 --> 00:23:04,159
issues

626
00:23:04,159 --> 00:23:06,400
but a larger issue would be the

627
00:23:06,400 --> 00:23:09,280
consideration to run all those at scale

628
00:23:09,280 --> 00:23:12,880
to run it on every external library used

629
00:23:12,880 --> 00:23:15,840
and every version that was used is used

630
00:23:15,840 --> 00:23:19,360
or will be used in the future

631
00:23:19,840 --> 00:23:22,320
finally we also find several transitive

632
00:23:22,320 --> 00:23:23,200
issues

633
00:23:23,200 --> 00:23:25,600
through the data and there are many more

634
00:23:25,600 --> 00:23:26,799
and we can go

635
00:23:26,799 --> 00:23:30,480
on for a day at this point you would

636
00:23:30,480 --> 00:23:32,640
probably have a better understanding of

637
00:23:32,640 --> 00:23:34,640
the risks

638
00:23:34,640 --> 00:23:36,559
so i will be sharing some of our key

639
00:23:36,559 --> 00:23:41,039
observations from processing these data

640
00:23:41,360 --> 00:23:43,760
from the examples we have noted that

641
00:23:43,760 --> 00:23:45,679
third party dependencies are vulnerable

642
00:23:45,679 --> 00:23:46,720
to the same

643
00:23:46,720 --> 00:23:49,520
type of code flaws and faces the same

644
00:23:49,520 --> 00:23:51,360
issues of fixing

645
00:23:51,360 --> 00:23:55,440
transitive issues by keeping frequently

646
00:23:55,440 --> 00:23:58,400
up to speed on the data that matters we

647
00:23:58,400 --> 00:23:59,760
are able to discover

648
00:23:59,760 --> 00:24:04,159
and act on these issues earlier

649
00:24:04,159 --> 00:24:06,000
now you might be wondering apart from

650
00:24:06,000 --> 00:24:07,440
malicious quote

651
00:24:07,440 --> 00:24:10,559
introduced by social engineering attack

652
00:24:10,559 --> 00:24:14,000
how serious can this get

653
00:24:14,000 --> 00:24:17,600
well to emphasize on the issue at hand

654
00:24:17,600 --> 00:24:19,679
we have seen new classes of highly

655
00:24:19,679 --> 00:24:21,840
critical vulnerabilities uncovered from

656
00:24:21,840 --> 00:24:23,279
time to time

657
00:24:23,279 --> 00:24:26,159
and affects existing code which may be

658
00:24:26,159 --> 00:24:27,840
widely used

659
00:24:27,840 --> 00:24:31,520
into this application this serialization

660
00:24:31,520 --> 00:24:32,240
issue

661
00:24:32,240 --> 00:24:35,760
such as those injection data buying

662
00:24:35,760 --> 00:24:38,080
arbitrary file or write true unzip

663
00:24:38,080 --> 00:24:40,000
functions

664
00:24:40,000 --> 00:24:42,880
the issue of prototype pollution these

665
00:24:42,880 --> 00:24:45,279
have all been observed to be widespread

666
00:24:45,279 --> 00:24:48,960
when they were first discovered and

667
00:24:48,960 --> 00:24:50,960
as the number of libraries are expected

668
00:24:50,960 --> 00:24:53,039
to increase with time

669
00:24:53,039 --> 00:24:56,080
it is also much more probable that newly

670
00:24:56,080 --> 00:24:58,840
discovered flaws can affect even more

671
00:24:58,840 --> 00:25:00,799
applications

672
00:25:00,799 --> 00:25:04,159
so to really be somewhat be safe

673
00:25:04,159 --> 00:25:06,400
we have to know what we are using

674
00:25:06,400 --> 00:25:08,320
whether they have known vulnerabilities

675
00:25:08,320 --> 00:25:11,760
and to actively keep up with this

676
00:25:11,760 --> 00:25:14,880
as a new flaw may be discovered at any

677
00:25:14,880 --> 00:25:18,320
point of time in the future

678
00:25:19,520 --> 00:25:21,600
now that we have a sort of baseline on

679
00:25:21,600 --> 00:25:23,679
what information is out there

680
00:25:23,679 --> 00:25:25,919
we can also think about taking the

681
00:25:25,919 --> 00:25:28,240
approach a step forward by discovering

682
00:25:28,240 --> 00:25:30,000
similar vulnerabilities in other

683
00:25:30,000 --> 00:25:31,760
libraries

684
00:25:31,760 --> 00:25:34,000
while this is still an ongoing work in

685
00:25:34,000 --> 00:25:34,799
progress

686
00:25:34,799 --> 00:25:37,679
the general concept is to be able to

687
00:25:37,679 --> 00:25:39,200
automatically sync up

688
00:25:39,200 --> 00:25:41,039
potential libraries that may be

689
00:25:41,039 --> 00:25:43,360
vulnerable to an existing vulnerability

690
00:25:43,360 --> 00:25:45,120
type

691
00:25:45,120 --> 00:25:47,760
further for each pattern we could come

692
00:25:47,760 --> 00:25:49,919
up with a key signature to automatically

693
00:25:49,919 --> 00:25:52,159
create a proof of concept

694
00:25:52,159 --> 00:25:54,240
and to test if an application or

695
00:25:54,240 --> 00:25:56,000
third-party library will produce

696
00:25:56,000 --> 00:26:00,080
positive results it is like

697
00:26:00,080 --> 00:26:02,880
running a targeted dynamic analytics

698
00:26:02,880 --> 00:26:04,320
scan

699
00:26:04,320 --> 00:26:06,640
and it may not be possible to

700
00:26:06,640 --> 00:26:07,840
automatically create

701
00:26:07,840 --> 00:26:10,480
a proof of concept for all known types

702
00:26:10,480 --> 00:26:12,850
of vulnerabilities

703
00:26:12,850 --> 00:26:15,200
[Music]

704
00:26:15,200 --> 00:26:17,520
to conclude this talk we have three

705
00:26:17,520 --> 00:26:20,080
points to make

706
00:26:20,080 --> 00:26:22,640
so we have to continuously be on the

707
00:26:22,640 --> 00:26:24,320
lookout for issues

708
00:26:24,320 --> 00:26:27,520
in our dependencies the number of

709
00:26:27,520 --> 00:26:28,480
dependencies

710
00:26:28,480 --> 00:26:31,039
increases over time and so does new

711
00:26:31,039 --> 00:26:33,520
types of vulnerabilities

712
00:26:33,520 --> 00:26:35,919
code that may look secure today may

713
00:26:35,919 --> 00:26:36,559
actually be

714
00:26:36,559 --> 00:26:40,000
insecure in the future the machine

715
00:26:40,000 --> 00:26:41,279
learning approach is not

716
00:26:41,279 --> 00:26:43,200
self-sufficient and can still be

717
00:26:43,200 --> 00:26:45,600
improved upon

718
00:26:45,600 --> 00:26:47,679
and that what we have discussed today

719
00:26:47,679 --> 00:26:49,039
does not cover

720
00:26:49,039 --> 00:26:52,720
all actual prevailing vulnerabilities

721
00:26:52,720 --> 00:26:55,679
so at the very least we should try to be

722
00:26:55,679 --> 00:26:56,240
on par

723
00:26:56,240 --> 00:26:58,240
with already disclosed known

724
00:26:58,240 --> 00:26:59,520
vulnerabilities

725
00:26:59,520 --> 00:27:01,440
while we continue to discover more

726
00:27:01,440 --> 00:27:04,840
vulnerabilities through different

727
00:27:04,840 --> 00:27:06,480
methods

728
00:27:06,480 --> 00:27:09,360
i hope we have brought across the idea

729
00:27:09,360 --> 00:27:09,600
of

730
00:27:09,600 --> 00:27:11,840
how we can discover vulnerabilities

731
00:27:11,840 --> 00:27:12,799
quicker

732
00:27:12,799 --> 00:27:16,159
for faster response to learn from what

733
00:27:16,159 --> 00:27:19,279
is out there and to develop an

734
00:27:19,279 --> 00:27:21,200
intuition to finding similar

735
00:27:21,200 --> 00:27:23,520
vulnerabilities that are out there

736
00:27:23,520 --> 00:27:27,120
thank you

