1
00:00:00,030 --> 00:00:06,420
so hi good morning everyone welcome to

2
00:00:02,399 --> 00:00:09,269
this session called the fish simulating

3
00:00:06,420 --> 00:00:09,750
malicious AI my name is Alejandro

4
00:00:09,269 --> 00:00:13,139
Carrera

5
00:00:09,750 --> 00:00:16,859
I work as VP of a and research at sixth

6
00:00:13,139 --> 00:00:20,640
era technology and allow me very quickly

7
00:00:16,859 --> 00:00:24,060
before I get into the whole content to

8
00:00:20,640 --> 00:00:26,369
introduce myself so I'm an industrial

9
00:00:24,060 --> 00:00:29,640
engineer with a background in financial

10
00:00:26,369 --> 00:00:31,980
engineer who was able to change very

11
00:00:29,640 --> 00:00:34,410
quickly to do a PhD in machine learning

12
00:00:31,980 --> 00:00:37,860
I did this in the University of

13
00:00:34,410 --> 00:00:41,550
Luxembourg where I was working part time

14
00:00:37,860 --> 00:00:45,840
also doing fraud detection models I have

15
00:00:41,550 --> 00:00:48,870
been very close to the whole open source

16
00:00:45,840 --> 00:00:52,829
ecosystem starting I used to do a lot of

17
00:00:48,870 --> 00:00:54,660
work as a contributor to Saiki learn if

18
00:00:52,829 --> 00:00:56,430
you have done much you learning in

19
00:00:54,660 --> 00:00:59,879
Python I'm pretty sure you have used

20
00:00:56,430 --> 00:01:02,730
cyclin at some point and I'm also have

21
00:00:59,879 --> 00:01:06,240
been very active organizing data science

22
00:01:02,730 --> 00:01:09,030
meetups wherever I'm living at the

23
00:01:06,240 --> 00:01:11,009
moment I have worked for a lot of

24
00:01:09,030 --> 00:01:15,780
different organizations and over the

25
00:01:11,010 --> 00:01:19,830
last four years I have been working at

26
00:01:15,780 --> 00:01:22,140
six Terra technologies as initially as

27
00:01:19,830 --> 00:01:28,710
chief data scientist right nowadays as

28
00:01:22,140 --> 00:01:32,880
VP of research so what I'm going to talk

29
00:01:28,710 --> 00:01:35,610
about you guys today it is a summary of

30
00:01:32,880 --> 00:01:38,490
the whole of three research papers that

31
00:01:35,610 --> 00:01:41,280
we wrote this year so everything that

32
00:01:38,490 --> 00:01:46,589
I'm going to tell you it's actually on

33
00:01:41,280 --> 00:01:49,530
the on those research papers and most of

34
00:01:46,590 --> 00:01:52,140
the things is actually I just put it

35
00:01:49,530 --> 00:01:53,840
yesterday on github so I will share all

36
00:01:52,140 --> 00:01:57,360
of that with you later

37
00:01:53,840 --> 00:02:01,350
first I'm going to talk about much in

38
00:01:57,360 --> 00:02:04,250
learning to detecting official URLs then

39
00:02:01,350 --> 00:02:08,549
deep learning to attack malicious er

40
00:02:04,250 --> 00:02:11,640
certificates lastly the last paper d

41
00:02:08,550 --> 00:02:13,890
fresh stimulating malicious AI and for

42
00:02:11,640 --> 00:02:16,950
some reason I decided to do a life

43
00:02:13,890 --> 00:02:19,410
so let's see how that goes

44
00:02:16,950 --> 00:02:26,040
I'm very proud that I was able to put

45
00:02:19,410 --> 00:02:27,870
all the buzzwords in one slide so what

46
00:02:26,040 --> 00:02:30,239
is fishing and I'm pretty sure we all

47
00:02:27,870 --> 00:02:35,730
all are very familiar with this but I

48
00:02:30,240 --> 00:02:37,770
still want to get everyone into the kind

49
00:02:35,730 --> 00:02:41,100
of fishing that I'm trying to detect so

50
00:02:37,770 --> 00:02:45,209
you have your average user in a lot of

51
00:02:41,100 --> 00:02:48,720
cases either financial user or consumer

52
00:02:45,209 --> 00:02:50,910
user that receive tons of this kind of

53
00:02:48,720 --> 00:02:54,300
emails every day so you need to change

54
00:02:50,910 --> 00:02:56,880
your your password because your account

55
00:02:54,300 --> 00:02:58,739
has been compromised or you receive more

56
00:02:56,880 --> 00:03:02,100
money please login into your banking

57
00:02:58,739 --> 00:03:06,090
account to confirm the user goat goes in

58
00:03:02,100 --> 00:03:08,519
here and most users if there isn't any

59
00:03:06,090 --> 00:03:11,459
solution that block that access the

60
00:03:08,520 --> 00:03:14,430
users are going to end up putting their

61
00:03:11,459 --> 00:03:17,250
credentials into that into outsides now

62
00:03:14,430 --> 00:03:19,260
and the fact is we can talk about more

63
00:03:17,250 --> 00:03:21,090
complex things and actually I love

64
00:03:19,260 --> 00:03:24,929
talking about more complex things but

65
00:03:21,090 --> 00:03:28,860
91% of cyber attacks still start with a

66
00:03:24,930 --> 00:03:31,110
phishing email so we have still a lot of

67
00:03:28,860 --> 00:03:34,230
things to do in order to keep protecting

68
00:03:31,110 --> 00:03:37,620
ourselves and our users for from

69
00:03:34,230 --> 00:03:39,420
phishing so what

70
00:03:37,620 --> 00:03:42,739
why phishing detection is hard and I'm

71
00:03:39,420 --> 00:03:45,809
going to talk up in a machine-learning

72
00:03:42,739 --> 00:03:47,519
setting so why creating a machine

73
00:03:45,810 --> 00:03:51,150
learning model to attacked phishing is

74
00:03:47,519 --> 00:03:53,880
hard you have the original original

75
00:03:51,150 --> 00:03:57,030
website and you have a lot of strategies

76
00:03:53,880 --> 00:04:02,670
their attackers use and actually change

77
00:03:57,030 --> 00:04:05,220
every year or so so 2016 or 2017 we saw

78
00:04:02,670 --> 00:04:07,649
a lot of phishing attacks in which they

79
00:04:05,220 --> 00:04:09,750
were just putting images and screenshots

80
00:04:07,650 --> 00:04:12,900
of the actual of the original website

81
00:04:09,750 --> 00:04:15,329
now why because the algorithms at the

82
00:04:12,900 --> 00:04:17,399
moment we're looking for keywords so

83
00:04:15,329 --> 00:04:20,418
they decided to do these kind of things

84
00:04:17,399 --> 00:04:23,940
to avoid being detected by searched

85
00:04:20,418 --> 00:04:26,520
algorithms then we started using

86
00:04:23,940 --> 00:04:27,660
computer vision algorithms so that a

87
00:04:26,520 --> 00:04:30,719
strategy

88
00:04:27,660 --> 00:04:33,840
work anymore but nowadays we see

89
00:04:30,720 --> 00:04:35,640
attackers using at the beginning they

90
00:04:33,840 --> 00:04:38,640
were trying just to replicate the

91
00:04:35,640 --> 00:04:40,169
website nowadays they know the user is

92
00:04:38,640 --> 00:04:42,120
just going to put their credentials so

93
00:04:40,170 --> 00:04:45,990
why don't ask for the social security

94
00:04:42,120 --> 00:04:51,330
number right away and users actually end

95
00:04:45,990 --> 00:04:53,370
up doing that so the ideal again machine

96
00:04:51,330 --> 00:04:57,450
learning phishing detection system is a

97
00:04:53,370 --> 00:05:00,420
system that receive the original website

98
00:04:57,450 --> 00:05:02,760
they extract all the images extract all

99
00:05:00,420 --> 00:05:06,650
the text extract all the source code all

100
00:05:02,760 --> 00:05:08,010
the references then you put that into

101
00:05:06,650 --> 00:05:10,560
fancy

102
00:05:08,010 --> 00:05:13,500
well no real funky random forest

103
00:05:10,560 --> 00:05:16,470
algorithm and you get the probability of

104
00:05:13,500 --> 00:05:18,660
that site being efficient and this kind

105
00:05:16,470 --> 00:05:22,040
of algorithms actually work if you give

106
00:05:18,660 --> 00:05:25,890
them enough data what is the issue that

107
00:05:22,040 --> 00:05:29,280
the time for respond is actually very

108
00:05:25,890 --> 00:05:31,830
it's actually quite consuming and you

109
00:05:29,280 --> 00:05:34,979
cannot use this kind of systems on

110
00:05:31,830 --> 00:05:37,320
mobile devices that is just not going to

111
00:05:34,980 --> 00:05:40,020
work you normally need even GPUs if you

112
00:05:37,320 --> 00:05:43,500
want to use complex algorithms so you

113
00:05:40,020 --> 00:05:46,710
can actually deploy very scalable api's

114
00:05:43,500 --> 00:05:48,810
but in a lot of cases you are not even

115
00:05:46,710 --> 00:05:51,780
allowed to send all of that information

116
00:05:48,810 --> 00:05:54,090
into your into your API so you need to

117
00:05:51,780 --> 00:05:58,609
came up with solutions that you can run

118
00:05:54,090 --> 00:06:04,039
very quickly on any device and for that

119
00:05:58,610 --> 00:06:09,000
we started to investigate some time ago

120
00:06:04,040 --> 00:06:13,169
why if we use only the URL and use that

121
00:06:09,000 --> 00:06:16,140
as a very quick as a very quick way to

122
00:06:13,169 --> 00:06:20,070
analyze if the website is being used for

123
00:06:16,140 --> 00:06:24,690
fishing so what we created our research

124
00:06:20,070 --> 00:06:27,870
question was are we able with the URL to

125
00:06:24,690 --> 00:06:33,390
capture fishing patterns that allow us

126
00:06:27,870 --> 00:06:36,450
to quickly run websites and and then

127
00:06:33,390 --> 00:06:41,020
being able to scale a scale if we have

128
00:06:36,450 --> 00:06:44,710
alerts or so on so in order to do that

129
00:06:41,020 --> 00:06:45,450
we collected about only Leon fishing

130
00:06:44,710 --> 00:06:48,099
URLs

131
00:06:45,450 --> 00:06:51,010
most of them from fish tank but also

132
00:06:48,100 --> 00:06:55,060
from other sources or even internal

133
00:06:51,010 --> 00:06:58,690
sources we also collect initially about

134
00:06:55,060 --> 00:07:01,270
100 million legitimate URLs now at the

135
00:06:58,690 --> 00:07:04,330
end we end up with about a million the

136
00:07:01,270 --> 00:07:06,340
the easiest ways to do this to represent

137
00:07:04,330 --> 00:07:11,859
the whole Internet is to use common

138
00:07:06,340 --> 00:07:14,349
crawl and then we fit all that

139
00:07:11,860 --> 00:07:16,750
information into in this case a deep

140
00:07:14,350 --> 00:07:18,760
learning model in particular a recurrent

141
00:07:16,750 --> 00:07:21,190
neural network without going into much

142
00:07:18,760 --> 00:07:25,599
detail about that what is interesting is

143
00:07:21,190 --> 00:07:29,290
that each input of the neural network is

144
00:07:25,600 --> 00:07:31,870
one character of the URL so what we are

145
00:07:29,290 --> 00:07:35,740
trying to do is to allow the you are at

146
00:07:31,870 --> 00:07:39,000
the Algrim to attack the patterns inside

147
00:07:35,740 --> 00:07:42,880
the sequence of characters of the URL a

148
00:07:39,000 --> 00:07:45,490
more detailed explanation of the

149
00:07:42,880 --> 00:07:48,400
algorithm goes this way so we put as an

150
00:07:45,490 --> 00:07:51,580
input all the characters of the URL you

151
00:07:48,400 --> 00:07:54,700
we we do a process normally done as a

152
00:07:51,580 --> 00:07:57,099
one-hole encoding and an embedding and

153
00:07:54,700 --> 00:08:03,130
finally we add an additional layer

154
00:07:57,100 --> 00:08:05,680
called a long-term memory network the

155
00:08:03,130 --> 00:08:07,840
output is just a sigmoid sigmoid here is

156
00:08:05,680 --> 00:08:10,600
going to give us a probability of that

157
00:08:07,840 --> 00:08:16,659
sequence of characters being used for

158
00:08:10,600 --> 00:08:20,050
fishing or not so right away two results

159
00:08:16,660 --> 00:08:22,000
on this one so the accuracy of the of

160
00:08:20,050 --> 00:08:25,780
this are going with those two million

161
00:08:22,000 --> 00:08:27,430
URLs almost 99% and that is amazing if

162
00:08:25,780 --> 00:08:30,369
you take into account that you are using

163
00:08:27,430 --> 00:08:34,360
the URL just as a string you are not

164
00:08:30,370 --> 00:08:37,390
doing any further analysis or even a

165
00:08:34,360 --> 00:08:40,060
ping in anywhere just just using the

166
00:08:37,390 --> 00:08:42,909
string of characters and with that you

167
00:08:40,059 --> 00:08:47,229
are able to attack with 98% of accuracy

168
00:08:42,909 --> 00:08:49,449
that a URL is being used for fishing or

169
00:08:47,230 --> 00:08:51,010
not and the good thing about this is

170
00:08:49,450 --> 00:08:54,130
that you can actually implement this on

171
00:08:51,010 --> 00:08:54,680
a mobile device without needing much

172
00:08:54,130 --> 00:09:03,100
real

173
00:08:54,680 --> 00:09:08,209
resources um so basically yeah I did it

174
00:09:03,100 --> 00:09:09,470
awesome and what happened here was two

175
00:09:08,210 --> 00:09:12,920
things first

176
00:09:09,470 --> 00:09:14,899
I ended sue me I am that submitted my

177
00:09:12,920 --> 00:09:16,520
presentation for a 50 minute talk so I

178
00:09:14,899 --> 00:09:20,980
have to come up with more things to talk

179
00:09:16,520 --> 00:09:23,990
about but more interesting though

180
00:09:20,980 --> 00:09:26,630
detecting phishing URLs is a very good

181
00:09:23,990 --> 00:09:35,959
starting point but it's definitely not

182
00:09:26,630 --> 00:09:39,680
enough so then one of the trends that we

183
00:09:35,959 --> 00:09:44,089
have been seen lately is that phishing

184
00:09:39,680 --> 00:09:46,310
attacks are using web certificates and I

185
00:09:44,089 --> 00:09:49,430
know for some of you the answer of wise

186
00:09:46,310 --> 00:09:53,750
obvious but let me elaborate on that

187
00:09:49,430 --> 00:09:56,180
so in fact by the end of 2017 almost a

188
00:09:53,750 --> 00:10:02,959
quarter of the phishing attacks were

189
00:09:56,180 --> 00:10:06,739
using web certificates so what is a web

190
00:10:02,959 --> 00:10:09,290
certificate and the issue as you can

191
00:10:06,740 --> 00:10:12,830
imagine is that for me for most users

192
00:10:09,290 --> 00:10:18,260
it's just what gave them the green

193
00:10:12,830 --> 00:10:22,180
padlock and the secure keywords so if

194
00:10:18,260 --> 00:10:25,130
you go to a user and just by adding a

195
00:10:22,180 --> 00:10:29,779
free web certificate into a phishing

196
00:10:25,130 --> 00:10:33,110
site you go from the ultra Bank URL

197
00:10:29,779 --> 00:10:36,860
without the HTTPS and then you go to the

198
00:10:33,110 --> 00:10:39,470
secure HTTPS in green with a green

199
00:10:36,860 --> 00:10:43,310
padlock what can you imagine your

200
00:10:39,470 --> 00:10:49,120
average user is going to think so

201
00:10:43,310 --> 00:10:53,599
actually Forrester asked did did a quick

202
00:10:49,120 --> 00:10:55,790
survey asking users what does the green

203
00:10:53,600 --> 00:11:00,070
padlock and the secure key word means

204
00:10:55,790 --> 00:11:03,529
and what do you think the users

205
00:11:00,070 --> 00:11:05,810
responded to that how many users are

206
00:11:03,529 --> 00:11:07,910
going to respond that the communication

207
00:11:05,810 --> 00:11:09,939
between the webpage and the server is

208
00:11:07,910 --> 00:11:09,939
encrypted

209
00:11:09,970 --> 00:11:14,680
how many users are going to say the

210
00:11:12,440 --> 00:11:18,470
website is safe

211
00:11:14,680 --> 00:11:21,140
so in fact 82% of the users said that

212
00:11:18,470 --> 00:11:23,960
the website is safe and that's scary

213
00:11:21,140 --> 00:11:27,080
because how much that is cost to an

214
00:11:23,960 --> 00:11:30,320
average attacker to put a web

215
00:11:27,080 --> 00:11:34,070
certificate into a phishing site in a

216
00:11:30,320 --> 00:11:35,900
lot of cases nothing is just and you can

217
00:11:34,070 --> 00:11:40,970
do that programmatically so is actually

218
00:11:35,900 --> 00:11:42,380
very easy thing to a lot of users say

219
00:11:40,970 --> 00:11:44,360
that the website is encrypted

220
00:11:42,380 --> 00:11:45,950
seventy-five percent even though that is

221
00:11:44,360 --> 00:11:48,650
not the complete answer is the most

222
00:11:45,950 --> 00:11:52,370
closer to one to the to the actual one

223
00:11:48,650 --> 00:11:55,340
and the website is trustworthy and the

224
00:11:52,370 --> 00:11:57,800
website is private but the first one the

225
00:11:55,340 --> 00:12:00,920
website is safe we all know there is not

226
00:11:57,800 --> 00:12:03,740
true but we have been teaching our users

227
00:12:00,920 --> 00:12:06,380
that when they see a green padlock is

228
00:12:03,740 --> 00:12:09,740
because everything is safe and you can

229
00:12:06,380 --> 00:12:11,860
click there and suddenly we decided to

230
00:12:09,740 --> 00:12:15,670
put that information to the user

231
00:12:11,860 --> 00:12:17,930
probably given them more context but its

232
00:12:15,670 --> 00:12:21,079
technical context that they are not

233
00:12:17,930 --> 00:12:23,810
going to to actually understand so there

234
00:12:21,080 --> 00:12:26,990
is not surprised that attackers are

235
00:12:23,810 --> 00:12:32,390
nowadays using way more web certificate

236
00:12:26,990 --> 00:12:36,260
on their attacks so we cannot really

237
00:12:32,390 --> 00:12:38,900
rely on the user thinking about first

238
00:12:36,260 --> 00:12:43,520
teaching them what encrypted means

239
00:12:38,900 --> 00:12:47,090
different from crypto so another even

240
00:12:43,520 --> 00:12:49,850
more complicated so we create with it

241
00:12:47,090 --> 00:12:54,680
another research project and this was at

242
00:12:49,850 --> 00:12:56,300
the end of last year call well the long

243
00:12:54,680 --> 00:12:58,250
name hunting malicious delayed

244
00:12:56,300 --> 00:13:02,780
certificates with deep neural networks

245
00:12:58,250 --> 00:13:04,700
more simplistic we wanted to fit web

246
00:13:02,780 --> 00:13:08,030
certificates to a machine learning

247
00:13:04,700 --> 00:13:10,310
algorithm to be able to tell us which

248
00:13:08,030 --> 00:13:13,880
work certificates are going to be used

249
00:13:10,310 --> 00:13:20,359
or follows the patterns of malicious web

250
00:13:13,880 --> 00:13:22,490
certificates so we collected well

251
00:13:20,360 --> 00:13:25,150
actually yeah a million legitimate

252
00:13:22,490 --> 00:13:28,220
birth certificate from criminal about

253
00:13:25,150 --> 00:13:30,770
5000 fishing certificates when we were

254
00:13:28,220 --> 00:13:33,530
doing this analysis nowadays we were

255
00:13:30,770 --> 00:13:35,960
able to collect more the hard part about

256
00:13:33,530 --> 00:13:39,350
collecting what certificate is that you

257
00:13:35,960 --> 00:13:42,760
can all only get them while the website

258
00:13:39,350 --> 00:13:45,740
while the fishing website is life so

259
00:13:42,760 --> 00:13:48,530
collecting fishing URLs is easier

260
00:13:45,740 --> 00:13:50,660
because you can go and if the site was

261
00:13:48,530 --> 00:13:54,459
already taken down you can still collect

262
00:13:50,660 --> 00:14:00,050
that but web certificate is harder and

263
00:13:54,460 --> 00:14:03,080
very quickly this is just a hint of what

264
00:14:00,050 --> 00:14:06,890
we were able to do you can see that the

265
00:14:03,080 --> 00:14:09,980
fishing certificate tends to contain the

266
00:14:06,890 --> 00:14:11,900
standard information normally used by

267
00:14:09,980 --> 00:14:15,050
let's encrypt so you see a lot of

268
00:14:11,900 --> 00:14:18,079
examples and calm lot localhost that

269
00:14:15,050 --> 00:14:21,890
local domain because at the end the

270
00:14:18,080 --> 00:14:24,890
attacker does not want I mean his whole

271
00:14:21,890 --> 00:14:26,870
objective is to get that secure keyword

272
00:14:24,890 --> 00:14:30,800
not really to put any additional

273
00:14:26,870 --> 00:14:33,440
information there so we were able to

274
00:14:30,800 --> 00:14:35,630
start seeing those patterns and is what

275
00:14:33,440 --> 00:14:39,830
we end up seeing that the algorithm at

276
00:14:35,630 --> 00:14:43,370
end up doing so in this case we fit all

277
00:14:39,830 --> 00:14:45,950
of those web certificates into a into a

278
00:14:43,370 --> 00:14:47,960
deep neural network in particular this

279
00:14:45,950 --> 00:14:50,890
is the architecture of that neural

280
00:14:47,960 --> 00:14:54,770
network and it contains a lot of layers

281
00:14:50,890 --> 00:14:58,840
some long-term memory networks combined

282
00:14:54,770 --> 00:15:01,340
with some dense layers it looks complex

283
00:14:58,840 --> 00:15:03,860
because we were submitting that paper to

284
00:15:01,340 --> 00:15:05,570
a machine learning conference no not

285
00:15:03,860 --> 00:15:08,870
really because you have to make it that

286
00:15:05,570 --> 00:15:11,360
complex again all of that is on the

287
00:15:08,870 --> 00:15:14,990
paper if you are if you are working on

288
00:15:11,360 --> 00:15:18,320
on this particular field and the results

289
00:15:14,990 --> 00:15:21,680
were that we were able to attack

290
00:15:18,320 --> 00:15:24,620
efficient the usage of a web certificate

291
00:15:21,680 --> 00:15:26,719
for phishing with 86% of accuracy and

292
00:15:24,620 --> 00:15:29,270
that is amazing if you take into account

293
00:15:26,720 --> 00:15:32,330
how much how little information you can

294
00:15:29,270 --> 00:15:36,079
find on a website if ax Kate so just by

295
00:15:32,330 --> 00:15:39,290
using so just by using this kind of

296
00:15:36,080 --> 00:15:43,250
dreams you actually are able to of

297
00:15:39,290 --> 00:15:45,050
course not with a berry not it's not a

298
00:15:43,250 --> 00:15:47,210
deterministic model so you are going to

299
00:15:45,050 --> 00:15:49,550
have some false positives but this allow

300
00:15:47,210 --> 00:15:51,140
you to filter very quickly all the web

301
00:15:49,550 --> 00:15:54,140
certificates that are passing by your

302
00:15:51,140 --> 00:15:57,650
network and everything that is that have

303
00:15:54,140 --> 00:16:00,290
a very high score according to some of

304
00:15:57,650 --> 00:16:04,640
these models you can put them as an

305
00:16:00,290 --> 00:16:08,719
alert to further investigate them of

306
00:16:04,640 --> 00:16:11,540
course something that I'm well aware is

307
00:16:08,720 --> 00:16:14,240
that just by doing this presentation I

308
00:16:11,540 --> 00:16:17,300
don't I assumed attacked some attackers

309
00:16:14,240 --> 00:16:19,520
are going to then make more complex web

310
00:16:17,300 --> 00:16:22,040
certificates at the end is something

311
00:16:19,520 --> 00:16:23,540
easy to do at that point I will probably

312
00:16:22,040 --> 00:16:27,349
will have to go back to the drawing

313
00:16:23,540 --> 00:16:30,439
board and and check how make my

314
00:16:27,350 --> 00:16:33,320
algorithm even more complex but the

315
00:16:30,440 --> 00:16:35,570
point here is that using these tools in

316
00:16:33,320 --> 00:16:38,180
a very specific using machine learning

317
00:16:35,570 --> 00:16:41,330
in a very specific scenario with a very

318
00:16:38,180 --> 00:16:43,910
defined objective is actually very

319
00:16:41,330 --> 00:16:47,450
feasible and actually helps help you to

320
00:16:43,910 --> 00:16:51,140
enhance a lot your whole process to be

321
00:16:47,450 --> 00:16:53,540
more proactive because if you if you are

322
00:16:51,140 --> 00:16:56,510
familiar with this currently the way and

323
00:16:53,540 --> 00:16:59,180
the browsers analyze web certificate

324
00:16:56,510 --> 00:17:02,330
they just check if there if the web

325
00:16:59,180 --> 00:17:03,680
certificate is on a blacklist with this

326
00:17:02,330 --> 00:17:12,709
kind of tools you can be way more

327
00:17:03,680 --> 00:17:15,709
proactive but once more I'm here having

328
00:17:12,709 --> 00:17:19,699
to the end to the actual to the big part

329
00:17:15,709 --> 00:17:24,080
of my presentation so every action has a

330
00:17:19,699 --> 00:17:26,690
fraudster reaction he's probably the

331
00:17:24,079 --> 00:17:30,080
only a slide that I allow my marketing

332
00:17:26,690 --> 00:17:34,580
department to put on my deck but I like

333
00:17:30,080 --> 00:17:36,970
it um what is the last the latest trend

334
00:17:34,580 --> 00:17:40,909
well actually what is the latest

335
00:17:36,970 --> 00:17:43,610
marketing trend some AI cyber attacks

336
00:17:40,910 --> 00:17:46,550
will be almost impossible for human to

337
00:17:43,610 --> 00:17:49,280
stop six ways hackers will use machine

338
00:17:46,550 --> 00:17:52,659
learning to launch attacks and how AI

339
00:17:49,280 --> 00:17:54,940
can be applied to enhance cyber attacks

340
00:17:52,660 --> 00:17:56,240
so we start seeing a lot of this

341
00:17:54,940 --> 00:18:00,680
articles

342
00:17:56,240 --> 00:18:04,940
last year and when I was walking into

343
00:18:00,680 --> 00:18:07,730
either the one of these conference

344
00:18:04,940 --> 00:18:10,280
expose it was very interesting to see a

345
00:18:07,730 --> 00:18:12,890
lot of vendors talking about this but in

346
00:18:10,280 --> 00:18:16,340
front roughly there wasn't any technical

347
00:18:12,890 --> 00:18:20,630
guy explaining me how that was actually

348
00:18:16,340 --> 00:18:24,980
doable so I decided to assign two guys

349
00:18:20,630 --> 00:18:29,000
of my team to work on how can you

350
00:18:24,980 --> 00:18:31,610
enhance their the attacks of a of a

351
00:18:29,000 --> 00:18:34,940
cyber criminal in particular how can you

352
00:18:31,610 --> 00:18:36,020
create a system that creates better

353
00:18:34,940 --> 00:18:39,500
phishing attacks

354
00:18:36,020 --> 00:18:43,220
and the way to evaluate that is actually

355
00:18:39,500 --> 00:18:45,380
how can you bypass our own systems so we

356
00:18:43,220 --> 00:18:51,550
end up creating this research project

357
00:18:45,380 --> 00:18:55,430
and if fish simulating malicious AI and

358
00:18:51,550 --> 00:18:59,360
the process of a project goes as follows

359
00:18:55,430 --> 00:19:02,540
so first the experiment we needed to in

360
00:18:59,360 --> 00:19:06,770
the to identify at the individual threat

361
00:19:02,540 --> 00:19:10,070
actors on the fishing on on the fishing

362
00:19:06,770 --> 00:19:12,080
side so we needed to know this set of

363
00:19:10,070 --> 00:19:15,350
phishing attacks belong to a same threat

364
00:19:12,080 --> 00:19:18,050
actor why because we needed to be able

365
00:19:15,350 --> 00:19:19,879
to analyze how their current strategies

366
00:19:18,050 --> 00:19:23,330
and which are their current strategies

367
00:19:19,880 --> 00:19:27,470
to create in dogs vision attacks so then

368
00:19:23,330 --> 00:19:32,270
we can so so then we were able to create

369
00:19:27,470 --> 00:19:35,090
a system that uses AI to create new

370
00:19:32,270 --> 00:19:39,560
phishing attacks so that was the

371
00:19:35,090 --> 00:19:42,560
experiment that we created first as I

372
00:19:39,560 --> 00:19:45,139
was showing you we needed to uncover the

373
00:19:42,560 --> 00:19:50,000
threat actors and the thing is that or

374
00:19:45,140 --> 00:19:54,590
when you are analyzing financial fish is

375
00:19:50,000 --> 00:19:56,860
normally a very it's normally a strategy

376
00:19:54,590 --> 00:20:00,379
in which the attacker wants to deploy

377
00:19:56,860 --> 00:20:01,510
millions of attacks with that with the

378
00:20:00,380 --> 00:20:05,380
less

379
00:20:01,510 --> 00:20:07,510
effort as possible and meaning you

380
00:20:05,380 --> 00:20:10,330
normally don't have time to stop and

381
00:20:07,510 --> 00:20:13,059
analyze why we stress actors are

382
00:20:10,330 --> 00:20:16,120
targeting which particular financial

383
00:20:13,059 --> 00:20:19,020
institution so it was important for us

384
00:20:16,120 --> 00:20:22,199
to go back and actually understand

385
00:20:19,020 --> 00:20:27,490
different strategies used by different

386
00:20:22,200 --> 00:20:29,559
by different different attackers and we

387
00:20:27,490 --> 00:20:32,860
of course were not able to see that

388
00:20:29,559 --> 00:20:35,649
directly so we needed to learn that from

389
00:20:32,860 --> 00:20:40,510
the actual attacks so we had a database

390
00:20:35,650 --> 00:20:44,650
of about 1.1 million confirm fish in

391
00:20:40,510 --> 00:20:49,629
URLs and what we did though was a very

392
00:20:44,650 --> 00:20:52,840
manual process in which we look for

393
00:20:49,630 --> 00:20:55,179
common domains that we found on phishing

394
00:20:52,840 --> 00:20:57,280
attacks in this example is a it's a

395
00:20:55,179 --> 00:21:02,290
domain that is clearly a compromise

396
00:20:57,280 --> 00:21:08,080
domain it was an antique and an antique

397
00:21:02,290 --> 00:21:10,389
in antiques ecommerce we found about 400

398
00:21:08,080 --> 00:21:14,530
URLs that were hosted on that particular

399
00:21:10,390 --> 00:21:17,049
domain and we then go and did a manual

400
00:21:14,530 --> 00:21:19,178
process to analyze which were the

401
00:21:17,049 --> 00:21:22,049
keywords that they were using how

402
00:21:19,179 --> 00:21:25,660
similar are the screenshots of those

403
00:21:22,049 --> 00:21:28,150
particular phishing attacks and what we

404
00:21:25,660 --> 00:21:31,330
did then was to look for those keywords

405
00:21:28,150 --> 00:21:35,049
in the rest of our database and do and

406
00:21:31,330 --> 00:21:36,668
again this was a very even though we

407
00:21:35,049 --> 00:21:39,309
work on much e-learning we have to do

408
00:21:36,669 --> 00:21:42,760
this manually because there wasn't any

409
00:21:39,309 --> 00:21:45,000
other way to do it we found a hundred

410
00:21:42,760 --> 00:21:47,919
six domains that we were able to

411
00:21:45,000 --> 00:21:50,500
correlate to correlate to the initial

412
00:21:47,919 --> 00:21:52,380
domain to say all of these attacks are

413
00:21:50,500 --> 00:21:56,080
coming from the same traductor

414
00:21:52,380 --> 00:21:58,720
also we compared all the whole all the

415
00:21:56,080 --> 00:22:01,449
screenshots from the phishing site

416
00:21:58,720 --> 00:22:07,240
either because we had the screenshots or

417
00:22:01,450 --> 00:22:09,790
they were hosted on on on the on feet on

418
00:22:07,240 --> 00:22:13,240
fishing on the fishing detection system

419
00:22:09,790 --> 00:22:14,280
and then we were able to say all those

420
00:22:13,240 --> 00:22:17,750
attacks árbol

421
00:22:14,280 --> 00:22:19,710
to the same traductor that was extremely

422
00:22:17,750 --> 00:22:22,320
important process for us because that

423
00:22:19,710 --> 00:22:25,830
allow us to understand better which are

424
00:22:22,320 --> 00:22:29,490
the strategies that they are using we

425
00:22:25,830 --> 00:22:32,129
did this for which we iterate doing this

426
00:22:29,490 --> 00:22:33,240
a lot of times and this is an example of

427
00:22:32,130 --> 00:22:36,270
another traductor

428
00:22:33,240 --> 00:22:39,840
again same strategy but arrive into a

429
00:22:36,270 --> 00:22:43,710
completely different targeted

430
00:22:39,840 --> 00:22:46,020
institution we keep doing this but at

431
00:22:43,710 --> 00:22:51,420
the end I'm just going to on these

432
00:22:46,020 --> 00:22:54,180
two on these two trade actors so as I

433
00:22:51,420 --> 00:22:58,020
was telling you now that we have all

434
00:22:54,180 --> 00:23:00,990
those attacks and we identify which

435
00:22:58,020 --> 00:23:02,940
threat actors were doing that we wanted

436
00:23:00,990 --> 00:23:06,600
to check first how effective they are

437
00:23:02,940 --> 00:23:09,240
and to be able to actually compare and

438
00:23:06,600 --> 00:23:11,520
to create a metric such that we can then

439
00:23:09,240 --> 00:23:18,030
go and create new phishing attacks from

440
00:23:11,520 --> 00:23:21,840
their side this time I for some reason I

441
00:23:18,030 --> 00:23:26,399
decided to do this in a very interactive

442
00:23:21,840 --> 00:23:28,760
way so allow me to regret this for a lot

443
00:23:26,400 --> 00:23:28,760
of time

444
00:23:51,220 --> 00:23:56,980
awesome so I did all of this on Jupiter

445
00:23:54,400 --> 00:23:59,830
if you are not yet using Jupiter please

446
00:23:56,980 --> 00:24:01,480
do it it's amazing and what I'm going to

447
00:23:59,830 --> 00:24:03,550
show you here is like the whole process

448
00:24:01,480 --> 00:24:08,110
all of this is in github if you want to

449
00:24:03,550 --> 00:24:11,260
look at look at that later so these are

450
00:24:08,110 --> 00:24:12,669
the set of URLs that we had from that

451
00:24:11,260 --> 00:24:16,960
particular traductor

452
00:24:12,670 --> 00:24:18,610
all of this is after we did that thread

453
00:24:16,960 --> 00:24:22,210
after identification

454
00:24:18,610 --> 00:24:26,639
so we already I start this notebook with

455
00:24:22,210 --> 00:24:26,640
the actual URLs used by one traductor

456
00:24:26,760 --> 00:24:31,780
these are the domains that were used so

457
00:24:29,890 --> 00:24:34,840
for it one percent of their attacks were

458
00:24:31,780 --> 00:24:40,030
hosted on that first domain and then we

459
00:24:34,840 --> 00:24:43,570
have a hundred 99 more domains that were

460
00:24:40,030 --> 00:24:45,550
used by the same traductor and the first

461
00:24:43,570 --> 00:24:49,480
thing that we wanted to do though was to

462
00:24:45,550 --> 00:24:51,970
evaluate the current and efficiency of

463
00:24:49,480 --> 00:24:56,410
the droids actor and here I have to be

464
00:24:51,970 --> 00:24:58,990
very clear the difference between the

465
00:24:56,410 --> 00:25:02,830
efficiency rate and the actual success

466
00:24:58,990 --> 00:25:04,990
rate is that if success rate means how

467
00:25:02,830 --> 00:25:07,360
many credentials a user or actually how

468
00:25:04,990 --> 00:25:09,730
much money that yes sir but and there is

469
00:25:07,360 --> 00:25:11,979
way out of the kind of information that

470
00:25:09,730 --> 00:25:15,250
I have on this data so efficiency here

471
00:25:11,980 --> 00:25:18,310
means how many of their attacks are by

472
00:25:15,250 --> 00:25:21,130
passing my own AI detection system such

473
00:25:18,310 --> 00:25:23,830
that they are able to such that the end

474
00:25:21,130 --> 00:25:27,520
user is able to see it so that is very

475
00:25:23,830 --> 00:25:31,419
important to keep in mind so here I'm

476
00:25:27,520 --> 00:25:33,639
using just an API of the first part of

477
00:25:31,420 --> 00:25:36,730
my presentation that's it you don't have

478
00:25:33,640 --> 00:25:40,650
to use that algorithm you can use any

479
00:25:36,730 --> 00:25:45,610
are green you have that is called URLs

480
00:25:40,650 --> 00:25:49,210
and then I analyze all the then I

481
00:25:45,610 --> 00:25:52,360
analyze all the individual attacks to

482
00:25:49,210 --> 00:25:54,670
check I was going to do this in a life

483
00:25:52,360 --> 00:25:57,490
animation but if you have ever used

484
00:25:54,670 --> 00:25:59,470
MATLAB and matplotlib

485
00:25:57,490 --> 00:26:02,640
this is going to break so I just

486
00:25:59,470 --> 00:26:05,200
recorded so what I'm doing here is that

487
00:26:02,640 --> 00:26:08,769
I'm passing by holding the

488
00:26:05,200 --> 00:26:11,649
well URLs when there is a rate is

489
00:26:08,769 --> 00:26:15,580
because the algorithm did not detect it

490
00:26:11,649 --> 00:26:17,799
M and what we have here is the actual

491
00:26:15,580 --> 00:26:20,260
fishing a score distribution so I would

492
00:26:17,799 --> 00:26:23,679
expect to everything to be concentrated

493
00:26:20,260 --> 00:26:27,370
here close to close to one meaning one

494
00:26:23,679 --> 00:26:30,399
that the website is fishing and this

495
00:26:27,370 --> 00:26:32,889
will be the percentage of URLs that are

496
00:26:30,399 --> 00:26:36,719
block and the percentage of URLs that

497
00:26:32,889 --> 00:26:36,719
are actually effective

498
00:26:56,870 --> 00:27:04,310
all right to let me go to the end oh of

499
00:27:02,250 --> 00:27:04,310
course

500
00:27:04,490 --> 00:27:11,820
actually how it here the last one so

501
00:27:09,990 --> 00:27:16,290
what this means that the current

502
00:27:11,820 --> 00:27:19,770
attracted a trade actor strategy is

503
00:27:16,290 --> 00:27:22,950
having an effectiveness rate of 0.7

504
00:27:19,770 --> 00:27:26,490
meaning seven out of every thousand

505
00:27:22,950 --> 00:27:29,340
attacks are being our bypassing the

506
00:27:26,490 --> 00:27:31,650
detection system are actually being

507
00:27:29,340 --> 00:27:34,919
choked to the user so it's a very very

508
00:27:31,650 --> 00:27:37,830
low rate and something that and that

509
00:27:34,920 --> 00:27:39,840
normally you will say that's enough this

510
00:27:37,830 --> 00:27:43,530
attacker is no longer going to bother me

511
00:27:39,840 --> 00:27:46,080
um not exactly a reason of why we end up

512
00:27:43,530 --> 00:27:49,800
doing this project so what we wanted to

513
00:27:46,080 --> 00:27:53,040
do next was what is a special about

514
00:27:49,800 --> 00:27:54,780
these seven attacks and how can we

515
00:27:53,040 --> 00:27:57,840
create an algorithm that learns the

516
00:27:54,780 --> 00:28:02,460
patterns of those attacks so let me go

517
00:27:57,840 --> 00:28:04,919
further here and this is the first

518
00:28:02,460 --> 00:28:06,660
summary of the actual algorithm again

519
00:28:04,920 --> 00:28:10,440
all of this is on the slides but I also

520
00:28:06,660 --> 00:28:14,580
put it here so we separate the non

521
00:28:10,440 --> 00:28:16,650
effective URL from the effective URLs we

522
00:28:14,580 --> 00:28:18,600
wanted then to create to create an

523
00:28:16,650 --> 00:28:23,100
algorithm that learns the patterns of

524
00:28:18,600 --> 00:28:26,159
the effective URLs for that we create we

525
00:28:23,100 --> 00:28:29,040
extract all the all the strings of those

526
00:28:26,160 --> 00:28:31,200
effective URLs we create that into a

527
00:28:29,040 --> 00:28:34,740
corpus so we can cut it concatenate that

528
00:28:31,200 --> 00:28:38,220
and create a whole dictionary of those

529
00:28:34,740 --> 00:28:41,070
of the sequence of those characters we

530
00:28:38,220 --> 00:28:43,710
applied encoding and then we create a we

531
00:28:41,070 --> 00:28:47,850
set all of that into the model and how

532
00:28:43,710 --> 00:28:51,150
the model looks like so let me jump here

533
00:28:47,850 --> 00:28:53,760
so this is what the model is doing so

534
00:28:51,150 --> 00:28:57,090
the model is collecting the sequence of

535
00:28:53,760 --> 00:29:00,480
characters of defective URLs and then

536
00:28:57,090 --> 00:29:04,050
predicting which are the next three

537
00:29:00,480 --> 00:29:06,600
characters according to the pattern seen

538
00:29:04,050 --> 00:29:09,690
on the effective ones

539
00:29:06,600 --> 00:29:12,990
for that we use one layer of lsdm

540
00:29:09,690 --> 00:29:17,149
network one layer of hyperbolic tangent

541
00:29:12,990 --> 00:29:20,250
tangent network finally a soft max M

542
00:29:17,149 --> 00:29:22,529
what this is doing is that out of the

543
00:29:20,250 --> 00:29:25,169
whole possible characters that can go

544
00:29:22,529 --> 00:29:28,590
next is going to predict which is the

545
00:29:25,169 --> 00:29:31,549
most likely character use according to

546
00:29:28,590 --> 00:29:35,428
the known effective ones

547
00:29:31,549 --> 00:29:40,139
all that complex as light is actually

548
00:29:35,429 --> 00:29:41,399
just and these six lines of code so more

549
00:29:40,139 --> 00:29:43,620
or less this is all you need to create

550
00:29:41,399 --> 00:29:48,840
that exactly that and a deep neural

551
00:29:43,620 --> 00:29:50,719
network it certainly doesn't look at

552
00:29:48,840 --> 00:29:56,250
that complex now

553
00:29:50,720 --> 00:29:59,429
so the algorithm 112,000 parameters and

554
00:29:56,250 --> 00:30:01,080
this is actually if you have a GPU this

555
00:29:59,429 --> 00:30:04,470
is something that you can train in under

556
00:30:01,080 --> 00:30:08,279
10 minutes it is the whole process of

557
00:30:04,470 --> 00:30:11,100
training again I was not going to do

558
00:30:08,279 --> 00:30:15,919
this life because trusting of my GPU

559
00:30:11,100 --> 00:30:18,360
working during a live demo was even I

560
00:30:15,919 --> 00:30:22,529
was not going to be able to risk that

561
00:30:18,360 --> 00:30:25,860
mush then how do we use that

562
00:30:22,529 --> 00:30:29,429
Algrim so once we know once we have the

563
00:30:25,860 --> 00:30:33,508
algorithm that knows the sequence of M

564
00:30:29,429 --> 00:30:36,659
the patterns of the effective URLs we

565
00:30:33,509 --> 00:30:41,279
use they are going to predict which are

566
00:30:36,659 --> 00:30:45,960
the next characters in a in until we

567
00:30:41,279 --> 00:30:48,809
create a full URL we apply that to the

568
00:30:45,960 --> 00:30:51,419
known compromised domains that the

569
00:30:48,809 --> 00:30:54,539
attack already have so that data already

570
00:30:51,419 --> 00:30:57,419
own and nail or antiques what we are

571
00:30:54,539 --> 00:30:59,370
changing here is that the part of that

572
00:30:57,419 --> 00:31:02,549
URL is going to be replaced to a path

573
00:30:59,370 --> 00:31:05,129
created by the Algrim and at the end

574
00:31:02,549 --> 00:31:08,639
with that we end up creating a whole new

575
00:31:05,129 --> 00:31:11,399
set of Algar you are else that the

576
00:31:08,639 --> 00:31:13,469
attacker now can use in this case some

577
00:31:11,399 --> 00:31:16,500
again this is the whole code to create

578
00:31:13,470 --> 00:31:19,260
that what is doing though is that is it

579
00:31:16,500 --> 00:31:22,230
is just generating new part

580
00:31:19,260 --> 00:31:26,190
and this is how some of the some of them

581
00:31:22,230 --> 00:31:29,310
but there are generated looks like so

582
00:31:26,190 --> 00:31:32,820
all of these URLs were actually created

583
00:31:29,310 --> 00:31:36,840
by the algorithm and what we start

584
00:31:32,820 --> 00:31:39,270
seeing though is that a lot of the and

585
00:31:36,840 --> 00:31:44,100
the keywords that end up happening here

586
00:31:39,270 --> 00:31:46,170
was are the keywords that the first Al

587
00:31:44,100 --> 00:31:49,320
Green Dot saw meaning our detection

588
00:31:46,170 --> 00:31:50,670
system dicen did not so so it's very

589
00:31:49,320 --> 00:31:54,330
very interesting that you are able to

590
00:31:50,670 --> 00:31:59,910
create this using that simple six lines

591
00:31:54,330 --> 00:32:05,990
of code so we created another a thousand

592
00:31:59,910 --> 00:32:09,330
of these URLs and again let me show you

593
00:32:05,990 --> 00:32:12,420
what is what is the effectiveness of

594
00:32:09,330 --> 00:32:15,810
that so what we did after was we

595
00:32:12,420 --> 00:32:18,150
evaluated of all the URLs also against

596
00:32:15,810 --> 00:32:20,610
our own fishing detection system so we

597
00:32:18,150 --> 00:32:28,260
wanted to know now how effective are

598
00:32:20,610 --> 00:32:30,629
they let me go here so in this case

599
00:32:28,260 --> 00:32:34,020
everything that goes relating here is

600
00:32:30,630 --> 00:32:39,990
because my system my AI detection system

601
00:32:34,020 --> 00:32:42,290
is not seen in here we have the

602
00:32:39,990 --> 00:32:47,520
percentage of URLs that our block is

603
00:32:42,290 --> 00:32:50,460
getting close to 75% remember the

604
00:32:47,520 --> 00:32:55,080
original the original set of URLs were

605
00:32:50,460 --> 00:32:57,030
being blocked in a 99.2% by using the

606
00:32:55,080 --> 00:33:00,449
algorithm the algorithm is learning how

607
00:32:57,030 --> 00:33:03,540
to bypass the AI detection system so in

608
00:33:00,450 --> 00:33:07,320
fact you can pour it in a way the AI is

609
00:33:03,540 --> 00:33:11,430
learning this AI is learning what the AI

610
00:33:07,320 --> 00:33:14,490
detection system did not learn I which

611
00:33:11,430 --> 00:33:17,300
is kind of amazing so I'm getting close

612
00:33:14,490 --> 00:33:17,300
to the end

613
00:33:24,080 --> 00:33:37,949
yeah so right now is converging and at

614
00:33:33,810 --> 00:33:39,480
the end we got something we got this so

615
00:33:37,950 --> 00:33:43,830
actually let me go right into a

616
00:33:39,480 --> 00:33:46,710
comparison so these are the original

617
00:33:43,830 --> 00:33:49,770
URLs in red in blue the one created by

618
00:33:46,710 --> 00:33:53,490
Selfridge so there are a lot of URLs

619
00:33:49,770 --> 00:33:56,550
that they phishing detection system is

620
00:33:53,490 --> 00:34:01,320
saying there are legitimate when in fact

621
00:33:56,550 --> 00:34:06,290
everything here is malicious the actual

622
00:34:01,320 --> 00:34:12,230
numbers this is the comparison between

623
00:34:06,290 --> 00:34:14,400
the initial effectiveness no excuse me

624
00:34:12,230 --> 00:34:18,330
so initially the attacker had an

625
00:34:14,400 --> 00:34:22,550
effectiveness of 0.7 line now he got

626
00:34:18,330 --> 00:34:22,549
into an effectiveness of 29%

627
00:34:33,840 --> 00:34:38,120
so let me go back here very quickly

628
00:34:45,730 --> 00:34:52,070
that's actually all the the headlights

629
00:34:49,190 --> 00:34:59,360
were in case my demo did not work so

630
00:34:52,070 --> 00:35:01,820
actually it work so what is different

631
00:34:59,360 --> 00:35:03,410
here I'm also adding the second threat

632
00:35:01,820 --> 00:35:06,110
actor that I was shown at the beginning

633
00:35:03,410 --> 00:35:09,980
we already know the first one actually

634
00:35:06,110 --> 00:35:13,790
the last iteration of the demo it went a

635
00:35:09,980 --> 00:35:15,920
bit higher for the other one they used

636
00:35:13,790 --> 00:35:25,279
to have an effectiveness of five point

637
00:35:15,920 --> 00:35:25,670
five point nine they went up to 36% so

638
00:35:25,280 --> 00:35:30,400
yeah

639
00:35:25,670 --> 00:35:32,630
attacks are real at least in this very

640
00:35:30,400 --> 00:35:36,890
specific scenario

641
00:35:32,630 --> 00:35:39,200
um we're doomed or at least that is Who

642
00:35:36,890 --> 00:35:41,720
I am what I'm sure my marketing people

643
00:35:39,200 --> 00:35:45,430
are going to say but let me go more in

644
00:35:41,720 --> 00:35:50,180
details so AI power it attacks are real

645
00:35:45,430 --> 00:35:52,310
as we show with this experiment and the

646
00:35:50,180 --> 00:35:55,129
whole objective was to do it all

647
00:35:52,310 --> 00:35:59,330
realistic as possible using tools that

648
00:35:55,130 --> 00:36:02,330
the attacker may use so well all the

649
00:35:59,330 --> 00:36:04,940
code that I put there is actually very

650
00:36:02,330 --> 00:36:06,920
easily to recreate using deep learning

651
00:36:04,940 --> 00:36:07,790
tutorials is not something that is

652
00:36:06,920 --> 00:36:10,310
complex

653
00:36:07,790 --> 00:36:13,940
Ares is all using public available

654
00:36:10,310 --> 00:36:14,630
information and it is also using open

655
00:36:13,940 --> 00:36:17,060
source tools

656
00:36:14,630 --> 00:36:19,400
so just Python and Kara's so it's

657
00:36:17,060 --> 00:36:24,590
extremely easy to create these kind of

658
00:36:19,400 --> 00:36:27,260
things what what we need to do to defend

659
00:36:24,590 --> 00:36:30,830
and to actually defend ourselves is to

660
00:36:27,260 --> 00:36:32,180
first we need to know this may be

661
00:36:30,830 --> 00:36:34,580
something that the attackers are done

662
00:36:32,180 --> 00:36:37,250
doing and we have to try to test how

663
00:36:34,580 --> 00:36:39,529
they can do it before they do so we need

664
00:36:37,250 --> 00:36:42,650
to enhance our own AI detection system

665
00:36:39,530 --> 00:36:50,000
to add to account for the possibility of

666
00:36:42,650 --> 00:36:51,830
attackers using AI as I told you since

667
00:36:50,000 --> 00:36:54,320
the beginning all of the things that I

668
00:36:51,830 --> 00:36:57,600
have been talking about is actually on

669
00:36:54,320 --> 00:36:59,400
these research papers everything is

670
00:36:57,600 --> 00:37:02,220
is not on the github but there is a link

671
00:36:59,400 --> 00:37:16,880
on that github and otherwise I will be

672
00:37:02,220 --> 00:37:20,490
happy to share that so thank you I have

673
00:37:16,880 --> 00:37:22,380
some time for for some questions so at

674
00:37:20,490 --> 00:37:25,009
this moment I would like to open the

675
00:37:22,380 --> 00:37:31,500
room for some questions

676
00:37:25,010 --> 00:37:33,360
sure Thank You hello

677
00:37:31,500 --> 00:37:36,510
so you've basically used generally

678
00:37:33,360 --> 00:37:38,100
better cell networks to train one

679
00:37:36,510 --> 00:37:42,540
network to fool the other is that

680
00:37:38,100 --> 00:37:44,520
correct yes matagi yeah so in in this

681
00:37:42,540 --> 00:37:46,590
model you increase the effectiveness of

682
00:37:44,520 --> 00:37:49,410
bypassing a network but have you

683
00:37:46,590 --> 00:37:51,000
estimated increased or decreased

684
00:37:49,410 --> 00:37:52,560
effectiveness so actually following the

685
00:37:51,000 --> 00:37:54,390
user in terms of a phishing attack

686
00:37:52,560 --> 00:37:57,450
itself because you can create a URL that

687
00:37:54,390 --> 00:37:59,460
would look to your detection network as

688
00:37:57,450 --> 00:38:02,189
a legitimate attack that would look very

689
00:37:59,460 --> 00:38:05,760
suspicious to the user no yeah for sure

690
00:38:02,190 --> 00:38:08,190
there is that is why I have to separate

691
00:38:05,760 --> 00:38:11,850
the definition between effective and

692
00:38:08,190 --> 00:38:14,850
successful because you could eventually

693
00:38:11,850 --> 00:38:18,060
bypass the detection system by creating

694
00:38:14,850 --> 00:38:22,290
something that will be obvious to the

695
00:38:18,060 --> 00:38:25,170
user that is a phishing attack that may

696
00:38:22,290 --> 00:38:27,120
end up happening what we have been

697
00:38:25,170 --> 00:38:30,060
seeing though is that if you look at a

698
00:38:27,120 --> 00:38:32,190
phishing attack in a mobile device the

699
00:38:30,060 --> 00:38:36,390
user is not even going to be able to see

700
00:38:32,190 --> 00:38:40,050
the URL some so that you know while that

701
00:38:36,390 --> 00:38:43,020
that that you're saying is true there we

702
00:38:40,050 --> 00:38:45,180
have been seen that users don't really

703
00:38:43,020 --> 00:38:48,600
are well informed to look at the actual

704
00:38:45,180 --> 00:38:51,540
URLs and do that analysis themselves so

705
00:38:48,600 --> 00:38:55,799
it will be way more interesting if I

706
00:38:51,540 --> 00:38:59,250
have the data regarding which attacks

707
00:38:55,800 --> 00:39:02,040
were successful at getting credentials

708
00:38:59,250 --> 00:39:04,230
but in frontal see that data I don't

709
00:39:02,040 --> 00:39:06,750
have it and I don't think it's that easy

710
00:39:04,230 --> 00:39:09,420
to collect in that case this will be

711
00:39:06,750 --> 00:39:10,270
even more realistic you may think though

712
00:39:09,420 --> 00:39:12,130
that the

713
00:39:10,270 --> 00:39:14,530
attacker do have that information

714
00:39:12,130 --> 00:39:18,070
because that occurred do know which of

715
00:39:14,530 --> 00:39:21,520
the URLs are actually getting him money

716
00:39:18,070 --> 00:39:24,760
so so they will have even more data to

717
00:39:21,520 --> 00:39:27,759
create this more targeted towards that

718
00:39:24,760 --> 00:39:29,500
particular end but indeed what you're

719
00:39:27,760 --> 00:39:32,550
saying is through I'm detecting

720
00:39:29,500 --> 00:39:36,010
efficient URLs not successful URLs

721
00:39:32,550 --> 00:39:37,869
that's right thank you thanks a lot for

722
00:39:36,010 --> 00:39:39,490
that really interesting talk I just

723
00:39:37,869 --> 00:39:42,940
wanted to know where can we find the

724
00:39:39,490 --> 00:39:45,609
notebooks on github and so if you look

725
00:39:42,940 --> 00:39:48,280
so actually my github name is the same

726
00:39:45,610 --> 00:39:52,930
one al Bunsen I just put that yesterday

727
00:39:48,280 --> 00:39:56,290
I will be I I'm sure I will tweet that

728
00:39:52,930 --> 00:40:04,480
after we finish here if you have any

729
00:39:56,290 --> 00:40:06,450
question please let me know there I also

730
00:40:04,480 --> 00:40:08,740
thank you for this very interesting

731
00:40:06,450 --> 00:40:10,750
information I've got a question

732
00:40:08,740 --> 00:40:12,640
regarding the certificates being used in

733
00:40:10,750 --> 00:40:14,470
the phishing attacks do you have any

734
00:40:12,640 --> 00:40:18,240
kind of information on breakdown what

735
00:40:14,470 --> 00:40:20,140
kinds of a breakdown of what kinds of

736
00:40:18,240 --> 00:40:23,470
certificates were being used was it

737
00:40:20,140 --> 00:40:27,250
mostly like some certificates did you

738
00:40:23,470 --> 00:40:30,390
see any any ones that had enhanced

739
00:40:27,250 --> 00:40:34,060
validation oh yeah for sure some

740
00:40:30,390 --> 00:40:37,660
actually I have a nice table about that

741
00:40:34,060 --> 00:40:39,490
on the paper because indeed you will not

742
00:40:37,660 --> 00:40:41,290
expect to see extended validation

743
00:40:39,490 --> 00:40:44,109
certificate on phishing attacks that's

744
00:40:41,290 --> 00:40:46,420
for sure the issue though is that there

745
00:40:44,109 --> 00:40:48,759
are a lot of legitimate website that

746
00:40:46,420 --> 00:40:51,580
does not have extended validation so

747
00:40:48,760 --> 00:40:54,220
that kind of simple rules will help you

748
00:40:51,580 --> 00:40:57,040
to only make sure that the user is

749
00:40:54,220 --> 00:41:02,859
logging into a top 10,000 Alexa not even

750
00:40:57,040 --> 00:41:04,529
a hundred thousand and also domain

751
00:41:02,859 --> 00:41:07,540
validation is not something that you see

752
00:41:04,530 --> 00:41:12,100
because all of that first cost money

753
00:41:07,540 --> 00:41:15,150
takes time and make more obvious who is

754
00:41:12,100 --> 00:41:18,490
creating the web certificate what we see

755
00:41:15,150 --> 00:41:21,660
attackers using let's encrypt or some or

756
00:41:18,490 --> 00:41:24,660
even paying for very simple

757
00:41:21,660 --> 00:41:24,660
certificates

758
00:41:26,920 --> 00:41:32,950
what is your strategy above directs I'm

759
00:41:30,280 --> 00:41:36,310
thinking particular two kinds something

760
00:41:32,950 --> 00:41:39,069
commercial like bitly or something more

761
00:41:36,310 --> 00:41:41,740
complex checking for area user browser

762
00:41:39,070 --> 00:41:45,450
behind yeah where you change completely

763
00:41:41,740 --> 00:41:51,669
true here I'm only using the end or the

764
00:41:45,450 --> 00:41:54,339
destination URL I'm not if I use here

765
00:41:51,670 --> 00:41:57,580
the shortener that your turn

766
00:41:54,340 --> 00:42:00,340
URL this will simply do not work how do

767
00:41:57,580 --> 00:42:03,430
how I end up working with that in

768
00:42:00,340 --> 00:42:05,350
practice of course you try to follow to

769
00:42:03,430 --> 00:42:07,000
follow the link but attackers are

770
00:42:05,350 --> 00:42:09,310
already blocking that because they are

771
00:42:07,000 --> 00:42:13,359
able to see you are doing that from

772
00:42:09,310 --> 00:42:15,430
unknown vendor IP or something so you

773
00:42:13,359 --> 00:42:17,680
end up having to create more complex

774
00:42:15,430 --> 00:42:21,430
pipelines in which you have to follow

775
00:42:17,680 --> 00:42:23,950
that shortener you'll seen geolocation

776
00:42:21,430 --> 00:42:27,129
taking into account geolocation you see

777
00:42:23,950 --> 00:42:30,549
a lot of attackers that suddenly if the

778
00:42:27,130 --> 00:42:31,960
wonder is trying to redirect is located

779
00:42:30,550 --> 00:42:33,940
outside the country they are track

780
00:42:31,960 --> 00:42:36,280
trying to attack they are going to block

781
00:42:33,940 --> 00:42:41,050
it so you have to also take that into

782
00:42:36,280 --> 00:42:44,619
account I will say for for my site

783
00:42:41,050 --> 00:42:47,410
meaning the research part did that is an

784
00:42:44,619 --> 00:42:50,200
engineering problem that we have to we

785
00:42:47,410 --> 00:42:53,580
had been working on that making sure we

786
00:42:50,200 --> 00:42:58,118
redirect using a lot of proxies a lot of

787
00:42:53,580 --> 00:43:01,690
locations at the end I'm I just get here

788
00:42:58,119 --> 00:43:03,130
the nice clean dataset but that is the

789
00:43:01,690 --> 00:43:07,390
kind of things that you have to do in

790
00:43:03,130 --> 00:43:14,680
order to to bypass that that a strategy

791
00:43:07,390 --> 00:43:18,609
a strategy you use by attackers did you

792
00:43:14,680 --> 00:43:22,750
try to use the output of your doofus to

793
00:43:18,609 --> 00:43:26,470
retrain your Moro detection model so the

794
00:43:22,750 --> 00:43:28,650
next the next AI paper that we are

795
00:43:26,470 --> 00:43:31,379
writing is how to make that in a very

796
00:43:28,650 --> 00:43:34,990
adversarial learning environment so

797
00:43:31,380 --> 00:43:36,300
there is a continuous retraining with

798
00:43:34,990 --> 00:43:41,910
the new data that we

799
00:43:36,300 --> 00:43:43,950
that we collect and and so sorry I was I

800
00:43:41,910 --> 00:43:47,160
was answering that in a very much

801
00:43:43,950 --> 00:43:50,460
elearning way so in a more general in a

802
00:43:47,160 --> 00:43:53,100
more general context if we know which

803
00:43:50,460 --> 00:43:55,080
are the URLs that after doing the fish

804
00:43:53,100 --> 00:43:57,540
they are going is non detecting will

805
00:43:55,080 --> 00:44:01,920
with retrain the initial algorithm and

806
00:43:57,540 --> 00:44:04,020
use that as also malicious URLs and we

807
00:44:01,920 --> 00:44:05,970
keep doing that there is a whole field

808
00:44:04,020 --> 00:44:07,920
of machine learning called adversarial

809
00:44:05,970 --> 00:44:10,379
learning that take care in to that and

810
00:44:07,920 --> 00:44:13,620
we have been working into doing that we

811
00:44:10,380 --> 00:44:15,390
have not finished that paper but there

812
00:44:13,620 --> 00:44:18,150
is a deadline that like in two weeks no

813
00:44:15,390 --> 00:44:23,850
we will do that soon I make sure to

814
00:44:18,150 --> 00:44:27,210
share that with you hello thank you for

815
00:44:23,850 --> 00:44:32,910
the talk just a question to the initial

816
00:44:27,210 --> 00:44:35,280
training and you okay sorry because you

817
00:44:32,910 --> 00:44:37,129
describe how you build up to neural

818
00:44:35,280 --> 00:44:41,190
network this initial training set but

819
00:44:37,130 --> 00:44:43,410
where do the 0.7 percent refer to to the

820
00:44:41,190 --> 00:44:45,860
data set from the training or to a

821
00:44:43,410 --> 00:44:49,290
randomized set and what would this

822
00:44:45,860 --> 00:44:51,810
detection wait in a real environment in

823
00:44:49,290 --> 00:44:56,130
terms of false positives yeah for sure

824
00:44:51,810 --> 00:44:58,620
so all those numbers are actually out of

825
00:44:56,130 --> 00:45:00,660
the five fold cross validation so so we

826
00:44:58,620 --> 00:45:03,330
actually have to do it that way like the

827
00:45:00,660 --> 00:45:05,670
the right way in a real world

828
00:45:03,330 --> 00:45:08,190
environment what happened you have a lot

829
00:45:05,670 --> 00:45:11,910
of different scenarios first you try to

830
00:45:08,190 --> 00:45:17,490
use this for a general as half browser

831
00:45:11,910 --> 00:45:19,560
plugin then you are going that 0.6 of 12

832
00:45:17,490 --> 00:45:22,109
positive is going to mean a lot of

833
00:45:19,560 --> 00:45:24,630
website because I on our users is going

834
00:45:22,110 --> 00:45:28,020
to be in a hundred website product so

835
00:45:24,630 --> 00:45:30,660
that will grow up how we end up using it

836
00:45:28,020 --> 00:45:33,240
we use this in a more triage way so we

837
00:45:30,660 --> 00:45:34,859
know things are suspicious or we know

838
00:45:33,240 --> 00:45:37,529
this is suspicious because some other

839
00:45:34,860 --> 00:45:40,170
particular thing is happening in that

840
00:45:37,530 --> 00:45:42,570
case we analyze it differently at the

841
00:45:40,170 --> 00:45:44,940
end we end up implementing a lot of

842
00:45:42,570 --> 00:45:50,130
version of the algorithm one train

843
00:45:44,940 --> 00:45:53,460
towards the worst financial user

844
00:45:50,130 --> 00:45:56,700
fishing one train towords looking at

845
00:45:53,460 --> 00:45:59,390
actually just the resources used to be

846
00:45:56,700 --> 00:46:04,169
able to analyze web logs one another one

847
00:45:59,390 --> 00:46:07,640
for more ecommerce kind of fishing but

848
00:46:04,170 --> 00:46:10,529
it only also happens on your use case I

849
00:46:07,640 --> 00:46:12,660
use a balanced data set to train the

850
00:46:10,529 --> 00:46:14,309
algorithm and you may very well argue

851
00:46:12,660 --> 00:46:15,690
the Internet is not balanced the

852
00:46:14,309 --> 00:46:17,970
percentage of fishing is very low

853
00:46:15,690 --> 00:46:21,539
compared to a whole set so it really

854
00:46:17,970 --> 00:46:24,000
depends on the use case a triage way is

855
00:46:21,539 --> 00:46:26,430
the right way to put it kind of tools

856
00:46:24,000 --> 00:46:29,190
into production otherwise you will be

857
00:46:26,430 --> 00:46:35,098
you will be having a lot of false

858
00:46:29,190 --> 00:46:37,369
positive definitely so I was just

859
00:46:35,099 --> 00:46:40,619
wondering when you mention these

860
00:46:37,369 --> 00:46:43,680
adversarial networks I'm if I if I could

861
00:46:40,619 --> 00:46:47,839
get hold of your algorithm and I trained

862
00:46:43,680 --> 00:46:52,950
my own gun would I actually be able to

863
00:46:47,839 --> 00:46:55,430
render your service inefficient because

864
00:46:52,950 --> 00:46:57,538
my generative Network can produce

865
00:46:55,430 --> 00:47:00,180
exactly exactly learns what you would

866
00:46:57,539 --> 00:47:04,079
what you cannot predict so definitely I

867
00:47:00,180 --> 00:47:06,180
mean that is them the question should I

868
00:47:04,079 --> 00:47:08,880
come to blood cut to show my algorithm

869
00:47:06,180 --> 00:47:11,279
but then an attacker is going to figure

870
00:47:08,880 --> 00:47:13,470
out a way to bypass this a specific

871
00:47:11,279 --> 00:47:16,259
version of the algorithm and the answer

872
00:47:13,470 --> 00:47:19,399
is for the community to grow we have to

873
00:47:16,259 --> 00:47:21,630
share it and be proactive in to

874
00:47:19,400 --> 00:47:25,680
retraining my own detection system

875
00:47:21,630 --> 00:47:27,390
faster that is the right answer to a

876
00:47:25,680 --> 00:47:31,440
specific or what you're saying regarding

877
00:47:27,390 --> 00:47:34,288
gun the gun had the generative algorithm

878
00:47:31,440 --> 00:47:38,369
is going is unsupervised so it's just

879
00:47:34,289 --> 00:47:41,160
going to create URLs I will have to use

880
00:47:38,369 --> 00:47:43,890
more interesting supper semi-supervised

881
00:47:41,160 --> 00:47:48,149
versions of a gun to be able to actually

882
00:47:43,890 --> 00:47:50,910
just generate effective urls and so on

883
00:47:48,150 --> 00:47:55,259
but more on on that part of the question

884
00:47:50,910 --> 00:47:57,480
but overall I think that we are better

885
00:47:55,259 --> 00:48:00,839
protected if we are able to share this

886
00:47:57,480 --> 00:48:02,400
even if I know I'm giving a lot of

887
00:48:00,839 --> 00:48:03,720
insights regarding how to build

888
00:48:02,400 --> 00:48:06,150
malicious web search

889
00:48:03,720 --> 00:48:22,970
you get for example but we have to do it

890
00:48:06,150 --> 00:48:25,980
obviously has thanks here's your Mike

891
00:48:22,970 --> 00:48:28,020
does your out algorithm actually update

892
00:48:25,980 --> 00:48:30,359
its web certificates obviously if a

893
00:48:28,020 --> 00:48:33,390
website is registered like every day

894
00:48:30,359 --> 00:48:36,029
even more than that does it update as it

895
00:48:33,390 --> 00:48:38,220
goes long or is it like you know a day

896
00:48:36,030 --> 00:48:40,109
update where you could have like those

897
00:48:38,220 --> 00:48:41,700
last three hours where it's not properly

898
00:48:40,109 --> 00:48:44,040
updated and then it's has a higher

899
00:48:41,700 --> 00:48:46,980
chance of you being hit from a phishing

900
00:48:44,040 --> 00:48:49,500
point of view so in that case is more

901
00:48:46,980 --> 00:48:52,740
onto the pipe pipeline of the

902
00:48:49,500 --> 00:48:54,450
engineering part so why I so the way I

903
00:48:52,740 --> 00:48:58,080
work with this I create these algorithms

904
00:48:54,450 --> 00:49:02,098
and I expose them as api's and depending

905
00:48:58,080 --> 00:49:04,230
on when we are receiving the name that

906
00:49:02,099 --> 00:49:06,180
the user is getting this particular web

907
00:49:04,230 --> 00:49:09,150
certificate we go call them

908
00:49:06,180 --> 00:49:12,210
store it somewhere and keep updating

909
00:49:09,150 --> 00:49:14,580
that for every single suspicious web

910
00:49:12,210 --> 00:49:17,220
certificate to try to avoid that kind of

911
00:49:14,580 --> 00:49:19,109
things and but again when you create the

912
00:49:17,220 --> 00:49:20,359
algorithm is very easy to just do that

913
00:49:19,109 --> 00:49:25,080
automatically

914
00:49:20,359 --> 00:49:30,990
every second you want so I have time for

915
00:49:25,080 --> 00:49:36,890
one last question or not awesome thank

916
00:49:30,990 --> 00:49:40,649
you thank you Andy's you want to finish

917
00:49:36,890 --> 00:49:42,598
so are you aware of tools which are

918
00:49:40,650 --> 00:49:45,630
similar to what saltfish is doing and

919
00:49:42,599 --> 00:49:47,339
did you try to fish against stats do you

920
00:49:45,630 --> 00:49:50,510
think it has any chance to succeed so

921
00:49:47,339 --> 00:49:54,119
that that's a very good question so

922
00:49:50,510 --> 00:49:57,060
indeed when we were writing selfish

923
00:49:54,119 --> 00:49:59,190
we went no really tools but actually on

924
00:49:57,060 --> 00:50:03,720
the Academy literature with which other

925
00:49:59,190 --> 00:50:06,450
algorithms were available and we haven't

926
00:50:03,720 --> 00:50:10,020
tested that against D fish so it was

927
00:50:06,450 --> 00:50:13,618
very using our own detection system what

928
00:50:10,020 --> 00:50:16,830
I expect is that the actual defeat de

929
00:50:13,619 --> 00:50:17,400
fish does not really care how do you

930
00:50:16,830 --> 00:50:20,490
build

931
00:50:17,400 --> 00:50:22,050
your URL classifier it can be a blog

932
00:50:20,490 --> 00:50:24,479
list it doesn't really care

933
00:50:22,050 --> 00:50:28,770
it will then learn how to bypass the

934
00:50:24,480 --> 00:50:31,250
blog list and but I say you can do it my

935
00:50:28,770 --> 00:50:35,610
way there are a lotta a lot of other

936
00:50:31,250 --> 00:50:38,310
ways to do it is just the algorithm

937
00:50:35,610 --> 00:50:41,310
learning how to I pass that way to do it

938
00:50:38,310 --> 00:50:43,380
so thank you for that last easy question

939
00:50:41,310 --> 00:50:45,150
indeed so thank you everyone

940
00:50:43,380 --> 00:50:47,820
my contact information is there I will

941
00:50:45,150 --> 00:50:48,360
be happy to answer more questions thank

942
00:50:47,820 --> 00:50:55,340
you

943
00:50:48,360 --> 00:50:55,340
[Applause]

