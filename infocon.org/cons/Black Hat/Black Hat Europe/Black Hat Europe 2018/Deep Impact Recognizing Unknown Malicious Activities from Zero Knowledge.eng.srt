1
00:00:00,000 --> 00:00:06,569
hi everyone my name is Shivaji Suzuki

2
00:00:02,929 --> 00:00:08,820
thank you for attending our session deep

3
00:00:06,569 --> 00:00:11,429
impact recognizing unknown malicious

4
00:00:08,820 --> 00:00:13,790
activities from zero knowledge I hope

5
00:00:11,429 --> 00:00:13,790
you like it

6
00:00:15,619 --> 00:00:21,960
first let me introduce ourselves

7
00:00:18,779 --> 00:00:25,890
my name is Royce Suzuki and this is

8
00:00:21,960 --> 00:00:30,830
Hassan Nashua we are from internet

9
00:00:25,890 --> 00:00:34,230
initiative Japan that is called for I AJ

10
00:00:30,830 --> 00:00:36,870
in short for short sorry I AG is a

11
00:00:34,230 --> 00:00:40,260
Japanese ISP and we are the first

12
00:00:36,870 --> 00:00:44,730
commercialized P in Japan we belong to

13
00:00:40,260 --> 00:00:50,820
the sisa Team Heidi sect we are Maria

14
00:00:44,730 --> 00:00:54,530
analysts and forensic investigators next

15
00:00:50,820 --> 00:00:57,270
let me explain what this talk is about

16
00:00:54,530 --> 00:01:00,210
this talk is about detecting malicious

17
00:00:57,270 --> 00:01:02,640
activities using deep learning in the

18
00:01:00,210 --> 00:01:05,700
absence of matching patterns brought

19
00:01:02,640 --> 00:01:11,369
lists behavioral analysis and other

20
00:01:05,700 --> 00:01:13,979
indicators we will cover these two

21
00:01:11,369 --> 00:01:20,759
methods see two service detection and

22
00:01:13,979 --> 00:01:25,158
exploit kits detection next let me

23
00:01:20,759 --> 00:01:28,560
explain about what Java knowledge mean

24
00:01:25,159 --> 00:01:31,650
sure you to agree that you cannot detect

25
00:01:28,560 --> 00:01:34,710
anything if you have very very thorough

26
00:01:31,650 --> 00:01:37,500
knowledge in this talk the knowledge

27
00:01:34,710 --> 00:01:41,009
means there are no any iosys to detect

28
00:01:37,500 --> 00:01:43,740
malicious activities you could be

29
00:01:41,009 --> 00:01:47,310
relieved from analyzing Martius samples

30
00:01:43,740 --> 00:01:49,820
and collecting iOS's by using our

31
00:01:47,310 --> 00:01:49,820
methods

32
00:01:52,150 --> 00:02:00,070
this is the agent of this talk first we

33
00:01:57,430 --> 00:02:03,250
will explain what is the problem on the

34
00:02:00,070 --> 00:02:07,270
existing detection methods and why we do

35
00:02:03,250 --> 00:02:10,600
this dis research second we will give

36
00:02:07,270 --> 00:02:16,690
you how to detect CNC servers with CNN

37
00:02:10,600 --> 00:02:20,380
models third we will show you how to

38
00:02:16,690 --> 00:02:24,760
detect exploit kids with Iranian and DNN

39
00:02:20,380 --> 00:02:31,690
models finally we will we will tell you

40
00:02:24,760 --> 00:02:34,840
the summary of this talk okay let's take

41
00:02:31,690 --> 00:02:42,190
a look at the problems of the existing

42
00:02:34,840 --> 00:02:44,020
detection methods and our motivation in

43
00:02:42,190 --> 00:02:46,570
order to detect malicious activities

44
00:02:44,020 --> 00:02:50,130
there are several existent approaches

45
00:02:46,570 --> 00:02:53,829
such as pattern matching bra crease

46
00:02:50,130 --> 00:02:59,910
behavior analysis event or correlation

47
00:02:53,830 --> 00:03:02,410
and so on but they have several problems

48
00:02:59,910 --> 00:03:05,680
for example some attacks could

49
00:03:02,410 --> 00:03:08,670
circumvent them because information such

50
00:03:05,680 --> 00:03:11,200
as malicious domains and IP addresses

51
00:03:08,670 --> 00:03:15,250
frequently and easily changed by

52
00:03:11,200 --> 00:03:18,339
attackers current approaches can only

53
00:03:15,250 --> 00:03:22,720
detect no Morea or attack methods as

54
00:03:18,340 --> 00:03:26,850
well in addition some of the solutions

55
00:03:22,720 --> 00:03:30,520
are too expensive for ordinary companies

56
00:03:26,850 --> 00:03:33,630
we want a more reliable and new approach

57
00:03:30,520 --> 00:03:40,390
without incurring any additional costs

58
00:03:33,630 --> 00:03:43,450
this is our main motivation for another

59
00:03:40,390 --> 00:03:48,040
motivation we want to utilize logs more

60
00:03:43,450 --> 00:03:51,579
more effectively because they take up so

61
00:03:48,040 --> 00:03:54,489
much space but we rarely use such rogues

62
00:03:51,580 --> 00:03:59,680
except for during incident response for

63
00:03:54,489 --> 00:04:02,260
example we only use we only use them for

64
00:03:59,680 --> 00:04:04,870
same in particular cases anomaly

65
00:04:02,260 --> 00:04:07,500
detection but our matching when you get

66
00:04:04,870 --> 00:04:07,500
IOC s

67
00:04:08,700 --> 00:04:15,010
however we are concerned to handle logs

68
00:04:12,310 --> 00:04:18,370
because the size of them are too huge to

69
00:04:15,010 --> 00:04:22,570
analyze complexity detection words are

70
00:04:18,370 --> 00:04:26,020
too hard to process them so we decided

71
00:04:22,570 --> 00:04:32,020
to use deep learning but why is it

72
00:04:26,020 --> 00:04:35,260
suitable deep learning can handle huge

73
00:04:32,020 --> 00:04:37,859
samples and many features it can also

74
00:04:35,260 --> 00:04:41,289
recognize patterns automatically

75
00:04:37,860 --> 00:04:44,380
therefore we felt it would be a suitable

76
00:04:41,290 --> 00:04:47,260
solution for log analysis and help us

77
00:04:44,380 --> 00:04:51,240
distinguish between militias and benign

78
00:04:47,260 --> 00:04:54,880
patterns this is the reason why we use

79
00:04:51,240 --> 00:04:57,760
deep learning in this talk from the next

80
00:04:54,880 --> 00:05:00,370
slide we will talk about how can we

81
00:04:57,760 --> 00:05:06,070
detect each malicious activity with the

82
00:05:00,370 --> 00:05:10,740
technique ok let's move on to the first

83
00:05:06,070 --> 00:05:14,500
detection method c2 savage detection

84
00:05:10,740 --> 00:05:18,400
first let me explain why c2 savage

85
00:05:14,500 --> 00:05:20,770
detection is difficult for example in

86
00:05:18,400 --> 00:05:23,880
order to detect them we need to correct

87
00:05:20,770 --> 00:05:27,120
malware samples and unwrite them and

88
00:05:23,880 --> 00:05:29,800
even if we get samples and iosys

89
00:05:27,120 --> 00:05:35,130
attackers will change them frequently

90
00:05:29,800 --> 00:05:35,130
and easy it's like a cat and mouse game

91
00:05:36,570 --> 00:05:44,979
next let think about how to detect c2

92
00:05:40,330 --> 00:05:48,159
service without any i/o sees many

93
00:05:44,979 --> 00:05:50,200
malware such as bot or at access to see

94
00:05:48,160 --> 00:05:53,620
to servers to get commands from

95
00:05:50,200 --> 00:05:57,460
attackers or to send keep alive at some

96
00:05:53,620 --> 00:06:00,190
intervals and typical pouring pouring

97
00:05:57,460 --> 00:06:04,180
takes place between every 20 seconds and

98
00:06:00,190 --> 00:06:08,169
seven minutes in this research we

99
00:06:04,180 --> 00:06:10,600
focused on c2 servers of bots or odd we

100
00:06:08,169 --> 00:06:13,510
don't target run somewhere else c2

101
00:06:10,600 --> 00:06:17,200
service because the kind of Marya often

102
00:06:13,510 --> 00:06:20,700
communicates only once or three or even

103
00:06:17,200 --> 00:06:20,700
no communication is occurred

104
00:06:24,270 --> 00:06:30,039
communication intervals are important

105
00:06:26,560 --> 00:06:33,010
for attackers because if they choose a

106
00:06:30,040 --> 00:06:34,590
shorter interval they will be able to

107
00:06:33,010 --> 00:06:37,690
move around freely

108
00:06:34,590 --> 00:06:40,320
however we will also be able to detect

109
00:06:37,690 --> 00:06:44,410
easily by counting the total numbers of

110
00:06:40,320 --> 00:06:47,409
communications on the other hand if they

111
00:06:44,410 --> 00:06:50,260
choose a long interval they will be

112
00:06:47,410 --> 00:06:53,110
limited to move but it will be difficult

113
00:06:50,260 --> 00:06:55,330
for us to detect the activity because it

114
00:06:53,110 --> 00:06:58,300
will be too small numbers of the

115
00:06:55,330 --> 00:07:01,810
communications to find it if we sum up

116
00:06:58,300 --> 00:07:08,080
each destination host this is a

117
00:07:01,810 --> 00:07:10,479
double-edged sword for them sorry next

118
00:07:08,080 --> 00:07:12,609
let's take a look at the difference

119
00:07:10,479 --> 00:07:18,849
between a benign communication pattern

120
00:07:12,610 --> 00:07:21,940
and emerges one these two tables these

121
00:07:18,850 --> 00:07:24,460
two tables show total numbers of of

122
00:07:21,940 --> 00:07:28,840
communications in every minute for an

123
00:07:24,460 --> 00:07:31,359
hour the left table shows legitimate

124
00:07:28,840 --> 00:07:34,960
communications between a benign client

125
00:07:31,360 --> 00:07:37,840
and a server it is a it is rare for the

126
00:07:34,960 --> 00:07:40,570
four typical users to communicate to

127
00:07:37,840 --> 00:07:44,669
communicate periodically with legitimate

128
00:07:40,570 --> 00:07:47,050
web server for a long time in contrast

129
00:07:44,669 --> 00:07:49,150
the right table shows much as

130
00:07:47,050 --> 00:07:53,199
communications between an infected

131
00:07:49,150 --> 00:07:55,960
client and the c2 server since both Arad

132
00:07:53,199 --> 00:07:59,889
communicates at some intervals you can

133
00:07:55,960 --> 00:08:05,849
see a pattern like vertical straight

134
00:07:59,889 --> 00:08:05,849
lines on the right figure like this

135
00:08:06,990 --> 00:08:12,340
therefore we consider deep learning

136
00:08:09,550 --> 00:08:14,650
models are able to recognize the

137
00:08:12,340 --> 00:08:19,239
difference between benign and smashes

138
00:08:14,650 --> 00:08:21,580
communication patterns we thought CNN

139
00:08:19,240 --> 00:08:25,139
can especially recognize the difference

140
00:08:21,580 --> 00:08:25,139
if we can image walls

141
00:08:29,720 --> 00:08:36,300
CNN is a sort of deep neural networks it

142
00:08:33,210 --> 00:08:38,610
is one of the best method for image

143
00:08:36,299 --> 00:08:41,179
classification and several CNN models

144
00:08:38,610 --> 00:08:45,390
are already superior to human beings

145
00:08:41,179 --> 00:08:52,199
that's why we use CN NS for detecting c2

146
00:08:45,390 --> 00:08:55,380
server tons in order to use CNN's we

147
00:08:52,200 --> 00:08:58,490
need to combat logs into images but how

148
00:08:55,380 --> 00:09:04,380
do we do that from the next slide

149
00:08:58,490 --> 00:09:06,420
let me explain about it a common

150
00:09:04,380 --> 00:09:10,530
graphical image structure consists of

151
00:09:06,420 --> 00:09:14,579
width height and three colour channels

152
00:09:10,530 --> 00:09:17,760
it means RGB and a monotone carry image

153
00:09:14,580 --> 00:09:24,240
has width height under a channel it

154
00:09:17,760 --> 00:09:26,670
means grayscale however we need we

155
00:09:24,240 --> 00:09:29,850
needed to pick effective parameters for

156
00:09:26,670 --> 00:09:32,610
channels since we generated images from

157
00:09:29,850 --> 00:09:37,100
wrongs because they don't have degrees

158
00:09:32,610 --> 00:09:40,410
of RGB class for example we can use

159
00:09:37,100 --> 00:09:42,890
informations such as total number of

160
00:09:40,410 --> 00:09:47,839
communications during the time interval

161
00:09:42,890 --> 00:09:47,840
sent and received bytes for channels

162
00:09:48,140 --> 00:09:57,949
here let's assume there are three rolls

163
00:09:52,860 --> 00:10:06,210
like this all communications between 170

164
00:09:57,950 --> 00:10:11,160
216 249 249 104 and example.com happened

165
00:10:06,210 --> 00:10:16,320
at 5:01 a.m. and they occurred three

166
00:10:11,160 --> 00:10:19,469
times so they can be converted into a

167
00:10:16,320 --> 00:10:21,870
monotone car image if we pick only total

168
00:10:19,470 --> 00:10:26,600
number of communications during the time

169
00:10:21,870 --> 00:10:26,600
interval as one channel like this

170
00:10:29,300 --> 00:10:36,650
at this time we tested three patterns of

171
00:10:31,880 --> 00:10:41,570
Permatex direction the first pattern has

172
00:10:36,650 --> 00:10:43,760
three channels like this the channels

173
00:10:41,570 --> 00:10:46,120
consist of total number of

174
00:10:43,760 --> 00:10:49,160
communications during the time interval

175
00:10:46,120 --> 00:10:56,390
averages of showing averages of sent

176
00:10:49,160 --> 00:10:58,459
bytes and averages of received bytes the

177
00:10:56,390 --> 00:11:02,540
second patter on the rift figure has a

178
00:10:58,460 --> 00:11:04,280
channel which expresses total numbers of

179
00:11:02,540 --> 00:11:08,480
communications during the time interval

180
00:11:04,280 --> 00:11:11,780
and that sub third pattern on the right

181
00:11:08,480 --> 00:11:14,750
figure has also a channel but it means

182
00:11:11,780 --> 00:11:18,530
communication flux instead of total

183
00:11:14,750 --> 00:11:22,130
numbers and these two myths

184
00:11:18,530 --> 00:11:26,900
two patterns got nice results against in

185
00:11:22,130 --> 00:11:33,980
the world Maria so we used these

186
00:11:26,900 --> 00:11:37,400
patterns to create our models next we

187
00:11:33,980 --> 00:11:41,930
also to consider width and height in

188
00:11:37,400 --> 00:11:46,640
order to convert vlogs we tested these

189
00:11:41,930 --> 00:11:49,870
five bottles and dollar to want able to

190
00:11:46,640 --> 00:11:55,130
distinguish marshes and benign patterns

191
00:11:49,870 --> 00:11:58,390
so we've chosen the start option which

192
00:11:55,130 --> 00:12:02,570
implies aggregating data every minute

193
00:11:58,390 --> 00:12:05,150
for our models at this time because it

194
00:12:02,570 --> 00:12:10,760
is the best result against in the world

195
00:12:05,150 --> 00:12:16,220
model next we will explain data sets for

196
00:12:10,760 --> 00:12:20,060
training and testing our models first

197
00:12:16,220 --> 00:12:23,810
let me explain that training data set we

198
00:12:20,060 --> 00:12:26,359
used over 1.5 million images that are

199
00:12:23,810 --> 00:12:28,880
converted from approximately three point

200
00:12:26,360 --> 00:12:32,300
seven gigabytes of proxy rules for

201
00:12:28,880 --> 00:12:34,670
benign data and for malicious data we

202
00:12:32,300 --> 00:12:37,760
generated over 1 million CT like

203
00:12:34,670 --> 00:12:40,849
communications with a simple script we

204
00:12:37,760 --> 00:12:42,540
didn't use any actual memory traffic for

205
00:12:40,850 --> 00:12:44,970
training data

206
00:12:42,540 --> 00:12:49,280
that's why we call this method general

207
00:12:44,970 --> 00:12:49,280
knowledge we will mention this Reiter

208
00:12:49,550 --> 00:12:58,339
next let me actually explain that to the

209
00:12:53,640 --> 00:13:01,560
testing data set for benign data we used

210
00:12:58,340 --> 00:13:04,530
approximately 4.5 million of benign

211
00:13:01,560 --> 00:13:09,300
images in total that are converted from

212
00:13:04,530 --> 00:13:11,370
about 11 gigabytes of proxy rules for

213
00:13:09,300 --> 00:13:13,770
malicious data we used in the world

214
00:13:11,370 --> 00:13:17,250
malware communications from actual

215
00:13:13,770 --> 00:13:22,439
incidents such as projects exact same M

216
00:13:17,250 --> 00:13:23,390
red ribs kins dreamboat or a sniff and

217
00:13:22,440 --> 00:13:26,310
so on

218
00:13:23,390 --> 00:13:28,890
we used delivering different Mario

219
00:13:26,310 --> 00:13:33,569
families to test whether our model can

220
00:13:28,890 --> 00:13:36,770
detect or not this time we decided to

221
00:13:33,570 --> 00:13:39,390
only use Mario families which were

222
00:13:36,770 --> 00:13:43,230
communicating with live C to serve us

223
00:13:39,390 --> 00:13:45,870
for our malicious test data this is

224
00:13:43,230 --> 00:13:48,780
because the sweeping intervals between

225
00:13:45,870 --> 00:13:52,440
cases which received commands from C to

226
00:13:48,780 --> 00:13:58,410
in a normal fashion and ones which did

227
00:13:52,440 --> 00:14:01,940
not are different we prepared these

228
00:13:58,410 --> 00:14:01,939
label Mario families

229
00:14:05,360 --> 00:14:09,810
next let me explain how we generate C to

230
00:14:09,390 --> 00:14:12,630
solve

231
00:14:09,810 --> 00:14:16,229
c2 like communication patterns as we

232
00:14:12,630 --> 00:14:19,800
mentioned area we use generated C to

233
00:14:16,230 --> 00:14:22,310
each patterns form Isis data of the

234
00:14:19,800 --> 00:14:25,920
training dataset with a simple script

235
00:14:22,310 --> 00:14:28,520
first we generated a variety of

236
00:14:25,920 --> 00:14:32,520
periodical patterns

237
00:14:28,520 --> 00:14:35,670
starting from once in 3 seconds and

238
00:14:32,520 --> 00:14:39,439
going up to 1 seeing every meet every

239
00:14:35,670 --> 00:14:46,680
three minutes building up in 100

240
00:14:39,440 --> 00:14:49,050
milliseconds increase means this script

241
00:14:46,680 --> 00:14:52,349
also outputs spots patterns

242
00:14:49,050 --> 00:14:56,579
starting from every 3 minutes and going

243
00:14:52,350 --> 00:15:03,690
up to every 12 minutes building up in 10

244
00:14:56,580 --> 00:15:07,260
seconds increase means we also simulated

245
00:15:03,690 --> 00:15:10,500
certain patterns which sweep which rip

246
00:15:07,260 --> 00:15:12,330
occurs for several minutes after free

247
00:15:10,500 --> 00:15:14,670
control now connections to see to

248
00:15:12,330 --> 00:15:20,340
servers because some malware families

249
00:15:14,670 --> 00:15:24,089
have similar patterns this WebWork this

250
00:15:20,340 --> 00:15:26,490
rift figure expresses two minutes two

251
00:15:24,090 --> 00:15:29,160
minutes rate after two minutes two

252
00:15:26,490 --> 00:15:32,490
minutes of activity and the right figure

253
00:15:29,160 --> 00:15:39,240
expresses three minutes rip after three

254
00:15:32,490 --> 00:15:42,780
minutes of activity in addition based on

255
00:15:39,240 --> 00:15:45,630
the patterns that have been generated so

256
00:15:42,780 --> 00:15:49,260
far we generated more patterns using

257
00:15:45,630 --> 00:15:56,490
these two methods rotation and random

258
00:15:49,260 --> 00:16:00,120
noise this is a rotation process the

259
00:15:56,490 --> 00:16:02,520
left figure is an actual the deal sorry

260
00:16:00,120 --> 00:16:05,490
the left figure is an original pattern

261
00:16:02,520 --> 00:16:09,120
and the right top fit the right top

262
00:16:05,490 --> 00:16:13,200
picture is an example that is rotated a

263
00:16:09,120 --> 00:16:15,570
minute from the original one the right

264
00:16:13,200 --> 00:16:18,710
bottom image is another one that is

265
00:16:15,570 --> 00:16:18,710
rotated two minutes

266
00:16:19,160 --> 00:16:27,560
and we also amplified simulated patterns

267
00:16:24,120 --> 00:16:32,120
by changing the number of each common

268
00:16:27,560 --> 00:16:35,399
randomly to better resist of CN n attack

269
00:16:32,120 --> 00:16:38,189
the right figure have been created

270
00:16:35,399 --> 00:16:44,879
create three comments from the original

271
00:16:38,189 --> 00:16:47,399
one okay in this subsection we will

272
00:16:44,879 --> 00:16:55,050
explain one of the best on best models

273
00:16:47,399 --> 00:16:57,660
we created this is one of our models we

274
00:16:55,050 --> 00:17:03,449
use chaos with tens of robot gain at

275
00:16:57,660 --> 00:17:06,389
this time this is the core code as we

276
00:17:03,449 --> 00:17:09,869
mentioned Aria we decided to use one

277
00:17:06,390 --> 00:17:12,689
hour window and we use total number of

278
00:17:09,869 --> 00:17:18,208
communications during minute as a

279
00:17:12,689 --> 00:17:22,350
channel as a result an image has sixty

280
00:17:18,209 --> 00:17:27,150
with by one height by one channel

281
00:17:22,349 --> 00:17:32,039
dimension firstly our model has to come

282
00:17:27,150 --> 00:17:36,659
to convolutional layers here and then it

283
00:17:32,039 --> 00:17:42,030
has a max pouring layer after that it

284
00:17:36,659 --> 00:17:45,270
has two convolutional layers again then

285
00:17:42,030 --> 00:17:51,899
there is a passive tone layer here after

286
00:17:45,270 --> 00:18:00,210
flattening finally there is the out of

287
00:17:51,900 --> 00:18:03,600
Korea it's very simple model right let

288
00:18:00,210 --> 00:18:08,159
me explain other training with training

289
00:18:03,600 --> 00:18:12,780
related parameters we also did these two

290
00:18:08,159 --> 00:18:15,210
methods to get better results suffering

291
00:18:12,780 --> 00:18:19,320
the training data set and feature

292
00:18:15,210 --> 00:18:23,330
scaling and other configuration values

293
00:18:19,320 --> 00:18:23,330
that we used are here

294
00:18:24,840 --> 00:18:34,149
and this is the result for training it

295
00:18:31,149 --> 00:18:37,059
is high accuracy as well as a roll loss

296
00:18:34,149 --> 00:18:38,850
rate for both training and validation

297
00:18:37,059 --> 00:18:41,739
samples

298
00:18:38,850 --> 00:18:45,939
this figure is automatically generated

299
00:18:41,739 --> 00:18:49,570
by Kaos I'm sorry the legends are

300
00:18:45,940 --> 00:18:53,080
overlapping with the actual values the

301
00:18:49,570 --> 00:18:55,480
blue line shows the accuracy of the

302
00:18:53,080 --> 00:18:58,359
training samples and the orange line

303
00:18:55,480 --> 00:19:05,230
shows the accuracy of the operation

304
00:18:58,359 --> 00:19:07,720
samples okay now let me explain the

305
00:19:05,230 --> 00:19:11,859
results of our models for testing

306
00:19:07,720 --> 00:19:17,109
datasets first this is the result of

307
00:19:11,859 --> 00:19:27,070
penang websites its high accuracy as

308
00:19:17,109 --> 00:19:29,320
well as low false positives here here we

309
00:19:27,070 --> 00:19:32,619
can filter out false positive activity

310
00:19:29,320 --> 00:19:39,249
ends with as white list because they are

311
00:19:32,619 --> 00:19:45,100
small numbers next for malicious samples

312
00:19:39,249 --> 00:19:53,200
our model was able to detect all romário

313
00:19:45,100 --> 00:19:57,549
families okay let's take a look at the

314
00:19:53,200 --> 00:20:01,950
result in detail first let's take a look

315
00:19:57,549 --> 00:20:05,220
at targeted attack Maria's families

316
00:20:01,950 --> 00:20:09,100
these tables are converted from

317
00:20:05,220 --> 00:20:13,960
converted images of project samples that

318
00:20:09,100 --> 00:20:18,279
is used by some other group in Padawan

319
00:20:13,960 --> 00:20:22,139
every minute the number the numbers are

320
00:20:18,279 --> 00:20:26,889
eaten changed from 1 to 8 randomly or

321
00:20:22,139 --> 00:20:31,379
there is a minute there is a 1 minute

322
00:20:26,889 --> 00:20:31,379
long street long sleep like this

323
00:20:31,770 --> 00:20:39,450
but our model could detect these changes

324
00:20:36,080 --> 00:20:41,669
patent two is easy to detect because it

325
00:20:39,450 --> 00:20:44,720
almost communicates around a hundred

326
00:20:41,670 --> 00:20:44,720
times every minute

327
00:20:47,000 --> 00:20:55,880
next Asterix used by Doug hotel this

328
00:20:51,660 --> 00:21:00,270
patent starts with nine minutes weep and

329
00:20:55,880 --> 00:21:03,450
it slips sometimes for 1 or 2 minutes

330
00:21:00,270 --> 00:21:09,929
after 2 times communications in the

331
00:21:03,450 --> 00:21:13,230
minute like this next xx mm used by tick

332
00:21:09,929 --> 00:21:16,650
on the right figure it almost

333
00:21:13,230 --> 00:21:18,240
communicates three times a minute but

334
00:21:16,650 --> 00:21:26,670
sometimes it's ripped

335
00:21:18,240 --> 00:21:29,130
2 minutes like this the rift figure is a

336
00:21:26,670 --> 00:21:32,580
pattern of gmail malware that is used by

337
00:21:29,130 --> 00:21:35,790
apt 10 it accesses almost every minute

338
00:21:32,580 --> 00:21:38,990
and sometimes trips for me for a few

339
00:21:35,790 --> 00:21:44,190
minutes after consecutive communications

340
00:21:38,990 --> 00:21:46,740
like this the right figure is an example

341
00:21:44,190 --> 00:21:51,030
of a Church's Maria that is also used by

342
00:21:46,740 --> 00:21:55,500
a PT 10 this pattern is very simple

343
00:21:51,030 --> 00:22:03,389
because it it accesses every fifth every

344
00:21:55,500 --> 00:22:07,740
five or six minutes these are patterns

345
00:22:03,390 --> 00:22:10,950
of Erichs malware the left the left one

346
00:22:07,740 --> 00:22:15,360
shows the the rest one shows that it

347
00:22:10,950 --> 00:22:18,390
accesses every three to five minutes the

348
00:22:15,360 --> 00:22:23,360
right one is a bit complicated it

349
00:22:18,390 --> 00:22:23,360
accesses one or two two times in a row

350
00:22:23,510 --> 00:22:29,990
then it drips one or two minutes like

351
00:22:27,960 --> 00:22:29,990
this

352
00:22:32,200 --> 00:22:39,860
mosha doula is used by rakia and it's

353
00:22:36,620 --> 00:22:44,750
written dotnet framework this Maurya

354
00:22:39,860 --> 00:22:50,840
access is only every 30 minutes but our

355
00:22:44,750 --> 00:22:54,890
model can detect it from now on let's

356
00:22:50,840 --> 00:23:00,909
take a look at banking Trojan first a

357
00:22:54,890 --> 00:23:03,490
sniff these are a little bit complicated

358
00:23:00,910 --> 00:23:07,010
patterns like this

359
00:23:03,490 --> 00:23:14,440
it connects 2 or 3 minutes in a row and

360
00:23:07,010 --> 00:23:14,440
it sleeps for several minutes like this

361
00:23:15,580 --> 00:23:25,250
next sheet or ship it almost connects

362
00:23:20,450 --> 00:23:28,820
every minute and boat rock it connects

363
00:23:25,250 --> 00:23:34,520
every 3 or 4 minutes and sometimes 2

364
00:23:28,820 --> 00:23:37,399
minutes in all and the last one is

365
00:23:34,520 --> 00:23:41,480
Keynes it almost connects every 7

366
00:23:37,400 --> 00:23:44,360
minutes thus our model is able to detect

367
00:23:41,480 --> 00:23:46,840
a variety of patterns and Marvel

368
00:23:44,360 --> 00:23:46,840
families

369
00:23:46,990 --> 00:23:54,410
ok let's summarize for this section our

370
00:23:51,700 --> 00:23:57,290
simple CNN model can detect malicious

371
00:23:54,410 --> 00:24:01,160
communication with sufficiently high

372
00:23:57,290 --> 00:24:04,550
performance the result for our test test

373
00:24:01,160 --> 00:24:07,280
data set is high accuracy as well as low

374
00:24:04,550 --> 00:24:10,190
false positives against in the world

375
00:24:07,280 --> 00:24:14,000
Maria our model can detect all 11 Mario

376
00:24:10,190 --> 00:24:16,850
families that we tested to accommodate

377
00:24:14,000 --> 00:24:19,850
very various patterns and image size

378
00:24:16,850 --> 00:24:23,240
should not be too big even though it

379
00:24:19,850 --> 00:24:25,760
seems to work well at first glance there

380
00:24:23,240 --> 00:24:29,990
is a possibility that it will not detect

381
00:24:25,760 --> 00:24:32,780
if a pattern changed slightly to rotate

382
00:24:29,990 --> 00:24:38,060
a pattern and to mix noise could reduce

383
00:24:32,780 --> 00:24:40,370
false negatives false positives sorry

384
00:24:38,060 --> 00:24:43,090
false positive images are required

385
00:24:40,370 --> 00:24:43,090
somewhat

386
00:24:43,970 --> 00:24:51,210
in order to apply real-world environment

387
00:24:47,490 --> 00:24:53,790
you should consider a measure of false

388
00:24:51,210 --> 00:24:57,000
positive force positives for example

389
00:24:53,790 --> 00:25:00,090
some external websites such as cloud

390
00:24:57,000 --> 00:25:03,450
storages spotting date spot news sites

391
00:25:00,090 --> 00:25:05,850
stock markets and so on might cause

392
00:25:03,450 --> 00:25:09,750
false positives because because of

393
00:25:05,850 --> 00:25:12,270
frequent or eroding or accessing so you

394
00:25:09,750 --> 00:25:13,170
need to filter out these websites with

395
00:25:12,270 --> 00:25:16,559
whitelist

396
00:25:13,170 --> 00:25:20,550
in advance or you need to filter them

397
00:25:16,559 --> 00:25:25,440
out if the same alerts come up from many

398
00:25:20,550 --> 00:25:28,830
clients ok that's it for this detection

399
00:25:25,440 --> 00:25:39,900
method let's move on to the next exploit

400
00:25:28,830 --> 00:25:42,090
kit detection okay we introduced our

401
00:25:39,900 --> 00:25:46,710
exploit kit detection method with deep

402
00:25:42,090 --> 00:25:48,899
neural networks firstly we introduced

403
00:25:46,710 --> 00:25:52,290
some existing approaches to detect

404
00:25:48,900 --> 00:25:55,230
exploit kids one of the most popular

405
00:25:52,290 --> 00:25:57,659
method is pattern matching well example

406
00:25:55,230 --> 00:26:01,860
URL pattern matching and a Content

407
00:25:57,660 --> 00:26:05,370
pattern matching this is an actual

408
00:26:01,860 --> 00:26:09,659
public exploit kit there are two

409
00:26:05,370 --> 00:26:11,820
meaningless parameters and palette and

410
00:26:09,660 --> 00:26:15,000
the example below is a regex pattern

411
00:26:11,820 --> 00:26:17,510
that we used to detect this URL it's

412
00:26:15,000 --> 00:26:17,510
very complex

413
00:26:18,530 --> 00:26:22,879
unfortunately there are some programs in

414
00:26:21,090 --> 00:26:25,559
this method

415
00:26:22,880 --> 00:26:29,370
attackers can change the characteristics

416
00:26:25,559 --> 00:26:31,649
of URLs and contents easily it's because

417
00:26:29,370 --> 00:26:35,428
these are not important for exploited

418
00:26:31,650 --> 00:26:37,740
functions and purposes first and

419
00:26:35,429 --> 00:26:41,730
parameters in those URLs are often

420
00:26:37,740 --> 00:26:43,740
randomized therefore it's difficult to

421
00:26:41,730 --> 00:26:48,840
collect the whole patterns of ongoing

422
00:26:43,740 --> 00:26:51,720
exploit kits and at card also first get

423
00:26:48,840 --> 00:26:56,030
contents heavily therefore the pattern

424
00:26:51,720 --> 00:26:56,030
matching method is not always successful

425
00:26:57,600 --> 00:27:04,209
behavioural analysis is another approach

426
00:27:00,280 --> 00:27:06,580
to detect exploit kids each carton boxes

427
00:27:04,210 --> 00:27:11,500
can detect exploit the kids by actually

428
00:27:06,580 --> 00:27:15,760
browsing each website however there are

429
00:27:11,500 --> 00:27:17,710
some program to this approach a sandbox

430
00:27:15,760 --> 00:27:21,160
requires a lot of web browsers and the

431
00:27:17,710 --> 00:27:24,330
program for detection it's impossible to

432
00:27:21,160 --> 00:27:26,350
prepare for all of the combinations

433
00:27:24,330 --> 00:27:29,710
behavioral analysis spend several

434
00:27:26,350 --> 00:27:32,080
minutes clicking each URL and some

435
00:27:29,710 --> 00:27:36,550
expertise could Dirac return boxes and

436
00:27:32,080 --> 00:27:40,830
could also a bait them therefore we have

437
00:27:36,550 --> 00:27:40,830
real analysis does not always work well

438
00:27:41,040 --> 00:27:47,200
this is our strategy extra to keep

439
00:27:45,100 --> 00:27:51,879
Sabbath send the content in a specific

440
00:27:47,200 --> 00:27:55,179
order first place in random pages second

441
00:27:51,880 --> 00:27:57,179
this and exploit contents such as flash

442
00:27:55,179 --> 00:28:00,040
exploit and so on

443
00:27:57,179 --> 00:28:03,880
finally this is an amalgam a road that

444
00:28:00,040 --> 00:28:05,649
was eroded by the exploit maybe it model

445
00:28:03,880 --> 00:28:08,080
to detect the exploit to kids with

446
00:28:05,650 --> 00:28:12,550
fractions by focusing on this specific

447
00:28:08,080 --> 00:28:14,740
order we also try to detect 2x for the

448
00:28:12,550 --> 00:28:16,050
kids with characteristics or blue areas

449
00:28:14,740 --> 00:28:19,000
at first

450
00:28:16,050 --> 00:28:21,909
from now on we'll explain the rata

451
00:28:19,000 --> 00:28:29,290
method first there we explain the formal

452
00:28:21,910 --> 00:28:32,050
method firstly we focused on detecting

453
00:28:29,290 --> 00:28:37,899
legal exploit the kid with stick neural

454
00:28:32,050 --> 00:28:43,450
networks these are examples of expert to

455
00:28:37,900 --> 00:28:46,559
teach URLs number one this is an exploit

456
00:28:43,450 --> 00:28:52,030
our past sample of the gig exploit kit

457
00:28:46,559 --> 00:28:54,720
nama - this is neighbor exploit kit nama

458
00:28:52,030 --> 00:29:00,970
sorry this is sandal exploit kit

459
00:28:54,720 --> 00:29:04,540
this may seem unfamiliar did Connecticut

460
00:29:00,970 --> 00:29:06,669
URLs have these characteristics path and

461
00:29:04,540 --> 00:29:08,899
queries have a lot of directories or

462
00:29:06,669 --> 00:29:10,640
parameters

463
00:29:08,900 --> 00:29:15,950
and they also consist so meaningless

464
00:29:10,640 --> 00:29:18,140
words or numbers host names in the URLs

465
00:29:15,950 --> 00:29:21,559
have strange theories that you don't

466
00:29:18,140 --> 00:29:23,450
usually use in your country they also

467
00:29:21,559 --> 00:29:26,990
have a long and were meaningless domain

468
00:29:23,450 --> 00:29:32,540
names so what are also located in

469
00:29:26,990 --> 00:29:35,330
strange country this o tech tips neural

470
00:29:32,540 --> 00:29:39,950
networks could learn features of those

471
00:29:35,330 --> 00:29:42,830
URLs in this subsection needs a term

472
00:29:39,950 --> 00:29:51,200
tips neural network as Malia passive

473
00:29:42,830 --> 00:29:54,800
draw at first I try to detect big extra

474
00:29:51,200 --> 00:29:57,080
ticket in Superbad running dotted

475
00:29:54,800 --> 00:29:59,270
because legal extra ticket has been the

476
00:29:57,080 --> 00:30:02,059
most popular actual ticket over the last

477
00:29:59,270 --> 00:30:08,480
few years and we had you have collected

478
00:30:02,059 --> 00:30:10,760
many samples to prove our selling for

479
00:30:08,480 --> 00:30:13,340
superbull training we converted to each

480
00:30:10,760 --> 00:30:16,580
line or proxy logs into future vector

481
00:30:13,340 --> 00:30:18,730
that was 345 dimensions are shown on the

482
00:30:16,580 --> 00:30:18,730
slide

483
00:30:19,420 --> 00:30:24,230
underlying the features could express

484
00:30:22,250 --> 00:30:31,280
the tract I stick from your typical

485
00:30:24,230 --> 00:30:34,610
average of extra two kids next we meet a

486
00:30:31,280 --> 00:30:37,940
family at a fully connected DNA model to

487
00:30:34,610 --> 00:30:42,800
run the vectors the first hidden layer

488
00:30:37,940 --> 00:30:45,980
had 100 250 nodes the second and the

489
00:30:42,800 --> 00:30:50,360
third video layered have 30 nodes in the

490
00:30:45,980 --> 00:30:54,370
hidden layer has honestly not amused

491
00:30:50,360 --> 00:31:00,309
our area as activation in your note and

492
00:30:54,370 --> 00:31:00,309
we set your apart at 0.2 in non Reyat

493
00:31:01,780 --> 00:31:07,129
mid-range the demon model with our

494
00:31:04,220 --> 00:31:10,580
training data set there are about two

495
00:31:07,130 --> 00:31:14,840
million lines of proxy logs we collected

496
00:31:10,580 --> 00:31:17,480
them from January to February 2017 the

497
00:31:14,840 --> 00:31:21,530
contains about 26,000 positive examples

498
00:31:17,480 --> 00:31:22,460
of big exploit kit after training the

499
00:31:21,530 --> 00:31:26,029
model with

500
00:31:22,460 --> 00:31:29,320
training dataset the test and now he

501
00:31:26,029 --> 00:31:31,639
tested the model with our test dataset

502
00:31:29,320 --> 00:31:34,730
we found that there are about two

503
00:31:31,639 --> 00:31:38,990
million lines of proxy logs we collected

504
00:31:34,730 --> 00:31:41,509
samples emerged 2017 and it contains

505
00:31:38,990 --> 00:31:47,679
about full circle positive examples of

506
00:31:41,509 --> 00:31:51,259
big exploit kit and the test resulted in

507
00:31:47,679 --> 00:31:56,749
99.99 percent accuracy and 100%

508
00:31:51,259 --> 00:32:06,440
precision however there are some

509
00:31:56,749 --> 00:32:08,330
problems the model could detect but the

510
00:32:06,440 --> 00:32:10,190
model could not detect other exploit the

511
00:32:08,330 --> 00:32:12,649
kids such as neighborhood on Sandow

512
00:32:10,190 --> 00:32:14,659
since these are characteristics in URLs

513
00:32:12,649 --> 00:32:18,350
are very different from league exploit

514
00:32:14,659 --> 00:32:23,080
to keep the model can't detect or an

515
00:32:18,350 --> 00:32:25,428
extra two kicks only therefore we think

516
00:32:23,080 --> 00:32:27,889
that the model is still useful to

517
00:32:25,429 --> 00:32:31,639
dedicate variant and to trace small

518
00:32:27,889 --> 00:32:33,769
changes unfortunately you are eight of

519
00:32:31,639 --> 00:32:36,469
each DK can be dramatically changed

520
00:32:33,769 --> 00:32:41,869
because they are not important for extra

521
00:32:36,470 --> 00:32:44,059
to kick functions and purposes then we

522
00:32:41,869 --> 00:32:47,990
with the detection model that could

523
00:32:44,059 --> 00:32:50,629
detect and exploit the kids from now on

524
00:32:47,990 --> 00:32:58,340
we introduced a method focusing on

525
00:32:50,629 --> 00:33:01,459
content type transition as mentioned

526
00:32:58,340 --> 00:33:04,820
previously a typical egg filter kit Cent

527
00:33:01,460 --> 00:33:06,799
malicious contents in this order when

528
00:33:04,820 --> 00:33:10,610
the big thing existed an injector server

529
00:33:06,799 --> 00:33:13,999
of extra two kids the big tail the shiva

530
00:33:10,610 --> 00:33:16,459
surrounding a page fast then the random

531
00:33:13,999 --> 00:33:20,899
page is a victim to download export

532
00:33:16,460 --> 00:33:26,179
content finally mario mario period is

533
00:33:20,899 --> 00:33:28,309
loaded as a result of the exploit these

534
00:33:26,179 --> 00:33:32,539
are the actual URL and content types

535
00:33:28,309 --> 00:33:34,190
trampled or big exploit kit this is a

536
00:33:32,539 --> 00:33:37,908
landing page

537
00:33:34,190 --> 00:33:45,960
this is an exploit content rush exploit

538
00:33:37,909 --> 00:33:48,210
this is a modular payload these are the

539
00:33:45,960 --> 00:33:52,940
actual URL and content type sample of

540
00:33:48,210 --> 00:34:00,630
neutrino exploit get a landing page a

541
00:33:52,940 --> 00:34:02,159
flash exploit and a male payload and

542
00:34:00,630 --> 00:34:05,700
these are the actual URL and content

543
00:34:02,159 --> 00:34:09,290
examples of caching exploit kit in this

544
00:34:05,700 --> 00:34:13,859
case much to exploit contents are loaded

545
00:34:09,290 --> 00:34:20,070
this is an IE exploit and this is a java

546
00:34:13,859 --> 00:34:23,369
exploit the order is different in banana

547
00:34:20,070 --> 00:34:25,409
birds and contents in the case of

548
00:34:23,369 --> 00:34:27,480
commercial or odd services they

549
00:34:25,409 --> 00:34:32,609
typically prepare dedicated servers for

550
00:34:27,480 --> 00:34:35,668
each content type for example one for

551
00:34:32,609 --> 00:34:38,609
static text content such as HTML CSS J's

552
00:34:35,668 --> 00:34:44,250
and so a lot of for graphic content such

553
00:34:38,609 --> 00:34:47,848
as jpg PNG and so in the case of small

554
00:34:44,250 --> 00:34:50,310
services and private websites they

555
00:34:47,849 --> 00:34:52,520
usually prepare a single server for all

556
00:34:50,310 --> 00:34:55,560
content types

557
00:34:52,520 --> 00:34:59,070
therefore much product content are sent

558
00:34:55,560 --> 00:35:00,630
from the same server we saw that we can

559
00:34:59,070 --> 00:35:05,180
distinguish between these benign

560
00:35:00,630 --> 00:35:05,180
contents order and extra to each one so

561
00:35:06,109 --> 00:35:13,470
we focus on content type sequences also

562
00:35:11,010 --> 00:35:15,740
those sequences are struggle deleted two

563
00:35:13,470 --> 00:35:18,180
extra two kids fundamental functions

564
00:35:15,740 --> 00:35:21,598
they cannot change the sequence pattern

565
00:35:18,180 --> 00:35:23,848
easily therefore we thought it's

566
00:35:21,599 --> 00:35:25,980
possible to detect extra tickets by

567
00:35:23,849 --> 00:35:28,410
checking content type sequences from

568
00:35:25,980 --> 00:35:34,619
each web server with recurrent neural

569
00:35:28,410 --> 00:35:36,810
network the controller network is a type

570
00:35:34,619 --> 00:35:38,520
of artificial neural network it's

571
00:35:36,810 --> 00:35:40,710
typically used to process natural

572
00:35:38,520 --> 00:35:43,800
language and time series data such as

573
00:35:40,710 --> 00:35:46,440
audio waveform and video stream any

574
00:35:43,800 --> 00:35:47,830
collateral networks each out to put over

575
00:35:46,440 --> 00:35:49,660
hidden layer node

576
00:35:47,830 --> 00:35:53,350
it really with the next data in the

577
00:35:49,660 --> 00:35:55,450
sequence again pick a name is a Lenin to

578
00:35:53,350 --> 00:35:59,380
remember it status in relationship to

579
00:35:55,450 --> 00:36:02,049
the previous data that Ireland can

580
00:35:59,380 --> 00:36:08,200
recognize the order of content in each

581
00:36:02,050 --> 00:36:11,710
sequence to pass fractions with the

582
00:36:08,200 --> 00:36:14,230
recurrent neural network model we

583
00:36:11,710 --> 00:36:17,650
converted proxy jobs into future vector

584
00:36:14,230 --> 00:36:23,650
sequences in these ways we also set the

585
00:36:17,650 --> 00:36:27,180
length of each secret at five firstly

586
00:36:23,650 --> 00:36:30,190
mix production rose by distillation host

587
00:36:27,180 --> 00:36:35,049
then we converted to each of them into

588
00:36:30,190 --> 00:36:38,820
one sequence these roles split it into

589
00:36:35,050 --> 00:36:38,820
these four sequences

590
00:36:42,480 --> 00:36:47,590
secondly we leads to each sequence to

591
00:36:46,000 --> 00:36:50,680
enable the random model to be tolerant

592
00:36:47,590 --> 00:36:53,470
of noise when lines containing the same

593
00:36:50,680 --> 00:36:55,180
content type of continuous we only did

594
00:36:53,470 --> 00:36:56,529
the second round and all of the

595
00:36:55,180 --> 00:37:02,109
following lines containing the same

596
00:36:56,530 --> 00:37:04,780
content type we also need to flip

597
00:37:02,110 --> 00:37:07,360
we also emitted the sixth and any future

598
00:37:04,780 --> 00:37:13,000
and because the ranks of sequence was

599
00:37:07,360 --> 00:37:15,340
set at five finally we converted each

600
00:37:13,000 --> 00:37:18,670
line into a future vector that has

601
00:37:15,340 --> 00:37:20,710
eighty four dimensions the first eighty

602
00:37:18,670 --> 00:37:23,680
three dimensions express a content type

603
00:37:20,710 --> 00:37:26,920
that was combative with one hot encoding

604
00:37:23,680 --> 00:37:29,410
and the remaining dimension is a frail

605
00:37:26,920 --> 00:37:36,340
if a URL and a referrer contains the

606
00:37:29,410 --> 00:37:38,770
same domain why not next we will

607
00:37:36,340 --> 00:37:43,360
aresty model with killers as showed on

608
00:37:38,770 --> 00:37:45,490
the slide a steam is an abbreviation for

609
00:37:43,360 --> 00:37:49,390
on short-term memory and exact type of

610
00:37:45,490 --> 00:37:51,609
the control network we also tested other

611
00:37:49,390 --> 00:37:53,470
early models such as simpler linear

612
00:37:51,610 --> 00:37:57,610
models and gated to the currently linked

613
00:37:53,470 --> 00:38:01,830
models we found that realistic models

614
00:37:57,610 --> 00:38:01,830
worked with other others in this case

615
00:38:02,040 --> 00:38:13,630
our mother has three and stimulated to

616
00:38:05,230 --> 00:38:17,070
recognize in the sequence featuring the

617
00:38:13,630 --> 00:38:20,710
model is these two datasets one dataset

618
00:38:17,070 --> 00:38:24,010
consisted of many sequences we gathered

619
00:38:20,710 --> 00:38:26,140
about 570 thousand of benign sequences

620
00:38:24,010 --> 00:38:29,800
from about four million lines of our

621
00:38:26,140 --> 00:38:32,049
proxy loops the other data set consisted

622
00:38:29,800 --> 00:38:35,619
of two domains of sequences that we

623
00:38:32,050 --> 00:38:37,480
generated in generated about two three

624
00:38:35,619 --> 00:38:40,240
hundred to three thousand extra to click

625
00:38:37,480 --> 00:38:48,160
like sequences that of characteristics

626
00:38:40,240 --> 00:38:50,109
are shown on the slide these are

627
00:38:48,160 --> 00:38:55,839
examples of generated content of

628
00:38:50,109 --> 00:39:00,250
sequences a is a typical sequence B in a

629
00:38:55,840 --> 00:39:01,690
case that exploits exceeded twice well

630
00:39:00,250 --> 00:39:04,660
if you included during a landing page

631
00:39:01,690 --> 00:39:10,660
and the other is a typical for us to

632
00:39:04,660 --> 00:39:14,950
exploit see in the case that multiple

633
00:39:10,660 --> 00:39:19,690
exploits are loaded and D is cast at an

634
00:39:14,950 --> 00:39:23,319
exploit failed the following slides will

635
00:39:19,690 --> 00:39:25,420
explain the test and the result we

636
00:39:23,320 --> 00:39:28,450
tested the model with much of sequences

637
00:39:25,420 --> 00:39:30,790
that consisted of actual 14 extra to

638
00:39:28,450 --> 00:39:34,450
kick traffic such as league Libre

639
00:39:30,790 --> 00:39:40,180
Terra and so on the model could detect

640
00:39:34,450 --> 00:39:43,270
or object these are examples that the

641
00:39:40,180 --> 00:39:46,029
model successfully detected sequence a

642
00:39:43,270 --> 00:39:49,859
in the real eager sequence to the

643
00:39:46,030 --> 00:39:53,530
debilitate car B is a nebula classic as

644
00:39:49,859 --> 00:39:57,730
the deck SWAT failed the sequence and

645
00:39:53,530 --> 00:39:59,920
wizard payload C is a Newton occur

646
00:39:57,730 --> 00:40:03,850
sequence this is one of the popular

647
00:39:59,920 --> 00:40:06,369
patterns of Newtonian and D is a

648
00:40:03,850 --> 00:40:09,160
question occurs occurs it contains much

649
00:40:06,369 --> 00:40:13,720
more expert content and loading actually

650
00:40:09,160 --> 00:40:16,470
and a landing page is loaded twice I it

651
00:40:13,720 --> 00:40:19,299
also end without failure

652
00:40:16,470 --> 00:40:21,520
we also tested the model with benign

653
00:40:19,300 --> 00:40:25,840
sequences other than the ones we had

654
00:40:21,520 --> 00:40:28,870
used in the training phase B is three

655
00:40:25,840 --> 00:40:32,290
three finished data sets each of them

656
00:40:28,870 --> 00:40:34,180
had around 500 to 17,000 sequences that

657
00:40:32,290 --> 00:40:39,730
are gathered from about four million

658
00:40:34,180 --> 00:40:43,720
lines of proxy logs we corrected the

659
00:40:39,730 --> 00:40:50,290
rogues in May 2017 and the test resulted

660
00:40:43,720 --> 00:40:52,390
in 99 that 88 percent accuracy we could

661
00:40:50,290 --> 00:40:54,730
reduce the number of false positives in

662
00:40:52,390 --> 00:40:58,540
to her by applying a simple white list

663
00:40:54,730 --> 00:41:01,060
that contains only 15 domains we can

664
00:40:58,540 --> 00:41:03,610
also use false positives is applying hot

665
00:41:01,060 --> 00:41:09,610
reputation and imagine Isis automated

666
00:41:03,610 --> 00:41:11,980
Santa boxes and manual analysis in this

667
00:41:09,610 --> 00:41:14,560
section we can detect or unlearn exploit

668
00:41:11,980 --> 00:41:16,800
the kids with our l HTI model it's

669
00:41:14,560 --> 00:41:20,740
likely to detect a brand new export kid

670
00:41:16,800 --> 00:41:23,920
we can also detect on land no extra two

671
00:41:20,740 --> 00:41:28,200
kids with our DNA model it's effective

672
00:41:23,920 --> 00:41:28,200
to trace variants of no exploit the kids

673
00:41:28,650 --> 00:41:36,730
okay let me summarize this talk our

674
00:41:34,390 --> 00:41:38,560
simple scene model can't detect

675
00:41:36,730 --> 00:41:42,970
emergency to communications with

676
00:41:38,560 --> 00:41:45,400
sufficiently high performance and our

677
00:41:42,970 --> 00:41:48,120
arrest a model candidate to Ireland EXO

678
00:41:45,400 --> 00:41:48,120
to kick traffic

679
00:41:51,920 --> 00:41:57,390
and I'll explain sound bites for our

680
00:41:54,600 --> 00:41:58,860
presentation first we provided the

681
00:41:57,390 --> 00:42:03,029
practical ways to detect malicious

682
00:41:58,860 --> 00:42:05,250
activities second we gave you several

683
00:42:03,030 --> 00:42:09,930
new techniques for utilizing August of

684
00:42:05,250 --> 00:42:11,520
ordinary devices third we disclosed all

685
00:42:09,930 --> 00:42:14,069
parameters to detect malicious

686
00:42:11,520 --> 00:42:18,600
activities and attendees are able to

687
00:42:14,070 --> 00:42:30,330
reproduce them that's it for our

688
00:42:18,600 --> 00:42:41,009
presentation any questions thank you

689
00:42:30,330 --> 00:42:43,170
very much thank you for the presentation

690
00:42:41,010 --> 00:42:46,320
you you had a very high dimensionality

691
00:42:43,170 --> 00:42:50,310
with 84 I think features in your on your

692
00:42:46,320 --> 00:42:51,750
vector and you also through some you

693
00:42:50,310 --> 00:42:55,230
have some very specific number of layers

694
00:42:51,750 --> 00:42:57,270
and for your for your deep networks did

695
00:42:55,230 --> 00:42:58,920
you experiment with different values to

696
00:42:57,270 --> 00:43:05,600
see if you could get away with fewer

697
00:42:58,920 --> 00:43:10,170
features or fewer layers yes we tried

698
00:43:05,600 --> 00:43:14,330
several radius and we have used

699
00:43:10,170 --> 00:43:21,600
different patterns over areas and yeah

700
00:43:14,330 --> 00:43:31,440
yes we tried some but not more so we

701
00:43:21,600 --> 00:43:37,430
could raise the accuracy of the by

702
00:43:31,440 --> 00:43:44,040
changing the models but at this time we

703
00:43:37,430 --> 00:43:47,930
will we would like to show you the we

704
00:43:44,040 --> 00:43:53,700
would like to show you the results of

705
00:43:47,930 --> 00:43:59,940
very small small models because we can

706
00:43:53,700 --> 00:44:04,160
use it with without GPUs or yeah you can

707
00:43:59,940 --> 00:44:04,160
only use CPU

708
00:44:13,640 --> 00:44:18,810
hi thanks for the talk

709
00:44:16,890 --> 00:44:25,080
referring to the first the c2

710
00:44:18,810 --> 00:44:28,620
communication detection first of all did

711
00:44:25,080 --> 00:44:34,290
you were all of the eleven malware in

712
00:44:28,620 --> 00:44:36,210
the training set that you detected you

713
00:44:34,290 --> 00:44:43,290
mentioned that you detected eleven types

714
00:44:36,210 --> 00:44:45,480
of these long before know that the yes

715
00:44:43,290 --> 00:44:52,140
as in were those in the training set

716
00:44:45,480 --> 00:44:56,450
there's yeah we don't include we didn't

717
00:44:52,140 --> 00:45:00,480
included we didn't include the actual

718
00:44:56,450 --> 00:45:05,089
actual Mari of harmonies oh yeah yeah

719
00:45:00,480 --> 00:45:07,350
yeah so um well my question because

720
00:45:05,090 --> 00:45:11,490
least at the end es mentioned you had to

721
00:45:07,350 --> 00:45:13,350
whitelist some domains because as far as

722
00:45:11,490 --> 00:45:15,680
I understand your detecting for

723
00:45:13,350 --> 00:45:18,860
basically consistent periodic

724
00:45:15,680 --> 00:45:21,899
communication which can happen with

725
00:45:18,860 --> 00:45:24,270
legitimate servers as well and I wonder

726
00:45:21,900 --> 00:45:27,630
if you were able to identify any unique

727
00:45:24,270 --> 00:45:30,770
characteristics of malicious consistent

728
00:45:27,630 --> 00:45:35,670
periodic communication as as opposed to

729
00:45:30,770 --> 00:45:43,650
legitimate ones for example weakening to

730
00:45:35,670 --> 00:45:46,830
a mail server versus so we are could you

731
00:45:43,650 --> 00:45:51,180
give me a simple question harm so

732
00:45:46,830 --> 00:45:53,299
basically what I'm looking for is I are

733
00:45:51,180 --> 00:45:55,830
there any characteristics of the

734
00:45:53,300 --> 00:46:01,560
communication between all of these

735
00:45:55,830 --> 00:46:05,060
families of malicious malware they are

736
00:46:01,560 --> 00:46:08,690
unique to those rather than legitimate

737
00:46:05,060 --> 00:46:08,690
periodic communication

738
00:46:17,430 --> 00:46:20,730
because I understand your you're

739
00:46:18,990 --> 00:46:24,089
detecting periodic communication we're

740
00:46:20,730 --> 00:46:25,920
using this model and that's why you end

741
00:46:24,090 --> 00:46:30,170
up having to whitelist things because

742
00:46:25,920 --> 00:46:30,170
periodic communication can happen with

743
00:46:31,030 --> 00:46:34,179
[Music]

744
00:46:49,610 --> 00:47:05,220
your questions do we use the regiment

745
00:46:59,490 --> 00:47:11,279
samples in training dataset right no I'm

746
00:47:05,220 --> 00:47:11,580
not sure the question I talk to you

747
00:47:11,280 --> 00:47:15,030
later

748
00:47:11,580 --> 00:47:17,730
yeah sorry one quick question also would

749
00:47:15,030 --> 00:47:21,990
be would you be able to use the same

750
00:47:17,730 --> 00:47:24,750
method for without specifying without

751
00:47:21,990 --> 00:47:26,339
separating per server so at the moment

752
00:47:24,750 --> 00:47:30,210
you're separating at the proxy per

753
00:47:26,340 --> 00:47:32,220
server at external server so if you

754
00:47:30,210 --> 00:47:35,690
combine them would you be able to find a

755
00:47:32,220 --> 00:47:38,310
pattern within the signal for example if

756
00:47:35,690 --> 00:47:42,300
the malware is communicating to multiple

757
00:47:38,310 --> 00:47:43,890
endpoints at the same time multiple see

758
00:47:42,300 --> 00:47:51,030
to serve us yeah

759
00:47:43,890 --> 00:47:58,529
multiple cities yeah several samples use

760
00:47:51,030 --> 00:48:03,900
used multiple c2 servers but many of

761
00:47:58,530 --> 00:48:09,540
Mara's once they connected they can they

762
00:48:03,900 --> 00:48:16,910
could connected it could connect it it

763
00:48:09,540 --> 00:48:25,140
used only one c2 server so we we can get

764
00:48:16,910 --> 00:48:27,629
the same result but if they use round

765
00:48:25,140 --> 00:48:33,960
robin or something

766
00:48:27,630 --> 00:48:39,769
then it's it's re bit harder to detect

767
00:48:33,960 --> 00:48:39,769
the sample of course all right next

768
00:48:52,099 --> 00:48:57,960
are you are using your models in

769
00:48:55,170 --> 00:49:01,589
practice as you are from an isp are you

770
00:48:57,960 --> 00:49:04,829
using it and what's the cost associated

771
00:49:01,589 --> 00:49:06,660
because it's not only their training

772
00:49:04,829 --> 00:49:09,390
it's the interesting thing is that at

773
00:49:06,660 --> 00:49:19,259
runtime how efficient can you kind of

774
00:49:09,390 --> 00:49:24,089
check the classifiers oh sorry your

775
00:49:19,260 --> 00:49:28,529
questions we are using this method in we

776
00:49:24,089 --> 00:49:32,880
are environment yes okay we are testing

777
00:49:28,529 --> 00:49:39,930
the method right now and yeah so far

778
00:49:32,880 --> 00:49:43,980
it's good result is it no you're correct

779
00:49:39,930 --> 00:49:54,990
now implementing the engine now we are

780
00:49:43,980 --> 00:49:59,890
testing artistic taste okay thank you

781
00:49:54,990 --> 00:50:04,189
for coming our session that's it

782
00:49:59,890 --> 00:50:04,190
[Applause]

