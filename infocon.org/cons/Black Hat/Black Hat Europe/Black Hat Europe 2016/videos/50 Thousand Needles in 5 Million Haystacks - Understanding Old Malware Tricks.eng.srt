1
00:00:00,570 --> 00:00:04,080
hello good morning we are here today to

2
00:00:04,080 --> 00:00:07,319
talk about how to find 50,000 needles in

3
00:00:07,319 --> 00:00:10,200
five million high stakes this talk is

4
00:00:10,200 --> 00:00:12,410
going to be about the combination of

5
00:00:12,410 --> 00:00:15,120
network traffic analysis split hunting

6
00:00:15,120 --> 00:00:19,650
and machine learning so that's what you

7
00:00:19,650 --> 00:00:24,750
should expect to see here but before we

8
00:00:24,750 --> 00:00:26,400
would like to introduce ourselves very

9
00:00:26,400 --> 00:00:28,310
briefly I'm Veronica I'm from Argentina

10
00:00:28,310 --> 00:00:31,980
I'm a manual traffic researcher and

11
00:00:31,980 --> 00:00:33,870
presidental analyst and conduct

12
00:00:33,870 --> 00:00:36,719
analytics which is part of Cisco Misaka

13
00:00:36,719 --> 00:00:38,790
founder of the meth lab hackerspace

14
00:00:38,790 --> 00:00:41,850
vacuum on Osiris and here today we took

15
00:00:41,850 --> 00:00:43,920
my colleagues tell voltage

16
00:00:43,920 --> 00:00:47,039
he's from Czech Republic network

17
00:00:47,039 --> 00:00:49,200
security researcher and Lukas must

18
00:00:49,200 --> 00:00:52,680
Melissa she's from Slovakia and she's

19
00:00:52,680 --> 00:00:58,109
also doing another security research in

20
00:00:58,109 --> 00:01:03,559
a group so let's get started we are

21
00:01:03,559 --> 00:01:05,909
today we are living in very interesting

22
00:01:05,909 --> 00:01:10,680
times our world is connected as never

23
00:01:10,680 --> 00:01:12,530
been before right

24
00:01:12,530 --> 00:01:16,890
from creatures to cars to anything and

25
00:01:16,890 --> 00:01:21,990
this is very useful sometimes and this

26
00:01:21,990 --> 00:01:24,299
connectivity is because sometimes we

27
00:01:24,299 --> 00:01:26,670
want it to be this way right and

28
00:01:26,670 --> 00:01:28,920
sometimes because we forgot to change

29
00:01:28,920 --> 00:01:32,369
the port password which is happens more

30
00:01:32,369 --> 00:01:36,450
often than we think and we we are citing

31
00:01:36,450 --> 00:01:38,369
unique challenges and that's only

32
00:01:38,369 --> 00:01:42,829
because of the new tricks methods and

33
00:01:42,829 --> 00:01:45,420
sophistication or lack of that malware

34
00:01:45,420 --> 00:01:47,159
authors are bringing to the table every

35
00:01:47,159 --> 00:01:49,680
week every every month but also because

36
00:01:49,680 --> 00:01:51,439
of the scale of the attacks

37
00:01:51,439 --> 00:01:54,810
organisations or users are one click

38
00:01:54,810 --> 00:01:56,850
away to get any infected almost every

39
00:01:56,850 --> 00:01:59,399
every single day from malicious

40
00:01:59,399 --> 00:02:02,430
advertising to as well and phishing

41
00:02:02,430 --> 00:02:04,950
phishing being a big one of the biggest

42
00:02:04,950 --> 00:02:07,789
sources of infections nowadays the most

43
00:02:07,789 --> 00:02:10,830
complex sets such as ransom well I'm

44
00:02:10,830 --> 00:02:13,220
sure you have a lot this year

45
00:02:13,220 --> 00:02:15,900
banking Trojans information stealers

46
00:02:15,900 --> 00:02:20,540
remote access trojan and so on so this

47
00:02:20,540 --> 00:02:25,500
this means that the question that we ask

48
00:02:25,500 --> 00:02:27,690
ourselves has changed in the last couple

49
00:02:27,690 --> 00:02:28,470
of years

50
00:02:28,470 --> 00:02:31,170
the question right now is not longer if

51
00:02:31,170 --> 00:02:33,000
an organization is going to be breached

52
00:02:33,000 --> 00:02:34,170
by one

53
00:02:34,170 --> 00:02:36,660
it can't happen this week it can happen

54
00:02:36,660 --> 00:02:40,110
next year right the thing is how do we

55
00:02:40,110 --> 00:02:42,720
prepare against that and if we assume

56
00:02:42,720 --> 00:02:45,480
that at some point we organizations are

57
00:02:45,480 --> 00:02:48,000
are going to be rich we are going to

58
00:02:48,000 --> 00:02:50,850
have active infections right then it's

59
00:02:50,850 --> 00:02:53,069
clear what we need to do is basically

60
00:02:53,069 --> 00:02:55,560
look for these threads that already

61
00:02:55,560 --> 00:02:57,569
bypass all the security measures that we

62
00:02:57,569 --> 00:02:59,730
have in place because we have anti

63
00:02:59,730 --> 00:03:02,549
viruses we have IDS's we have all these

64
00:03:02,549 --> 00:03:04,170
rights but what happened if there is

65
00:03:04,170 --> 00:03:07,290
something new that already bypassed

66
00:03:07,290 --> 00:03:09,840
these security measures and is on our

67
00:03:09,840 --> 00:03:15,180
network some but this this is basically

68
00:03:15,180 --> 00:03:18,810
the definition of site hunting which is

69
00:03:18,810 --> 00:03:21,209
continuous tombs compromised okay

70
00:03:21,209 --> 00:03:22,709
they assume that you are already

71
00:03:22,709 --> 00:03:25,350
compromised and they have a series of

72
00:03:25,350 --> 00:03:27,299
methodologies and techniques to actually

73
00:03:27,299 --> 00:03:29,040
search for these threats on your network

74
00:03:29,040 --> 00:03:31,890
that's what many companies do but and

75
00:03:31,890 --> 00:03:33,630
this is what I do

76
00:03:33,630 --> 00:03:40,500
big-scale for a living so if my job is

77
00:03:40,500 --> 00:03:43,620
not actually quite like this and if it's

78
00:03:43,620 --> 00:03:45,329
very interesting to see the comparisons

79
00:03:45,329 --> 00:03:48,060
because in normal hunting you actually

80
00:03:48,060 --> 00:03:50,100
know many things you know the

81
00:03:50,100 --> 00:03:51,780
environment where you are going to hunt

82
00:03:51,780 --> 00:03:55,980
you know your weapon you know I'm more

83
00:03:55,980 --> 00:03:57,989
importantly you know your plane you know

84
00:03:57,989 --> 00:04:00,510
what you are hunting for you know how it

85
00:04:00,510 --> 00:04:02,430
looks like you know the colors you know

86
00:04:02,430 --> 00:04:05,549
the type so you know if you have good

87
00:04:05,549 --> 00:04:09,359
chances or not but in my job and many of

88
00:04:09,359 --> 00:04:10,139
your jobs

89
00:04:10,139 --> 00:04:13,139
this is not like it because I don't know

90
00:04:13,139 --> 00:04:16,070
what I'm hunting for in my network I

91
00:04:16,070 --> 00:04:18,269
don't know where to start and I'm

92
00:04:18,269 --> 00:04:19,798
looking for things that I already

93
00:04:19,798 --> 00:04:21,810
bypassed they're anti viruses

94
00:04:21,810 --> 00:04:24,120
I already bypass all the signatures I'm

95
00:04:24,120 --> 00:04:26,460
looking I'm hunting for something

96
00:04:26,460 --> 00:04:30,479
completely unknown so this is this is

97
00:04:30,479 --> 00:04:34,169
how common network looks like and when I

98
00:04:34,169 --> 00:04:36,599
have no idea what I'm looking for and in

99
00:04:36,599 --> 00:04:39,900
my case is thousands or hundreds of

100
00:04:39,900 --> 00:04:44,430
different networks so what do we do here

101
00:04:44,430 --> 00:04:46,860
is not actually true that I don't know

102
00:04:46,860 --> 00:04:49,800
anything I'm not I'm not truly hunting

103
00:04:49,800 --> 00:04:51,599
for them no because there are some

104
00:04:51,599 --> 00:04:53,970
things that we already know because we

105
00:04:53,970 --> 00:04:55,830
know how one contortions communicate

106
00:04:55,830 --> 00:04:56,340
right

107
00:04:56,340 --> 00:04:58,710
we know bank interest in general we know

108
00:04:58,710 --> 00:05:00,780
that they goal is to steal credentials

109
00:05:00,780 --> 00:05:03,599
from the user so they will at some point

110
00:05:03,599 --> 00:05:05,550
when they steal the credentials they

111
00:05:05,550 --> 00:05:07,919
need to send them out okay to the

112
00:05:07,919 --> 00:05:10,380
attackers if we have a remote access

113
00:05:10,380 --> 00:05:13,889
Trojan the that piece of malware

114
00:05:13,889 --> 00:05:15,660
actually needs an active communication

115
00:05:15,660 --> 00:05:17,039
because it needs to be actually

116
00:05:17,039 --> 00:05:18,960
controlled by the attacker if we have

117
00:05:18,960 --> 00:05:21,720
acceleration surgeons it's actually safe

118
00:05:21,720 --> 00:05:24,180
clicked run it's actually the same so

119
00:05:24,180 --> 00:05:26,039
there is one thing that they have in

120
00:05:26,039 --> 00:05:28,229
common and that is they need to

121
00:05:28,229 --> 00:05:30,539
communicate to the network and there is

122
00:05:30,539 --> 00:05:32,669
where we can take this need to

123
00:05:32,669 --> 00:05:35,280
communicate exploit it to make it our

124
00:05:35,280 --> 00:05:38,759
competitive advantage and this is what

125
00:05:38,759 --> 00:05:41,550
we do but the the problem the next

126
00:05:41,550 --> 00:05:43,169
problem is like the sizes of our

127
00:05:43,169 --> 00:05:45,930
networks we are talking about every user

128
00:05:45,930 --> 00:05:49,770
in an organization has 3 4 5 6 devices

129
00:05:49,770 --> 00:05:52,949
so if no longer that or network is

130
00:05:52,949 --> 00:05:55,229
hundreds of devices is that multiplied

131
00:05:55,229 --> 00:05:59,070
for 5 right so we are consuming we are

132
00:05:59,070 --> 00:06:03,300
talking about a lot of data but wait big

133
00:06:03,300 --> 00:06:05,070
data is no longer a problem not a

134
00:06:05,070 --> 00:06:09,449
challenge anymore we know how to or with

135
00:06:09,449 --> 00:06:11,280
big data we have this software we have

136
00:06:11,280 --> 00:06:14,699
the storage right this is this is not

137
00:06:14,699 --> 00:06:16,530
matter of discussion anymore

138
00:06:16,530 --> 00:06:19,530
and the problem now the next problem is

139
00:06:19,530 --> 00:06:23,430
I cannot replace humans right because

140
00:06:23,430 --> 00:06:26,130
the threats expert is knows where to

141
00:06:26,130 --> 00:06:29,159
look at notes if they they are looking

142
00:06:29,159 --> 00:06:30,389
at the network if I'm look at the

143
00:06:30,389 --> 00:06:31,919
network I know which things are

144
00:06:31,919 --> 00:06:34,710
interesting I know I can tell ok this

145
00:06:34,710 --> 00:06:36,960
piece of proxy

146
00:06:36,960 --> 00:06:40,979
it seems very suspicious to me and can

147
00:06:40,979 --> 00:06:42,960
we how can we do that and here's where

148
00:06:42,960 --> 00:06:45,270
machine learning comes to place because

149
00:06:45,270 --> 00:06:47,520
what if we can teach machine learning to

150
00:06:47,520 --> 00:06:52,080
actually see through my eyes but if we

151
00:06:52,080 --> 00:06:54,630
can teach the algorithms to see specific

152
00:06:54,630 --> 00:06:56,970
features that is a site analyst I would

153
00:06:56,970 --> 00:07:00,930
I could look at some discoveries of all

154
00:07:00,930 --> 00:07:03,930
it's going to be about this because

155
00:07:03,930 --> 00:07:06,570
machine learning with combining these

156
00:07:06,570 --> 00:07:08,610
three things we can go from this picture

157
00:07:08,610 --> 00:07:12,830
to actually something more like this

158
00:07:12,830 --> 00:07:16,860
where we cannot longer sit on a network

159
00:07:16,860 --> 00:07:19,470
say I don't know where to look at we can

160
00:07:19,470 --> 00:07:22,650
have things specific things pointed us

161
00:07:22,650 --> 00:07:25,229
pointed to us saying ok instead of

162
00:07:25,229 --> 00:07:26,639
looking at everything look at this

163
00:07:26,639 --> 00:07:28,680
specific group of interesting things and

164
00:07:28,680 --> 00:07:31,620
not only that but also look at these

165
00:07:31,620 --> 00:07:35,639
things that seem similar together so if

166
00:07:35,639 --> 00:07:37,979
we have one infection it may not mean

167
00:07:37,979 --> 00:07:39,300
anything but if you have three

168
00:07:39,300 --> 00:07:40,889
infections then you have more

169
00:07:40,889 --> 00:07:44,610
information to correlate right so this

170
00:07:44,610 --> 00:07:47,400
top is I going to be about combining

171
00:07:47,400 --> 00:07:49,139
these three things we are not going to

172
00:07:49,139 --> 00:07:52,169
present another revolutionary machine

173
00:07:52,169 --> 00:07:54,750
learning algorithm but we are here today

174
00:07:54,750 --> 00:07:56,639
because we want to share our experience

175
00:07:56,639 --> 00:08:01,229
on how we how we combine this because it

176
00:08:01,229 --> 00:08:03,870
feels like every day I wake up and read

177
00:08:03,870 --> 00:08:06,270
the news it seems that it is so

178
00:08:06,270 --> 00:08:08,460
depressing it's like all the same right

179
00:08:08,460 --> 00:08:10,949
and we seems like a defendant we are

180
00:08:10,949 --> 00:08:13,740
always one step behind so how do we

181
00:08:13,740 --> 00:08:16,440
position ourselves want to step ahead of

182
00:08:16,440 --> 00:08:19,500
the game and that the answer is not

183
00:08:19,500 --> 00:08:22,889
secrecy right and we believe in

184
00:08:22,889 --> 00:08:24,630
transparency and collaboration and we

185
00:08:24,630 --> 00:08:28,770
think that if we tell explain how we

186
00:08:28,770 --> 00:08:32,490
work what are successes we have we can

187
00:08:32,490 --> 00:08:36,179
take this step forward and we combine

188
00:08:36,179 --> 00:08:37,950
these three things in a real-life

189
00:08:37,950 --> 00:08:41,789
implementation we face in the way we

190
00:08:41,789 --> 00:08:44,010
face different challenges and my

191
00:08:44,010 --> 00:08:45,779
colleague Carol is going to walk you

192
00:08:45,779 --> 00:08:49,460
through those challenges

193
00:08:49,460 --> 00:08:52,070
Thank You Veronica

194
00:08:52,070 --> 00:08:54,750
so we answer network security

195
00:08:54,750 --> 00:08:57,930
researchers are fixing four major

196
00:08:57,930 --> 00:09:00,630
challenges that we believe prevent

197
00:09:00,630 --> 00:09:03,570
machine learning from being successfully

198
00:09:03,570 --> 00:09:07,500
and massively used in practice and few

199
00:09:07,500 --> 00:09:09,870
years back addressing those challenges

200
00:09:09,870 --> 00:09:15,050
would seem basically like a Star Wars

201
00:09:15,050 --> 00:09:18,990
but in the following 40 minutes we are

202
00:09:18,990 --> 00:09:21,270
going to show you our solutions to those

203
00:09:21,270 --> 00:09:24,000
challenges and that it's not such a star

204
00:09:24,000 --> 00:09:27,470
wars anymore so the first challenge is

205
00:09:27,470 --> 00:09:30,990
high dynamics of mulher networked

206
00:09:30,990 --> 00:09:33,290
environment is highly dynamic and

207
00:09:33,290 --> 00:09:36,090
malware samples and malicious traffic is

208
00:09:36,090 --> 00:09:39,840
dynamic even more because attackers are

209
00:09:39,840 --> 00:09:42,030
trying everything that they can then

210
00:09:42,030 --> 00:09:43,980
change everything that they can to

211
00:09:43,980 --> 00:09:47,010
bypass the current security systems and

212
00:09:47,010 --> 00:09:50,880
to remain invisible the other challenge

213
00:09:50,880 --> 00:09:54,810
is the lack of labels to build a

214
00:09:54,810 --> 00:09:57,710
successful and reliable and precise

215
00:09:57,710 --> 00:10:00,480
classification systems we need a lot of

216
00:10:00,480 --> 00:10:03,990
labels and in network security this is a

217
00:10:03,990 --> 00:10:06,690
big problem and what's even more

218
00:10:06,690 --> 00:10:09,030
troubling is that obtaining additional

219
00:10:09,030 --> 00:10:11,910
labels is also very costly and very

220
00:10:11,910 --> 00:10:15,840
painful process another challenge is

221
00:10:15,840 --> 00:10:20,130
large skill training to make the

222
00:10:20,130 --> 00:10:23,340
classifiers work on different companies

223
00:10:23,340 --> 00:10:27,060
and in different networks we need the

224
00:10:27,060 --> 00:10:29,430
ability to train the classifiers from

225
00:10:29,430 --> 00:10:33,480
big data and the last challenge is

226
00:10:33,480 --> 00:10:35,670
actually how to automate all these

227
00:10:35,670 --> 00:10:38,510
things how to retrain the classifiers

228
00:10:38,510 --> 00:10:42,000
automatically from the data to react on

229
00:10:42,000 --> 00:10:43,500
the ever-changing network threat

230
00:10:43,500 --> 00:10:49,140
landscape so this scheme summarizes the

231
00:10:49,140 --> 00:10:51,180
four challenges that we will be talking

232
00:10:51,180 --> 00:10:54,600
about today and I will be talking about

233
00:10:54,600 --> 00:10:58,320
the first two and how we how we succeed

234
00:10:58,320 --> 00:11:01,059
it in here and Lukesh will be talking

235
00:11:01,059 --> 00:11:03,639
I'm out the other two so let's start

236
00:11:03,639 --> 00:11:07,749
with Muller dynamic two attackers change

237
00:11:07,749 --> 00:11:10,719
malicious code or payload on daily basis

238
00:11:10,719 --> 00:11:13,989
to bypass the signatures based systems

239
00:11:13,989 --> 00:11:17,289
right and instead of doing the static

240
00:11:17,289 --> 00:11:20,069
analysis we decided to explore another

241
00:11:20,069 --> 00:11:23,499
let's say feature or need would the

242
00:11:23,499 --> 00:11:27,219
mother traffic gas and that is the need

243
00:11:27,219 --> 00:11:30,489
to communicate over network so for that

244
00:11:30,489 --> 00:11:34,599
we are using metadata more specifically

245
00:11:34,599 --> 00:11:38,709
proxy log records that is an information

246
00:11:38,709 --> 00:11:40,449
acquired from the header of the packets

247
00:11:40,449 --> 00:11:43,059
and it has information about with

248
00:11:43,059 --> 00:11:45,909
communicating in who and how much and

249
00:11:45,909 --> 00:11:49,419
when but we don't see the content of the

250
00:11:49,419 --> 00:11:53,459
communication which us also makes us

251
00:11:53,459 --> 00:11:58,329
HTTP agnostic so when working with these

252
00:11:58,329 --> 00:12:02,529
when with this data this gives us an

253
00:12:02,529 --> 00:12:05,049
opportunity to be invariant against all

254
00:12:05,049 --> 00:12:07,389
of the malicious code or payload changes

255
00:12:07,389 --> 00:12:09,249
right but the attackers do a lot of

256
00:12:09,249 --> 00:12:12,159
other things a lot of other changes that

257
00:12:12,159 --> 00:12:15,849
we need to consider and that includes

258
00:12:15,849 --> 00:12:18,639
the change of server IP addresses or

259
00:12:18,639 --> 00:12:21,609
host names to bypass the blacklist or

260
00:12:21,609 --> 00:12:24,849
feeds or they change thinking time or

261
00:12:24,849 --> 00:12:29,369
your URL resources or parameters to

262
00:12:29,369 --> 00:12:32,409
bypass anomaly detection systems or

263
00:12:32,409 --> 00:12:35,529
other behavioral analytics so to tackle

264
00:12:35,529 --> 00:12:37,539
this problem we need to build an

265
00:12:37,539 --> 00:12:39,959
environment representation that would be

266
00:12:39,959 --> 00:12:42,339
robust and environment against all of

267
00:12:42,339 --> 00:12:45,369
these changes and I will be talking

268
00:12:45,369 --> 00:12:48,429
about it right now so the first step is

269
00:12:48,429 --> 00:12:50,949
to extract some basic features we are

270
00:12:50,949 --> 00:12:53,559
using two types of features the first

271
00:12:53,559 --> 00:12:56,259
type is are the features extracted from

272
00:12:56,259 --> 00:12:58,209
the individual connection from the

273
00:12:58,209 --> 00:13:00,909
individual requests or flocks and they

274
00:13:00,909 --> 00:13:04,929
can be URL based for example you can

275
00:13:04,929 --> 00:13:08,919
extract Engram statistics to detect

276
00:13:08,919 --> 00:13:11,919
BGA's or you can extract some

277
00:13:11,919 --> 00:13:14,150
distribution of special characters

278
00:13:14,150 --> 00:13:17,840
to detect let's say tunneling data

279
00:13:17,840 --> 00:13:20,150
through URL and we have also other

280
00:13:20,150 --> 00:13:23,420
fields at disposal for example the

281
00:13:23,420 --> 00:13:26,120
number of bytes transferred up and down

282
00:13:26,120 --> 00:13:29,840
or HTTP status referrer my type user

283
00:13:29,840 --> 00:13:32,540
agent and so on so you can extract

284
00:13:32,540 --> 00:13:35,890
hundreds of features out of this field

285
00:13:35,890 --> 00:13:38,590
another type of features besides that

286
00:13:38,590 --> 00:13:41,540
they are the features computed from the

287
00:13:41,540 --> 00:13:43,520
global visibility because we have that

288
00:13:43,520 --> 00:13:47,770
so we can actually compute features like

289
00:13:47,770 --> 00:13:51,410
let's say user domain popularity or the

290
00:13:51,410 --> 00:13:54,500
popularity of of the server IPS or the

291
00:13:54,500 --> 00:13:57,670
popularity of hashes and we can also

292
00:13:57,670 --> 00:14:00,920
excuse some external sources like who is

293
00:14:00,920 --> 00:14:05,890
to to work with the age of the domain

294
00:14:05,890 --> 00:14:09,590
but it's not that simple because if we

295
00:14:09,590 --> 00:14:11,570
just would extract all the features and

296
00:14:11,570 --> 00:14:13,700
put it into the classifier it will not

297
00:14:13,700 --> 00:14:18,980
work because because of this here you

298
00:14:18,980 --> 00:14:21,860
can see thirty-two different malware

299
00:14:21,860 --> 00:14:24,140
categories that are the rows and the

300
00:14:24,140 --> 00:14:27,590
columns are the features the flow based

301
00:14:27,590 --> 00:14:30,500
features and the yellow color means that

302
00:14:30,500 --> 00:14:32,090
all the feature values for the

303
00:14:32,090 --> 00:14:34,310
particular malware category and for that

304
00:14:34,310 --> 00:14:36,860
feature all the feature areas are

305
00:14:36,860 --> 00:14:39,230
different while the blue color means

306
00:14:39,230 --> 00:14:43,490
that the features are the same so as you

307
00:14:43,490 --> 00:14:46,310
can see here it might be even quite hard

308
00:14:46,310 --> 00:14:48,620
to actually train one classifier for one

309
00:14:48,620 --> 00:14:51,950
specific malware category not mentioning

310
00:14:51,950 --> 00:14:54,590
one classifier that will be detecting

311
00:14:54,590 --> 00:14:59,120
all of the categories so we have to come

312
00:14:59,120 --> 00:15:01,310
up with something else and that is the

313
00:15:01,310 --> 00:15:05,150
bag based approach so what we do we take

314
00:15:05,150 --> 00:15:07,430
the incoming connections and we group

315
00:15:07,430 --> 00:15:10,640
them into bags and one bag is basically

316
00:15:10,640 --> 00:15:13,730
a set of connections from one user to

317
00:15:13,730 --> 00:15:17,030
one domain or one server IP so it

318
00:15:17,030 --> 00:15:19,430
describes the communication between a

319
00:15:19,430 --> 00:15:23,240
user and a domain in time and we can

320
00:15:23,240 --> 00:15:25,700
extract very interesting features out of

321
00:15:25,700 --> 00:15:27,560
that which can be then

322
00:15:27,560 --> 00:15:30,290
into the classifier and this such

323
00:15:30,290 --> 00:15:33,520
classifier would be able to detect a

324
00:15:33,520 --> 00:15:36,470
reasonable amount of variety of malware

325
00:15:36,470 --> 00:15:40,160
samples here you can see examples of far

326
00:15:40,160 --> 00:15:42,650
malicious bags and one legitimate bank

327
00:15:42,650 --> 00:15:45,230
and I hope you can't see the you

328
00:15:45,230 --> 00:15:47,779
individual characters because then you

329
00:15:47,779 --> 00:15:49,550
would be focusing on the flow based

330
00:15:49,550 --> 00:15:51,260
features and that's what we are trying

331
00:15:51,260 --> 00:15:53,870
to avoid but if you have a look at it

332
00:15:53,870 --> 00:15:56,750
from the distance you would see that the

333
00:15:56,750 --> 00:15:59,960
URLs within each malware bag have

334
00:15:59,960 --> 00:16:01,970
similar structure they are not the same

335
00:16:01,970 --> 00:16:04,610
but almost the same there is a change

336
00:16:04,610 --> 00:16:07,400
here and there but as opposed to D they

337
00:16:07,400 --> 00:16:09,950
have the similar structure as opposed to

338
00:16:09,950 --> 00:16:11,870
the legitimate bank because if you are

339
00:16:11,870 --> 00:16:14,540
visiting some legitimate site then you

340
00:16:14,540 --> 00:16:18,130
are downloading a set of images and I

341
00:16:18,130 --> 00:16:21,350
friends and Java scripts of the URLs

342
00:16:21,350 --> 00:16:24,380
look completely different and this is

343
00:16:24,380 --> 00:16:26,690
exactly the thing that we are trying to

344
00:16:26,690 --> 00:16:28,760
capture here in the representation the

345
00:16:28,760 --> 00:16:32,480
malware dynamics so we got inspired from

346
00:16:32,480 --> 00:16:35,839
the action recognition where you have a

347
00:16:35,839 --> 00:16:38,210
sequence of images and you want to

348
00:16:38,210 --> 00:16:44,560
detect some actions so for us flows are

349
00:16:44,560 --> 00:16:48,290
the images one flow is one image and the

350
00:16:48,290 --> 00:16:50,540
back the whole communication is the

351
00:16:50,540 --> 00:16:52,940
video so we are trying to actually

352
00:16:52,940 --> 00:16:54,860
recognize malware videos from the

353
00:16:54,860 --> 00:16:58,280
background so here you can see the

354
00:16:58,280 --> 00:17:00,500
overview and I'm not going to go into

355
00:17:00,500 --> 00:17:04,069
the details but we start with the

356
00:17:04,069 --> 00:17:07,280
initial connections we group them into

357
00:17:07,280 --> 00:17:09,679
the bags extract the basic features I

358
00:17:09,679 --> 00:17:12,859
was talking about and then we take for

359
00:17:12,859 --> 00:17:14,689
every feature we take all the feature

360
00:17:14,689 --> 00:17:16,939
values for all the flows within a bag

361
00:17:16,939 --> 00:17:19,790
and compute different self simulator

362
00:17:19,790 --> 00:17:22,869
matrices and then we convert them into

363
00:17:22,869 --> 00:17:25,280
the histograms to increase the

364
00:17:25,280 --> 00:17:27,740
invariance and finally we combine

365
00:17:27,740 --> 00:17:30,050
everything into one feature vector and

366
00:17:30,050 --> 00:17:33,140
apply our optimization algorithm that

367
00:17:33,140 --> 00:17:36,620
would actually learn all the parameters

368
00:17:36,620 --> 00:17:38,780
for example the number of bins or the

369
00:17:38,780 --> 00:17:40,169
bin width and

370
00:17:40,169 --> 00:17:42,379
everything that we'll learn all of these

371
00:17:42,379 --> 00:17:44,460
automatically from the data so the

372
00:17:44,460 --> 00:17:47,009
representation would be specifically

373
00:17:47,009 --> 00:17:50,249
tuned data tuned to the malware samples

374
00:17:50,249 --> 00:17:54,119
and if you are more interested into that

375
00:17:54,119 --> 00:17:56,429
please have a look into our using

376
00:17:56,429 --> 00:18:00,720
security paper from this year so that

377
00:18:00,720 --> 00:18:02,970
was the first challenge how to capture

378
00:18:02,970 --> 00:18:05,369
the malware dynamics and how to make a

379
00:18:05,369 --> 00:18:07,710
representation that would be that would

380
00:18:07,710 --> 00:18:11,700
be ideal for this problem another

381
00:18:11,700 --> 00:18:14,210
problem is the mistakes in labels

382
00:18:14,210 --> 00:18:18,239
because what we typically have is a

383
00:18:18,239 --> 00:18:21,359
small amount of reliable labels but

384
00:18:21,359 --> 00:18:23,700
basically most reliable other labels

385
00:18:23,700 --> 00:18:27,059
that are manually created right but this

386
00:18:27,059 --> 00:18:30,269
is this does not scale so for example we

387
00:18:30,269 --> 00:18:32,190
all know that mr. yoga is a good guy

388
00:18:32,190 --> 00:18:34,980
right but what about the rest well for

389
00:18:34,980 --> 00:18:38,070
the rest we can see we can use other

390
00:18:38,070 --> 00:18:40,919
sources for example black lift or feeds

391
00:18:40,919 --> 00:18:45,690
that are not that reliable and label the

392
00:18:45,690 --> 00:18:47,700
remaining connections or the remaining

393
00:18:47,700 --> 00:18:51,029
network traffic but the question is

394
00:18:51,029 --> 00:18:53,399
whether there will be some other

395
00:18:53,399 --> 00:18:57,720
mistakes and that will be right so if we

396
00:18:57,720 --> 00:19:00,330
can actually use it for training a

397
00:19:00,330 --> 00:19:04,830
robust and reliable classifier and we

398
00:19:04,830 --> 00:19:06,749
believe that if you would use the

399
00:19:06,749 --> 00:19:09,359
traditional approach it's not possible

400
00:19:09,359 --> 00:19:12,809
because the classification model would

401
00:19:12,809 --> 00:19:16,070
be too polluted with the mistakes so

402
00:19:16,070 --> 00:19:20,129
instead we suggest to use a different

403
00:19:20,129 --> 00:19:22,470
technique which is called multiple

404
00:19:22,470 --> 00:19:25,109
instance learning approach which can

405
00:19:25,109 --> 00:19:27,419
actually handle these types of mistakes

406
00:19:27,419 --> 00:19:29,539
and I'm going to show you just the idea

407
00:19:29,539 --> 00:19:33,239
so at the beginning we have a set of

408
00:19:33,239 --> 00:19:37,379
connections that are those black lines

409
00:19:37,379 --> 00:19:40,080
and they are either legitimate or

410
00:19:40,080 --> 00:19:41,879
malicious so if the connection is

411
00:19:41,879 --> 00:19:45,480
legitimate then there is the green minus

412
00:19:45,480 --> 00:19:48,090
sign if the connection is malicious then

413
00:19:48,090 --> 00:19:50,240
it is denoted with the red

414
00:19:50,240 --> 00:19:52,910
sign but we don't know the true label so

415
00:19:52,910 --> 00:19:56,240
we apply blacklist or feet or whatever

416
00:19:56,240 --> 00:19:59,750
is available and label the connections

417
00:19:59,750 --> 00:20:02,179
and as I said there will be some

418
00:20:02,179 --> 00:20:05,290
mistakes right so if there is the EM in

419
00:20:05,290 --> 00:20:08,480
that means that for example legitimate

420
00:20:08,480 --> 00:20:11,210
flow is classified as malicious or vice

421
00:20:11,210 --> 00:20:14,390
versa and if you put put it like this

422
00:20:14,390 --> 00:20:17,480
into the classifier you can expect that

423
00:20:17,480 --> 00:20:19,929
the classifier will be behaving poorly

424
00:20:19,929 --> 00:20:22,940
because of the polluted model because

425
00:20:22,940 --> 00:20:25,910
you will be forcing him to send to

426
00:20:25,910 --> 00:20:30,110
adjust some kind of hyperplanes in the

427
00:20:30,110 --> 00:20:33,500
space where it shouldn't be but instead

428
00:20:33,500 --> 00:20:36,320
if you use the back approach and combine

429
00:20:36,320 --> 00:20:39,860
the individual flows into bags and label

430
00:20:39,860 --> 00:20:43,450
the bags then you have the ability to

431
00:20:43,450 --> 00:20:46,460
dramatically reduce this negative effect

432
00:20:46,460 --> 00:20:50,420
and it has two advantages first you

433
00:20:50,420 --> 00:20:52,820
don't need to label everything you don't

434
00:20:52,820 --> 00:20:54,980
need to label each individual flaw you

435
00:20:54,980 --> 00:20:57,350
just need to label the bags and the best

436
00:20:57,350 --> 00:21:00,290
could be everything let's say the all

437
00:21:00,290 --> 00:21:02,120
the traffic from a user if you know that

438
00:21:02,120 --> 00:21:05,240
the user is infected that is enough and

439
00:21:05,240 --> 00:21:07,370
you don't have to say specifically which

440
00:21:07,370 --> 00:21:10,400
flow is the one that caused that because

441
00:21:10,400 --> 00:21:13,100
the classifier would just take only a

442
00:21:13,100 --> 00:21:16,910
few representatives and most interesting

443
00:21:16,910 --> 00:21:19,670
flaws and put it into the model and

444
00:21:19,670 --> 00:21:22,460
before that we have a modified SVM

445
00:21:22,460 --> 00:21:25,340
classifier modify for for this type of

446
00:21:25,340 --> 00:21:27,860
mill approach so again if you are more

447
00:21:27,860 --> 00:21:31,429
interested please have a look to be our

448
00:21:31,429 --> 00:21:36,400
at our HTML paper so we were kind of

449
00:21:36,400 --> 00:21:40,010
successful with deployment of those take

450
00:21:40,010 --> 00:21:42,110
those back approaches and we were able

451
00:21:42,110 --> 00:21:46,100
to actually classify a nice variety of

452
00:21:46,100 --> 00:21:48,200
model samples including crypto all

453
00:21:48,200 --> 00:21:49,700
exploit kits or different banking

454
00:21:49,700 --> 00:21:51,710
Trojans but Veronica will be talking

455
00:21:51,710 --> 00:21:58,300
about it after me so that was just the

456
00:21:58,300 --> 00:22:00,740
explaining of how to build a reliable

457
00:22:00,740 --> 00:22:03,950
representation and how to use

458
00:22:03,950 --> 00:22:07,730
weak labels for classification but there

459
00:22:07,730 --> 00:22:09,890
is another important step and that is

460
00:22:09,890 --> 00:22:13,340
how to build reliable classification

461
00:22:13,340 --> 00:22:15,860
models on the top of that and this is

462
00:22:15,860 --> 00:22:17,240
something that Lucas will be talking

463
00:22:17,240 --> 00:22:22,340
Lovely's right now well hello

464
00:22:22,340 --> 00:22:25,540
so okay so this is a third challenge and

465
00:22:25,540 --> 00:22:28,130
the question is now how to build the

466
00:22:28,130 --> 00:22:30,590
reliable data set for training and even

467
00:22:30,590 --> 00:22:32,660
about models to use in order to be

468
00:22:32,660 --> 00:22:38,300
captured the motor so the first thing

469
00:22:38,300 --> 00:22:40,490
that I will be talking about is how to

470
00:22:40,490 --> 00:22:42,860
sample your training data to get a

471
00:22:42,860 --> 00:22:44,960
reliable training set of your classifier

472
00:22:44,960 --> 00:22:47,630
the first thing is that we per day the

473
00:22:47,630 --> 00:22:49,370
processor of ten billions of requests

474
00:22:49,370 --> 00:22:51,920
which is a huge number and in fact most

475
00:22:51,920 --> 00:22:54,740
of this these requests cannot be fully

476
00:22:54,740 --> 00:22:56,210
labeled of course just a small portion

477
00:22:56,210 --> 00:22:58,870
of them can be another thing is that the

478
00:22:58,870 --> 00:23:01,520
problem is very imbalanced only some of

479
00:23:01,520 --> 00:23:04,310
them are malicious but the most of them

480
00:23:04,310 --> 00:23:07,700
is legitimate or benign behavior so in

481
00:23:07,700 --> 00:23:12,160
this picture you can see the green red

482
00:23:12,160 --> 00:23:16,340
circles that right now represent the no

483
00:23:16,340 --> 00:23:18,350
legitimate temples and the bars

484
00:23:18,350 --> 00:23:19,730
represent the malicious one so if you

485
00:23:19,730 --> 00:23:21,380
would train a classifier you would get a

486
00:23:21,380 --> 00:23:23,570
end up with the boundaries depicted here

487
00:23:23,570 --> 00:23:26,090
but of course they are trained only on

488
00:23:26,090 --> 00:23:27,380
the known stuff that you have labeled

489
00:23:27,380 --> 00:23:30,170
whenever you introduce the rest of the

490
00:23:30,170 --> 00:23:31,640
of the traffic you will figure out that

491
00:23:31,640 --> 00:23:33,140
the boundaries are in fact very very

492
00:23:33,140 --> 00:23:35,360
weak and the precision of the

493
00:23:35,360 --> 00:23:38,840
classification goes goes down so what

494
00:23:38,840 --> 00:23:40,880
you can do obviously right we can use

495
00:23:40,880 --> 00:23:44,270
also the unlabeled samples and in that

496
00:23:44,270 --> 00:23:45,590
very strength in the boundaries of the

497
00:23:45,590 --> 00:23:47,450
classification but the question is how

498
00:23:47,450 --> 00:23:49,910
to do that and how to avoid processing

499
00:23:49,910 --> 00:23:53,240
ten billions of samples so what we do we

500
00:23:53,240 --> 00:23:54,620
have a set of statistical simple

501
00:23:54,620 --> 00:23:59,150
classifiers that in fact process the

502
00:23:59,150 --> 00:24:02,290
data and we get as maliciousness score

503
00:24:02,290 --> 00:24:04,940
we rank the traffic according to the

504
00:24:04,940 --> 00:24:07,760
score and instead of taking all the

505
00:24:07,760 --> 00:24:10,100
samples we take only the top and samples

506
00:24:10,100 --> 00:24:13,490
and call this across a longer period of

507
00:24:13,490 --> 00:24:15,990
time to get a diverse data set

508
00:24:15,990 --> 00:24:17,929
in this way in fact we can get rid of

509
00:24:17,929 --> 00:24:21,000
the benign or not interesting samples

510
00:24:21,000 --> 00:24:23,910
and focus only on those samples that are

511
00:24:23,910 --> 00:24:27,929
populating our space of interest another

512
00:24:27,929 --> 00:24:31,110
thing is how to get rid of malicious

513
00:24:31,110 --> 00:24:32,340
samples in the unlabeled

514
00:24:32,340 --> 00:24:35,790
unlabeled set at least those that are

515
00:24:35,790 --> 00:24:37,290
mostly hardened to classification and

516
00:24:37,290 --> 00:24:39,720
for this reason I've used the positive

517
00:24:39,720 --> 00:24:42,240
unlabeled training principle and it's

518
00:24:42,240 --> 00:24:45,210
quite simple you take you have a

519
00:24:45,210 --> 00:24:47,309
malicious labeled malicious sample set

520
00:24:47,309 --> 00:24:49,500
and you take a few a small portion of

521
00:24:49,500 --> 00:24:52,470
samples as spies and you inject them

522
00:24:52,470 --> 00:24:55,920
into your negative training set and then

523
00:24:55,920 --> 00:24:57,630
you train a binary classifier from these

524
00:24:57,630 --> 00:24:59,730
two sets and then what you do you just

525
00:24:59,730 --> 00:25:04,200
score your unlabeled data and you will

526
00:25:04,200 --> 00:25:07,320
find a threshold below which none of the

527
00:25:07,320 --> 00:25:09,660
spies or the known positives occurs then

528
00:25:09,660 --> 00:25:12,540
and in this way you can kind of be

529
00:25:12,540 --> 00:25:14,910
scarred the most probiotic samples and

530
00:25:14,910 --> 00:25:18,210
get much more cleaner negative training

531
00:25:18,210 --> 00:25:21,120
set okay so now we have some training

532
00:25:21,120 --> 00:25:22,830
principles and representations the

533
00:25:22,830 --> 00:25:24,690
question is what classifiers we use and

534
00:25:24,690 --> 00:25:27,780
how use them so the first one is svms

535
00:25:27,780 --> 00:25:30,690
Carlos are talking about for the mill

536
00:25:30,690 --> 00:25:33,240
representation but the other one that we

537
00:25:33,240 --> 00:25:35,010
use is a random product a very popular

538
00:25:35,010 --> 00:25:36,780
technique using many state-of-the-art

539
00:25:36,780 --> 00:25:38,970
machine learning techniques it has a

540
00:25:38,970 --> 00:25:40,559
one-night property that is randomness

541
00:25:40,559 --> 00:25:44,309
and we how do you use it is that instead

542
00:25:44,309 --> 00:25:46,679
of using the full feature set or for for

543
00:25:46,679 --> 00:25:48,660
features that we have we sample only

544
00:25:48,660 --> 00:25:50,700
randomly a smaller subset of these

545
00:25:50,700 --> 00:25:53,490
features and train specific instance of

546
00:25:53,490 --> 00:25:55,320
the model at a time only from the subset

547
00:25:55,320 --> 00:25:57,600
whenever the model is retrained it uses

548
00:25:57,600 --> 00:25:59,550
again another random subset of the

549
00:25:59,550 --> 00:26:01,710
features so therefore the trader cannot

550
00:26:01,710 --> 00:26:03,360
be sure exactly what kind of features we

551
00:26:03,360 --> 00:26:06,330
are using at the moment and we use it

552
00:26:06,330 --> 00:26:08,790
provides it for vector classification

553
00:26:08,790 --> 00:26:10,800
what I mean by that is for example that

554
00:26:10,800 --> 00:26:13,590
if you want to detect or use a

555
00:26:13,590 --> 00:26:15,900
communication using DGA

556
00:26:15,900 --> 00:26:17,580
then we can extracting a feature vector

557
00:26:17,580 --> 00:26:19,950
from the domain name and we can assign

558
00:26:19,950 --> 00:26:21,540
directly a label through this single

559
00:26:21,540 --> 00:26:22,920
feature vector so it's just a single

560
00:26:22,920 --> 00:26:24,570
feature vector

561
00:26:24,570 --> 00:26:27,310
classification however in that case of

562
00:26:27,310 --> 00:26:29,650
course you need labels on the level of

563
00:26:29,650 --> 00:26:31,360
individual vectors which is quite

564
00:26:31,360 --> 00:26:33,180
expensive and often not possible

565
00:26:33,180 --> 00:26:35,710
therefore other principle we use our

566
00:26:35,710 --> 00:26:38,380
neural networks again there are a lot of

567
00:26:38,380 --> 00:26:42,420
different architectures that can be used

568
00:26:42,420 --> 00:26:45,310
but we use the specific architecture and

569
00:26:45,310 --> 00:26:46,990
the classification right now is

570
00:26:46,990 --> 00:26:49,180
performed on the level of users not on

571
00:26:49,180 --> 00:26:50,890
the level of vectors and how we do that

572
00:26:50,890 --> 00:26:53,650
is depicted here so we have a traffic of

573
00:26:53,650 --> 00:26:56,560
user Jason is here several requests for

574
00:26:56,560 --> 00:26:59,140
example going to Google Gmail some raw

575
00:26:59,140 --> 00:27:01,830
IP and CNN and so on we can extract

576
00:27:01,830 --> 00:27:04,150
feature vectors or representations that

577
00:27:04,150 --> 00:27:05,830
Cara was talking about for each of these

578
00:27:05,830 --> 00:27:08,290
requests what we do is then that we

579
00:27:08,290 --> 00:27:10,300
propagate all these speech directors

580
00:27:10,300 --> 00:27:12,880
related to full traffic to the first

581
00:27:12,880 --> 00:27:14,650
hidden layer in the neural network

582
00:27:14,650 --> 00:27:16,780
already trained so that means that now

583
00:27:16,780 --> 00:27:20,670
we come up with a new representation and

584
00:27:20,670 --> 00:27:23,830
we got this new representation again for

585
00:27:23,830 --> 00:27:25,930
each single request and what we do next

586
00:27:25,930 --> 00:27:28,120
is we do pooling a very common in

587
00:27:28,120 --> 00:27:29,890
convolutional neural networks and the

588
00:27:29,890 --> 00:27:32,380
pooling is in fact an aggregation where

589
00:27:32,380 --> 00:27:35,100
we aggregate all the feature vectors

590
00:27:35,100 --> 00:27:38,140
related to one hostname or one domain

591
00:27:38,140 --> 00:27:39,910
name so at the first hidden layer we now

592
00:27:39,910 --> 00:27:41,620
get a one feature vector for Google for

593
00:27:41,620 --> 00:27:43,420
one feature vector for Gmail and so on

594
00:27:43,420 --> 00:27:45,250
so this feature vectors kind of depict

595
00:27:45,250 --> 00:27:47,680
the communication of the user going to

596
00:27:47,680 --> 00:27:49,870
these domains then we propagate all

597
00:27:49,870 --> 00:27:51,490
these feature vectors next to the second

598
00:27:51,490 --> 00:27:53,350
hidden layer and again we do the pooling

599
00:27:53,350 --> 00:27:54,880
and we get up with a feature vector

600
00:27:54,880 --> 00:27:57,850
representing the full traffic of user

601
00:27:57,850 --> 00:28:01,060
J's miss and finally to be able to get a

602
00:28:01,060 --> 00:28:03,250
classification score we propagate the

603
00:28:03,250 --> 00:28:04,720
feature vector to the third hidden layer

604
00:28:04,720 --> 00:28:06,790
and we get a classification score and

605
00:28:06,790 --> 00:28:08,500
this is just compared to a threshold and

606
00:28:08,500 --> 00:28:14,740
then if higher than arm is triggered so

607
00:28:14,740 --> 00:28:18,460
this is how we classify user traffic and

608
00:28:18,460 --> 00:28:22,810
how we user context ok so we have a few

609
00:28:22,810 --> 00:28:24,610
classifiers now the question is how does

610
00:28:24,610 --> 00:28:26,410
the classification topology look like

611
00:28:26,410 --> 00:28:28,180
the first thing is that the classifiers

612
00:28:28,180 --> 00:28:29,860
have to see all the traffic or classify

613
00:28:29,860 --> 00:28:31,300
every every traffic so all the 10

614
00:28:31,300 --> 00:28:32,890
billions requests and it is quite

615
00:28:32,890 --> 00:28:35,290
time-consuming therefore we use for just

616
00:28:35,290 --> 00:28:36,870
a pre-filter ink layer which is

617
00:28:36,870 --> 00:28:39,660
also classifier data-driven classifier

618
00:28:39,660 --> 00:28:41,730
but it uses just a simple features that

619
00:28:41,730 --> 00:28:45,390
can be extracted quite simply and then

620
00:28:45,390 --> 00:28:47,190
at other levels you can use more

621
00:28:47,190 --> 00:28:48,720
advanced techniques and more than stick

622
00:28:48,720 --> 00:28:50,460
vectors so for example you can see here

623
00:28:50,460 --> 00:28:53,309
the traffic that is filtered by the

624
00:28:53,309 --> 00:28:55,170
first player and it can contain also

625
00:28:55,170 --> 00:28:57,480
false positives or false detection but

626
00:28:57,480 --> 00:29:01,230
it's just the first layer and it should

627
00:29:01,230 --> 00:29:04,410
just filter out ordinary benign traffic

628
00:29:04,410 --> 00:29:07,260
so at the next level what we have here

629
00:29:07,260 --> 00:29:09,780
is a set of classifiers which can be

630
00:29:09,780 --> 00:29:12,390
quite generic they are for example in

631
00:29:12,390 --> 00:29:14,280
this case we can detect dgs or

632
00:29:14,280 --> 00:29:16,440
communication using domain generation

633
00:29:16,440 --> 00:29:19,290
algorithms or we can detect obfuscated

634
00:29:19,290 --> 00:29:22,200
urls these detectors our classifiers are

635
00:29:22,200 --> 00:29:24,960
already highly precise so they can

636
00:29:24,960 --> 00:29:26,520
distinguish between malicious and

637
00:29:26,520 --> 00:29:28,920
legitimate communication but they don't

638
00:29:28,920 --> 00:29:30,960
give you any higher overview what was

639
00:29:30,960 --> 00:29:33,000
what is it going on there and therefore

640
00:29:33,000 --> 00:29:35,520
we have the last level where we have

641
00:29:35,520 --> 00:29:37,410
specific classifiers focusing directly

642
00:29:37,410 --> 00:29:40,740
on specific malware communication such

643
00:29:40,740 --> 00:29:43,020
as phishing click for an click throat or

644
00:29:43,020 --> 00:29:45,600
CNC communication and when you follow

645
00:29:45,600 --> 00:29:48,270
the classification path you can also say

646
00:29:48,270 --> 00:29:51,179
ok this was a CNC communication with a

647
00:29:51,179 --> 00:29:53,429
domain generation algorithm and also

648
00:29:53,429 --> 00:29:55,679
using confiscated URLs so this kind of

649
00:29:55,679 --> 00:29:57,240
information that you get from from the

650
00:29:57,240 --> 00:30:01,320
full classification architecture so this

651
00:30:01,320 --> 00:30:04,020
was the third challenge and now here

652
00:30:04,020 --> 00:30:05,400
also the model you have the architecture

653
00:30:05,400 --> 00:30:08,670
and question is what were to get the

654
00:30:08,670 --> 00:30:11,160
labels how to update the labels and even

655
00:30:11,160 --> 00:30:13,050
how to update the whole system with when

656
00:30:13,050 --> 00:30:16,800
something changes so the first very

657
00:30:16,800 --> 00:30:18,720
important module is the active learning

658
00:30:18,720 --> 00:30:21,260
module right consists of a human analyst

659
00:30:21,260 --> 00:30:23,690
the input to the module are detections

660
00:30:23,690 --> 00:30:26,010
these deductions are coming from the

661
00:30:26,010 --> 00:30:28,290
general classifiers and all the cost

662
00:30:28,290 --> 00:30:31,230
varies in fact that we have and role of

663
00:30:31,230 --> 00:30:33,750
the human analogy is analyzed or and

664
00:30:33,750 --> 00:30:35,970
confirm the maliciousness of the

665
00:30:35,970 --> 00:30:39,510
provided samples but also to categorize

666
00:30:39,510 --> 00:30:41,010
these samples into specific categories

667
00:30:41,010 --> 00:30:43,140
such as click throw data exfiltration

668
00:30:43,140 --> 00:30:45,060
add injector and so on if this is

669
00:30:45,060 --> 00:30:47,850
possible the role is not to fully

670
00:30:47,850 --> 00:30:49,799
labeled every detection

671
00:30:49,799 --> 00:30:52,470
but just those representative samples

672
00:30:52,470 --> 00:30:55,559
that are most in most mostly interesting

673
00:30:55,559 --> 00:30:57,119
for the classifier for example those

674
00:30:57,119 --> 00:31:00,779
that lie on the decision boundaries of

675
00:31:00,779 --> 00:31:05,239
each classifier so let's have a look on

676
00:31:05,239 --> 00:31:09,139
how does the loop or classification

677
00:31:09,139 --> 00:31:12,659
architecture looks like now we have the

678
00:31:12,659 --> 00:31:14,249
classification module there are the

679
00:31:14,249 --> 00:31:15,840
general classifiers they produce the

680
00:31:15,840 --> 00:31:17,220
directions they go to the active

681
00:31:17,220 --> 00:31:19,649
learning module and from the active

682
00:31:19,649 --> 00:31:22,049
learning module we can just easily close

683
00:31:22,049 --> 00:31:25,470
the loop and return the feedback from

684
00:31:25,470 --> 00:31:27,929
the human analyst to the classification

685
00:31:27,929 --> 00:31:30,149
model right now we have also the

686
00:31:30,149 --> 00:31:31,799
categorical labels therefore we can

687
00:31:31,799 --> 00:31:33,299
train not only binary classifiers

688
00:31:33,299 --> 00:31:36,330
anymore but we train directly multi

689
00:31:36,330 --> 00:31:39,179
class classifier that output information

690
00:31:39,179 --> 00:31:41,340
on what kind of malicious behavior it

691
00:31:41,340 --> 00:31:43,859
was and again along with the general

692
00:31:43,859 --> 00:31:46,049
classifiers they produce detections that

693
00:31:46,049 --> 00:31:48,299
go to the active learning and this is

694
00:31:48,299 --> 00:31:51,509
how we close the loop in order to train

695
00:31:51,509 --> 00:31:56,100
the models use many spark but not not

696
00:31:56,100 --> 00:31:58,529
only Sparkle - park and to retrain the

697
00:31:58,529 --> 00:32:00,539
model space around one to two days on

698
00:32:00,539 --> 00:32:04,289
200 TPS cluster and on tens of millions

699
00:32:04,289 --> 00:32:09,480
of samples ok and just in summary ok so

700
00:32:09,480 --> 00:32:11,549
we define the automatic retraining loop

701
00:32:11,549 --> 00:32:13,619
and now from the time perspective how

702
00:32:13,619 --> 00:32:16,049
does it look like now at each point each

703
00:32:16,049 --> 00:32:18,749
point on the time axis represents a

704
00:32:18,749 --> 00:32:20,909
situation where we got new samples or

705
00:32:20,909 --> 00:32:22,980
new sorry new labels from the active

706
00:32:22,980 --> 00:32:25,889
learning module whenever we got them we

707
00:32:25,889 --> 00:32:28,379
can retrain the model or train a new

708
00:32:28,379 --> 00:32:30,779
model and store the model but at the

709
00:32:30,779 --> 00:32:33,809
same time we already back in time we

710
00:32:33,809 --> 00:32:35,340
already did that and we already had some

711
00:32:35,340 --> 00:32:37,919
auto strength so these models are

712
00:32:37,919 --> 00:32:41,279
already running on the same data and we

713
00:32:41,279 --> 00:32:44,249
can just update their statistics in form

714
00:32:44,249 --> 00:32:49,169
of precision on accuracy how they fit

715
00:32:49,169 --> 00:32:52,470
how well they perform given the new

716
00:32:52,470 --> 00:32:55,830
labels from from the activate activity

717
00:32:55,830 --> 00:32:58,950
learning module and this way we can just

718
00:32:58,950 --> 00:33:01,409
easily pick any best working model at a

719
00:33:01,409 --> 00:33:02,669
given time

720
00:33:02,669 --> 00:33:04,649
and use the model in the production

721
00:33:04,649 --> 00:33:08,330
environment and at the same time we just

722
00:33:08,330 --> 00:33:11,279
control or we just store all the updated

723
00:33:11,279 --> 00:33:13,259
results of each individual models and

724
00:33:13,259 --> 00:33:15,210
whenever something goes wrong just can

725
00:33:15,210 --> 00:33:17,249
easily return to any model that behaves

726
00:33:17,249 --> 00:33:22,649
still the best well and now this is the

727
00:33:22,649 --> 00:33:24,840
end of the theory and I give big words

728
00:33:24,840 --> 00:33:27,330
to Veronica and she will show you some

729
00:33:27,330 --> 00:33:31,259
real examples thank you some mark the

730
00:33:31,259 --> 00:33:35,940
relatives the interesting thing so we

731
00:33:35,940 --> 00:33:38,489
saw hold the ball from this right to

732
00:33:38,489 --> 00:33:41,730
this and for a thread analyse this is

733
00:33:41,730 --> 00:33:42,509
huge

734
00:33:42,509 --> 00:33:44,549
already because it saves a lot of time

735
00:33:44,549 --> 00:33:47,580
believe me so right now I'm going to

736
00:33:47,580 --> 00:33:49,200
show you some examples of these groups

737
00:33:49,200 --> 00:33:51,960
and what did we actually find with this

738
00:33:51,960 --> 00:33:55,019
all these tools and algorithms so the

739
00:33:55,019 --> 00:33:56,639
first example is going to be about the N

740
00:33:56,639 --> 00:33:59,070
stranger and now if not the audience

741
00:33:59,070 --> 00:34:02,929
changer is a new one from back in

742
00:34:02,929 --> 00:34:05,659
beginning of the year we deploy a new

743
00:34:05,659 --> 00:34:08,099
multi instance learning classifier that

744
00:34:08,099 --> 00:34:09,899
was training in hundreds of different

745
00:34:09,899 --> 00:34:14,699
manual behaviors and as usual we were so

746
00:34:14,699 --> 00:34:19,500
eager to know how it performed so when I

747
00:34:19,500 --> 00:34:22,440
do analysis I usually group coherent

748
00:34:22,440 --> 00:34:24,329
behaviors because analyzing flow by flow

749
00:34:24,329 --> 00:34:27,540
is too time-consuming so I took all the

750
00:34:27,540 --> 00:34:29,790
interns characterized by this mill

751
00:34:29,790 --> 00:34:32,040
classifier that's the orange and start

752
00:34:32,040 --> 00:34:34,649
grouping things together and say ok

753
00:34:34,649 --> 00:34:36,750
which group is more interesting to look

754
00:34:36,750 --> 00:34:40,799
at and that was the yellow one so when I

755
00:34:40,799 --> 00:34:43,980
look into it in the flows which is the

756
00:34:43,980 --> 00:34:47,609
source source of truth the URL looks

757
00:34:47,609 --> 00:34:50,699
like this and is not right forward eyes

758
00:34:50,699 --> 00:34:53,309
malicious is a quite interesting though

759
00:34:53,309 --> 00:34:56,579
so we start looking into bit more deeply

760
00:34:56,579 --> 00:34:59,670
into this and it was there many

761
00:34:59,670 --> 00:35:02,520
interesting features he here basically

762
00:35:02,520 --> 00:35:05,790
the the domains were changing the URL

763
00:35:05,790 --> 00:35:09,420
was not encoded in any known encoding

764
00:35:09,420 --> 00:35:13,020
scheme so it was it was quite

765
00:35:13,020 --> 00:35:15,100
interesting another factor was that

766
00:35:15,100 --> 00:35:18,820
first week we saw spite of from 0 to 500

767
00:35:18,820 --> 00:35:23,350
users infected which for my voice not so

768
00:35:23,350 --> 00:35:25,900
common so we were kind of reluctant to

769
00:35:25,900 --> 00:35:30,430
believe this one of we managed to get

770
00:35:30,430 --> 00:35:33,130
one sample because one binary because we

771
00:35:33,130 --> 00:35:34,720
look at the network and sometimes it's

772
00:35:34,720 --> 00:35:36,790
very hard to actually get the malicious

773
00:35:36,790 --> 00:35:39,400
binary that generated traffic in this

774
00:35:39,400 --> 00:35:41,200
case we found it and thanks to our

775
00:35:41,200 --> 00:35:43,390
colleague Rostov he did the reverse

776
00:35:43,390 --> 00:35:46,360
engineering and he found that this small

777
00:35:46,360 --> 00:35:48,400
Trojan was a deal exchanger Trojan and

778
00:35:48,400 --> 00:35:50,500
the communication that we were seen is

779
00:35:50,500 --> 00:35:51,820
was actually common encounter

780
00:35:51,820 --> 00:35:55,720
communication and in those all long URLs

781
00:35:55,720 --> 00:35:57,280
it was sending a lot of information

782
00:35:57,280 --> 00:35:59,890
about the user but it didn't end there

783
00:35:59,890 --> 00:36:02,950
because while the DNS change of version

784
00:36:02,950 --> 00:36:06,160
for those who don't know is basically

785
00:36:06,160 --> 00:36:08,050
doing something very small and very

786
00:36:08,050 --> 00:36:10,360
simple that is changes the change in the

787
00:36:10,360 --> 00:36:12,940
name servers of your computer which

788
00:36:12,940 --> 00:36:14,770
basically means when you try to vote the

789
00:36:14,770 --> 00:36:17,500
rules you ask for an IP if your name

790
00:36:17,500 --> 00:36:20,320
server will return your own IP in this

791
00:36:20,320 --> 00:36:21,790
case because the name servers were

792
00:36:21,790 --> 00:36:23,740
compromised if you want to visit Google

793
00:36:23,740 --> 00:36:25,870
you will get a malicious IP and then

794
00:36:25,870 --> 00:36:28,510
they can do anything but on your web

795
00:36:28,510 --> 00:36:31,930
page with infected call and so and so on

796
00:36:31,930 --> 00:36:35,110
so we started looking on this who the

797
00:36:35,110 --> 00:36:37,630
users got infected with this and thanks

798
00:36:37,630 --> 00:36:39,370
to their reverse engineering we found

799
00:36:39,370 --> 00:36:41,170
that this was actually delivered by on

800
00:36:41,170 --> 00:36:43,450
another version that was called Mamba

801
00:36:43,450 --> 00:36:48,700
and mammals have items' malware that has

802
00:36:48,700 --> 00:36:52,420
a basically can update itself so the

803
00:36:52,420 --> 00:36:56,590
first stage was once it was deployed

804
00:36:56,590 --> 00:36:58,960
then it will download from a file server

805
00:36:58,960 --> 00:37:02,230
another version of itself and then it

806
00:37:02,230 --> 00:37:06,360
will another the DNS changer Trojan and

807
00:37:06,360 --> 00:37:09,400
we went one step further and we start

808
00:37:09,400 --> 00:37:12,670
correlating this with ok how these the

809
00:37:12,670 --> 00:37:15,250
users actually got infected with his

810
00:37:15,250 --> 00:37:19,240
Mahmoud region and we found that most of

811
00:37:19,240 --> 00:37:21,370
the infections we couldn't prove

812
00:37:21,370 --> 00:37:23,890
completely we are still working on that

813
00:37:23,890 --> 00:37:24,670
but

814
00:37:24,670 --> 00:37:26,770
there was a strong correlation meaning

815
00:37:26,770 --> 00:37:29,710
out of ten infections nine were having

816
00:37:29,710 --> 00:37:32,290
other infections like optimizer Pro

817
00:37:32,290 --> 00:37:35,710
installed on the system and actually in

818
00:37:35,710 --> 00:37:37,770
the communication of the ideas changer

819
00:37:37,770 --> 00:37:39,150
[Music]

820
00:37:39,150 --> 00:37:43,089
version we saw the mullah reporting

821
00:37:43,089 --> 00:37:45,549
these names of adware to the command and

822
00:37:45,549 --> 00:37:48,670
control so this was one of the first

823
00:37:48,670 --> 00:37:53,710
findings and this is called in summary

824
00:37:53,710 --> 00:37:55,990
very constraints the command control

825
00:37:55,990 --> 00:37:58,210
looks like so you can see how is the

826
00:37:58,210 --> 00:38:00,309
Mallory's change in the domain right

827
00:38:00,309 --> 00:38:03,609
also changing a piece and also change in

828
00:38:03,609 --> 00:38:06,660
the URL but there are some things that

829
00:38:06,660 --> 00:38:09,490
we saw in the beginning of the talks are

830
00:38:09,490 --> 00:38:12,010
kind of invariant in this case is a part

831
00:38:12,010 --> 00:38:15,339
on some parameter names which some of

832
00:38:15,339 --> 00:38:17,380
them are also changing because we have a

833
00:38:17,380 --> 00:38:21,480
and cubed meaning so this is why

834
00:38:21,480 --> 00:38:24,220
determinants are good at so they can

835
00:38:24,220 --> 00:38:27,730
actually be smart and say okay this

836
00:38:27,730 --> 00:38:30,430
looks different but actually they look

837
00:38:30,430 --> 00:38:32,710
the same right so they can do that for

838
00:38:32,710 --> 00:38:34,630
us what's quite interesting

839
00:38:34,630 --> 00:38:36,720
another carry that we are still

840
00:38:36,720 --> 00:38:39,040
investigating we found a couple of

841
00:38:39,040 --> 00:38:43,680
months ago is it's very curious

842
00:38:43,680 --> 00:38:48,130
it's about advertising gone rogue and we

843
00:38:48,130 --> 00:38:51,059
found this traffic in the network and

844
00:38:51,059 --> 00:38:54,250
this is look at suicide very malicious

845
00:38:54,250 --> 00:39:00,250
and if vga domains random paths or

846
00:39:00,250 --> 00:39:04,599
resources random parameter names which

847
00:39:04,599 --> 00:39:06,869
actually point to the same type of

848
00:39:06,869 --> 00:39:10,089
content like the referrer doesn't cyril

849
00:39:10,089 --> 00:39:12,339
faribault it says some random parameter

850
00:39:12,339 --> 00:39:15,420
names so we start digging into these and

851
00:39:15,420 --> 00:39:18,190
we actually found on different behaviors

852
00:39:18,190 --> 00:39:20,410
related to this traffic and it talked to

853
00:39:20,410 --> 00:39:21,790
me that after some time they were

854
00:39:21,790 --> 00:39:26,200
downloading some flash file which thanks

855
00:39:26,200 --> 00:39:28,809
to are also or colleague was give and we

856
00:39:28,809 --> 00:39:30,369
also have a second opinion from our

857
00:39:30,369 --> 00:39:32,510
colleagues in ours

858
00:39:32,510 --> 00:39:35,030
it's not malicious by itself is not an

859
00:39:35,030 --> 00:39:38,839
exploit but it may be part of the really

860
00:39:38,839 --> 00:39:42,470
exploited infection change as because it

861
00:39:42,470 --> 00:39:45,680
is this slush pile is really small it

862
00:39:45,680 --> 00:39:47,839
contains finger-painting logic basically

863
00:39:47,839 --> 00:39:49,880
getting information from your computer

864
00:39:49,880 --> 00:39:52,099
what what is a system you have installed

865
00:39:52,099 --> 00:39:56,390
etc so and in at least one couple of

866
00:39:56,390 --> 00:39:57,950
cases we cannot reproduce

867
00:39:57,950 --> 00:40:01,640
we actually got exploited by by this

868
00:40:01,640 --> 00:40:04,910
very expected and dropping the handset

869
00:40:04,910 --> 00:40:09,740
or dropper so I went further because I

870
00:40:09,740 --> 00:40:13,240
wanted to know I'm sorry

871
00:40:13,240 --> 00:40:16,789
another note to note in this slide is

872
00:40:16,789 --> 00:40:19,880
they all the strings in this slush

873
00:40:19,880 --> 00:40:22,490
filing on also other communication of

874
00:40:22,490 --> 00:40:25,760
this traffic we found that references to

875
00:40:25,760 --> 00:40:28,220
pop a dotnet that's where the part of

876
00:40:28,220 --> 00:40:30,289
the advertising comes in so I was

877
00:40:30,289 --> 00:40:32,210
investigating and say okay but dig each

878
00:40:32,210 --> 00:40:35,059
other diagonally if this is supposed to

879
00:40:35,059 --> 00:40:39,920
be legitimate or not so I actually did a

880
00:40:39,920 --> 00:40:41,690
mapping of the infrastructure so try to

881
00:40:41,690 --> 00:40:44,480
understand if this is a systematic way

882
00:40:44,480 --> 00:40:47,809
of doing this or not so I'm I'm up all

883
00:40:47,809 --> 00:40:50,150
across names and how long they were

884
00:40:50,150 --> 00:40:53,599
active and actually I hope you see the

885
00:40:53,599 --> 00:40:56,119
animation this is this is their host

886
00:40:56,119 --> 00:40:58,819
names and how long they are active and

887
00:40:58,819 --> 00:41:00,619
you can see that it's reducing and they

888
00:41:00,619 --> 00:41:02,869
are changing a lot almost in the end

889
00:41:02,869 --> 00:41:05,240
there are active for only one day and I

890
00:41:05,240 --> 00:41:08,299
just go offline and it is supposed to be

891
00:41:08,299 --> 00:41:11,390
legitimate advertising which I don't

892
00:41:11,390 --> 00:41:16,660
think so some another thing that I

893
00:41:16,660 --> 00:41:21,020
wanted to talk about the finish is once

894
00:41:21,020 --> 00:41:24,020
I saw a third hunter I want you find

895
00:41:24,020 --> 00:41:26,869
something which is super cool you are

896
00:41:26,869 --> 00:41:28,460
going you want to move on right you

897
00:41:28,460 --> 00:41:30,200
don't want to be maintaining the IOC's

898
00:41:30,200 --> 00:41:32,210
list of the same malware over and over

899
00:41:32,210 --> 00:41:34,369
you're stuck with that it's not it's not

900
00:41:34,369 --> 00:41:38,690
fun so how I can mix all these things

901
00:41:38,690 --> 00:41:40,490
together we already saw that we can

902
00:41:40,490 --> 00:41:43,350
actually drain very specific classifiers

903
00:41:43,350 --> 00:41:46,620
so what if the algorithms can take care

904
00:41:46,620 --> 00:41:49,140
of this tracking and not me that can be

905
00:41:49,140 --> 00:41:51,900
great so this is what we did and put in

906
00:41:51,900 --> 00:41:57,720
place and basically the yellow is the

907
00:41:57,720 --> 00:42:00,690
initial set of biases which was around a

908
00:42:00,690 --> 00:42:03,390
dozen hot names and this is kind of the

909
00:42:03,390 --> 00:42:05,730
size of the infections and a yellow is

910
00:42:05,730 --> 00:42:07,740
the initial thing that we use for

911
00:42:07,740 --> 00:42:09,750
training to say okay the algorithm

912
00:42:09,750 --> 00:42:12,330
please to learn this okay

913
00:42:12,330 --> 00:42:15,030
please learn these that I want to track

914
00:42:15,030 --> 00:42:16,260
it

915
00:42:16,260 --> 00:42:18,600
then we deploy like aspire you can see

916
00:42:18,600 --> 00:42:23,310
the blue after some time the classifier

917
00:42:23,310 --> 00:42:26,550
is able to actually start generating

918
00:42:26,550 --> 00:42:28,500
instance and both of these behaving

919
00:42:28,500 --> 00:42:31,290
basing based on this behavior completely

920
00:42:31,290 --> 00:42:34,680
alone and it's much more than we

921
00:42:34,680 --> 00:42:38,100
actually could capture with the initial

922
00:42:38,100 --> 00:42:41,790
Isis right so actually three more times

923
00:42:41,790 --> 00:42:45,360
more detections and didn't require me

924
00:42:45,360 --> 00:42:48,770
any type of interaction which is great

925
00:42:48,770 --> 00:42:51,570
so we are doing these with more than 100

926
00:42:51,570 --> 00:42:55,890
campaigns and it's very useful because

927
00:42:55,890 --> 00:42:58,500
actually that you can have the experts

928
00:42:58,500 --> 00:43:00,360
focusing on what matters most which is

929
00:43:00,360 --> 00:43:03,210
actually finding new things and leave

930
00:43:03,210 --> 00:43:07,010
the maintainer for the four machines so

931
00:43:07,010 --> 00:43:12,180
to conclude we presented how we we can

932
00:43:12,180 --> 00:43:14,580
create models that are invariant to

933
00:43:14,580 --> 00:43:17,430
these network traffic changes which is

934
00:43:17,430 --> 00:43:19,080
very important to capture all this

935
00:43:19,080 --> 00:43:23,370
dynamic behavior of module we we also

936
00:43:23,370 --> 00:43:25,770
presented how we can use these weak

937
00:43:25,770 --> 00:43:28,080
labels whether it feeds blacklist

938
00:43:28,080 --> 00:43:30,180
anything that is sometimes they are very

939
00:43:30,180 --> 00:43:32,010
good sometimes that they are not so

940
00:43:32,010 --> 00:43:35,100
reliable and we can use these to learn

941
00:43:35,100 --> 00:43:40,020
at large scale and we can also show you

942
00:43:40,020 --> 00:43:42,810
also show how we use active learning to

943
00:43:42,810 --> 00:43:45,600
watch from automatic li train track

944
00:43:45,600 --> 00:43:50,550
module and we use these as we say in the

945
00:43:50,550 --> 00:43:54,330
beginning we are using this combination

946
00:43:54,330 --> 00:43:55,480
of things in

947
00:43:55,480 --> 00:44:00,130
real life and more in network covering

948
00:44:00,130 --> 00:44:02,520
in total more than million users and

949
00:44:02,520 --> 00:44:05,350
finding tens of thousands of infections

950
00:44:05,350 --> 00:44:09,310
and this is good news and bad news the

951
00:44:09,310 --> 00:44:12,040
bad news is that these tens of thousands

952
00:44:12,040 --> 00:44:14,950
of infections are infections that bypass

953
00:44:14,950 --> 00:44:16,869
everything we have in place right now

954
00:44:16,869 --> 00:44:18,880
because you have to have in place

955
00:44:18,880 --> 00:44:21,480
everything but you can also do these

956
00:44:21,480 --> 00:44:24,670
finding infections after like three

957
00:44:24,670 --> 00:44:29,770
hunting so these leave us with this that

958
00:44:29,770 --> 00:44:32,500
what got us here one get up there right

959
00:44:32,500 --> 00:44:35,710
we have ideas we have anti viruses we

960
00:44:35,710 --> 00:44:37,810
have everything and it's great we should

961
00:44:37,810 --> 00:44:40,900
keep keep those but we should also think

962
00:44:40,900 --> 00:44:42,850
about the future and how we start mixing

963
00:44:42,850 --> 00:44:45,040
all these techniques together because we

964
00:44:45,040 --> 00:44:50,080
can do much more and we should this is

965
00:44:50,080 --> 00:44:53,580
why we are here today talking about this

966
00:44:53,580 --> 00:44:57,190
so thank you

967
00:44:57,190 --> 00:45:00,709
[Applause]

968
00:45:03,339 --> 00:45:06,520
I think we have time for questions if

969
00:45:06,520 --> 00:45:14,040
anyone has questions no questions or

970
00:45:14,040 --> 00:45:30,490
they're okay yes I mean the number of

971
00:45:30,490 --> 00:45:32,260
simplified for training how many samples

972
00:45:32,260 --> 00:45:34,630
if you can inside use on and to train a

973
00:45:34,630 --> 00:45:38,280
reliable system they depend right

974
00:45:38,280 --> 00:45:41,050
depends how the sample looks like or how

975
00:45:41,050 --> 00:45:43,150
diverse it is or how different is from

976
00:45:43,150 --> 00:45:46,030
the rest of the traffic so of course we

977
00:45:46,030 --> 00:45:49,510
can even for just singles of samples

978
00:45:49,510 --> 00:45:51,730
trainer reliable coffee fire but it's

979
00:45:51,730 --> 00:45:54,910
not almost okay just strong regiment but

980
00:45:54,910 --> 00:45:57,040
still we just what what we do we

981
00:45:57,040 --> 00:45:59,710
everything we have maybe just one sample

982
00:45:59,710 --> 00:46:02,200
we train the model still and what we do

983
00:46:02,200 --> 00:46:04,690
we just re-evaluate and over the time

984
00:46:04,690 --> 00:46:06,880
whenever new levels are available and

985
00:46:06,880 --> 00:46:08,109
when we see that it behaves correctly

986
00:46:08,109 --> 00:46:10,119
then it is deployed right but this is an

987
00:46:10,119 --> 00:46:11,589
automatically you don't have to care

988
00:46:11,589 --> 00:46:14,859
just use it trainees should see that it

989
00:46:14,859 --> 00:46:21,270
works and deploy any other questions

990
00:46:21,270 --> 00:46:24,270
okay

991
00:46:30,069 --> 00:46:32,650
yeah sure sure we have a kind of lot of

992
00:46:32,650 --> 00:46:34,150
qualifiers we'll just for illustration

993
00:46:34,150 --> 00:46:36,220
because there are the most cases or the

994
00:46:36,220 --> 00:46:39,329
one that people know but we have around

995
00:46:39,329 --> 00:46:41,770
70 different coffee Paris more coffee

996
00:46:41,770 --> 00:46:44,109
Paris conspiring general behavior and

997
00:46:44,109 --> 00:46:47,170
then these are then combined into these

998
00:46:47,170 --> 00:46:49,960
categories and we have around 20 or 50

999
00:46:49,960 --> 00:46:51,549
different from Alberta categories that

1000
00:46:51,549 --> 00:46:53,980
we can classify right now I've injected

1001
00:46:53,980 --> 00:46:56,799
ransomware exfiltration so on and they

1002
00:46:56,799 --> 00:46:58,630
are still increasing yeah so definitely

1003
00:46:58,630 --> 00:47:04,230
more yeah

1004
00:47:11,590 --> 00:47:14,749
[Music]

1005
00:47:15,700 --> 00:47:18,760
right now we are using mainly proxy

1006
00:47:18,760 --> 00:47:23,710
locks which does six many things but we

1007
00:47:23,710 --> 00:47:26,980
already started to work to move these

1008
00:47:26,980 --> 00:47:29,710
techniques to NetFlow which will give us

1009
00:47:29,710 --> 00:47:32,470
more insight another protocol but with

1010
00:47:32,470 --> 00:47:39,670
we don't have any results yet or not any

1011
00:47:39,670 --> 00:47:40,780
other questions

1012
00:47:40,780 --> 00:47:58,510
anything yeah yeah I think that I think

1013
00:47:58,510 --> 00:48:03,880
that we should be more balls and start

1014
00:48:03,880 --> 00:48:05,710
combining things in a different way

1015
00:48:05,710 --> 00:48:08,410
shaking things up because we have in

1016
00:48:08,410 --> 00:48:11,530
place many traditional things and many

1017
00:48:11,530 --> 00:48:13,810
people right now there are hundreds of

1018
00:48:13,810 --> 00:48:15,520
companies saying with the machine

1019
00:48:15,520 --> 00:48:20,500
learning but it's not only about machine

1020
00:48:20,500 --> 00:48:22,690
learning we only can catch we work on

1021
00:48:22,690 --> 00:48:26,410
the network so we are ready we are you

1022
00:48:26,410 --> 00:48:27,760
are already infected if we see the

1023
00:48:27,760 --> 00:48:33,040
traffic right so essa' isn't I mean in a

1024
00:48:33,040 --> 00:48:36,850
sense that anything's so far we have

1025
00:48:36,850 --> 00:48:39,310
these unique products that will protect

1026
00:48:39,310 --> 00:48:43,270
you from everything and is not the did

1027
00:48:43,270 --> 00:48:45,250
is not going to work it's nothing well

1028
00:48:45,250 --> 00:48:46,570
right now it doesn't work it's not going

1029
00:48:46,570 --> 00:48:48,510
to work in five years so we need to

1030
00:48:48,510 --> 00:48:51,040
change things up so start thinking

1031
00:48:51,040 --> 00:48:59,320
security differently okay no more

1032
00:48:59,320 --> 00:49:03,610
questions okay thank you very much thank

1033
00:49:03,610 --> 00:49:04,270
you

1034
00:49:04,270 --> 00:49:07,639
[Applause]

