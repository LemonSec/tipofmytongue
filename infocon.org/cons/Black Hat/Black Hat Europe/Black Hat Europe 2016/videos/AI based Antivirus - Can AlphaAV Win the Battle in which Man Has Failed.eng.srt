1
00:00:00,030 --> 00:00:01,790
good afternoon ladies and gentlemen

2
00:00:01,790 --> 00:00:06,779
today I will introduce our work on AI

3
00:00:06,779 --> 00:00:10,230
based antivirus and using active

4
00:00:10,230 --> 00:00:13,259
learning system my name is Molly and my

5
00:00:13,259 --> 00:00:16,410
english name is Thomas and from company

6
00:00:16,410 --> 00:00:20,460
by two and I also like you have heard of

7
00:00:20,460 --> 00:00:23,550
deep learning and also the android APK

8
00:00:23,550 --> 00:00:29,400
file ok let's start with a story tell

9
00:00:29,400 --> 00:00:32,689
years ago my first job was virus analyst

10
00:00:32,689 --> 00:00:37,110
who let is really a boring job every day

11
00:00:37,110 --> 00:00:41,160
account a lot of virus samples and they

12
00:00:41,160 --> 00:00:44,329
are let us detected by our competitors

13
00:00:44,329 --> 00:00:48,780
but we missed so many example I know it

14
00:00:48,780 --> 00:00:53,430
is a virus what I need to do is just 2d

15
00:00:53,430 --> 00:00:56,579
compare it with Ida Pro and the growing

16
00:00:56,579 --> 00:00:58,829
the mouse to find a signature and then

17
00:00:58,829 --> 00:01:01,320
copy and paste the signature by the

18
00:01:01,320 --> 00:01:03,840
sequence to a text file so at that time

19
00:01:03,840 --> 00:01:06,720
I had a dream that one day the computer

20
00:01:06,720 --> 00:01:09,990
in front of me and take replace only to

21
00:01:09,990 --> 00:01:12,510
handle virus samples so I can have time

22
00:01:12,510 --> 00:01:17,490
to have a talk on blackhat but nothing's

23
00:01:17,490 --> 00:01:20,250
come true yeah ok

24
00:01:20,250 --> 00:01:22,380
but worst thing one thing I learned from

25
00:01:22,380 --> 00:01:26,970
laptop is a experienced analyst can

26
00:01:26,970 --> 00:01:30,829
identify a virus variant

27
00:01:33,840 --> 00:01:38,550
like these are examples this is a become

28
00:01:38,550 --> 00:01:43,040
how that apk file if the enemy sees code

29
00:01:43,040 --> 00:01:47,130
like these in the red rectangles click

30
00:01:47,130 --> 00:01:49,880
and he'll if we if his a virus at once

31
00:01:49,880 --> 00:01:53,070
he didn't read the code to understand

32
00:01:53,070 --> 00:01:56,190
the logic but he has seen so many very

33
00:01:56,190 --> 00:01:59,040
simple circuit is put on amis a new

34
00:01:59,040 --> 00:02:01,320
virus of variant is just like a new

35
00:02:01,320 --> 00:02:04,380
hundred and number six he has seen so

36
00:02:04,380 --> 00:02:07,350
many six so he can tell if it is a six

37
00:02:07,350 --> 00:02:11,580
at once this is image recognition which

38
00:02:11,580 --> 00:02:14,070
is one of the best applications of deep

39
00:02:14,070 --> 00:02:16,470
learning so this is the first reason we

40
00:02:16,470 --> 00:02:18,510
want to use his learning being anti

41
00:02:18,510 --> 00:02:22,590
virus another reason is the Android

42
00:02:22,590 --> 00:02:25,110
malware has has been growing too fast

43
00:02:25,110 --> 00:02:28,620
and the signatures efficiency is

44
00:02:28,620 --> 00:02:32,010
declining even more faster and you see

45
00:02:32,010 --> 00:02:33,930
the lab the figure shows the total

46
00:02:33,930 --> 00:02:36,120
number of Android malware these years it

47
00:02:36,120 --> 00:02:40,049
has to reach 15 meetings and you can see

48
00:02:40,049 --> 00:02:42,570
there is a leap year basis which is not

49
00:02:42,570 --> 00:02:47,010
kusa and the red figure shows shows the

50
00:02:47,010 --> 00:02:49,580
signature efficiency against the touting

51
00:02:49,580 --> 00:02:52,260
dodging is a popular Android malware

52
00:02:52,260 --> 00:02:57,590
family which has to a lot of variants

53
00:02:57,590 --> 00:03:02,160
you can see in 2013 when signature can

54
00:03:02,160 --> 00:03:06,870
catch almost 30,000 thousand samples but

55
00:03:06,870 --> 00:03:10,230
in 2016 16 when system and signature can

56
00:03:10,230 --> 00:03:12,780
catch only result in starting samples

57
00:03:12,780 --> 00:03:15,810
and the worst of all I have no high

58
00:03:15,810 --> 00:03:21,030
Kong's for new virus variant so we know

59
00:03:21,030 --> 00:03:23,250
we're underneath so how to think of

60
00:03:23,250 --> 00:03:24,840
other ways for example AI paste

61
00:03:24,840 --> 00:03:27,630
antivirus that's not high relate depend

62
00:03:27,630 --> 00:03:31,920
on manpower this is the roadmap of our

63
00:03:31,920 --> 00:03:34,590
mobile mobile antivirus engine they

64
00:03:34,590 --> 00:03:36,450
started with us to interpret the rules

65
00:03:36,450 --> 00:03:41,790
which is which like anyone else and then

66
00:03:41,790 --> 00:03:45,460
we found many large

67
00:03:45,460 --> 00:03:47,700
families have obvious behavior rules

68
00:03:47,700 --> 00:03:51,130
next we develop our code base the rules

69
00:03:51,130 --> 00:03:54,790
which can match some opcode value

70
00:03:54,790 --> 00:03:56,830
sequence and have some logic relief

71
00:03:56,830 --> 00:04:00,640
I finally we got to the happiest people

72
00:04:00,640 --> 00:04:05,680
earning certain people union has two

73
00:04:05,680 --> 00:04:08,800
stages my training stage the other is

74
00:04:08,800 --> 00:04:12,310
prediction stage the input of training

75
00:04:12,310 --> 00:04:16,839
stage is training data size in all suit

76
00:04:16,839 --> 00:04:20,399
in this 15 meeting android APK files

77
00:04:20,399 --> 00:04:26,110
including malware PUA and v9 apps the

78
00:04:26,110 --> 00:04:29,380
first and most important that infinite

79
00:04:29,380 --> 00:04:32,130
stages feature each squad instruction

80
00:04:32,130 --> 00:04:35,470
will have structural type features the

81
00:04:35,470 --> 00:04:38,350
typical type features and in kill hotel

82
00:04:38,350 --> 00:04:42,880
features these features some of which

83
00:04:42,880 --> 00:04:45,370
tend to feature continuous value and

84
00:04:45,370 --> 00:04:50,260
some others has zero one values and the

85
00:04:50,260 --> 00:04:52,330
continuous work and continuous value has

86
00:04:52,330 --> 00:04:55,510
very different range and the

87
00:04:55,510 --> 00:04:59,350
distribution of the range is very uneven

88
00:04:59,350 --> 00:05:02,140
so we need to do no more efficient

89
00:05:02,140 --> 00:05:05,530
feature normalization to make to align

90
00:05:05,530 --> 00:05:07,270
the data to a same range and the

91
00:05:07,270 --> 00:05:09,310
negative distribution and eliminate

92
00:05:09,310 --> 00:05:11,890
possible when I get the normalization

93
00:05:11,890 --> 00:05:14,650
normalize the data we can input them

94
00:05:14,650 --> 00:05:16,750
into the deep neural network for

95
00:05:16,750 --> 00:05:20,290
training and we change the data on hydro

96
00:05:20,290 --> 00:05:23,110
hydro platform is an open source the

97
00:05:23,110 --> 00:05:25,810
people learning platform we are to

98
00:05:25,810 --> 00:05:29,950
improve network structure we add our

99
00:05:29,950 --> 00:05:34,060
radicular and we also use the pass out

100
00:05:34,060 --> 00:05:38,580
encoder to get high quality and

101
00:05:38,580 --> 00:05:41,830
invariant features and we also get

102
00:05:41,830 --> 00:05:44,800
custom configuration tunings after

103
00:05:44,800 --> 00:05:47,920
trimming our negate models between the

104
00:05:47,920 --> 00:05:50,800
Miller model and the puree model

105
00:05:50,800 --> 00:05:55,240
separately with live models we can do

106
00:05:55,240 --> 00:05:56,470
prediction

107
00:05:56,470 --> 00:05:59,790
t-carr apk from testing data size

108
00:05:59,790 --> 00:06:04,690
Express these features and normalize the

109
00:06:04,690 --> 00:06:06,790
features and the input normalize the

110
00:06:06,790 --> 00:06:09,730
data into the model to get a prediction

111
00:06:09,730 --> 00:06:12,940
result and is it Miller

112
00:06:12,940 --> 00:06:17,050
APU a open-air that's the three strategy

113
00:06:17,050 --> 00:06:20,110
will be the focus of today's talk let's

114
00:06:20,110 --> 00:06:25,350
look at the first one feature extraction

115
00:06:25,350 --> 00:06:29,410
tip learning system cannot accept an apk

116
00:06:29,410 --> 00:06:33,520
file as input so we need to tell the

117
00:06:33,520 --> 00:06:38,080
city what should be looking for that

118
00:06:38,080 --> 00:06:40,030
will be informative in making this

119
00:06:40,030 --> 00:06:44,080
decision is its feature extraction we

120
00:06:44,080 --> 00:06:47,919
have structural features to statistical

121
00:06:47,919 --> 00:06:51,880
features and empirical features such as

122
00:06:51,880 --> 00:06:57,930
structural features is mainly about

123
00:06:57,930 --> 00:07:01,210
information of aggregate file structure

124
00:07:01,210 --> 00:07:05,410
for example the number of you two

125
00:07:05,410 --> 00:07:07,870
beauties Phoenicians in Android manifest

126
00:07:07,870 --> 00:07:13,120
file the number of picture file in our

127
00:07:13,120 --> 00:07:17,830
us directory the size of ISDN recurring

128
00:07:17,830 --> 00:07:22,229
the number of classes starts with our

129
00:07:22,229 --> 00:07:26,169
comm slash the number of classes starts

130
00:07:26,169 --> 00:07:29,830
with our travel slash the number of

131
00:07:29,830 --> 00:07:33,580
fields with Clark bling the number of

132
00:07:33,580 --> 00:07:36,729
measures which has parameters greater

133
00:07:36,729 --> 00:07:40,030
than 20 you can see that the structural

134
00:07:40,030 --> 00:07:43,410
features is very intuitive and primitive

135
00:07:43,410 --> 00:07:47,190
that's exactly what we want

136
00:07:47,190 --> 00:07:49,660
besides structural features we also have

137
00:07:49,660 --> 00:07:52,890
knowledge related to features such as

138
00:07:52,890 --> 00:07:54,880
statistical features and empirical

139
00:07:54,880 --> 00:07:58,060
features example of statistical feature

140
00:07:58,060 --> 00:08:00,419
uses

141
00:08:00,629 --> 00:08:08,669
if that the DA we discriminate you

142
00:08:08,669 --> 00:08:12,770
screening certificate sir we we collect

143
00:08:12,770 --> 00:08:15,749
certificate files from all the sample

144
00:08:15,749 --> 00:08:19,679
from the training data size and then we

145
00:08:19,679 --> 00:08:22,409
count the stream occurrence of each

146
00:08:22,409 --> 00:08:26,369
field then we follow this stream email

147
00:08:26,369 --> 00:08:29,179
address equals AB game at a mobile comm

148
00:08:29,179 --> 00:08:35,958
this string appears in in mail where if

149
00:08:35,958 --> 00:08:40,610
the 52 times light appears in denied ABS

150
00:08:40,610 --> 00:08:43,610
so we'll use this screen as well feature

151
00:08:43,610 --> 00:08:48,149
and empirical features is many are based

152
00:08:48,149 --> 00:08:52,470
on virus underneath experience for

153
00:08:52,470 --> 00:08:56,850
example are yes evacuating the educate

154
00:08:56,850 --> 00:09:00,810
Excel it's time to store the result well

155
00:09:00,810 --> 00:09:03,860
such as structural pictures and axonal

156
00:09:03,860 --> 00:09:07,019
but personally found that some may are

157
00:09:07,019 --> 00:09:10,740
sometimes put executable file into is

158
00:09:10,740 --> 00:09:15,800
directory so we used if is directory has

159
00:09:15,800 --> 00:09:19,800
executable as a feature similarly we

160
00:09:19,800 --> 00:09:23,970
have if a site directory has a TK file

161
00:09:23,970 --> 00:09:28,500
title feature since deploying existing

162
00:09:28,500 --> 00:09:30,930
only accepts real number as input so we

163
00:09:30,930 --> 00:09:34,130
need to convert all these features to

164
00:09:34,130 --> 00:09:38,639
refer to real numbers some of the

165
00:09:38,639 --> 00:09:40,740
features can be converted to zero one

166
00:09:40,740 --> 00:09:45,589
value for example if our yet theater has

167
00:09:45,589 --> 00:09:48,569
you execute about file if it is higher

168
00:09:48,569 --> 00:09:50,699
in the value is one if not two value

169
00:09:50,699 --> 00:09:55,139
theorem somewhat values cloning the

170
00:09:55,139 --> 00:09:57,779
cover to a continuous value

171
00:09:57,779 --> 00:10:00,180
continuous value has very differently in

172
00:10:00,180 --> 00:10:03,480
written series of seven and the there is

173
00:10:03,480 --> 00:10:06,630
an and there is a median number in these

174
00:10:06,630 --> 00:10:10,800
features so if this number input into

175
00:10:10,800 --> 00:10:13,950
the TV neural network

176
00:10:13,950 --> 00:10:16,770
actually the streams where the small

177
00:10:16,770 --> 00:10:22,380
valuables will soon be surprised and the

178
00:10:22,380 --> 00:10:25,170
in fact over small so most small value

179
00:10:25,170 --> 00:10:28,260
features will be greatly reduced

180
00:10:28,260 --> 00:10:31,020
so we need to a landed theta into same

181
00:10:31,020 --> 00:10:35,040
range and in fact that a terrine the

182
00:10:35,040 --> 00:10:37,620
distribution of each range is is not

183
00:10:37,620 --> 00:10:43,260
even we will we need to make it actually

184
00:10:43,260 --> 00:10:44,760
I realized possible

185
00:10:44,760 --> 00:10:48,510
this is the feature normalization and it

186
00:10:48,510 --> 00:10:50,670
is very important and we have done a lot

187
00:10:50,670 --> 00:10:57,410
of work on their system details I dearly

188
00:10:57,410 --> 00:11:01,550
feature data up a constant distribution

189
00:11:01,550 --> 00:11:04,020
we can use the standard score

190
00:11:04,020 --> 00:11:07,950
normalization to align the data to to a

191
00:11:07,950 --> 00:11:11,640
closing - closing interval between minus

192
00:11:11,640 --> 00:11:12,560
1 and 1

193
00:11:12,560 --> 00:11:17,070
it's perfect but in the reality is much

194
00:11:17,070 --> 00:11:18,530
more complex

195
00:11:18,530 --> 00:11:22,850
for example the feature the size of

196
00:11:22,850 --> 00:11:25,940
certificate file this features

197
00:11:25,940 --> 00:11:29,100
distribution which looks like this now

198
00:11:29,100 --> 00:11:32,360
what you call an parallel with y axis

199
00:11:32,360 --> 00:11:37,560
this brownish distribution this is a

200
00:11:37,560 --> 00:11:40,550
very bad feature because is not

201
00:11:40,550 --> 00:11:44,250
discriminating the thing cannot make the

202
00:11:44,250 --> 00:11:48,600
ceiling depend on the dumbest feature

203
00:11:48,600 --> 00:11:52,050
all the samples has value in this

204
00:11:52,050 --> 00:11:56,960
feature so however when they are

205
00:11:56,960 --> 00:12:00,210
double-checked the data I will we found

206
00:12:00,210 --> 00:12:02,220
that this is actually an knowledge

207
00:12:02,220 --> 00:12:06,060
problem there are some very large values

208
00:12:06,060 --> 00:12:10,020
at the far end of x axis x axis so we

209
00:12:10,020 --> 00:12:12,540
used cutting techniques to cut off the

210
00:12:12,540 --> 00:12:16,520
noisy data then the journey distribution

211
00:12:16,520 --> 00:12:22,590
transform to this one it's amazing how a

212
00:12:22,590 --> 00:12:25,230
vertical line transformed to a multi

213
00:12:25,230 --> 00:12:27,059
model distribution

214
00:12:27,059 --> 00:12:30,959
and this is a underneath is a maximal

215
00:12:30,959 --> 00:12:33,499
batter because it is much more

216
00:12:33,499 --> 00:12:39,359
discriminative like no word : but this

217
00:12:39,359 --> 00:12:41,309
can be a little introduction can be

218
00:12:41,309 --> 00:12:43,709
further optimized because and you can

219
00:12:43,709 --> 00:12:47,279
see it there are six peaks in this new

220
00:12:47,279 --> 00:12:50,549
solution is not even so we use cutting

221
00:12:50,549 --> 00:12:54,389
light techniques again to cut it into

222
00:12:54,389 --> 00:13:00,419
six constant leg distributions and then

223
00:13:00,419 --> 00:13:03,179
we can use standard normalization to

224
00:13:03,179 --> 00:13:04,829
align the data to a closing travel

225
00:13:04,829 --> 00:13:08,459
between miners run around another

226
00:13:08,459 --> 00:13:13,679
example is the file numbers being apk

227
00:13:13,679 --> 00:13:16,799
file in a decade Patrick the parent

228
00:13:16,799 --> 00:13:19,019
numbers in apk Patrick package if

229
00:13:19,019 --> 00:13:21,449
distribution looks like these is a long

230
00:13:21,449 --> 00:13:25,619
tail distribution for it for this one we

231
00:13:25,619 --> 00:13:28,919
can use compiled normalization which is

232
00:13:28,919 --> 00:13:32,609
fine controls and that can divide the

233
00:13:32,609 --> 00:13:36,989
data evenly and then allow each division

234
00:13:36,989 --> 00:13:41,479
to close interval between minus 1 and 1

235
00:13:41,479 --> 00:13:44,729
and this is a key part of this training

236
00:13:44,729 --> 00:13:49,589
the katrinak stage you have to find the

237
00:13:49,589 --> 00:13:52,319
appropriate algorithm based on your own

238
00:13:52,319 --> 00:13:56,099
data characteristics and it's effective

239
00:13:56,099 --> 00:13:59,279
of sitting the precision of our system

240
00:13:59,279 --> 00:14:05,149
has increased by 9% this normalization

241
00:14:06,590 --> 00:14:09,470
so then after normalize we can't

242
00:14:09,470 --> 00:14:11,000
normalize data we can input them into

243
00:14:11,000 --> 00:14:13,790
the neural network streaming this is our

244
00:14:13,790 --> 00:14:15,529
network

245
00:14:15,529 --> 00:14:18,220
this is a typical feed-forward

246
00:14:18,220 --> 00:14:21,470
artificial neural network which has a

247
00:14:21,470 --> 00:14:24,710
value input layer when output layer and

248
00:14:24,710 --> 00:14:28,130
the three hidden layers we include the

249
00:14:28,130 --> 00:14:30,140
network structure we also add a

250
00:14:30,140 --> 00:14:33,470
procedure layer the difference between

251
00:14:33,470 --> 00:14:35,360
residual layer and the common hidden

252
00:14:35,360 --> 00:14:38,320
layer is that confident layer only

253
00:14:38,320 --> 00:14:42,279
accepts input input from previous layer

254
00:14:42,279 --> 00:14:47,360
and your digital AR will receive input

255
00:14:47,360 --> 00:14:51,940
from not only previous layer but also

256
00:14:51,940 --> 00:14:55,880
the layer before previous layer is

257
00:14:55,880 --> 00:14:58,850
called identity identity has no weight

258
00:14:58,850 --> 00:15:01,970
from parameter or we can say the beta

259
00:15:01,970 --> 00:15:03,950
parameter of identity is always equal to

260
00:15:03,950 --> 00:15:09,680
one another character the input layer we

261
00:15:09,680 --> 00:15:17,890
have 571 continuous features and we have

262
00:15:17,890 --> 00:15:24,020
664 the robot features totally 1230 file

263
00:15:24,020 --> 00:15:26,780
features you may think of 1000 features

264
00:15:26,780 --> 00:15:31,670
is a little small for for the deep

265
00:15:31,670 --> 00:15:34,430
learning but I want to say is good

266
00:15:34,430 --> 00:15:39,260
enough we have spent a lot of effort to

267
00:15:39,260 --> 00:15:42,589
reduce the feature from 10,000 to 1000

268
00:15:42,589 --> 00:15:47,030
and more importantly once on the feature

269
00:15:47,030 --> 00:15:51,290
can work on mobile phone and milk

270
00:15:51,290 --> 00:15:54,170
we will discuss the production

271
00:15:54,170 --> 00:15:58,670
deployment in the next slide ok another

272
00:15:58,670 --> 00:16:01,190
thought about the training process we

273
00:16:01,190 --> 00:16:05,270
use Spock encoder to change this network

274
00:16:05,270 --> 00:16:09,890
first house encoder is unsupervised

275
00:16:09,890 --> 00:16:13,610
learning algorithms that can fund high

276
00:16:13,610 --> 00:16:16,120
quality and environment features

277
00:16:16,120 --> 00:16:19,840
enterprise back propagation and settings

278
00:16:19,840 --> 00:16:23,130
the target value to equal to the input

279
00:16:23,130 --> 00:16:27,940
like this schematic diagram shows by

280
00:16:27,940 --> 00:16:30,940
placing some constraints on the network

281
00:16:30,940 --> 00:16:33,400
for example most of the new roads new

282
00:16:33,400 --> 00:16:37,690
rains should being active and we get two

283
00:16:37,690 --> 00:16:40,780
parts out encoder using auto encoder is

284
00:16:40,780 --> 00:16:43,330
the main difference between people

285
00:16:43,330 --> 00:16:50,080
learning and actually am yes

286
00:16:50,080 --> 00:16:52,390
after training with Ock encoder we train

287
00:16:52,390 --> 00:16:54,880
it with the label of data now let's look

288
00:16:54,880 --> 00:16:58,600
at some configurations of this neural

289
00:16:58,600 --> 00:17:03,850
network we use tons and remove as hidden

290
00:17:03,850 --> 00:17:06,609
layer activation function you can use

291
00:17:06,609 --> 00:17:09,700
sigmoid but these two functions is is

292
00:17:09,700 --> 00:17:15,579
much faster than sigmoid we use video

293
00:17:15,579 --> 00:17:18,579
you use multi class cross entity as a

294
00:17:18,579 --> 00:17:22,750
cost function and we use 88 dark out as

295
00:17:22,750 --> 00:17:26,680
a learning method and we use softmax

296
00:17:26,680 --> 00:17:30,580
as a final layer activation function

297
00:17:30,580 --> 00:17:31,660
Francis ultimax

298
00:17:31,660 --> 00:17:34,390
microscope can be used for multi

299
00:17:34,390 --> 00:17:37,240
classification problem and the training

300
00:17:37,240 --> 00:17:40,090
package is twenty to thirty one hundred

301
00:17:40,090 --> 00:17:43,480
classics will cause overfitting and

302
00:17:43,480 --> 00:17:48,670
let's eat so when we cut the models our

303
00:17:48,670 --> 00:17:51,280
China we can call models then we can do

304
00:17:51,280 --> 00:17:55,240
the prediction this is the production

305
00:17:55,240 --> 00:17:59,830
development of our sitting we extract

306
00:17:59,830 --> 00:18:02,770
features on the phone and then send the

307
00:18:02,770 --> 00:18:06,310
features to the cloud we do prediction

308
00:18:06,310 --> 00:18:08,890
in the cloud considering the performance

309
00:18:08,890 --> 00:18:12,220
and inside the prediction result to the

310
00:18:12,220 --> 00:18:16,000
form the whole process only takes 140

311
00:18:16,000 --> 00:18:19,150
milliseconds and the traffic is 1 KB for

312
00:18:19,150 --> 00:18:23,730
80k to evaluate the detection for

313
00:18:23,730 --> 00:18:24,880
performance

314
00:18:24,880 --> 00:18:28,960
let's check the ROC curve now this model

315
00:18:28,960 --> 00:18:29,920
is between

316
00:18:29,920 --> 00:18:32,590
July and the task against the paid taxes

317
00:18:32,590 --> 00:18:36,450
imposed on tool and you can see that is

318
00:18:36,450 --> 00:18:38,740
this needle model has very good

319
00:18:38,740 --> 00:18:43,810
detection because it's recall is almost

320
00:18:43,810 --> 00:18:49,150
a is 96% and the for the pollak you Rick

321
00:18:49,150 --> 00:18:53,860
is almost zero now let's look at a model

322
00:18:53,860 --> 00:18:57,400
lifetime this model is trained on

323
00:18:57,400 --> 00:18:59,920
January and the test against every tile

324
00:18:59,920 --> 00:19:04,330
samples are January March May and the

325
00:19:04,330 --> 00:19:08,500
tool and we can see that the recall rate

326
00:19:08,500 --> 00:19:12,190
has dropped by seven point six in six

327
00:19:12,190 --> 00:19:14,920
month six so see from these figures we

328
00:19:14,920 --> 00:19:17,830
can know and also the model has very

329
00:19:17,830 --> 00:19:20,470
cool detection performance by the way

330
00:19:20,470 --> 00:19:23,200
about it need to continually continue

331
00:19:23,200 --> 00:19:24,700
with the training with the label data

332
00:19:24,700 --> 00:19:32,650
otherwise the recoil will drop yes

333
00:19:32,650 --> 00:19:36,010
let's talk about the limitations first

334
00:19:36,010 --> 00:19:37,840
people learning can provide explanations

335
00:19:37,840 --> 00:19:41,530
for if detection results loss as we n

336
00:19:41,530 --> 00:19:44,620
can do it but tip learn economy it is

337
00:19:44,620 --> 00:19:48,430
because there are too many parameters in

338
00:19:48,430 --> 00:19:52,570
the hidden layers but if it also has the

339
00:19:52,570 --> 00:19:56,220
benefit that attackers

340
00:19:56,220 --> 00:19:59,080
don't know which feature caused the

341
00:19:59,080 --> 00:20:03,670
detection for is a malware either and

342
00:20:03,670 --> 00:20:07,630
besides that the features are mainly

343
00:20:07,630 --> 00:20:12,130
primitive information such as the number

344
00:20:12,130 --> 00:20:14,770
of files in apk and the size of a

345
00:20:14,770 --> 00:20:18,160
directory so it is hard it's more

346
00:20:18,160 --> 00:20:23,940
difficult to evade detection second and

347
00:20:23,940 --> 00:20:26,620
uncertain can't understand coda meaning

348
00:20:26,620 --> 00:20:29,320
is learned in a unique recognition way

349
00:20:29,320 --> 00:20:32,830
so it don't even try to understand the

350
00:20:32,830 --> 00:20:36,850
coordinating pearl it's built on static

351
00:20:36,850 --> 00:20:38,860
analysis and the lack of dynamic

352
00:20:38,860 --> 00:20:42,400
instruction and last the concept

353
00:20:42,400 --> 00:20:42,820
learning

354
00:20:42,820 --> 00:20:43,460
need

355
00:20:43,460 --> 00:20:45,230
continue the training with label data we

356
00:20:45,230 --> 00:20:48,890
have seen in NASA figures and it also

357
00:20:48,890 --> 00:20:50,990
has advantages for example more

358
00:20:50,990 --> 00:20:52,909
difficult for you eight we have just

359
00:20:52,909 --> 00:20:55,880
discussed and it has a fixed of sizing

360
00:20:55,880 --> 00:20:58,870
model the size of a traditional

361
00:20:58,870 --> 00:21:04,039
signature database grows with sample

362
00:21:04,039 --> 00:21:06,919
size linearly but the people learning

363
00:21:06,919 --> 00:21:10,159
model the size of deep learning model is

364
00:21:10,159 --> 00:21:15,370
only related to to the network structure

365
00:21:15,370 --> 00:21:20,120
for our system the model size is owning

366
00:21:20,120 --> 00:21:28,309
two megabytes conclusion feature

367
00:21:28,309 --> 00:21:32,179
extraction is the key step virus analyst

368
00:21:32,179 --> 00:21:34,850
appearance and how to encoder and how to

369
00:21:34,850 --> 00:21:39,529
find the valuable features and this

370
00:21:39,529 --> 00:21:41,750
system is designed to detect Anglo

371
00:21:41,750 --> 00:21:43,940
malware but these measures can be used

372
00:21:43,940 --> 00:21:46,789
in detecting male wearing other

373
00:21:46,789 --> 00:21:52,429
platforms last how certain if learns in

374
00:21:52,429 --> 00:21:54,860
image recognition way is effective only

375
00:21:54,860 --> 00:21:59,960
in detecting male very vibrant virus but

376
00:21:59,960 --> 00:22:02,750
it is a concern in a speech recognition

377
00:22:02,750 --> 00:22:06,230
way maybe it can understand the code

378
00:22:06,230 --> 00:22:08,390
meaning and then read the code logic to

379
00:22:08,390 --> 00:22:12,409
uncover a new malware family not manatee

380
00:22:12,409 --> 00:22:15,610
what we are going to do next

381
00:22:17,620 --> 00:22:20,470
welcome to contact me for any reason and

382
00:22:20,470 --> 00:22:23,240
welcome cooperation and partnership with

383
00:22:23,240 --> 00:22:26,470
us thank you all

384
00:22:26,690 --> 00:22:29,799
[Music]

385
00:22:31,760 --> 00:22:33,590
ladies and gentlemen we have time for a

386
00:22:33,590 --> 00:22:43,100
few questions anyone has one high

387
00:22:43,100 --> 00:22:46,520
technical talk you mentioned that you

388
00:22:46,520 --> 00:22:48,560
need labels input right for your

389
00:22:48,560 --> 00:22:53,750
training you what input labels label

390
00:22:53,750 --> 00:22:56,450
labels yes label data and where did you

391
00:22:56,450 --> 00:22:59,870
get the label data from oh yes oh how a

392
00:22:59,870 --> 00:23:02,480
team of focus on mobile and you are so

393
00:23:02,480 --> 00:23:06,440
we have a lot of prowlers and cats and

394
00:23:06,440 --> 00:23:08,150
holes and we also have somehow exchange

395
00:23:08,150 --> 00:23:10,990
with other security companies okay

396
00:23:10,990 --> 00:23:12,260
thanks

397
00:23:12,260 --> 00:23:24,530
yes oh thank you hi great talk

398
00:23:24,530 --> 00:23:26,330
why do you have to normalize the data

399
00:23:26,330 --> 00:23:29,200
before opening into the neural network

400
00:23:29,200 --> 00:23:31,700
so what I just put the numbers

401
00:23:31,700 --> 00:23:35,110
straighted rather than normalizing them

402
00:23:35,110 --> 00:23:39,020
why normal sorry or so why do you have

403
00:23:39,020 --> 00:23:42,020
to normalize data before putting it into

404
00:23:42,020 --> 00:23:46,340
the neural network oh yeah for for two

405
00:23:46,340 --> 00:23:50,660
reasons and further days the data has a

406
00:23:50,660 --> 00:23:52,700
very deep in the region some really from

407
00:23:52,700 --> 00:23:54,470
ten to hundred and other it's really

408
00:23:54,470 --> 00:23:55,970
from 102 billion

409
00:23:55,970 --> 00:24:01,400
so if these data including into the

410
00:24:01,400 --> 00:24:05,240
neural network some peak values will

411
00:24:05,240 --> 00:24:09,280
surprise the rat I mean surprise the

412
00:24:09,280 --> 00:24:13,670
effect of small values the the neuron

413
00:24:13,670 --> 00:24:16,850
even neuron accepts a very big value it

414
00:24:16,850 --> 00:24:21,080
will be others I don't know how to say

415
00:24:21,080 --> 00:24:21,440
other

416
00:24:21,440 --> 00:24:28,850
it was to talk in couple SAP small

417
00:24:28,850 --> 00:24:32,240
values so we need to align the data into

418
00:24:32,240 --> 00:24:35,480
a single value range and the other

419
00:24:35,480 --> 00:24:37,970
reason is

420
00:24:37,970 --> 00:24:42,320
this is not enough because daily is not

421
00:24:42,320 --> 00:24:46,600
implicate highs not even look at the

422
00:24:53,470 --> 00:24:58,700
yeah no cat is a vertical and then all

423
00:24:58,700 --> 00:25:02,149
the older samples have same value this

424
00:25:02,149 --> 00:25:06,470
feature isn't used to these for the

425
00:25:06,470 --> 00:25:08,149
system because it may come to make it

426
00:25:08,149 --> 00:25:14,000
excited by this feature so we need to do

427
00:25:14,000 --> 00:25:17,240
the to make it the dissolution as even

428
00:25:17,240 --> 00:25:19,360
as possible

429
00:25:27,050 --> 00:25:36,950
I could talk then can you mention

430
00:25:36,950 --> 00:25:39,940
something about false positive rates

431
00:25:39,940 --> 00:25:43,550
about what are false positive rates of

432
00:25:43,550 --> 00:25:49,160
detection hot sales positive Oh sauce

433
00:25:49,160 --> 00:25:53,900
was lack of all calculate okay you see

434
00:25:53,900 --> 00:25:57,530
the the Jacques Rogge shows a full

435
00:25:57,530 --> 00:26:03,200
positive rate then the x-axis of a

436
00:26:03,200 --> 00:26:06,980
rocker in the middle figure is the for

437
00:26:06,980 --> 00:26:13,670
the positive rate of our model has very

438
00:26:13,670 --> 00:26:18,770
good detection the faulty voltages and

439
00:26:18,770 --> 00:26:24,890
the first goal of little Susan is to is

440
00:26:24,890 --> 00:26:27,140
to control the for the parking rate or

441
00:26:27,140 --> 00:26:31,340
the precision because we want to use

442
00:26:31,340 --> 00:26:35,300
these to attend every test and it

443
00:26:35,300 --> 00:26:37,520
actually it's already attended every

444
00:26:37,520 --> 00:26:42,190
test on January this year ten words is

445
00:26:42,190 --> 00:26:46,370
these comparative tests the photo

446
00:26:46,370 --> 00:26:50,240
Pollock you read is very important for

447
00:26:50,240 --> 00:26:52,820
these comparative have test and because

448
00:26:52,820 --> 00:26:55,040
even you have one for the full parking

449
00:26:55,040 --> 00:26:58,240
rate will get punished very severely

450
00:26:58,240 --> 00:27:02,270
civilly so the first go of listen is to

451
00:27:02,270 --> 00:27:05,870
control the precision or for the parking

452
00:27:05,870 --> 00:27:09,260
rate but I think the deep learning

453
00:27:09,260 --> 00:27:11,300
sitting you can give running to active

454
00:27:11,300 --> 00:27:16,220
antivirals now control the precise

455
00:27:16,220 --> 00:27:19,400
precision of all calculate too much it

456
00:27:19,400 --> 00:27:22,250
through the latter goal and the recall

457
00:27:22,250 --> 00:27:27,270
is the most important point of listening

458
00:27:27,270 --> 00:27:29,230
[Music]

459
00:27:29,230 --> 00:27:33,040
question thank you

460
00:27:37,910 --> 00:27:40,710
hi thank you for TRADOC thank you

461
00:27:40,710 --> 00:27:43,830
so ah he must recognizer neural networks

462
00:27:43,830 --> 00:27:46,350
have been added his line of work of

463
00:27:46,350 --> 00:27:49,380
adversarial samples and basically what

464
00:27:49,380 --> 00:27:52,230
people have sold is that you can do some

465
00:27:52,230 --> 00:27:54,150
specific changes that you put in very

466
00:27:54,150 --> 00:27:56,610
small like say less than 1% of the

467
00:27:56,610 --> 00:27:59,460
features of the pixels and cause the

468
00:27:59,460 --> 00:28:03,150
network misclassified are the input so

469
00:28:03,150 --> 00:28:05,490
given that you follow a similar line of

470
00:28:05,490 --> 00:28:07,680
architecture in here it's very important

471
00:28:07,680 --> 00:28:10,020
to correctly classify have you looked

472
00:28:10,020 --> 00:28:13,230
into this area of like this algorithms

473
00:28:13,230 --> 00:28:16,200
causing miss classification saying like

474
00:28:16,200 --> 00:28:18,570
changing one feature by a very small

475
00:28:18,570 --> 00:28:21,120
value and this will cause the network to

476
00:28:21,120 --> 00:28:24,570
output a different value so yeah I was

477
00:28:24,570 --> 00:28:26,850
wondering if you are aware of this area

478
00:28:26,850 --> 00:28:29,400
and whether you are planning to test

479
00:28:29,400 --> 00:28:33,740
such algorithm audience your system

480
00:28:34,130 --> 00:28:36,810
sorry I don't understand your question

481
00:28:36,810 --> 00:28:39,930
very clear we can close about yeah yeah

482
00:28:39,930 --> 00:28:41,730
so basically what's happening is that

483
00:28:41,730 --> 00:28:44,610
image recognition neural networks there

484
00:28:44,610 --> 00:28:46,080
are this line of work that you can

485
00:28:46,080 --> 00:28:48,030
basically caused them to misclassify

486
00:28:48,030 --> 00:28:50,010
inputs here you have an input which is

487
00:28:50,010 --> 00:28:52,440
an elephant and by changing to pixels

488
00:28:52,440 --> 00:28:54,780
you got a network to classify it as a

489
00:28:54,780 --> 00:28:57,840
cut out with very high precision with

490
00:28:57,840 --> 00:29:01,470
very very high confidence so I was

491
00:29:01,470 --> 00:29:03,570
wondering whether you are aware of this

492
00:29:03,570 --> 00:29:05,040
because you follow a similar

493
00:29:05,040 --> 00:29:07,050
architecture whether you have tested any

494
00:29:07,050 --> 00:29:08,970
of these algorithms against you know

495
00:29:08,970 --> 00:29:16,350
your system let's discuss after pox ok

496
00:29:16,350 --> 00:29:20,340
wait to taste it thank you ladies and

497
00:29:20,340 --> 00:29:22,020
gentlemen brothers I'll to thank Thomas

498
00:29:22,020 --> 00:29:23,780
cool on

499
00:29:23,780 --> 00:29:29,020
[Applause]

