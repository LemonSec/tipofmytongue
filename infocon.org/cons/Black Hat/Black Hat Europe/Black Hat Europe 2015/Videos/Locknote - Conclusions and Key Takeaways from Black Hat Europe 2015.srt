1
00:00:00,000 --> 00:00:04,870
hello amsterdam and thank you for
sticking around to this final session I

2
00:00:04,870 --> 00:00:10,349
have a feeling probably raise your hand
if the rain kept you in ok you're very

3
00:00:10,349 --> 00:00:17,170
honest gentleman there so this is gonna
be are locked out session and its pale

4
00:00:17,170 --> 00:00:21,630
review board members in our keynote
Haroun Mir and myself and we're going to

5
00:00:21,630 --> 00:00:25,710
have this conversation around a couple
of topics things that came up at the

6
00:00:25,710 --> 00:00:30,939
conference and also we're going to
hopefully make it interactive how many

7
00:00:30,939 --> 00:00:34,750
people have been a panel sessions in you
know don't get that much out of it I

8
00:00:34,750 --> 00:00:38,480
wanna make it more more interactive I
want to get your questions interjected

9
00:00:38,480 --> 00:00:41,879
so we'll do is we'll talk for a while
maybe fifteen twenty minutes and then

10
00:00:41,879 --> 00:00:45,360
we'll start trying to draw the
conversation to involve you in the

11
00:00:45,360 --> 00:00:49,370
audience so if you hear something that
we say that interest in bringing up

12
00:00:49,370 --> 00:00:54,629
later when we go to the audience and
we'll explore your your question so

13
00:00:54,629 --> 00:00:59,879
before we kick it off I've got a couple
of closing announcements and one is just

14
00:00:59,879 --> 00:01:04,989
how the show did this year it's a record
show for us and Amsterdam we had all had

15
00:01:04,989 --> 00:01:11,979
counted we had over 1,500 people here
pretty impressive for us so very happy

16
00:01:11,979 --> 00:01:18,299
a success and also a record number of
sponsors of about thirty sponsors and so

17
00:01:18,299 --> 00:01:22,820
really good growth and so what that's
telling me is these questions that we're

18
00:01:22,820 --> 00:01:29,339
going to explore everybody has a need to
find answers right it's for some reason

19
00:01:29,340 --> 00:01:31,210
we're not solving the problem

20
00:01:31,210 --> 00:01:35,579
fast enough what more problems are being
created until everybody is desperate for

21
00:01:35,579 --> 00:01:36,490
information

22
00:01:36,490 --> 00:01:40,189
everybody is desperate for solutions and
that's leading to this incredible growth

23
00:01:40,189 --> 00:01:44,169
were saying not just a black eye but
count how many security conferences

24
00:01:44,170 --> 00:01:48,750
there are you can be at one everyday of
the of the week so we're in a really

25
00:01:48,750 --> 00:01:53,350
unique period right now I think in our
industry and I just wanna call it out

26
00:01:53,350 --> 00:01:55,990
because it might not be this way ten
years from now but right now we're sort

27
00:01:55,990 --> 00:01:59,689
of in this golden era and what we do it
this this is sort of opportunity to

28
00:01:59,689 --> 00:02:04,429
shape the future just be aware of it
right don't be oblivious to it to take

29
00:02:04,430 --> 00:02:07,460
advantage of it so

30
00:02:07,460 --> 00:02:13,620
on the social side we've got a winner no
black hat Twitter feed we also have a

31
00:02:13,620 --> 00:02:17,450
Flickr page and so if you wanna see the
pictures that you've seen these

32
00:02:17,450 --> 00:02:21,839
professional photographers taking of us
and the crowd the speakers go to our

33
00:02:21,840 --> 00:02:26,920
Flickr page black hat events on the
start getting uploaded after the event

34
00:02:26,920 --> 00:02:31,010
we also have already posted some and
we'll post more presentation materials

35
00:02:31,010 --> 00:02:35,870
at the black hat dot com site so you saw
some slides that maybe we're different

36
00:02:35,870 --> 00:02:41,739
you wanna get the latest version of what
was actually presented black at the comp

37
00:02:41,739 --> 00:02:46,650
here's my big announcement you probably
did not see coming next year

38
00:02:46,650 --> 00:02:54,150
black hat will be november 124 in London
we're moving right into the middle of

39
00:02:54,150 --> 00:02:58,900
downtown London into a really cool area
into a really cool space and it's gonna

40
00:02:58,900 --> 00:03:02,170
give us a lot more of a social vibrator
can be surrounded by a lot of really

41
00:03:02,170 --> 00:03:08,329
need pubs and other things and and
really try to tie the social in with the

42
00:03:08,330 --> 00:03:13,320
technical and and really help that part
grow because we've all been feeling like

43
00:03:13,320 --> 00:03:17,410
we don't quite have that right
environment being so far away from the

44
00:03:17,410 --> 00:03:21,880
hotels and we've been trying to capture
it and fortunately there's just without

45
00:03:21,880 --> 00:03:28,130
running stream which is really sad so
hello london and I hope to see you there

46
00:03:28,130 --> 00:03:33,030
next year on the first to the fourth ok
so let's kick off her own you're the

47
00:03:33,030 --> 00:03:38,420
star here used welcome everybody to the
event and I might say it was a little

48
00:03:38,420 --> 00:03:42,760
bit of a doom-and-gloom kind of not
navel-gazing but you know you're

49
00:03:42,760 --> 00:03:46,239
definitely pointing out every word on
the face of information security right

50
00:03:46,239 --> 00:03:52,340
which is I'm not opposed to cause I like
you know pointing out problems too but

51
00:03:52,340 --> 00:03:57,380
you about it and so you've been thinking
about this a while so I'm kind of

52
00:03:57,380 --> 00:04:01,560
curious over the time period you've
thought about this

53
00:04:01,560 --> 00:04:06,209
have problems actually have certain
things gotten better and then been

54
00:04:06,209 --> 00:04:10,239
replaced by new problems are we
essentially just accumulating problems

55
00:04:10,239 --> 00:04:13,840
and we've gotten so many now that you're
so frustrated that you're speaking out

56
00:04:13,840 --> 00:04:18,980
you think talk to us a little bit about
the yeah so I'm hoping it wasn't all

57
00:04:18,980 --> 00:04:20,310
doom and gloom

58
00:04:20,310 --> 00:04:27,130
had some suggestions in there but in
truth I don't think there's a lot of

59
00:04:27,130 --> 00:04:30,950
getting better I think there are some
things getting better in fact strangely

60
00:04:30,950 --> 00:04:35,650
I think software security despite the
fact that we also like some of its

61
00:04:35,650 --> 00:04:42,070
turning it on reasonably well Microsoft
and they managed to turn it on a massive

62
00:04:42,070 --> 00:04:47,960
ship it took them about 10 years to do
it and so does signs that some stuff can

63
00:04:47,960 --> 00:04:53,000
be done better but what worries me is
that like if you take the effects quote

64
00:04:53,000 --> 00:04:57,600
about everything being a gate that
fixing one or two of the things actually

65
00:04:57,600 --> 00:05:03,750
doesn't fix enough to make a meaningful
impact on it all and yes I am reasonably

66
00:05:03,750 --> 00:05:08,550
passion about it mainly because like I
said in the talk I think a lot of us

67
00:05:08,550 --> 00:05:15,240
into the field kind of half may even be
half thinking we're really gonna

68
00:05:15,240 --> 00:05:19,500
the world to be truthful did not have
the stuff to exist

69
00:05:19,500 --> 00:05:24,620
exactly the problem with the lot smaller
only gotten bigger and look smaller and

70
00:05:24,620 --> 00:05:26,850
in truth if

71
00:05:26,850 --> 00:05:31,210
selfishly like we kind of thought we
were clever enough to make a serious

72
00:05:31,210 --> 00:05:38,270
dent in the problem and along the way I
think we've redefined the problem so

73
00:05:38,270 --> 00:05:43,430
that we still clever but I don't think
we making a meaningful dent in it and I

74
00:05:43,430 --> 00:05:46,760
think we should get the goal posts so
that we could feel good about ourselves

75
00:05:46,760 --> 00:05:52,650
but fundamentally I think if you take
why we got into it we we're not solving

76
00:05:52,650 --> 00:05:57,560
sold only in Elgin you tell me if you
think it's valid 12 when I talked to

77
00:05:57,560 --> 00:06:02,030
some policy people are management folks
I say if you're going to enter security

78
00:06:02,030 --> 00:06:08,010
you have to think of yourself as sort of
a doctor and maybe do a medical analogy

79
00:06:08,010 --> 00:06:13,070
where my dad is a doctor was a doctor
until he retired and if he entered the

80
00:06:13,070 --> 00:06:17,270
field telling himself that he was going
to cure cancer he would have burned out

81
00:06:17,270 --> 00:06:23,510
right but instead he was going to fight
cancer right so that little mental shift

82
00:06:23,510 --> 00:06:26,419
probably was a difference between
insanity and you know being able to

83
00:06:26,419 --> 00:06:29,960
sleep at night are we in that sort of
same situation where we can't tell us

84
00:06:29,960 --> 00:06:32,849
we're gonna solve security yeah

85
00:06:32,849 --> 00:06:37,050
so it's it's a good point and it's a
good way to think about it like like

86
00:06:37,050 --> 00:06:40,869
I'll have to think about it it's it's a
good analogy but in truth I think

87
00:06:40,869 --> 00:06:46,809
there's some things that we are doing
horribly broken lives and and so I think

88
00:06:46,809 --> 00:06:51,839
like like it was way back like Marcus
Ranum I think you'll remember something

89
00:06:51,839 --> 00:06:57,020
in 2000 said you you saying you want to
kill the cockroaches and every night you

90
00:06:57,020 --> 00:07:02,159
garden leave food for them and and I
think that some of what we doing like we

91
00:07:02,159 --> 00:07:10,188
will not just not winning against cancer
we actively we can get our hands on and

92
00:07:10,189 --> 00:07:14,209
so forth stop them saying let's stop
doing that and then we can start

93
00:07:14,209 --> 00:07:19,189
actually fixing stuff that goes on that
question right does it to nihilistic or

94
00:07:19,189 --> 00:07:23,800
you have to give us all shock treatment
yeah I think we need a little bit of

95
00:07:23,800 --> 00:07:28,099
shock to you so so at no point in me
being completely nihilistic and saying

96
00:07:28,099 --> 00:07:33,938
your hands up don't do it like I think
this famous stockdale quote that says

97
00:07:33,939 --> 00:07:40,399
you never confuse the honesty of how bad
your situation is what the hope that

98
00:07:40,399 --> 00:07:41,309
you'll prevail

99
00:07:41,309 --> 00:07:45,629
so so you still hope that you prevail
but you gotta take stock and say no to

100
00:07:45,629 --> 00:07:53,319
be honest about this and and somehow we
all managed to become really ok with

101
00:07:53,319 --> 00:08:00,269
being really bad like like we've really
grown our tolerance for insecurity and

102
00:08:00,269 --> 00:08:05,599
again I think the big mistake that we
making days we seem to think everyone's

103
00:08:05,599 --> 00:08:11,639
ok with it but I think we're now talking
the other day about affected like we got

104
00:08:11,639 --> 00:08:16,629
into the stuff in it was reasonably fun
and games and originally it was and

105
00:08:16,629 --> 00:08:20,269
along the way it's gotten seriously get
started to involve nation states it

106
00:08:20,269 --> 00:08:26,339
started to involve policy and lots of a
kind of blase about the stuff and it's

107
00:08:26,339 --> 00:08:31,889
like that stuff's changing rapidly and I
think we've kind of now got stuck in the

108
00:08:31,889 --> 00:08:36,430
old way of thinking that says its you do
your best to show up you have some fun

109
00:08:36,429 --> 00:08:42,029
and I think we have to change because I
think we in trouble so let me get some

110
00:08:42,029 --> 00:08:47,809
reaction here from review board or do
you think Jen any reaction to that you

111
00:08:47,809 --> 00:08:54,760
think that he's pretty much on spot or
do you think I read of change you know

112
00:08:54,760 --> 00:08:59,600
within the industry is he seeing the
rate at which technologies new

113
00:08:59,600 --> 00:09:04,059
technology is being released but we
aren't replacing old broken technology

114
00:09:04,059 --> 00:09:11,029
fast enough in rebuilding markup on top
of crap so yes I even feel like security

115
00:09:11,029 --> 00:09:16,189
analyst and sometimes you know I feel
like this is an uncontrollable force and

116
00:09:16,189 --> 00:09:20,699
I feel like maybe I don't want things to
the electronic anymore like maybe I just

117
00:09:20,699 --> 00:09:24,880
don't want to be the kind of data is
being collected about me to be collected

118
00:09:24,880 --> 00:09:31,240
and maybe I don't have control over it
anymore so you know how do you handle

119
00:09:31,240 --> 00:09:36,040
each problem separately security is not
you know some amorphous thing it's not

120
00:09:36,040 --> 00:09:40,930
like something you can ever truly
achieve we base our assumptions about

121
00:09:40,930 --> 00:09:43,029
whether something is secure or not

122
00:09:43,029 --> 00:09:48,160
on things that are testable each
individual thing is tested for each

123
00:09:48,160 --> 00:09:54,180
individual attack so you can't say like
you can say you know overall it has good

124
00:09:54,180 --> 00:09:59,849
security record therefore it's
reasonably secure product but you can

125
00:09:59,850 --> 00:10:04,139
never say anything is truly secure a
snapshot in time

126
00:10:04,139 --> 00:10:09,139
yeah right so so that goes back to
something that maybe we talked about

127
00:10:09,139 --> 00:10:13,930
earlier like can anybody really think of
any security problem we've actually

128
00:10:13,930 --> 00:10:20,180
really solved or are we just innovating
and moving so quickly we leave all these

129
00:10:20,180 --> 00:10:23,899
problems in the dust and so I was saying
you know who's watched that movie war

130
00:10:23,899 --> 00:10:29,540
games right how many people think that
we've ever solve the modem dial-up

131
00:10:29,540 --> 00:10:34,839
problem we just don't use modems anymore
but we never successfully solve that

132
00:10:34,839 --> 00:10:40,750
problem and so I'm thinking like
sequence action no buffer overflow room

133
00:10:40,750 --> 00:10:45,089
like what if we ever really solved and i
dont wanna go all doom and gloom but

134
00:10:45,089 --> 00:10:48,509
like maybe if I could look at our past
successes I could predict our future

135
00:10:48,509 --> 00:10:50,150
successes and I start looking

136
00:10:50,150 --> 00:10:57,390
past I'm not trying yeah it's super
interesting so I think it was professor

137
00:10:57,390 --> 00:11:01,920
called I think it was Richard Danzig
record this super cool paper called

138
00:11:01,920 --> 00:11:07,560
surviving on a diet of frozen fruit and
he was talking about how you s

139
00:11:07,560 --> 00:11:12,020
government is going to survive through
the software stuff and he seemed pretty

140
00:11:12,020 --> 00:11:15,730
much the same thing you've got to assume
that the stuffs poisoned and you've got

141
00:11:15,730 --> 00:11:19,600
to consume just enough of it cuz you
still need the nutrients and and he said

142
00:11:19,600 --> 00:11:23,090
of super interesting thing in the paper
so so he's got a interesting background

143
00:11:23,090 --> 00:11:27,770
where like they threw him at nuclear
proliferation and he goes away for

144
00:11:27,770 --> 00:11:32,890
awhile and talks to everyone he can and
comes back with you as a plan and then

145
00:11:32,890 --> 00:11:36,120
they threw him outside when he did the
same thing and so someone asked him

146
00:11:36,120 --> 00:11:40,110
what's the fundamental fundamental
difference between sidebar and nuclear

147
00:11:40,110 --> 00:11:45,500
and he said when you speak to people
inside nuclear you got you get you

148
00:11:45,500 --> 00:11:51,410
christiane them answers last longer than
six months and he says you got to talk

149
00:11:51,410 --> 00:11:55,290
to someone what you say what are the top
threats facing you now he says you go

150
00:11:55,290 --> 00:11:59,449
back to go back in six months and ask
them and everything's changed and he

151
00:11:59,450 --> 00:12:05,520
gave some some point that even I forgot
about his deed office was a solved

152
00:12:05,520 --> 00:12:11,490
problem he says so far while we really
thought that was a book a min everyone

153
00:12:11,490 --> 00:12:16,310
was running pipes guys were dropping
stuff all over the world and suddenly

154
00:12:16,310 --> 00:12:21,849
it's not like suddenly Doss is is
blackmail worthy again and and it's not

155
00:12:21,850 --> 00:12:26,950
because we think it's just a different
problem attackers have gotten smarter

156
00:12:26,950 --> 00:12:54,920
yeah and that stuff's constantly going
to be shifting

157
00:12:54,920 --> 00:13:43,709
problems that's a good point about
things and in German cars and CPU

158
00:13:43,709 --> 00:13:48,310
equipment where you know I'm really
concerned that we don't have a game plan

159
00:13:48,310 --> 00:13:50,750
on the Internet of Things we're just
gonna be here three years from now

160
00:13:50,750 --> 00:13:55,680
talking about it and the question is how
do these devices update themselves and

161
00:13:55,680 --> 00:13:59,880
in washington D C where I'm living
there's a lot of policy discussions

162
00:13:59,880 --> 00:14:03,029
around it and if things in there
referring to it sort of it's called the

163
00:14:03,029 --> 00:14:09,620
think it's called the latter problem so
like you sell change your cell phone

164
00:14:09,620 --> 00:14:14,250
every two years or so three years max
right how often you change your smoke

165
00:14:14,250 --> 00:14:19,800
detector right and to change your smoke
detector you need a ladder screwdriver

166
00:14:19,800 --> 00:14:23,329
and so the long tail of these embedded
devices are gonna be 10 to 15 years

167
00:14:23,329 --> 00:14:27,459
right right now we're running past all
these mobile problems we just keep it in

168
00:14:27,459 --> 00:14:30,640
a new phone you're not gonna run past
the embedded smoke detector problem

169
00:14:30,640 --> 00:14:35,329
you're gonna have that forever you know
he invented toaster problem and so we're

170
00:14:35,329 --> 00:14:39,540
going to enter this new world that we're
not ready for there's no upgrade path

171
00:14:39,540 --> 00:14:42,779
you know you update your PC on a
rotation you don't update your toaster

172
00:14:42,779 --> 00:14:51,089
really so so it's gonna be on your next
talk about so I think I'm not talking

173
00:14:51,089 --> 00:14:57,190
about just but then gear and and says
look if you're putting out embedded

174
00:14:57,190 --> 00:14:59,420
stuff you've got two options

175
00:14:59,420 --> 00:15:02,630
you've got to have an admin interface so
that you can patch it or it's going to

176
00:15:02,630 --> 00:15:06,460
be built to die and if you don't have
one of those two things

177
00:15:06,460 --> 00:15:09,640
you've got a problem and of course once
you have an admin interface you've now

178
00:15:09,640 --> 00:15:13,870
got problems the same problem and
someone was someone raised over dinner

179
00:15:13,870 --> 00:15:18,150
that the day just to make it more
dramatic you've got that same problem in

180
00:15:18,150 --> 00:15:24,439
pacemakers you've got that same problem
in steering wheels that are so so yeah

181
00:15:24,440 --> 00:15:31,130
it's it's a problem and I think just add
to the grief the rate of change that the

182
00:15:31,130 --> 00:15:36,120
general store is just gonna go up in
like everyone can order a kit that

183
00:15:36,120 --> 00:15:43,910
allows you to build your IOT stuff now
for the hope like the one thing part of

184
00:15:43,910 --> 00:15:44,730
the reason

185
00:15:44,730 --> 00:15:51,170
web was so insecure was because we the
web was the way it was all architected

186
00:15:51,170 --> 00:15:55,010
it allowed the lowest common denominator
to build a website and then browsers

187
00:15:55,010 --> 00:16:00,360
that could see that site and I think if
you looked at it not with your security

188
00:16:00,360 --> 00:16:05,450
had on its been massively successful
like it's driven commerce that wasn't

189
00:16:05,450 --> 00:16:10,400
planned for and it's it's made scallions
and maybe that's all the stuff goes like

190
00:16:10,400 --> 00:16:15,530
maybe it goes as far as it can without
being completely horribly broken and

191
00:16:15,530 --> 00:16:19,400
then wait can it will be patched to a
reasonable amount sort of like

192
00:16:19,400 --> 00:16:25,060
acceptable losses yeah Carter and I'm
not saying that is not something maybe

193
00:16:25,060 --> 00:16:29,069
that's what happens like maybe we just
keep getting to the absolute brink

194
00:16:29,070 --> 00:16:33,780
before someone comes along and does a
little bit of patching there and then

195
00:16:33,780 --> 00:16:45,379
moves on to be extremely vulnerable in
some new area

196
00:16:45,379 --> 00:16:56,789
the problem no control over all the keys
to the kingdom so many cases were for

197
00:16:56,789 --> 00:17:26,009
example we're going to a great time to
upgrade all of your routers and

198
00:17:26,009 --> 00:17:30,370
equipment so if I see p equipment
underwriters were actually more secure

199
00:17:30,370 --> 00:17:33,689
here's the purchasing cycle where we can
actually move in more secure devices

200
00:17:33,690 --> 00:17:38,500
except as your talked about earlier
they're actually not more secure so

201
00:17:38,500 --> 00:17:42,210
we're going to get these devices its
peak v-6 and then people just sit on

202
00:17:42,210 --> 00:17:48,129
them again for the long tail until I
keep trying to grasp on positive note

203
00:17:48,129 --> 00:17:52,350
here and I'm not I need a lot right I'm
hoping the audience can save me because

204
00:17:52,350 --> 00:17:58,100
we've been doing this for decades in you
know maybe we're just internal optimists

205
00:17:58,100 --> 00:18:03,658
one of the talks I saw here that I found
really fascinating was the GPS moving

206
00:18:03,659 --> 00:18:08,850
locations talk and partially just cause
I'm fascinated by GPS and interaction

207
00:18:08,850 --> 00:18:13,779
between the physical location or
orbiting satellites and security

208
00:18:13,779 --> 00:18:16,309
decisions and I were a couple years ago
companies are trying to sell these

209
00:18:16,309 --> 00:18:20,090
solutions where we'll grab your location
off your phone and if you're active

210
00:18:20,090 --> 00:18:23,350
company and then you're trying to login
will make this decision that you're

211
00:18:23,350 --> 00:18:27,908
probably should be authenticated or
authorised but now it turns out right

212
00:18:27,909 --> 00:18:33,570
for $300 the researchers who can spook
GPS and then for free they can spoof

213
00:18:33,570 --> 00:18:39,750
WiFi location and so part of me was like
that's awesome because now we've killed

214
00:18:39,750 --> 00:18:43,860
that are potentially killed that concept
that we're just gonna grab our location

215
00:18:43,860 --> 00:18:47,750
and use that as a security decision it
is always a little dubious but now for

216
00:18:47,750 --> 00:18:51,379
30 bucks we just kill that and pretty
soon it'll be a hundred fifty bucks so

217
00:18:51,379 --> 00:18:56,279
I'm wondering whether other areas where
we've either killed off our technology

218
00:18:56,279 --> 00:18:58,010
has come along and pretty much squash

219
00:18:58,010 --> 00:19:04,500
good ideas that were never going to
survive so can we point to you know

220
00:19:04,500 --> 00:19:12,270
looking desperately for something
something that we can say we killed it

221
00:19:12,270 --> 00:19:22,460
yeah yeah and you use it the way it's
intended out of the box and you never go

222
00:19:22,460 --> 00:19:27,050
and create queries against the database
directly then you have eliminated sequel

223
00:19:27,050 --> 00:19:33,100
injection from your web but most people
have to go outside of the box so yes I

224
00:19:33,100 --> 00:19:40,980
know we treat these fixes that are
intended to eliminate an entire class of

225
00:19:40,980 --> 00:19:45,000
vulnerabilities and also make things
easier for a developer but if we don't

226
00:19:45,000 --> 00:19:49,470
take the time to do developer training
they still make a mistake i mean that's

227
00:19:49,470 --> 00:19:54,140
like why can we still go to Google and
when you carry for code examples

228
00:19:54,140 --> 00:19:57,450
examples almost always insecure and
that's what the developers are cutting

229
00:19:57,450 --> 00:20:04,470
and pasting again and to your point I
think there's some hope like I said I

230
00:20:04,470 --> 00:20:08,390
think despite the fact that everything's
honorable software security in some

231
00:20:08,390 --> 00:20:13,930
places has made good jumps and of plays
Microsoft again now gone please OpenBSD

232
00:20:13,930 --> 00:20:19,150
deal just recently put out a
presentation where he spoke against

233
00:20:19,150 --> 00:20:23,190
optional security measures and actually
I think there's something to that like

234
00:20:23,190 --> 00:20:26,670
like normally you look at some of his
friends and you think like that's the

235
00:20:26,670 --> 00:20:32,640
field and you look at his stuff and you
say is made it so impractical that

236
00:20:32,640 --> 00:20:38,170
that's why only a hundred people are
using OpenBSD as the default but but i

237
00:20:38,170 --> 00:20:46,380
can download the multiple discs but I
think he's got a point and I think maybe

238
00:20:46,380 --> 00:20:50,700
we getting to the point where we see
that it's enough of a problem that we

239
00:20:50,700 --> 00:20:55,270
can now start seeing to developers when
when Microsoft did their shift like one

240
00:20:55,270 --> 00:21:00,360
of the things they did was just been a
whole bunch of calls like you just can't

241
00:21:00,360 --> 00:21:07,439
do this anymore anymore and I think we
can start taking some of their thinking

242
00:21:07,440 --> 00:21:10,070
into the rest of the stuff we do

243
00:21:10,070 --> 00:21:15,860
but in truth I think one of the things
we seeing now is like you mentioned

244
00:21:15,860 --> 00:21:19,990
something about hackers going into
management into that don't think we have

245
00:21:19,990 --> 00:21:26,560
enough of a body of knowledge of how to
do this properly yet if if you take

246
00:21:26,560 --> 00:21:31,820
software engineering like for a long
while it was just try software stuff and

247
00:21:31,820 --> 00:21:35,629
then you started seeing guys come out
with making it a science and making it

248
00:21:35,630 --> 00:21:41,390
management and we've not gotten day and
on the one hand is technological

249
00:21:41,390 --> 00:21:44,930
progress that makes it hard but there's
other stuff that we haven't figured out

250
00:21:44,930 --> 00:21:47,900
and I think we now starting to get to
the point where we've got to start

251
00:21:47,900 --> 00:21:49,680
qualifying some of that stuff

252
00:21:49,680 --> 00:21:54,700
figuring out some of that stuff figure
out what's the optimum size for security

253
00:21:54,700 --> 00:21:58,470
team like in in software all while ago

254
00:21:58,470 --> 00:22:02,780
Fred Brooks put all the medical
management like so he he told he told

255
00:22:02,780 --> 00:22:06,500
everyone at that point like adding more
developers to a project doesn't help you

256
00:22:06,500 --> 00:22:12,430
and like you see the fact that targeted
300 security goes and like one of the

257
00:22:12,430 --> 00:22:16,650
things I want to do you think they need
to 300 security guys or if they paid

258
00:22:16,650 --> 00:22:23,960
like four times the market rate and
hired piano and healthier position and

259
00:22:23,960 --> 00:22:28,490
I'm starting to think we can stop
getting to like once we stop thinking

260
00:22:28,490 --> 00:22:31,920
about that sort of stuff we can
hopefully start making more enrolled

261
00:22:31,920 --> 00:22:37,310
into those things but but I don't think
we did I think we've just gotten bad

262
00:22:37,310 --> 00:22:41,210
enough that we know we need to try
something different and maybe we'll go

263
00:22:41,210 --> 00:22:50,630
there and other researchers remember the
Securities taking themselves too

264
00:22:50,630 --> 00:22:55,730
important I I did get a feeling for our
community and other important but the

265
00:22:55,730 --> 00:23:01,370
people put the focus on the wrong things
because as we talk about target they see

266
00:23:01,370 --> 00:23:06,949
a lot of talk about breaches laughing
about the victim

267
00:23:06,950 --> 00:23:10,000
well what we as a community

268
00:23:10,000 --> 00:23:18,320
the situation built-in security and help
get better but we spend most time on

269
00:23:18,320 --> 00:23:25,350
talking about whether people like the
wrong with the Securities and pretty

270
00:23:25,350 --> 00:23:28,520
sure they had told the people there but
they would have needed there was only

271
00:23:28,520 --> 00:23:36,120
one going thinking about the exact alert
that they missed the question of how we

272
00:23:36,120 --> 00:23:43,159
can teach people to show people the
right things to think about what you did

273
00:23:43,160 --> 00:23:43,540
wrong

274
00:23:43,540 --> 00:23:52,330
attack that is the fundamental question
because you know like I can there is a

275
00:23:52,330 --> 00:23:56,409
great talk at the conference was like
all thrills and the crazy train it was

276
00:23:56,410 --> 00:23:59,780
it was fantastic if you are rails
developer you want to learn about

277
00:23:59,780 --> 00:24:06,410
security or authentication authorization
and the rules but you know that is

278
00:24:06,410 --> 00:24:11,470
targeted talk for developers the kind of
thing we should be doing right as a as a

279
00:24:11,470 --> 00:24:16,740
community and we do a lot of that with
Oscar other things those are all great

280
00:24:16,740 --> 00:24:21,920
but we have to teach the idea what an
attack is fundamentally and how to

281
00:24:21,920 --> 00:24:27,960
perform attacks from from like a step
backwards I was talking to some

282
00:24:27,960 --> 00:24:32,180
university educators and they are all
the universities United States are

283
00:24:32,180 --> 00:24:35,730
basically desperate to put out security
professional site cuz I told companies

284
00:24:35,730 --> 00:24:40,270
want to hire and I remember talking this
lady and she was like what what we teach

285
00:24:40,270 --> 00:24:44,230
which we do and I said you know I'm
wondering what your college lawyer would

286
00:24:44,230 --> 00:24:50,040
say if you start teaching how to attack
and judges chat her up she's like oh ok

287
00:24:50,040 --> 00:24:53,600
I probably can't teach up like a bit
that's what some of those skills are

288
00:24:53,600 --> 00:24:57,320
actually needed and your structurally
blocked from providing some of the

289
00:24:57,320 --> 00:25:02,370
insight right you mentioned something
they want to come back to what you was

290
00:25:02,370 --> 00:25:07,679
how many here I was curious show of
hands how do you remember that moment

291
00:25:07,680 --> 00:25:11,440
when all the sudden you realize you had
to make sort of a transition from heads

292
00:25:11,440 --> 00:25:15,640
down technical term or policy right more
management if you want to be effective

293
00:25:15,640 --> 00:25:20,630
you realize you actually had to interact
and translate business needs right

294
00:25:20,630 --> 00:25:24,540
today but he can't have that oh my god
I've gotta learn a little policy now man

295
00:25:24,540 --> 00:25:30,960
yeah and so I think that helped us a bit
in the watershed moment for me was when

296
00:25:30,960 --> 00:25:34,590
Google came out and said that China had
attacked them because now all of a

297
00:25:34,590 --> 00:25:40,149
sudden it was ok for the c-suite talk
about being attacked and not allowed a

298
00:25:40,150 --> 00:25:44,310
new class of conversation to occur that
we could never heard of penetrate up

299
00:25:44,310 --> 00:25:48,620
into the board of the sea level I'm sort
of saying that now again because of

300
00:25:48,620 --> 00:25:53,709
Snowdon leaks right that's a new type of
conversation are allowed to have the

301
00:25:53,710 --> 00:25:57,930
talk you heard at the very beginning of
the show on last night and that tends to

302
00:25:57,930 --> 00:26:02,460
point to me okay we've kind of having to
live with management now have to get

303
00:26:02,460 --> 00:26:08,850
into policy and now you're gonna have to
translate technical security things into

304
00:26:08,850 --> 00:26:14,290
policy and that's a new area for us that
we're not comfortable with and so it's

305
00:26:14,290 --> 00:26:17,629
an opportunity in a risk and I'm curious
on your thoughts of that if we get it

306
00:26:17,630 --> 00:26:18,160
right

307
00:26:18,160 --> 00:26:21,840
great food industry if we get it wrong
we end up with really terrible policy

308
00:26:21,840 --> 00:26:26,419
outcomes you know you trying to think we
would you advocate for people to try to

309
00:26:26,420 --> 00:26:32,990
get involved in policy on the one hand I
think if you look at how well we've done

310
00:26:32,990 --> 00:26:41,200
with management you are gonna say no so
technically retired in management that

311
00:26:41,200 --> 00:26:48,320
congress but in truth I think we have to
like effects is given a whole talk and

312
00:26:48,320 --> 00:26:53,490
almost anything any topic that's
interesting if I told you said something

313
00:26:53,490 --> 00:26:57,810
smart about it all day and and at some
point he and so good practice

314
00:26:57,810 --> 00:27:04,409
effectively said look if we don't do it
who is and is like this just a point

315
00:27:04,410 --> 00:27:07,750
where we've gotta figure out that we've
gotta step up to some of that stuff but

316
00:27:07,750 --> 00:27:12,280
there's this concept of those closest to
the knob responsibility right your

317
00:27:12,280 --> 00:27:16,730
closest to the problem so therefore you
bear a certain responsibility to an end

318
00:27:16,730 --> 00:27:22,570
I think fundamentally some of us it's
funny because again I mentioned my talk

319
00:27:22,570 --> 00:27:28,950
I heard the old much talks recently and
he was talking about going to Congress

320
00:27:28,950 --> 00:27:31,640
and the famous love goes to congress

321
00:27:31,640 --> 00:27:34,360
and one of the things he stepped back
and said is like you know despite

322
00:27:34,360 --> 00:27:40,889
everything you see this smart people but
they have your hearing on IOT and then

323
00:27:40,890 --> 00:27:45,020
they have a hearing on whether green
should be imported the conf a hearing on

324
00:27:45,020 --> 00:27:51,260
whether I should and so for all of them
you've got some junior staffer coming in

325
00:27:51,260 --> 00:27:55,600
giving them a file and that that's
holding making the calls and if we're

326
00:27:55,600 --> 00:28:00,260
not in that file or adding some sense to
their trial then we can't complain when

327
00:28:00,260 --> 00:28:06,210
nonsense is comes out the other end I
think one of the dangers with it though

328
00:28:06,210 --> 00:28:12,170
and it might lead to a whole different
topic is even amongst ourselves we don't

329
00:28:12,170 --> 00:28:20,260
easily have so you can get consensus
solution don't have consensus we don't

330
00:28:20,260 --> 00:28:24,560
have easily chosen representatives they
can't think of too many people too I'd

331
00:28:24,560 --> 00:28:26,480
say I'd like him

332
00:28:26,480 --> 00:28:32,120
representing my feet the upper levels
but I think we have to like the easy

333
00:28:32,120 --> 00:28:36,750
answer is I think to not play this
stupid because the world changes around

334
00:28:36,750 --> 00:28:43,730
us and you'd rather be involved they're
not so I don't think it's an option to

335
00:28:43,730 --> 00:28:47,720
stay away from it because I have another
question to everybody and then we'll go

336
00:28:47,720 --> 00:28:53,750
to some questions from the audience
hopefully so in your view pick one of

337
00:28:53,750 --> 00:28:57,280
two things you know what will help are
using technologies on the future I

338
00:28:57,280 --> 00:29:00,930
mentioned v-6 not that it's necessarily
obscurity technology but are you seeing

339
00:29:00,930 --> 00:29:06,940
things DNS a car RPK are you seeing
certain technologies that will do you

340
00:29:06,940 --> 00:29:11,350
think over the next five to 10 years
will fundamentally change things or if

341
00:29:11,350 --> 00:29:15,139
there are no transformative technologies
are we just looking for the long slog

342
00:29:15,140 --> 00:29:19,170
more of the same and we're just gonna be
playing whack-a-mole you know maybe it's

343
00:29:19,170 --> 00:29:23,490
a new development platform or maybe it's
you know everybody goes to Chromebooks

344
00:29:23,490 --> 00:29:28,690
and life is saved everybody goes to the
cloud but the story

345
00:29:28,690 --> 00:29:33,660
so my answer is that

346
00:29:33,660 --> 00:29:37,460
technologies will come technologies will
go the end of the day we need to limit

347
00:29:37,460 --> 00:29:41,480
the data that we're storing about people
because you're dealing with three

348
00:29:41,480 --> 00:29:46,050
nations where you don't know what
Brandon teenagers going to become the

349
00:29:46,050 --> 00:29:50,340
elected official that represents a
country and their data is stored in

350
00:29:50,340 --> 00:29:56,159
random websites created by irresponsible
people working at startups and they

351
00:29:56,160 --> 00:30:00,840
don't care about pushing product out the
door they care about rocket ship it they

352
00:30:00,840 --> 00:30:05,580
don't care about security at all and so
some of them are very good I i dont need

353
00:30:05,580 --> 00:30:12,090
to put them all down so we need to think
about recommending limiting data we have

354
00:30:12,090 --> 00:30:15,850
a responsibility to the companies we
work for to make that represent maybe

355
00:30:15,850 --> 00:30:21,469
let me transcribe your answer more and
it is a cannon and demanded anonymity

356
00:30:21,470 --> 00:30:32,610
systems would be useful yet so I think I
have a rather radical idea about how to

357
00:30:32,610 --> 00:30:38,280
make things better remember recently I
was working on one's coming up with

358
00:30:38,280 --> 00:30:43,860
ideas help make things better I put
together five points which are two

359
00:30:43,860 --> 00:30:49,990
factor authentication
compartmentalization secrecy encryption

360
00:30:49,990 --> 00:30:57,210
and training so with these five
measurements I think we're making us the

361
00:30:57,210 --> 00:31:03,590
board instead of fighting goes by trying
to detect the defend the way either can

362
00:31:03,590 --> 00:31:10,419
see your technology already exists so
it's really just apply known solutions

363
00:31:10,420 --> 00:31:15,120
I mean that's running in circles we
could just pick up although they make

364
00:31:15,120 --> 00:31:24,770
them good again just like the other guys
do in a few ways like if you take in if

365
00:31:24,770 --> 00:31:28,879
if you working on an iPad and an iOS
device

366
00:31:28,880 --> 00:31:36,610
typically safer from most attacks than
you were on any machine so so despite

367
00:31:36,610 --> 00:31:40,689
what it means for the freedom loving
liberal in the death of the

368
00:31:40,690 --> 00:31:45,230
general-purpose computer garden I love
it yeah exactly so so end of

369
00:31:45,230 --> 00:31:49,550
general-purpose computer in a walled
garden talking to a proprietary web

370
00:31:49,550 --> 00:31:56,700
service but it's it's an interesting
thing that does give you some measure of

371
00:31:56,700 --> 00:32:02,180
security and a while back like at the
source Boston keynote that the dengue

372
00:32:02,180 --> 00:32:07,420
gave like about seven years ago he kind
of ended with saying at some point you

373
00:32:07,420 --> 00:32:12,110
have to figure out that security is not
safe and he says like if you want to be

374
00:32:12,110 --> 00:32:12,740
secure

375
00:32:12,740 --> 00:32:16,620
that's what it's going to take you to
amend like everything he does it like

376
00:32:16,620 --> 00:32:21,219
super politically and he says the
technology that I've never danced

377
00:32:21,220 --> 00:32:26,370
imagine like cursive like a founding
father right now it's it's it's

378
00:32:26,370 --> 00:32:31,830
impressive but he ends with a monologue
that says something like the technology

379
00:32:31,830 --> 00:32:33,159
that can keep you safe

380
00:32:33,160 --> 00:32:37,300
perfectly safe is the technology that
can take it all away yeah and that's

381
00:32:37,300 --> 00:32:41,899
kind of where we going right I think
people kind of mostly make that trade

382
00:32:41,900 --> 00:32:47,480
off pretty openly like most security
guys I know started off saying iOS is

383
00:32:47,480 --> 00:32:54,260
the devil will also use Android phones
quickly made that swap and said actually

384
00:32:54,260 --> 00:33:00,560
I just be happy just give me an iOS
device which makes Google's move to go

385
00:33:00,560 --> 00:33:03,810
from the one thing they were offering
that will secure with their Chromebooks

386
00:33:03,810 --> 00:33:10,290
to the most exploited that home is on
mobile but but anyway I think yes there

387
00:33:10,290 --> 00:33:15,180
is some hope with a boat secure
endpoints and no matter what people say

388
00:33:15,180 --> 00:33:18,510
they are more secure and then I wanna
hear your points are quickly on cloud

389
00:33:18,510 --> 00:33:22,180
because you were saying that one of the
points that yes so so it's funny because

390
00:33:22,180 --> 00:33:27,260
like in 2007 we did during the cold
which was a way to hit almost every

391
00:33:27,260 --> 00:33:32,490
cloud vendor there is but fundamentally
I think the code is going to become a

392
00:33:32,490 --> 00:33:36,750
viable option for lots of small
businesses largely because we were so

393
00:33:36,750 --> 00:33:38,930
broken with the sole model and

394
00:33:38,930 --> 00:33:44,020
and Marcus Ranum says he's super
insulting about it he says that's right

395
00:33:44,020 --> 00:33:47,960
you couldn't solve it here so now you
gonna solve it by giving it all away and

396
00:33:47,960 --> 00:33:51,200
you need to understand that some point
you gotta pay like all you're doing is

397
00:33:51,200 --> 00:33:55,540
pushing the debt away from you at some
point it's going to cost you so you move

398
00:33:55,540 --> 00:33:59,760
it all to the cloud you don't have
security and I are teams when it goes

399
00:33:59,760 --> 00:34:04,010
wrong you need to hire people for ten
times the cost if you just did it right

400
00:34:04,010 --> 00:34:07,930
but practically I think the college
going to be an option

401
00:34:07,930 --> 00:34:14,290
Google can secure gmail better than most
people today can secure send like if

402
00:34:14,290 --> 00:34:16,540
you're running sendmail Exim

403
00:34:16,540 --> 00:34:21,480
good luck finding someone who knows what
a macro is these days but most small

404
00:34:21,480 --> 00:34:25,159
companies if you ask them if you are a
bit off running their own said male

405
00:34:25,159 --> 00:34:29,649
bonding gmail they probably better off
running gmail if you take away the

406
00:34:29,650 --> 00:34:34,020
government order stuff and and that's
going to be a crossed the line are you

407
00:34:34,020 --> 00:34:34,500
better

408
00:34:34,500 --> 00:34:38,929
hosting your own infrastructure running
it on a WS and people will tell you this

409
00:34:38,929 --> 00:34:44,549
hypervisor exploit and AWS was in danger
and I'm willing to bet that Amazon patch

410
00:34:44,550 --> 00:34:50,090
the hypervisor exploits a school Yin
times faster than ever organizations and

411
00:34:50,090 --> 00:34:53,950
that shift going to keep happening like
because they gonna keep hiring the smart

412
00:34:53,949 --> 00:34:59,790
folks if you work with hypervisors doin
work at Bob's Fishing Company odiaun

413
00:34:59,790 --> 00:35:04,210
work at Amazon you gonna move dem zones
are going to suck up all the talent and

414
00:35:04,210 --> 00:35:10,250
it's it's gonna be a reasonable paradigm
so you gonna have cropped up stuff which

415
00:35:10,250 --> 00:35:15,950
says you can have a secure Chromebook or
secure I paired that's been talking of

416
00:35:15,950 --> 00:35:19,859
an encrypted tunnel to a vendor who
you've then got a contract worth to you

417
00:35:19,860 --> 00:35:28,910
can then hopefully hold liable when they
drop you and not happen but I think

418
00:35:28,910 --> 00:35:31,580
that's where it's going to go and I
think it's a reasonable place where to

419
00:35:31,580 --> 00:35:31,900
go

420
00:35:31,900 --> 00:36:31,660
ok let's see who's got something in the
audience user all the way back

421
00:36:31,660 --> 00:36:49,440
security industry are always terrified
that they will become a target common

422
00:36:49,440 --> 00:36:57,760
attack so yes so I I totally agree with
what you said the first you know be the

423
00:36:57,760 --> 00:37:03,260
change you want to see but that goes
back to I think you know you gotta walk

424
00:37:03,260 --> 00:37:08,950
the walk and talk the talk and so even
if it's paying for it if you advocated

425
00:37:08,950 --> 00:37:12,750
uses to factor then you better use it
yourself or your kind of a charlatan

426
00:37:12,750 --> 00:37:17,910
right and then you can learn through
that pain like maybe how to make it

427
00:37:17,910 --> 00:37:21,430
better but the other examples you used
unfortunately were brought about through

428
00:37:21,430 --> 00:37:26,609
legislation and so what I was talking
about like we're getting closer to

429
00:37:26,609 --> 00:37:30,730
policy we're getting closer to policy at
the point where policy is getting closer

430
00:37:30,730 --> 00:37:37,260
to us to legislate and I think soon as
we have a large incident mothers in a

431
00:37:37,260 --> 00:37:40,829
things are connected toaster burning
down the house will start team

432
00:37:40,829 --> 00:37:46,390
legislation show up because the industry
is not shown it can regulate itself the

433
00:37:46,390 --> 00:37:53,470
thing I always point to his PCP 3894 and
source address validation right you can

434
00:37:53,470 --> 00:37:58,730
still send smooth traffic in 2015 and
we've known about this problem for

435
00:37:58,730 --> 00:38:02,020
twenty years we understand it we've
studied it we know the impacts of

436
00:38:02,020 --> 00:38:08,230
filtering it and we can't solve the most
simple well understood problem areas so

437
00:38:08,230 --> 00:38:11,960
what confidence to have their gonna
solve this more complicated you know

438
00:38:11,960 --> 00:38:19,700
situation and so don't be surprised if
one days BC p38 gets legislated right

439
00:38:19,700 --> 00:38:24,808
and so i'm sort of starting to think
that maybe a little little liability is

440
00:38:24,809 --> 00:38:28,349
a good thing people respond you know
signal some kind of curious on your

441
00:38:28,349 --> 00:38:33,720
thoughts about liability right does the
software shrink software shrink wrap

442
00:38:33,720 --> 00:38:38,930
license survived contact with the
Internet of Things and smart cars yes

443
00:38:38,930 --> 00:38:45,319
almost everyone smocked an open mind on
this has said we gotta get liability and

444
00:38:45,319 --> 00:38:52,480
that unless we introduce Venda liability
we never gonna fix the problem for me

445
00:38:52,480 --> 00:38:57,599
it's stuff like personally I never liked
the government stepping in just because

446
00:38:57,599 --> 00:39:02,849
they almost always muddy the water but I
think there's gotta be something that

447
00:39:02,849 --> 00:39:07,640
forces people's hands in in exactly the
seat belt discussion like it happens

448
00:39:07,640 --> 00:39:12,879
after the alternator steps in and I
suspect we heading that way whether we

449
00:39:12,880 --> 00:39:18,200
like it or not I don't know that it's
it's that I done so but I think it

450
00:39:18,200 --> 00:40:32,740
doesn't matter it's gonna happen sir or
ma'am I'm sorry

451
00:40:32,740 --> 00:40:53,618
so the question

452
00:40:53,619 --> 00:40:57,680
so changing the corporate culture to
maybe sulfide it you're saying maybe

453
00:40:57,680 --> 00:41:48,359
that's how people to the industry as we
have a massive lack of talent already

454
00:41:48,359 --> 00:41:53,749
likely more diversity we could other
groups that are not present their

455
00:41:53,749 --> 00:42:00,078
participation to make a greater security
community overall standards of training

456
00:42:00,079 --> 00:42:01,220
people

457
00:42:01,220 --> 00:42:11,078
unsolved problem companies know what
they get for example from our customers

458
00:42:11,079 --> 00:42:16,559
that they are not aware that they have a
problem with their security that starts

459
00:42:16,559 --> 00:42:23,630
at the point where they don't know where
that is actually important that couldn't

460
00:42:23,630 --> 00:42:29,150
have been bridging so step one first
acknowledge you have a problem before

461
00:42:29,150 --> 00:42:32,430
you can even the company's game and
going to step 2 may be increasing

462
00:42:32,430 --> 00:42:36,848
diversity or two batters security team
if they don't so we have time for one

463
00:42:36,849 --> 00:42:43,120
last question and then we're gonna ok
who's the guy down there okay

464
00:42:43,120 --> 00:43:33,700
future batteries would explode and burst
into flames

465
00:43:33,700 --> 00:43:42,819
so i think is a complex answer hidden in
there and everybody's just about getting

466
00:43:42,820 --> 00:43:47,770
ready to run I think the short answer is
there is a solution that goes down there

467
00:43:47,770 --> 00:43:52,780
but there is a solution that you live in
a walled garden world and it's safe and

468
00:43:52,780 --> 00:43:57,130
it's better but I think there's a
there's a hidden lesson for us in the

469
00:43:57,130 --> 00:44:01,170
witches I'm not sure how many of you
remember but a little while back

470
00:44:01,170 --> 00:44:06,260
Microsoft tried palladium ok which was
DRM all the way down and it would have

471
00:44:06,260 --> 00:44:12,080
been based on 30 p.m. it would have been
secure and everyone freaked out like we

472
00:44:12,080 --> 00:44:17,620
all went this is the end of the world
like get away from us and it's what

473
00:44:17,620 --> 00:44:23,420
Apple did when they can win and it's
where Apple increasingly going to an

474
00:44:23,420 --> 00:44:29,730
almost all of us are okay with it and so
lots of people's natural reaction is you

475
00:44:29,730 --> 00:44:34,030
see she pulled blah blah blah but I
think the lesson in there for us is

476
00:44:34,030 --> 00:44:38,060
something that Moxie's taught us really
well with his signal and stuff which is

477
00:44:38,060 --> 00:44:44,170
you've got to be secure and better not
just secure and enter one of the things

478
00:44:44,170 --> 00:44:50,390
that are hoping to try to encourage us
to do is for more faster start building

479
00:44:50,390 --> 00:44:56,790
products that are good products and also
happened to be secure because I think

480
00:44:56,790 --> 00:45:00,300
that that's the way we gonna have to win
and I think it's a whole new set of

481
00:45:00,300 --> 00:45:04,800
challenges for us like like when do you
stop playing the game it's different but

482
00:45:04,800 --> 00:45:11,680
I do think there's hope so you might
also who so on I told her we're going to

483
00:45:11,680 --> 00:45:15,700
close it out thank you for attending
some of us will be around afterward and

484
00:45:15,700 --> 00:45:20,060
hopefully you don't get rained on so
thank you so much look forward to seeing

485
00:45:20,060 --> 00:45:20,450
you next year

