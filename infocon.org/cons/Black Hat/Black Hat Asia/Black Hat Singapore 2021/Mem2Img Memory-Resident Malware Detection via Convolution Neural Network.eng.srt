1
00:00:01,130 --> 00:00:14,690
[Music]

2
00:00:16,560 --> 00:00:19,840
hello the topic of this talk is meant to

3
00:00:19,840 --> 00:00:22,000
image a memory rather than malware

4
00:00:22,000 --> 00:00:23,920
detection via convolutional neural

5
00:00:23,920 --> 00:00:25,279
network

6
00:00:25,279 --> 00:00:27,680
memory injection is a technique often

7
00:00:27,680 --> 00:00:29,840
used by modern malware to bypass

8
00:00:29,840 --> 00:00:31,039
detection

9
00:00:31,039 --> 00:00:33,760
it has become an headache for security

10
00:00:33,760 --> 00:00:36,160
products to defend against this kind of

11
00:00:36,160 --> 00:00:39,360
malware in this talk we propose this

12
00:00:39,360 --> 00:00:40,559
framework

13
00:00:40,559 --> 00:00:42,640
to help us

14
00:00:42,640 --> 00:00:44,960
detect and classify memory resident

15
00:00:44,960 --> 00:00:47,200
middleware

16
00:00:47,200 --> 00:00:50,320
ergon is a malware researcher in team t5

17
00:00:50,320 --> 00:00:52,480
he will walk you through the details of

18
00:00:52,480 --> 00:00:54,960
this work later and i'm charles the

19
00:00:54,960 --> 00:00:58,000
chief analyst of team t5 both of us are

20
00:00:58,000 --> 00:01:00,239
dealing with various malware in our

21
00:01:00,239 --> 00:01:02,239
daily job and we are trying every

22
00:01:02,239 --> 00:01:04,559
possible way to improve our malware

23
00:01:04,559 --> 00:01:07,840
detection capability without

24
00:01:07,840 --> 00:01:10,320
this work

25
00:01:10,320 --> 00:01:12,640
the agenda of this talk

26
00:01:12,640 --> 00:01:14,640
in the beginning we will show you some

27
00:01:14,640 --> 00:01:17,360
recent injection techniques used by apd

28
00:01:17,360 --> 00:01:18,320
attacks

29
00:01:18,320 --> 00:01:21,200
the main part is the data set

30
00:01:21,200 --> 00:01:23,200
and the framework

31
00:01:23,200 --> 00:01:26,560
the experiment result of this framework

32
00:01:26,560 --> 00:01:29,600
in the end we will talk about the

33
00:01:29,600 --> 00:01:32,240
salience map the russia learning and

34
00:01:32,240 --> 00:01:36,640
adversarial attack about this framework

35
00:01:36,640 --> 00:01:39,040
memory injection technique is popularly

36
00:01:39,040 --> 00:01:41,759
used by malware to achieve malware

37
00:01:41,759 --> 00:01:43,119
residents

38
00:01:43,119 --> 00:01:45,200
before start of this talk we will

39
00:01:45,200 --> 00:01:48,240
discuss some novel technique to achieve

40
00:01:48,240 --> 00:01:50,560
injection that might not be easily

41
00:01:50,560 --> 00:01:52,799
detected

42
00:01:52,799 --> 00:01:54,960
the first technique we'd like to

43
00:01:54,960 --> 00:01:57,759
introduce is uuid show code this

44
00:01:57,759 --> 00:02:00,799
technique was first observed to be used

45
00:02:00,799 --> 00:02:03,759
in the wild by laureus and in famous

46
00:02:03,759 --> 00:02:05,680
north korean apd group

47
00:02:05,680 --> 00:02:08,479
its implementation is fairly simple

48
00:02:08,479 --> 00:02:12,080
using api function uuid from string to

49
00:02:12,080 --> 00:02:15,040
encode the shell code to bypass security

50
00:02:15,040 --> 00:02:17,760
product detection

51
00:02:17,760 --> 00:02:20,640
there are two advantages by using uid

52
00:02:20,640 --> 00:02:22,480
show code first

53
00:02:22,480 --> 00:02:24,720
by providing a show called to hip

54
00:02:24,720 --> 00:02:27,520
address this function can be abused to

55
00:02:27,520 --> 00:02:31,680
both decode and write the data to memory

56
00:02:31,680 --> 00:02:33,519
directory

57
00:02:33,519 --> 00:02:36,239
second abusing callback function such as

58
00:02:36,239 --> 00:02:38,319
in new windows candidate through

59
00:02:38,319 --> 00:02:40,720
shortcut execution

60
00:02:40,720 --> 00:02:41,519
both

61
00:02:41,519 --> 00:02:44,160
are typical checkpoint of security

62
00:02:44,160 --> 00:02:47,280
product for defending against memory

63
00:02:47,280 --> 00:02:48,840
injection

64
00:02:48,840 --> 00:02:50,800
attacks

65
00:02:50,800 --> 00:02:52,959
there are many alternative way to

66
00:02:52,959 --> 00:02:55,440
utilize the callback function for

67
00:02:55,440 --> 00:02:58,400
example a new system language group in

68
00:02:58,400 --> 00:03:01,920
this case will take the address returned

69
00:03:01,920 --> 00:03:03,519
by hip lock

70
00:03:03,519 --> 00:03:08,000
and you will execute the shortcut

71
00:03:08,159 --> 00:03:10,879
the second technique we will introduce

72
00:03:10,879 --> 00:03:14,159
is fentanyl halloween typical injection

73
00:03:14,159 --> 00:03:17,360
often results memory blocks with rewrite

74
00:03:17,360 --> 00:03:18,959
xq privilege

75
00:03:18,959 --> 00:03:21,680
this feature is utilized by security

76
00:03:21,680 --> 00:03:24,799
products to detect possible injected

77
00:03:24,799 --> 00:03:26,319
memory attack

78
00:03:26,319 --> 00:03:28,560
however phantom dealer halloween can

79
00:03:28,560 --> 00:03:30,840
effectively bypass this detection

80
00:03:30,840 --> 00:03:33,760
mechanism the code in the provided

81
00:03:33,760 --> 00:03:35,920
screenshot can be found in a public

82
00:03:35,920 --> 00:03:38,879
github page but we have seen various

83
00:03:38,879 --> 00:03:43,120
chinese apd groups including abd27

84
00:03:43,120 --> 00:03:46,640
windy etc to abuse this attack in their

85
00:03:46,640 --> 00:03:49,200
real world attacks

86
00:03:49,200 --> 00:03:51,440
this photo shows the workflow of the

87
00:03:51,440 --> 00:03:53,760
phantom dealer halloween technique

88
00:03:53,760 --> 00:03:56,720
the essence of this technique is to find

89
00:03:56,720 --> 00:04:00,879
a target ello in system directory whose

90
00:04:00,879 --> 00:04:04,400
the txt section is big enough as the

91
00:04:04,400 --> 00:04:07,040
host of the payload show code

92
00:04:07,040 --> 00:04:09,760
the injector component will call

93
00:04:09,760 --> 00:04:13,840
anti-create section and provide the flag

94
00:04:13,840 --> 00:04:17,199
thick image as its perimeter this

95
00:04:17,199 --> 00:04:20,880
results the initial prediction of the

96
00:04:20,880 --> 00:04:24,560
mapped section to be rewrite execute the

97
00:04:24,560 --> 00:04:27,360
payload code can then be copied to the

98
00:04:27,360 --> 00:04:29,440
target memory area

99
00:04:29,440 --> 00:04:32,720
further code to anti-protect virtual

100
00:04:32,720 --> 00:04:34,000
memory

101
00:04:34,000 --> 00:04:37,120
will change the memory privilege can

102
00:04:37,120 --> 00:04:41,360
effectively bypass detection

103
00:04:41,360 --> 00:04:43,600
this photo shows the result of the

104
00:04:43,600 --> 00:04:44,800
technique

105
00:04:44,800 --> 00:04:48,800
the payload implant in implant has been

106
00:04:48,800 --> 00:04:53,000
injected to the tft station of the aa

107
00:04:53,000 --> 00:04:55,919
client.dll but the debugger information

108
00:04:55,919 --> 00:04:59,120
shows its privilege to be only execute

109
00:04:59,120 --> 00:05:01,759
and read

110
00:05:02,080 --> 00:05:04,639
next we are introducing some novel show

111
00:05:04,639 --> 00:05:07,520
called related technique abused by what

112
00:05:07,520 --> 00:05:11,039
bear is an infamous rate tool used by a

113
00:05:11,039 --> 00:05:12,880
chinese apt group

114
00:05:12,880 --> 00:05:15,919
their first technique is to write their

115
00:05:15,919 --> 00:05:19,360
show code in some random generated data

116
00:05:19,360 --> 00:05:22,560
to threat static shortcode analysis

117
00:05:22,560 --> 00:05:25,280
before preparing the real show code the

118
00:05:25,280 --> 00:05:28,160
loader first generate two number

119
00:05:28,160 --> 00:05:31,680
indicating the length of painting before

120
00:05:31,680 --> 00:05:33,840
and after the show code

121
00:05:33,840 --> 00:05:36,400
finally it decodes the show code and

122
00:05:36,400 --> 00:05:39,199
writes the result to the designated

123
00:05:39,199 --> 00:05:41,759
location between the

124
00:05:41,759 --> 00:05:44,720
heading data

125
00:05:45,919 --> 00:05:47,919
this painting makes finding the show

126
00:05:47,919 --> 00:05:50,960
called more difficult and may help avoid

127
00:05:50,960 --> 00:05:53,840
detection

128
00:05:54,080 --> 00:05:56,240
after writing the show code the loader

129
00:05:56,240 --> 00:05:58,960
starts a trade using

130
00:05:58,960 --> 00:06:02,880
begins right ex function begin thread ex

131
00:06:02,880 --> 00:06:06,080
acts as a proxy here and starts the new

132
00:06:06,080 --> 00:06:07,840
thread at the

133
00:06:07,840 --> 00:06:09,600
3 star ex

134
00:06:09,600 --> 00:06:12,880
another function provided by c library

135
00:06:12,880 --> 00:06:15,440
instead of the address where the show

136
00:06:15,440 --> 00:06:18,840
code is located as if using create

137
00:06:18,840 --> 00:06:22,800
straight directly this makes

138
00:06:22,800 --> 00:06:25,680
the show code less detectable as some

139
00:06:25,680 --> 00:06:28,400
antivirus software checks whether the

140
00:06:28,400 --> 00:06:29,759
entry point

141
00:06:29,759 --> 00:06:33,039
of the thread locates in a manually

142
00:06:33,039 --> 00:06:36,159
allocated memory

143
00:06:36,319 --> 00:06:39,280
the data set overview of the machine

144
00:06:39,280 --> 00:06:41,758
learning

145
00:06:41,919 --> 00:06:46,160
before experiment we prepare totally 21

146
00:06:46,160 --> 00:06:50,479
malware family they are actively used by

147
00:06:50,479 --> 00:06:55,080
apt group in asia region including apd32

148
00:06:55,080 --> 00:07:01,039
abd-37 fb10 fb27 windy etc

149
00:07:01,039 --> 00:07:03,520
we also include some

150
00:07:03,520 --> 00:07:06,240
cyber crime malware families including

151
00:07:06,240 --> 00:07:11,120
imitate phone book 3 texts etc

152
00:07:11,599 --> 00:07:14,720
before doing experiment we use tools

153
00:07:14,720 --> 00:07:18,639
such as pec fertility and holofy to help

154
00:07:18,639 --> 00:07:20,880
us find and extract

155
00:07:20,880 --> 00:07:22,960
memory in

156
00:07:22,960 --> 00:07:24,400
memory

157
00:07:24,400 --> 00:07:26,080
malware in memory

158
00:07:26,080 --> 00:07:30,080
our data source including uh

159
00:07:30,080 --> 00:07:33,120
data from real victim computer

160
00:07:33,120 --> 00:07:35,120
also we try to

161
00:07:35,120 --> 00:07:38,319
try edge to find more related samples on

162
00:07:38,319 --> 00:07:42,000
various total or online samples

163
00:07:42,000 --> 00:07:44,960
this is the file distribution for 13

164
00:07:44,960 --> 00:07:48,240
totally 30 malware family used for

165
00:07:48,240 --> 00:07:49,280
training

166
00:07:49,280 --> 00:07:51,919
the biggest category

167
00:07:51,919 --> 00:07:52,720
is

168
00:07:52,720 --> 00:07:55,919
cyber crime malware they have around

169
00:07:55,919 --> 00:07:59,120
hundreds of memory blocks however for

170
00:07:59,120 --> 00:08:01,039
some malware

171
00:08:01,039 --> 00:08:02,720
in apt

172
00:08:02,720 --> 00:08:05,919
some has only tens of memory blocks you

173
00:08:05,919 --> 00:08:10,160
can see some imbalance for the data set

174
00:08:10,160 --> 00:08:12,800
to address this issue we use some

175
00:08:12,800 --> 00:08:17,039
typical methods such as classwise smart

176
00:08:17,039 --> 00:08:20,000
data augmentation transfer learning to

177
00:08:20,000 --> 00:08:21,520
help us

178
00:08:21,520 --> 00:08:24,639
to address this issue

179
00:08:24,639 --> 00:08:26,720
why do we choose transfer learning

180
00:08:26,720 --> 00:08:29,759
because some epd memory rather malware

181
00:08:29,759 --> 00:08:32,799
is only a small set of data transfer

182
00:08:32,799 --> 00:08:35,519
learning uses knowledge from a learned

183
00:08:35,519 --> 00:08:38,320
task to improve the performance

184
00:08:38,320 --> 00:08:41,599
on a related task is typically reducing

185
00:08:41,599 --> 00:08:46,159
the amount of required training data

186
00:08:46,240 --> 00:08:48,560
our framework will transform the malware

187
00:08:48,560 --> 00:08:51,920
binary to an image for classification

188
00:08:51,920 --> 00:08:54,480
before introducing our framework we

189
00:08:54,480 --> 00:08:56,880
would want to show you some generated

190
00:08:56,880 --> 00:09:00,000
photo to give you a feeling

191
00:09:00,000 --> 00:09:02,720
and also this

192
00:09:02,720 --> 00:09:06,000
for some malware families for example

193
00:09:06,000 --> 00:09:09,839
dennis tritex the generated photo looks

194
00:09:09,839 --> 00:09:13,680
very similar however the generated photo

195
00:09:13,680 --> 00:09:17,360
could look very different for some other

196
00:09:17,360 --> 00:09:20,480
families such as cobra strike stager

197
00:09:20,480 --> 00:09:22,560
imotate etc

198
00:09:22,560 --> 00:09:25,600
we will show you our framework and

199
00:09:25,600 --> 00:09:29,920
effectively classify this male ware

200
00:09:29,920 --> 00:09:32,320
this part we are going to talk about the

201
00:09:32,320 --> 00:09:34,839
man-to-image

202
00:09:34,839 --> 00:09:37,600
framework the first step is to

203
00:09:37,600 --> 00:09:39,839
pre-processing the data

204
00:09:39,839 --> 00:09:41,920
there are some continuous strong bias

205
00:09:41,920 --> 00:09:44,080
painting at the bottom or the beginning

206
00:09:44,080 --> 00:09:46,080
of the memory blocks like the pictures

207
00:09:46,080 --> 00:09:47,760
shown on the slide

208
00:09:47,760 --> 00:09:50,160
it must be removed to avoid the model

209
00:09:50,160 --> 00:09:51,760
running those drunk bytes on the

210
00:09:51,760 --> 00:09:52,880
features

211
00:09:52,880 --> 00:09:55,360
in our data suite they often have newer

212
00:09:55,360 --> 00:09:59,120
bias or hex ff

213
00:09:59,600 --> 00:10:03,200
here is to talk about how we convert 1d

214
00:10:03,200 --> 00:10:05,440
array 2 image

215
00:10:05,440 --> 00:10:08,160
the malware is a 1d array

216
00:10:08,160 --> 00:10:10,640
first we convert the binary to decimal

217
00:10:10,640 --> 00:10:13,360
value and call the square root of the

218
00:10:13,360 --> 00:10:16,640
length of the 1d array of the 2d arrays

219
00:10:16,640 --> 00:10:18,640
width and height

220
00:10:18,640 --> 00:10:21,440
and with this 2d array we can convert it

221
00:10:21,440 --> 00:10:23,920
to a grayscale image like the image in

222
00:10:23,920 --> 00:10:25,680
the slide

223
00:10:25,680 --> 00:10:28,160
so the size of the image is determined

224
00:10:28,160 --> 00:10:32,079
by the length of the malware

225
00:10:32,079 --> 00:10:35,279
we construct rgb image to represent a

226
00:10:35,279 --> 00:10:37,279
malware memory block

227
00:10:37,279 --> 00:10:39,920
the red channel is the decimal values of

228
00:10:39,920 --> 00:10:41,200
each byte

229
00:10:41,200 --> 00:10:43,519
also can think of the grayscale image

230
00:10:43,519 --> 00:10:45,360
from the slide

231
00:10:45,360 --> 00:10:47,839
the green channel is composed of local

232
00:10:47,839 --> 00:10:50,560
entropy values of the image we use an

233
00:10:50,560 --> 00:10:53,360
entropy function by skin image library

234
00:10:53,360 --> 00:10:55,680
to count value

235
00:10:55,680 --> 00:10:58,160
the local entropy can show some

236
00:10:58,160 --> 00:11:00,560
complexity relationship contained in the

237
00:11:00,560 --> 00:11:02,480
given navigator

238
00:11:02,480 --> 00:11:05,200
the filter returns the minimum number of

239
00:11:05,200 --> 00:11:07,839
bits needed to encode the local grade

240
00:11:07,839 --> 00:11:10,399
level distribution

241
00:11:10,399 --> 00:11:13,440
the disk is set to 10 in mem to image

242
00:11:13,440 --> 00:11:14,720
framework

243
00:11:14,720 --> 00:11:17,279
the blue channel is composed of shadow

244
00:11:17,279 --> 00:11:21,200
entropy values of each byte

245
00:11:21,680 --> 00:11:23,920
these are schematic diagrams of the

246
00:11:23,920 --> 00:11:25,680
three channels

247
00:11:25,680 --> 00:11:28,079
red channel is a grad scale image

248
00:11:28,079 --> 00:11:31,360
composed of decimal values of each byte

249
00:11:31,360 --> 00:11:34,079
blue channel is the local entropy

250
00:11:34,079 --> 00:11:36,640
if one area is encrypted

251
00:11:36,640 --> 00:11:39,120
the entropy will be very high

252
00:11:39,120 --> 00:11:41,760
and the model may not use that area as a

253
00:11:41,760 --> 00:11:43,360
feature

254
00:11:43,360 --> 00:11:45,519
the output image of the channel entropy

255
00:11:45,519 --> 00:11:48,079
of each bias is very similar to decimal

256
00:11:48,079 --> 00:11:50,000
values in red channel

257
00:11:50,000 --> 00:11:52,560
but they are still a little different

258
00:11:52,560 --> 00:11:54,639
we won't use this channel to increase

259
00:11:54,639 --> 00:11:57,600
the influence of bias value instead of

260
00:11:57,600 --> 00:11:59,839
using the same value of the decimal

261
00:11:59,839 --> 00:12:02,160
again

262
00:12:02,480 --> 00:12:04,800
this is a schematic diagram how we

263
00:12:04,800 --> 00:12:07,519
generating the rgb image

264
00:12:07,519 --> 00:12:09,680
the red channel and blue channel can

265
00:12:09,680 --> 00:12:12,639
directly come from binaural value

266
00:12:12,639 --> 00:12:15,200
the shadow entropy values are between 0

267
00:12:15,200 --> 00:12:16,320
to 1.

268
00:12:16,320 --> 00:12:19,040
so we multiply the channel entropy value

269
00:12:19,040 --> 00:12:22,800
by 60 to increase the influence of the

270
00:12:22,800 --> 00:12:23,680
channel

271
00:12:23,680 --> 00:12:25,839
the green channel is the local entropy

272
00:12:25,839 --> 00:12:27,440
value of the image

273
00:12:27,440 --> 00:12:29,519
we first convert the binary to graph

274
00:12:29,519 --> 00:12:32,240
skill image and generate a local entry

275
00:12:32,240 --> 00:12:33,200
image

276
00:12:33,200 --> 00:12:35,760
improve each bias value of the entropy

277
00:12:35,760 --> 00:12:38,480
image to a green channel

278
00:12:38,480 --> 00:12:41,600
and we also multiply the local entropy

279
00:12:41,600 --> 00:12:46,720
value by 50 to increase the influence

280
00:12:47,839 --> 00:12:50,480
local binary pattern is an efficient

281
00:12:50,480 --> 00:12:53,600
texture operator which levels the pixel

282
00:12:53,600 --> 00:12:56,320
of the image by first showing

283
00:12:56,320 --> 00:12:58,399
the neighborhood of each pixel and

284
00:12:58,399 --> 00:13:01,680
considers the result of binary number

285
00:13:01,680 --> 00:13:04,000
it can represent the texture of the

286
00:13:04,000 --> 00:13:05,040
image

287
00:13:05,040 --> 00:13:08,560
so we also use lbp as features in our

288
00:13:08,560 --> 00:13:10,079
framework

289
00:13:10,079 --> 00:13:12,720
this line is to talk about the theorem

290
00:13:12,720 --> 00:13:15,040
of the logo binary pattern

291
00:13:15,040 --> 00:13:17,920
i won't go into details here

292
00:13:17,920 --> 00:13:21,279
and we are using circular lpp

293
00:13:21,279 --> 00:13:23,760
but we will rotate the picture during

294
00:13:23,760 --> 00:13:25,839
data augmentation

295
00:13:25,839 --> 00:13:28,720
as you can see in the picture the lbp

296
00:13:28,720 --> 00:13:30,560
value will change

297
00:13:30,560 --> 00:13:33,040
during the rotation

298
00:13:33,040 --> 00:13:34,959
we will explain how to solve this

299
00:13:34,959 --> 00:13:38,239
problem in the next slide

300
00:13:38,480 --> 00:13:41,120
to make sure the invariance

301
00:13:41,120 --> 00:13:43,680
there are another feature called lbp

302
00:13:43,680 --> 00:13:46,000
rotational in variance

303
00:13:46,000 --> 00:13:49,600
if we got the value biosecure lpp

304
00:13:49,600 --> 00:13:52,560
and it will try to owe possibilities in

305
00:13:52,560 --> 00:13:54,079
any angles

306
00:13:54,079 --> 00:13:56,480
and choose the smallest one value as a

307
00:13:56,480 --> 00:14:00,240
local binary pattern value

308
00:14:01,279 --> 00:14:04,240
we use data augmentation technique to

309
00:14:04,240 --> 00:14:06,959
generate more data for training

310
00:14:06,959 --> 00:14:10,720
we flip the image or render rotate

311
00:14:10,720 --> 00:14:13,440
and render and scale the image

312
00:14:13,440 --> 00:14:16,240
the data about maybe four times to the

313
00:14:16,240 --> 00:14:17,760
original data

314
00:14:17,760 --> 00:14:21,120
after augmentation

315
00:14:21,680 --> 00:14:23,600
here is the first part of the man to

316
00:14:23,600 --> 00:14:26,240
image framework first we convert the

317
00:14:26,240 --> 00:14:29,120
malware map binary to rgb image and

318
00:14:29,120 --> 00:14:32,639
resize our image to fix size

319
00:14:32,639 --> 00:14:36,240
and why the size is chosen to 224

320
00:14:36,240 --> 00:14:38,639
or because this this size is the input

321
00:14:38,639 --> 00:14:41,279
size of the bgg60

322
00:14:41,279 --> 00:14:43,040
in the beginning it draws from

323
00:14:43,040 --> 00:14:44,639
convenient

324
00:14:44,639 --> 00:14:47,199
and after the experiment

325
00:14:47,199 --> 00:14:51,120
the size also perform the best result

326
00:14:51,120 --> 00:14:54,399
the next step is feature extraction we

327
00:14:54,399 --> 00:14:58,480
use v2g16 inception v3 and one to change

328
00:14:58,480 --> 00:15:00,160
cn network

329
00:15:00,160 --> 00:15:03,760
and the off size is shown in the block

330
00:15:03,760 --> 00:15:06,720
additionally i also add the local binary

331
00:15:06,720 --> 00:15:08,880
pattern as a feature

332
00:15:08,880 --> 00:15:12,320
the weight in bgg16 and inception v3 we

333
00:15:12,320 --> 00:15:14,560
use is imagenet

334
00:15:14,560 --> 00:15:16,800
and the weight of the cn is trained on

335
00:15:16,800 --> 00:15:19,360
30k smaller family

336
00:15:19,360 --> 00:15:21,440
after feature extraction

337
00:15:21,440 --> 00:15:23,519
the feature fusion step

338
00:15:23,519 --> 00:15:27,839
combine the four features to one array

339
00:15:28,639 --> 00:15:31,040
because the dimension after feature

340
00:15:31,040 --> 00:15:33,920
fusion is very high as you can see

341
00:15:33,920 --> 00:15:35,040
is

342
00:15:35,040 --> 00:15:37,519
94 000

343
00:15:37,519 --> 00:15:41,360
so we use pca to reduce the dimension

344
00:15:41,360 --> 00:15:44,399
after keeping 95 feature which is

345
00:15:44,399 --> 00:15:46,320
important to the model

346
00:15:46,320 --> 00:15:49,519
the dimension is reduced to 1000

347
00:15:49,519 --> 00:15:50,800
and last

348
00:15:50,800 --> 00:15:53,519
we use logistic regression to channel

349
00:15:53,519 --> 00:15:57,279
model and math prediction

350
00:15:57,360 --> 00:15:59,120
here is the architecture of the

351
00:15:59,120 --> 00:16:01,040
pre-transdn

352
00:16:01,040 --> 00:16:03,120
there are nine convolution layers and

353
00:16:03,120 --> 00:16:05,199
two max pro layers

354
00:16:05,199 --> 00:16:07,440
we also use some drop-out there's

355
00:16:07,440 --> 00:16:11,199
english cnn network

356
00:16:11,680 --> 00:16:14,320
we split out the data to training and

357
00:16:14,320 --> 00:16:18,880
testing the proportion is five to one

358
00:16:18,880 --> 00:16:21,519
the task is a 13 world class

359
00:16:21,519 --> 00:16:23,519
classification

360
00:16:23,519 --> 00:16:26,040
there are 12

361
00:16:26,040 --> 00:16:29,519
569 memory blocks

362
00:16:29,519 --> 00:16:30,560
and

363
00:16:30,560 --> 00:16:32,240
the uh the

364
00:16:32,240 --> 00:16:34,399
amount is our after the data

365
00:16:34,399 --> 00:16:36,800
argumentation

366
00:16:36,800 --> 00:16:39,440
and the activation function in the cnn

367
00:16:39,440 --> 00:16:40,880
is relu

368
00:16:40,880 --> 00:16:43,680
and we also use page normalization and

369
00:16:43,680 --> 00:16:46,160
learning radical

370
00:16:46,160 --> 00:16:48,399
in the cn network

371
00:16:48,399 --> 00:16:53,279
and the training epochs we set is 32

372
00:16:53,519 --> 00:16:56,560
this table is the experiment result of

373
00:16:56,560 --> 00:16:58,160
different features

374
00:16:58,160 --> 00:17:00,480
the first one mem to image use all the

375
00:17:00,480 --> 00:17:02,560
feature is straightforward 3 convolution

376
00:17:02,560 --> 00:17:04,799
network and the lbp

377
00:17:04,799 --> 00:17:08,240
it has the best result

378
00:17:09,280 --> 00:17:12,400
if we only use cn to extract features

379
00:17:12,400 --> 00:17:16,160
the accuracy is about 96 percent

380
00:17:16,160 --> 00:17:19,439
if we only use vgg 16 with the image net

381
00:17:19,439 --> 00:17:20,400
weight

382
00:17:20,400 --> 00:17:24,160
the result is surprising high of the cn

383
00:17:24,160 --> 00:17:27,520
and so of the inception v3

384
00:17:27,520 --> 00:17:30,720
and if we only use lbp features to

385
00:17:30,720 --> 00:17:36,080
channel the accuracy we are down to s4

386
00:17:36,960 --> 00:17:39,280
here are the experience results for

387
00:17:39,280 --> 00:17:42,240
different forms of the image

388
00:17:42,240 --> 00:17:44,799
if we use all the three channels the

389
00:17:44,799 --> 00:17:46,880
accuracy is the best

390
00:17:46,880 --> 00:17:48,559
and if we just use

391
00:17:48,559 --> 00:17:50,720
red channel and blue channel with the

392
00:17:50,720 --> 00:17:52,559
local android feature

393
00:17:52,559 --> 00:17:56,000
the accuracy will down to 92 percent

394
00:17:56,000 --> 00:17:58,960
if we only use decimal value as a grad

395
00:17:58,960 --> 00:18:04,799
scale image the accuracy is down to 88

396
00:18:04,799 --> 00:18:07,600
so we can conclude that local entropy

397
00:18:07,600 --> 00:18:10,080
can effectively help improve the

398
00:18:10,080 --> 00:18:12,720
accuracy

399
00:18:13,120 --> 00:18:15,600
here are the experiment results for

400
00:18:15,600 --> 00:18:17,840
different algorithm

401
00:18:17,840 --> 00:18:20,480
the result of logistic regression and

402
00:18:20,480 --> 00:18:23,039
sbn are both great

403
00:18:23,039 --> 00:18:25,440
and we choose logistic regression in our

404
00:18:25,440 --> 00:18:28,080
framework because the computing cost is

405
00:18:28,080 --> 00:18:29,520
less

406
00:18:29,520 --> 00:18:32,320
the performance of xg boost and random

407
00:18:32,320 --> 00:18:34,799
flow rates are not as good as the other

408
00:18:34,799 --> 00:18:37,840
two algorithms

409
00:18:38,960 --> 00:18:40,960
from the confusion matrix

410
00:18:40,960 --> 00:18:43,200
we can see that most of the categories

411
00:18:43,200 --> 00:18:45,919
can be classified very well

412
00:18:45,919 --> 00:18:48,160
only four types of malware that have

413
00:18:48,160 --> 00:18:49,760
misjudgement

414
00:18:49,760 --> 00:18:50,880
among them

415
00:18:50,880 --> 00:18:53,039
there are one categories that have

416
00:18:53,039 --> 00:18:56,400
significant errors as you can see in the

417
00:18:56,400 --> 00:18:59,600
picture on the right side

418
00:18:59,600 --> 00:19:02,400
the two categories are poison ivy

419
00:19:02,400 --> 00:19:04,640
and the present iv variant

420
00:19:04,640 --> 00:19:07,200
phantom iv

421
00:19:07,200 --> 00:19:10,080
our model may recognize the common area

422
00:19:10,080 --> 00:19:11,120
of the

423
00:19:11,120 --> 00:19:14,000
vengeance iv and prison ivy

424
00:19:14,000 --> 00:19:17,840
so for some malware variants our model

425
00:19:17,840 --> 00:19:20,559
may not be able to classify them very

426
00:19:20,559 --> 00:19:22,799
well

427
00:19:23,760 --> 00:19:27,120
this is the tsne for invading after pca

428
00:19:27,120 --> 00:19:29,520
of 30 malware family

429
00:19:29,520 --> 00:19:31,679
there are two interesting area

430
00:19:31,679 --> 00:19:34,000
the first one is on the right

431
00:19:34,000 --> 00:19:36,000
we can see that the malware immediately

432
00:19:36,000 --> 00:19:38,640
used by print evp group

433
00:19:38,640 --> 00:19:41,360
are very close like capture keyboards

434
00:19:41,360 --> 00:19:44,080
and whatever it means that the model

435
00:19:44,080 --> 00:19:46,080
used by then have many similar

436
00:19:46,080 --> 00:19:47,600
characteristics

437
00:19:47,600 --> 00:19:49,840
maybe we can use this phenomenon to

438
00:19:49,840 --> 00:19:53,280
attribute malware to every group

439
00:19:53,280 --> 00:19:56,080
the second one is in the left we can see

440
00:19:56,080 --> 00:19:58,320
the copyright beacon the carboxylic

441
00:19:58,320 --> 00:20:00,160
stage loaded and the copper strike

442
00:20:00,160 --> 00:20:03,600
become varied are also very close

443
00:20:03,600 --> 00:20:06,000
so it means that our embedding can make

444
00:20:06,000 --> 00:20:09,039
the marlin variant close to the original

445
00:20:09,039 --> 00:20:10,799
power family

446
00:20:10,799 --> 00:20:13,919
this feature is helpful to recognize new

447
00:20:13,919 --> 00:20:15,679
malware favorites

448
00:20:15,679 --> 00:20:18,000
and inspire our zeroshot learning we

449
00:20:18,000 --> 00:20:20,880
will talk better

450
00:20:20,880 --> 00:20:23,600
a senior c map is an image that shows

451
00:20:23,600 --> 00:20:26,080
each pixel's unique quality

452
00:20:26,080 --> 00:20:28,400
we use it to indicate

453
00:20:28,400 --> 00:20:30,559
which pixels are more meaningful or

454
00:20:30,559 --> 00:20:32,640
important for each model to predict

455
00:20:32,640 --> 00:20:33,760
result

456
00:20:33,760 --> 00:20:37,440
so more light area is more important

457
00:20:37,440 --> 00:20:39,440
in this slide we can see that our

458
00:20:39,440 --> 00:20:42,799
pre-chances may obviously focus on

459
00:20:42,799 --> 00:20:46,559
certain area and the area which bgg16

460
00:20:46,559 --> 00:20:52,158
and inception b3 focus on more divergent

461
00:20:52,480 --> 00:20:54,480
poison ivy and products also have

462
00:20:54,480 --> 00:20:56,559
similar similar characteristics in

463
00:20:56,559 --> 00:20:58,159
sensing map

464
00:20:58,159 --> 00:21:00,640
from these four categories we can see

465
00:21:00,640 --> 00:21:03,360
that bgg16 will pay more attention to

466
00:21:03,360 --> 00:21:06,400
some places on the edge of the picture

467
00:21:06,400 --> 00:21:09,039
and inception b3 will pay more attention

468
00:21:09,039 --> 00:21:13,039
to central area of the picture

469
00:21:13,760 --> 00:21:16,559
if you look a little more closely

470
00:21:16,559 --> 00:21:17,520
on the

471
00:21:17,520 --> 00:21:19,840
sentencing map you can find some

472
00:21:19,840 --> 00:21:23,039
interesting phenomena for example the

473
00:21:23,039 --> 00:21:25,360
focus area of the water bear

474
00:21:25,360 --> 00:21:28,080
is the conflict block of the water-based

475
00:21:28,080 --> 00:21:30,480
stage

476
00:21:30,480 --> 00:21:33,679
and for a captured node the focus area

477
00:21:33,679 --> 00:21:37,919
is in its auditor section

478
00:21:38,720 --> 00:21:41,600
and for phantom iv the focus area is

479
00:21:41,600 --> 00:21:43,440
some shell called snips

480
00:21:43,440 --> 00:21:46,000
are in his

481
00:21:46,000 --> 00:21:47,280
block

482
00:21:47,280 --> 00:21:50,960
we also use this shellcloth section in

483
00:21:50,960 --> 00:21:55,520
gyararoo to detect phantom iv

484
00:21:55,679 --> 00:21:57,120
for progress

485
00:21:57,120 --> 00:21:59,360
the focus area is the section which the

486
00:21:59,360 --> 00:22:02,719
stake stream located

487
00:22:03,120 --> 00:22:05,840
grade cam has some similarity

488
00:22:05,840 --> 00:22:07,679
with selecting map

489
00:22:07,679 --> 00:22:10,240
we also use this method to realize how

490
00:22:10,240 --> 00:22:12,400
our convolutional network them from the

491
00:22:12,400 --> 00:22:13,840
malware image

492
00:22:13,840 --> 00:22:16,400
more red area indicates that area was

493
00:22:16,400 --> 00:22:18,799
more important to that class

494
00:22:18,799 --> 00:22:22,080
in dratix on the top right area is a c2

495
00:22:22,080 --> 00:22:24,960
parsing function and api span bypass

496
00:22:24,960 --> 00:22:27,520
function and the second red area is

497
00:22:27,520 --> 00:22:29,919
composed of some code function before

498
00:22:29,919 --> 00:22:31,679
our data section

499
00:22:31,679 --> 00:22:33,520
in copper stripe beacon

500
00:22:33,520 --> 00:22:35,520
area is part of our data section and

501
00:22:35,520 --> 00:22:38,640
part of data section

502
00:22:38,640 --> 00:22:41,440
in d-pass loader the red area of some

503
00:22:41,440 --> 00:22:45,440
unique strings block shows on the right

504
00:22:45,440 --> 00:22:48,320
in phone book a red arrow is sung on

505
00:22:48,320 --> 00:22:49,679
first casey

506
00:22:49,679 --> 00:22:53,080
stack strings

507
00:22:54,000 --> 00:22:56,799
and when we want to detect unknown uh

508
00:22:56,799 --> 00:22:58,720
unknown malware they didn't in the

509
00:22:58,720 --> 00:23:01,280
trending class we can use neuroshock

510
00:23:01,280 --> 00:23:02,240
learning

511
00:23:02,240 --> 00:23:05,120
which also use mental image to extract

512
00:23:05,120 --> 00:23:09,120
embedding and then use kd3 to find 5 to

513
00:23:09,120 --> 00:23:10,880
10 nearest neighbors

514
00:23:10,880 --> 00:23:13,120
in our dataset

515
00:23:13,120 --> 00:23:15,440
for example if the nearest neighbors are

516
00:23:15,440 --> 00:23:18,559
tears cookie and cubers we can expect to

517
00:23:18,559 --> 00:23:20,880
learn that non-malware may be modified

518
00:23:20,880 --> 00:23:24,080
frontiers cookie and maybe have high

519
00:23:24,080 --> 00:23:27,520
connection to the princeton group

520
00:23:27,520 --> 00:23:30,240
when we improve the sample maori into

521
00:23:30,240 --> 00:23:33,039
men to image next time the nearest

522
00:23:33,039 --> 00:23:35,840
neighborhood maybe the maui input last

523
00:23:35,840 --> 00:23:36,720
time

524
00:23:36,720 --> 00:23:39,600
and they can be new class when they have

525
00:23:39,600 --> 00:23:42,080
reached a certain amount

526
00:23:42,080 --> 00:23:46,639
it didn't need to return a new model

527
00:23:46,720 --> 00:23:49,679
that's fantastic

528
00:23:49,679 --> 00:23:51,520
here are some they will show the new

529
00:23:51,520 --> 00:23:53,919
results we test on everything malware

530
00:23:53,919 --> 00:23:56,799
didn't use in chaining dataset

531
00:23:56,799 --> 00:23:59,200
jingle spy is a new malware used by

532
00:23:59,200 --> 00:24:00,720
abd37

533
00:24:00,720 --> 00:24:02,159
and we can see that the nearest

534
00:24:02,159 --> 00:24:04,320
neighbors are rock great which also used

535
00:24:04,320 --> 00:24:06,559
by ap37

536
00:24:06,559 --> 00:24:08,799
and product as fast version and other

537
00:24:08,799 --> 00:24:11,360
progress variant also shows good results

538
00:24:11,360 --> 00:24:13,840
on your shot learning

539
00:24:13,840 --> 00:24:15,760
another interesting thing is that there

540
00:24:15,760 --> 00:24:18,320
are new malware called friend catcher

541
00:24:18,320 --> 00:24:19,919
named by us

542
00:24:19,919 --> 00:24:22,080
we can't really attribute the malware to

543
00:24:22,080 --> 00:24:23,600
an empty group

544
00:24:23,600 --> 00:24:26,240
but through the zeroshot learning is

545
00:24:26,240 --> 00:24:28,559
embedding is very close to the starting

546
00:24:28,559 --> 00:24:29,919
out rate

547
00:24:29,919 --> 00:24:33,279
so we can speculate that friend catcher

548
00:24:33,279 --> 00:24:35,520
may be relating to the actual behind

549
00:24:35,520 --> 00:24:37,120
renault rate

550
00:24:37,120 --> 00:24:40,639
which was title

551
00:24:41,679 --> 00:24:44,559
machine learning model is embedded in

552
00:24:44,559 --> 00:24:48,320
but inevitably to adversarial attack

553
00:24:48,320 --> 00:24:50,720
so we also think some possible attack

554
00:24:50,720 --> 00:24:53,039
methods to this framework

555
00:24:53,039 --> 00:24:56,240
first actor may pay the most random

556
00:24:56,240 --> 00:24:58,960
drunk bites to make the file size very

557
00:24:58,960 --> 00:24:59,840
large

558
00:24:59,840 --> 00:25:02,559
this way may affect the resolution of

559
00:25:02,559 --> 00:25:05,200
the image and then our framework may can

560
00:25:05,200 --> 00:25:08,320
recognize the real malicious part

561
00:25:08,320 --> 00:25:10,480
the second way is that in liberation we

562
00:25:10,480 --> 00:25:12,880
put the code of other model family into

563
00:25:12,880 --> 00:25:14,880
the original malware

564
00:25:14,880 --> 00:25:17,919
for opposition

565
00:25:17,919 --> 00:25:19,679
and then our framework may have

566
00:25:19,679 --> 00:25:22,480
misjudgement

567
00:25:22,559 --> 00:25:25,760
we have also seen some actual peg file

568
00:25:25,760 --> 00:25:29,279
in mary using upx and medium protect

569
00:25:29,279 --> 00:25:32,799
the last method is self modifying code

570
00:25:32,799 --> 00:25:35,279
it can alter its own instruction where

571
00:25:35,279 --> 00:25:36,880
it is executed

572
00:25:36,880 --> 00:25:39,440
we have simply used this technique in

573
00:25:39,440 --> 00:25:42,720
their malware

574
00:25:42,720 --> 00:25:45,360
usually you sell modeling code

575
00:25:45,360 --> 00:25:47,360
the show code will decrease the code

576
00:25:47,360 --> 00:25:49,919
that is needed and increase the code

577
00:25:49,919 --> 00:25:52,559
that is not needed while executing

578
00:25:52,559 --> 00:25:56,559
and repeat this action continuously

579
00:25:56,559 --> 00:25:59,520
such mechanism may be able to bypass our

580
00:25:59,520 --> 00:26:00,960
framework

581
00:26:00,960 --> 00:26:03,440
for example you can see that only the

582
00:26:03,440 --> 00:26:05,360
function waiting for the cognition will

583
00:26:05,360 --> 00:26:07,440
be decrypted

584
00:26:07,440 --> 00:26:09,360
during executing

585
00:26:09,360 --> 00:26:12,640
and the others are encrypted after

586
00:26:12,640 --> 00:26:16,000
self motivating code

587
00:26:17,200 --> 00:26:20,720
and here's is our conclusion

588
00:26:20,720 --> 00:26:23,520
more and more advanced methods of

589
00:26:23,520 --> 00:26:26,240
process injection have been used in

590
00:26:26,240 --> 00:26:30,320
every group and cyber crime malware

591
00:26:30,320 --> 00:26:32,720
transfer learning have great performance

592
00:26:32,720 --> 00:26:34,320
on memory resident malware

593
00:26:34,320 --> 00:26:35,840
classification

594
00:26:35,840 --> 00:26:39,520
especially on small set of data

595
00:26:39,520 --> 00:26:41,919
the features extracted by a convolution

596
00:26:41,919 --> 00:26:44,159
network can find out the spatial area of

597
00:26:44,159 --> 00:26:47,120
malware which unexpectedly overlapped

598
00:26:47,120 --> 00:26:49,760
with some error rules we wrote to the

599
00:26:49,760 --> 00:26:52,080
malware family

600
00:26:52,080 --> 00:26:54,559
with zero shot learning we don't need to

601
00:26:54,559 --> 00:26:58,080
retrain the model frequently

602
00:26:58,080 --> 00:27:01,440
we also propose some attackable methods

603
00:27:01,440 --> 00:27:05,039
for adventure attack

604
00:27:05,200 --> 00:27:07,440
and the map to image

605
00:27:07,440 --> 00:27:09,919
framework

606
00:27:10,000 --> 00:27:10,799
will

607
00:27:10,799 --> 00:27:12,480
put on the github

608
00:27:12,480 --> 00:27:14,640
so if you are interesting to this

609
00:27:14,640 --> 00:27:19,400
framework you can go to github

610
00:27:20,080 --> 00:27:23,919
and here's is our our talk to the big

611
00:27:23,919 --> 00:27:25,279
asia

612
00:27:25,279 --> 00:27:27,360
2021

613
00:27:27,360 --> 00:27:30,000
thank you everyone

614
00:27:30,000 --> 00:27:32,880
if you have any questions guys welcome

615
00:27:32,880 --> 00:27:36,120
to containers

